{
    "10.1016/j.enpol.2012.09.045": {
        "file_name": "1 Smart grids and the transformation of the electricity sector",
        "title": "Smart grids and the transformation of the electricity sector: ICT firms as potential catalysts for sectoral change",
        "abstract": "The sustainability challenges associated with increasing demand and generation of electricity require a far-reaching transformation of the energy system. Smart grid technologies are expected to play a major role in such sectoral transformation. While a growing body of literature is concerned with the dynamics and particularities of sectoral transformation, most contributions have focused on exogenous shocks or new technological developments as drivers of change. This paper complements the existing perspectives by exploring the role of actors as catalysts for transformation. Within the field of smart grid, we study the transformative influence of ICT firms on the energy sector in Europe. More specifically, we analyze actor participation in 450 European smart grid projects between 2000 and 2011 as well as acquisitions in the field. We find that incumbent firms from the ICT sector have gained influence and drive transformation through the creation of variety, in terms of technology, business models and value chains. As a strategic reaction, electricity sector incumbents have recently acquired many start-ups specialized in ICT technology and thus expanded their competence base. We conclude that entrants from another sector can be important catalysts for sectoral transformation and should be analyzed more systematically in transition studies.",
        "label": "Qualitative",
        "text": {
            "Introduction": " In the 21st century, society faces fundamental sustainability challenges such as depletion of natural resources, water scarcity and air pollution. Solutions to these challenges require sustainability transitions (Markard et al., 2012), i.e. far-reaching transitions in established sectors such as the energy, the transportation or the water sector (Unruh, 2000;Geels, 2011;Markard, 2011). Transforming the energy sector, for example, requires not only a radical change in power generation from fossil and nuclear to renewable energy sources (Foxon et al., 2005;Stephens and Jiusto, 2010;Geels, 2011), but also the development of a smarter grid infrastructure to cope with intermittent and potentially decentralized power sources (Farhangi, 2010;Faruqui et al., 2010;Fox-Penner, 2010). Understanding what drives and hampers such sectoral transformation is therefore of high interest for academic research as well as for policy makers who might want to guide or accelerate the underlying processes. In academics, studies on the transformation of socio-technical systems have been drawing on concepts such as the multi-level perspective, large technical systems or sectoral systems of innovation. These concepts have described different catalysts for sectoral transformation such as landscape pressures (Geels, 2002(Geels, , 2004;;Geels and Schot, 2007), radical innovation developed in niches (Geels and Raven, 2006) or the transformative capacity of technology (Dolata, 2009). All of the aforementioned frameworks have a systemic view on sectors in common. They conceptualize sectors as socio-technical systems (Jacobsson and Johnson, 2000;Malerba, 2002;Geels, 2007;Geels and Kemp, 2007), including actors such as firms, research institutes, users or policy makers, institutional structures and specific technologies. This systemic view takes into account path dependencies and lock-ins (e.g. David, 1985;Unruh, 2000;Dolata, 2008) and thereby explains the rigidities of existing sectors (Markard, 2011). Developed as a response to previous technology or actor focused perspectives, 1 socio-technical systems emphasize the interrelated nature and non-linearities of innovation processes (Geels, 2004;Markard and Truffer, 2008a;Van Den Bergh et al., 2011). While these frameworks have provided major insights into sectoral change and socio-technical transitions, their focus on systemic effects (meso level) has sometimes come at the expense of a careful analysis of actors, their strategies and resources (micro level) (Farla et al., 2012). We argue that exploring the linkages between micro and meso level can provide additional explanatory power to system concepts (Markard and Truffer, 2008b;Musiolik and Markard, 2011). Understanding the interests, strategies and actions of actors, their interplay and their influence on the wider socio-technical system would allow policy makers to effectively address actors, 2 e.g. through incentive schemes, in an overall attempt to guide sustainability transitions (Markard et al., 2012). Against this background our paper explores the role of different actor types in sectoral transformation. More specifically we intend to analyze the influence of actors from outside the focal sector and their interaction with incumbent actors. We aim to understand whether and how entrants from outside the focal sector can drive or even accelerate sectoral transformation. The focus on entrants from other sectors is novel. In transition studies typically two types of actors are distinguished, incumbent firms of the focal sector and start-ups (Geels and Schot, 2007;Geels, 2010;Hockerts and W \u00fcstenhagen, 2010). While scholars have acknowledged the relevance of developments outside the focal sector (Raven and Verbong, 2007;Konrad et al., 2008;Dolata, 2009), studies have not analyzed the role of incumbents in other sectors entering the focal sector. Such a focus is particularly important if technologies from 'outside' become relevant for the focal sector (Dolata, 2009). In this case formerly unrelated sectors shift closer and become adjacent sectors. Actors from these sectors may then decide to enter the focal sector to exploit their existing technological resources (Nicholls-Nixon and Jasinski, 1995). In the analysis below we distinguish three types actors: incumbents of the focal sector, start-up firms and entrants from another sector. The latter will be referred to as adjacents as a short form for this actor group. 3  Our research and contributions are explorative in nature. The multi-level perspective (Geels, 2002(Geels, , 2004) ) and the concept of sectoral systems of innovation (Malerba, 2002;Dolata, 2009) form the theoretical background of our research. Empirically, we focus on the electricity sector and the innovation activities in the field of smart grid. Studying this empirical field is suitable for two reasons. Firstly, the transformation towards a smarter grid infrastructure in the electricity sector is currently ongoing and might be even part of a more fundamental socio-technical transition with far-reaching changes in several dimensions: political, economic, institutional, organizational, material and technological (Kemp, 1994;Geels, 2010). Secondly, it allows studying the effect of entrants from outside as we observe firms from the information and communication technology (ICT) sector entering this field. With our study we do not just contribute to research on sectoral change in general, but also enrich the understanding of what is going on in the field of smart grids. So far research on the smart grid has focused on technological challenges (e.g. Brown, 2008;Pipattanasomporn et al., 2009) and cost-benefit considerations (Faruqui et al., 2010;Hogan, 2010;Giordano and Fulli, 2012). Little or no focus has been on the transformation of the wider electricity sector. A notable exception is the study of Ngar-yin Mah et al. (2012) on the transition towards a smart grid in Korea, which highlights the important role of the state and a lack of consumer engagement (Ngar-yin Mah et al., 2012). As the basis for our study, we have compiled a database with 450 smart grid projects in Europe, which started in between 2000 and June 2011. This set of data should be almost complete. Our data enables us to differentiate between incumbents, start-ups and adjacents that participate in these projects. This allows us to gain insights into the relative importance of ICT firms. Furthermore, we present data on mergers and acquisitions in the field to obtain an initial understanding of the aspired role of different actors and strategic reactions of firms. We are able to identify early indications that ICT firms create variety by providing alternative solutions and that they successfully withstand selection pressure of the regime. The paper is structured as follows: The following theory section discusses previous contributions of literature to sectoral transformation and develops our argument regarding the particular role of actors herein. Section 3 introduces the field of smart grid. Section 4 describes the methodology. Section 5 presents the empirical findings and our interpretation of the results. The final Section 6 concludes with a discussion of the results, theoretical contributions, implications for policy makers and an outlook for future research.",
            "Theoretical background": " Our research aims to contribute to a growing body of literature that analyzes transformation processes at the sectoral level, which might even lead to very far-reaching changes, so-called socio-technical transitions.4 Among others, the multi-level perspective (MLP) (Geels, 2002(Geels, , 2004) ) and the concept of (sectoral) systems of innovation (SSI) (Edquist, 1997;Malerba, 2002;Dolata, 2009) are well established frameworks in the literature that have made major contributions to understanding sectoral transformation. 5 These frameworks are therefore taken as conceptual starting points for our research. We are particularly interested in the main catalysts they identify for transformation. By catalysts we mean stylized factors that trigger transformation, e.g. through their capacity to create variety (Nelson and Winter, 1982) and break up rigidities in existing socio-technical systems.",
            "Major drivers for sectoral transformation": " Three main catalysts for sectoral transformation are described in the aforementioned frameworks: landscape pressures, niche developments and new technologies from outside the sector. 1 Industry lifecycle concepts are an example here (Utterback and Abernathy, 1975;Afuah and Utterback, 1997). 2 The work of Motohashi and Yuan (2010) is a good example for policy recommendations based on firm interactions (Motohashi and Yuan, 2010). 3 This term makes no implications about the former (technological) distance of the two sectors. It just refers to the emerging vicinity of the underlying knowledge fields. Landscape pressures as described in the MLP have the potential to destabilize the regime and its selection pressures (Geels and Schot, 2007). The landscape is conceptualized as the exogenous environment, which is beyond the direct influence of any actor in the regime or niche (Geels and Schot, 2007). Landscapes typically develop slowly over long periods of time. Only if shocks occur, the landscape changes abruptly and radically. Both, a slow development of the landscape and a shock can put pressure on the regime. The regime is subsequently destabilized thus creating room for transformation. Examples of landscape pressures on the electricity sector include the oil crises in the 1970s, an increasing public awareness for environmental issues and climate change over the last decades or the nuclear accidents in Chernobyl and Fukushima (Markard and Truffer, 2006). Developments in socio-technical niches can create variety and break through to regime level (Geels, 2002). Niches are conceptualized as independent from the path dependencies (and selection pressures) of the regime. Niches are small networks of actors with a low degree of structuration (Geels and Schot, 2007). Over time, niche structures have the potential to align, stabilize and ultimately become strong enough to withstand or alter selection pressures and breakthrough to regime level. Such a break-through of a niche might be assisted by a previous destabilization of the regime through landscape pressures. Examples of transformative niche developments in the electricity sector include renewable energy technologies such as wind, solar or biomass. Moreover, technology developed elsewhere can drive the transformation of existing sectors (Dolata, 2009). According to Dolata (2009) transformative capacity of a technology is the specific pressure that this technology exerts in relation to a specific sector. A new technology can for example put pressure on the existing socio-economic and institutional structures in a sector. The mode of sectoral transformation is then determined by the interplay between pressure through technology and sectoral adaptability. Modes of transformation can be anticipative and pro-active when pressure is moderate and adaptability high, or reactive and crisis-ridden when pressure is high and adaptability low. An example of a semi-transformative exogenous technology in electricity supply is the adaptation and uptake of gas turbines developed in the aeronautics sector (Markard and Truffer, 2006). In the following we will argue that actors can also be catalysts for transformation. This has already been a prominent theme in the earlier literature on large technical systems assigning socalled system builders a key role in the creation and transformation of socio-technical systems (Hughes, 1987). We will argue more generally that actors differ in their potential to bring about sectoral change and that under certain conditions some actors may play a very crucial and transformative role.",
            "Role of different actor types in sectoral transformation": " So far, two types of actors are typically distinguished in the literature on socio-technical transitions, incumbents and new entrants (mostly start-ups) (Geels and Schot, 2007;Geels, 2010;Hockerts and W \u00fcstenhagen, 2010). Incumbents are established firms of the focal sector, also referred to as regime actors. They are highly intertwined with the core technologies, business models and user-practices of the regime. New entrants are actors that have entered the focal sector. Often they are recently founded and part of a niche (Geels and Schot, 2007). We will refer to recently founded firms as start-ups in the following. They are rather independent from the path dependencies and lock-ins of the regime (Geels and Schot, 2007). While start-ups may deviate radically from existing business practices, they often lack financial resources and political influence to bring about system change. In certain situations, however, a third group of actors can play a substantial role in sectoral transformation: incumbents from another sector (or adjacents). They enter the focal sector when they see the opportunity to exploit their existing technological competencies in the focal sector. Incumbents of the focal sector, start-ups and adjacents differ significantly in terms of their histories, organizational routines, cognitive frames, resource endowments and embeddings in broader institutional structures. Therefore we argue that these types of actors also differ in their capacity to drive sectoral transformation. Actors can be expected to have a high transformative capacity if they (i) create variety (e.g. in terms of technology, business models or cognitive frames) and (ii) are able to withstand the selection pressures of the regime (Nelson and Winter, 1982). As effective catalysts for transformation actors have to possess both of these characteristics. Actors are able to create variety if they are little intertwined with user practices, business models, value chains, organizational structures and regulations of the regime (Rip and Kemp, 1998;Geels, 2002;Geels and Schot, 2007). The niche concept builds on this argument as niches are seen as independent from pathdependencies of the regime (Geels and Raven, 2006). Both startups and adjacents can be expected to create variety in the focal sector. While start-ups create variety through new technologies and business models, adjacents bring existing technologies and business models from their sector of origin to the focal sector. Kaplan and Tripsas (2008) have studied the effect of entrants from adjacent sectors on industry lifecycles. They find that these entrants are an important source of variety thanks to their different cognitive frames. As a consequence these outsiders are more likely to introduce discontinuities (Kaplan and Tripsas, 2008). Actors are able to challenge the regime and withstand its selection pressures if they command the necessary resources to compete with sector incumbents and are firmly embedded in local institutional structures (Smith et al., 2005;Geels and Raven, 2006;Geels and Schot, 2007). Well-endowed, resourceful actors that are able to create new socio-technical systems or change the structures of existing ones have also been described in the literature as system builders (Hughes, 1987) or prime movers (Jacobsson and Johnson, 2000;Farla et al., 2012). The importance of embeddedness in networks and local institutional structures is at the core of the niche concept (Smith et al., 2005;Geels and Raven, 2006;Geels and Schot, 2007). and was also highlighted in recent contributions on innovation system building (Musiolik and Markard, 2011;Musiolik et al., 2012). Actors in well-structured niches and actors embedded in other regimes have a greater ability to challenge the focal regime. The work of Aminzade (1992) as well as H \u00e5kansson and Waluszewski (2002) further strengthens our argument. They argue that the intersection of trajectories of two regimes is a source of structural change, variety and consequently innovation through a new combination of existing resources (Aminzade, 1992;H \u00e5kansson and Waluszewski, 2002). Against this background, we can now provide a preliminary assessment of how incumbents, start-ups and adjacents compare in terms of transformative capacity (cf. Table 1). Incumbents can be expected to have a rather low transformative capacity. Their ability to create variety is restricted by established cognitive frames and the material path-dependencies of the regime. Moreover, their strength in terms of resources and embeddedness is rather deployed towards stabilizing existing regime structures. In contrast, start-ups are much more independent and therefore able to create variety. But their transformative capacity is typically limited by a lack of resources to withstand selection pressures. Finally, entrants from an adjacent sector seem to be both able to create variety and withstand selection pressures and may thus exert a relatively high degree of transformative capacity.",
            "Smart grid: a novel field at the intersection of the electricity and the ICT sector": " The smart grid is an emerging field, which in functional terms is part of the electricity sector but requires technological components and know-how that originate from the ICT sector. The field is still in an early stage of development with technological standards, business models and consumer services still in flux and many different firms trying to find their role and to establish their business (Giordano and Fulli, 2012). Below, we will briefly introduce both the electricity and the ICT sector and depict the essential characteristics of smart grid technology, its development (projects) and the actors involved.",
            "Developments and challenges in the electricity sector": " The electricity sector is an infrastructure sector (Markard, 2011), which encompasses technologies, material components (grid infrastructure, power plants, etc.), organizations (utility companies, technology suppliers, public authorities) and institutional structures (technical norms, regulations) that work together to provide electricity supply services. The structures of the electricity sector have developed over decades and one of its core parts, the electricity grid, has experienced only very little change over the last 100 years (Bauknecht, 2012). Technological change mostly occurred in electricity generation with nuclear power plants and later also gas turbines replacing coal fired power plants and, more recently, new renewable energy technologies such as wind, biogas and solar also becoming part of the sector (Markard and Truffer, 2006;Haas et al., 2011). A major change in the organizational and institutional structures of the sector was initiated in many countries with the liberalization of electricity generation and sales from the 1990s onward (Markard et al., 2004;Sioshansi, 2006). These changes, however, left the electricity grid largely unaffected. Both the transmission and the distribution grid remained regulated (natural monopolies). They also maintained their original topology, i.e. transmitting and distributing electricity from large, centralized power plants to millions of end users. As a consequence, businesses related to the grid infrastructure tend to be highly consolidated with very tight relations between equipment suppliers and customers (electric utility companies). Today, climate change and the depletion of fossil fuels as well as the risks of nuclear energy require a massive shift towards new renewable energy sources. Renewable energy sources, however, challenge the existing grid architecture, which is not able to cope with a large share of intermittent and possibly decentralized energy sources (OECD/IEA, 2011). Major changes in grid architecture and technology are therefore required (Farhangi, 2010). These new requirements also pose challenges for grid operators, utility companies, equipment suppliers and regulators. One of the challenges is that technologies and competences from the ICT sector will have to be integrated in the future grid infrastructure.",
            "Developments and challenges in the ICT sector": " The ICT sector is a highly dynamic and innovative sector, which provides products as well as services in the field of electronic information processing and communication (OECD, 2002). It encompasses many different kinds of technologies, organizations (service providers, manufacturers, regulatory agencies, etc.) and institutions (e.g. technical norms, compatibility standards, protocols). The ICT sector has emerged from the convergence of two initially distinct sectors, the communication and the information technology sector (Edquist, 2003;Hacklin et al., 2009). The communication sector has undergone dramatic changes as a consequence of market liberalization and technological progress (Corrocher, 2003). Liberalization started in the early 1980s in the USA with other countries following suit. Technological change included the breakthrough of mobile phone and internet technology in the 1990s. As a consequence value chains were re-organized, business models changed dramatically and many new actors entered the market (Li and Whalley, 2002;Peppard and Rylander, 2006;Hacklin et al., 2009;Fischer et al., 2012). These developments opened up large growth opportunities for firms like Nokia or Cisco as equipment providers or Vodafone as system operator. Today, however, the growth opportunities in the sector seem to be decreasing, as, for example, mobile phone sales and usage have already reached saturation in most developed countries (Newswire Today, 2009;MobiThinking, 2012). The IT sector also experienced major changes. It went through a hype in the late 1990s with the overwhelming success of internet technology. This hype was followed by a very pronounced disappointment and significant shake-out of internet firms in 2000 and 2001. Following this consolidation the sector returned to a growth path. Prominent players in the IT sector include IBM, Microsoft, Google, Amazon and Apple. Today, the ICT sector remains very dynamic. Apple is a good example here. It started as a computer manufacturer, later entering the music industry (Dolata, 2008) and also began competing in the mobile handset market. While smart phones, tablet computers and other new hardware devices still experience interesting growth rates, other ICT business fields such as the mobile and fixed carrier business face moderate growth and fierce competition. Their actors are particularly receptive to new business opportunities outside of the ICT sector (Nicholls-Nixon and Jasinski, 1995). The smart grid is perceived as such an opportunity (Hidaka, 2011).",
            "The smart grid": " The smart grid is an advanced electricity network infrastructure characterized by a two-way flow of information and in many It is important to note that the smart grid is not an end in itself. It serves as an enabler to integrate new forms of energy generation or consumption into the grid and enables new services and business models (OECD/IEA, 2011; Giordano and Fulli, 2012). Also note that this definition excludes energy production, storage and consumption itself as well as extensions or renovations of the traditional electricity grid. 7Typical smart grid architectures consist of three layers: a hardware layer, a communication layer and a software or application layer. The hardware layer consists of the traditional transmission and distribution hardware plus 'intelligent' sensors that collect information about the status and operations of the hardware. The communication layer allows gathering data from distributed end devices (e.g. metering data) and sending signals to the end device (twoway communication). The third layer is the software or application layer that allows for aggregation and analysis of the collected data. A meter data management system (MDM) is one example for a software solution. Finally, all three layers need to be integrated into an end-to-end solution to allow for the system to work seamlessly. Neither the communication nor the software layer were needed in the past. Therefore they were not part of the portfolio of incumbent equipment suppliers in the electricity sector. In mobile phone networks, however, a similar layer model is used which is why firms from the mobile phone industry already have experiences and competences they can apply to smart grid technology (Fig. 1). With the help of this architectural model, typical roles of actors in smart grid projects can be distinguished. These include hardware supplier, communication supplier, software supplier and system integrator. We will come back to these roles in Section 5.2.",
            "Smart grid projects and actors in Europe": " A smart grid project can be defined as a finite undertaking ;of more than one actor8 with the goal to deploy, demonstrate, test or develop smart grid technologies or architectures as defined above. We distinguish between deployment and pilot projects. Deployment projects are commercial projects, while pilot projects are R&D or demonstration projects. Typical deployment projects are smart meter rollouts with electric utilities as customers asking meter suppliers and service providers to install a smart meter infrastructure in 'their' part of the distribution grid. (Giordano et al., 2011). Pilot projects, in contrast, are often financed by public funds.They aim at increasing the stock of knowledge by undertaking creative work on a systematic basis (OECD, 2002;Giordano et al., 2011). Smart grid projects in Europe experienced significant growth over the last decade. Between 2000 and 2008 the number of smart grid projects increased to over 80 new projects per year (Fig. 2). More precisely, the development of the field can be split in three phases: a first phase with one or two sporadic projects per year between 2000 and 2003, a second phase with a growing number of pilot and deployment projects between 2004 and 2007, and a third phase with a massive increase in projects starting after 2007. This sharp increase can be explained by the stimulus packages launched by governments after the financial crisis in 2008 (Ginsberg et al., 2010). Today, the majority of projects are still pilot projects. This is a clear indicator for the early development and the complexity of the task.",
            "Traditional grid Smart grid": " In most countries the rolloutt of smart meters is considered the first step and basis for subsequent steps of ''smartening'' the grid. Therefore more than half of all smart grid projects are smart meter projects (see Section 4 for a definition). 9 While meter projects have reached deployment stage, almost all other smart grid projects are still in pilot phase (see also Table 2). Other smart grid projects are often larger and more complex. A good example for a very large smart grid pilot is the EcoGrid EU project on Bornholm island in Denmark. The project aims to show case, how more than 50% renewable energy generation can be integrated in the transmission and distribution network by means of more flexible consumption of households. Other smart grid pilots focus for example on the integration of electrical vehicles, on demand response mechanisms or on distribution automation (see Giordano et al., 2011 for a more detailed description and more examples). As of 2011, over 800 actors were involved in smart grid projects in Europe (Table 3). In total, 250 are firms that supply smart grid technology (83 incumbents, 71 adjacents and 84 startups) and approximately 280 are utilities. Another 290 organizations include mostly research institutes and universities but also regulatory authorities and associations. Two types of incumbent firms can be distinguished. The first type includes suppliers of transmission and distribution (T&D) infrastructure (e.g. transformer stations) for the high, medium and low voltage grid. Examples are ABB, Siemens or GE. The second type are metering equipment suppliers such as Landis \u00feGyr, Elster or Itron. These two types of incumbents hardly overlap in their offering. Among ICT firms three types can be distinguished. These include software companies such as SAP or Oracle that provide standard software, telecommunication providers such as Deutsche Telekom or Vodafone and IT system integrators such as IBM or Atos, which integrate standard software and hardware into complex IT solutions. Fig. 3 maps the traditional competencies of each type of actors to the smart grid architecture.",
            "Methodology": " Our research approach is explorative in nature as we deal with a new empirical field with little transparency (Giordano et al., 2011). It is based on two comprehensive sets of data, a database with 449 smart grid projects and a list of 64 smart grid related acquisitions performed by incumbents and adjacents. In the following we will first explain or research design. Secondly we will describe our data sources.",
            "Research approach and scope": " Our research design follows a three step approach. As the first step we aim to explore the role of ICT firms in terms of presence and influence in the field of smart grid: are many ICT firms present in the field? How is their presence developing over time? Were they successful, e.g. in selling their solutions? And how does their presence compare to incumbents and start-ups? As the second step we aim to understand the role of ICT firms in terms of their (technological) contribution to the field and their complementary or competing relation to incumbents. That means we aim to understand: Which technologies do ICT firms contribute to the field? How do these technologies differ from the technological solutions proposed by incumbents? Which role do ICT firms play in projects and do they have a complementary or competitive relationship to incumbents? Finally we intend to create an initial understanding of the strategy and aspired role of ICT firms and incumbents in the field. That means we aim to understand: Which (project) roles do firms strategically intend to fill? Can we observe reactions to strategic moves of one actor group? The presence and relative influence of ICT firms in the field can be explored through an analysis of actor participation in smart grid projects. A high absolute number of ICT firms in the field and a growing share of projects with ICT firm participation are indicators for a growing presence and influence of ICT firms. The influence of adjacents can be further understood through an analysis of deployment projects. The participation in deployment projects is an indicator for the success and growing influence of actors in the field. Securing a deployment project indicates that a firm has been selected by customers as supplier of smart grid technology. Participation in deployment projects is therefore a sign that ICT firms have successfully withstood selection pressures of the regime. Another indicator for the influence of ICT firms on the field is the sequence of firm entries into the field by actor type. An early entry and even more an early success in deployment projects is an indicator for an early influence on the field. 10 We therefore determined in which year a firm participated for the first time in a (deployments) project and compared the results for ICT firms, incumbents and start-ups. An understanding of the role of ICT firms in terms of their (technological) contribution to the field and their complementary or competing relation to incumbents can be achieved through an in-depth analysis of project documentation. Such an analysis also allows differences to be identified in how each actor type fulfills each role and whether ICT firms offer systematically different (technological) solutions than incumbents. To achieve comparable results in this analysis, we just focused on smart meter projects because they are mostly similar in terms of project scope and roles to be fulfilled. 11 Their project scope typically includes the installation of smart meters in private homes and of the related communication and software infrastructure. Typical roles in smart meter projects are meter supplier, communication technology supplier, software supplier and system integrator (see also Section 3.3). In order to understand a firm's aspired role in the field, firm strategies should be analyzed especially with regard to resource developments. Adequate resource endowments are a pre-requisite 10 If actors stay in the field and increase their presence and influence in the years after their entry. 11 Such a clear scope and roles have not yet emerged for other smart grid projects. Other smart grid projects could be split up in further categories such as integration of electrical vehicles or integration of distributed renewable energy sources, but these can be distinguished less clearly as typical project scopes and configurations have not emerged yet. Furthermore many projects focus on several of these possible sub-categories. We therefore did not make a further distinction. for firms to assume a specific position in the field. Consequently an expansion in the resource base can be interpreted as a strategic move by a firm to assume a new role. The previous project analysis gave implicit insights into actors' strategies and resource endowments. More explicit insights can be gained through an analysis of actors' resource acquisitions strategies. Mergers and acquisitions (M&A) are one way to gain new resources that can be easily observed from outside of a firm. In strategy literature, M&A transactions are described as a fast and irreversible way to close perceived resource gaps. (Eschen and Bresser, 2005). Furthermore M&A transactions are described as a way to acquire unrelated resources in an exploratory strategy (Wagner, 2011). We therefore analyzed all M&A transactions of incumbents and adjacents participating in smart grid projects in Europe. We determined whether the transactions were technologyrelated or not. Finally we mapped, how for each acquisition the acquired technology relates to the smart grid architecture and project roles. For example, if an incumbent acquires a communication technology supplier and states that this acquisition is related to its smart grid activities, we assume that the incumbent wants to become a supplier of communication technology in smart grid projects. As a last step, the above-described analyses were complemented by five expert interviews and by participating in two industry conferences. This allowed us to clarify open questions, discuss and validate our results and interpretations.",
            "Data sources and collection and analysis": " For the collection and analysis of the data we proceeded in several steps. We collected project data of smart grid projects that were initiated between 2000 and June 2011 in Europe from different sources. We integrated the data into one relational database using MS Access as a database tool. The identified projects were initiated between the year 2000 and June 2011Our main data sources were the smart grid catalogue of the European Commission (Giordano et al., 2011), the EU Cordis project database (European Union, 2011), market reports from research analysts and competitive intelligence that was made available to us by a leading firm in the field. 12 From these data sources we obtained information for the distinction between pilot versus deployment projects as well as smart meter versus other smart grid projects. We also obtained information on the project location (country) the project start year and involved actors. We eliminated double counts of projects that were listed in more than one data source. From the information on actor participation in the projects, we compiled a list of actors active in the projects. 13  Following this, we assigned actors to actor groups (cf. Section 3). This was achieved by determining the sector of origin as well as the date of foundation from the firms' websites. To test this coding for robustness a part of the actors were coded by two persons. Codings were subsequently compared. The deviations between the two codings were not significant. 14 The year 2000 was determined as threshold to distinguish start-ups from incumbents and adjacents (see also Table 3). For the analysis of smart grid-related M&A transactions in the field we built on the previous analysis. For each incumbent and adjacent we researched all press releases and investor communications made available on the firm's website about ments of completed M&A transactions. M&A transactions were only included in our analysis if the acquiring company explicitly states in their press release that the acquisition is related to their smart grid strategy. Since M&A transactions have high strategic relevance and in most cases involve substantial monetary investments (Eschen and Bresser, 2005), we can assume that companies communicate such investments to their stakeholders. Using this method we believe to have captured a relevant share of all performed smart grid related acquisitions. In a subsequent step we analyzed the identified transactions in more detail. For this purpose we have distinguished between technology-and nontechnology related M&A transactions. For technology-related M&A transactions we have analyzed the distance between the resources of the acquiring firm and the target. 15 To do so, we derived a categorization from the description of the acquisition purpose in the companies' press release. In most cases the rationale (e.g. acquisition of a certain technology) behind the acquisition was well explained in the press release. This approach also allowed us to map the acquired technology to the smart grid architecture and consequently to the aspired project role.",
            "Empirical results": " In the following we show the results of our empirical analysis. We first describe the project participation of different actor groups. We then show the results of the analysis of project roles. Finally we describe the results of the M&A analysis.",
            "Actor groups in the field of smart grid": " As of June 2011, we have recorded 83 incumbents, 71 ICT firms and 84 start-ups in the field of smart grid technology in Europe. The novel field has obviously not only attracted electricity sector incumbents but also a significant share of newcomers including both ICT sector incumbents and start-up firms. Interestingly, the different groups of firms exhibit similar entry patterns (Fig. 4). Overall, the field saw only very few entries until 2003. Then came a phase with moderate entries (2004)(2005)(2006)(2007) followed by a rather massive number of entries (2008)(2009)(2010). Although incumbents started their entry slightly earlier, ICT firms and start-ups have also entered systematically and in increasing numbers since 2004. It seems that all types of actors had the chance to exert their influence on the field quite early on. However, a detailed analysis of project participation shows that incumbent firms very much dominate the field. 16 Incumbents participated in almost all of the 450 projects, while ICT firms show up in one quarter of the projects. Yet, our data also show that the share of ICT firms in smart grid projects has increased over time. In the early years (2000)(2001)(2002)(2003)(2004)(2005), ICT firms participated only in a very few projects. Later, the share of projects with ICT firms increased up to more than 30% in 2009 and slightly declined in 2010. Fig. 5 depicts for each year the number of new projects started, thereby comparing projects without ICT players (bars on the left) and projects, in which ICT firms participate (bars on the right). A closer look at the four different project types reveals that participation of ICT firms in smart meter projects tends to be much lower than in other smart grid projects. ICT firm participation in pilot projects is almost twice as high as in deployment projects (Table 4). Note the differences in the underlying absolute numbers of projects (cf. Table 2). While ICT firm participation in deployment projects in average is only 17%, it was increasing from 2008 on up to a level of 30% in 2010. A more in-depth analysis of deployment projects also reveals that again incumbents were first to succeed in winning deployment projects in 2001. Adjacents started to win deployment projects from 2005 on. Start-ups were last win deployment projects only winning the first deployment project in 2007. Our interpretation of these findings is that today, adjacent firms have a growing presence and influence in the emerging field of smart grids although incumbents very much dominate the scene. In projects, which are more complex and experimental (e.g. broader smart grid pilot projects), adjacents play a stronger role than in 'standard' smart meter deployment projects. Furthermore the ability of ICT firms to win deployment projects can be interpreted as a sign for their ability to withstand selection pressures. This early success of ICT firms compared to start-ups further supports our theoretical considerations with regard to strength to withstand selection pressure.",
            "Roles and positions of actors in smart meter projects": " ICT firms, incumbents and start-up firms may assume different roles in smart grid projects. In this section we present findings from an analysis the smart meter projects in our sample (deployment and pilot). We can distinguish four roles: meter supplier, communication supplier, software supplier and system integrator (cf. Section 3.3). The analysis reveals that incumbents remain the dominant suppliers of metering hardware. This explains why incumbents are present in almost all projects. There are only very few exceptions such as Aidon, a start-up that also supplies smart meters. In addition to their traditional role as meter supplier, incumbents increasingly assume the role of communication supplier and in some cases also software supplier or system integrator. In these new roles, incumbents compete with ICT firms and start-ups. The in-depth content analysis of projects shows the differences in how actor groups fulfill these roles. In the role of communication supplier, ICT firms successfully piloted and deployed GSM technology (mobile phones) and wired broadband technology. 17 Both technologies are part of the existing technology portfolio of ICT firms such as Deutsche Telekom, Telenor or Cisco. By utilizing these technologies ICT firms can leverage both their competencies and their infrastructure assets e.g. mobile phone networks infrastructure in the new field. When incumbent firms act as communication supplier, they typically offer specialized communication technologies such as power line communication (PLC) or Radio Frequency (RF) Mesh technologies. With these technologies the utility establishes its own, proprietary communication network dedicated for smart grid use. These technologies compete with those offered by ICT firms. The smart meter pilots in Ireland are good examples for the competitive situation. The Irish grid operator ESB Networks is testing the different technological options in separate pilots with different supplier configurations each. The role of software is most often assumed by ICT firms with a focus on enterprise software. 18 They supply central software systems such as ''Meter Data Management'' systems (e.g. by Oracle) or billing software for meter readings (e.g. by SAP). These firms again leverage their existing resources and technological competencies as they integrate smart grid specific functionalities into their existing software platforms. ICT firms offer the software independently from hardware installations. Incumbents provide such software solutions less often. They offer the software often in combination with their metering and communication technology as an integrated solution for smart metering (decentralized data generation via the meters, transportation of the data via communication technology, collection and analysis of data via software products). ICT firms assume the role of system integrator more often than incumbents. They play this role especially in very large projects such as nation-wide smart meter roll-outs: Atos is the system integrator for the French smart meter solution and IBM is the system integrator for the smart meter roll out in Malta. In some cases such as Malta, the ICT firm even acts as the general contractor 19 towards the utility. Meter and communication suppliers then become subcontractor to the general contractor. The position of a general contractor is well established in the ICT sector but new to the electricity sector. A general contractor is a new role in the metering business, which cuts into the existing business relationship of meter suppliers and electric utilities. Our analysis of actor roles shows that ICT firms and incumbents currently compete for the role of communication and software supplier as well as system integrator. Moreover, the offerings of ICT firms and incumbents are clearly different. These differences can be interpreted as variety created in the field. Technological variety is created as ICT firms promote mobile communication (GSM technology) while incumbents support power line and radio frequency communication. The software solutions of adjacents and incumbents are equally different. Variety in terms of business models is generated, where ICT firms act as general contractors to the utility and consequently cut into established customer-supplier relationships.",
            "Acquisitions of incumbents and adjacents": " From 2005 to mid-2011 both incumbents and ICT firms performed acquisitions that were related to their smart grid activities. Until 2008 the total number of acquisitions did not exceed five acquisitions per year. After 2008 the number of acquisitions performed by incumbents increased significantly to over ten acquisitions per year. At the same time the number of acquisitions by ICT firms remained at a level of one to five acquisitions per year (see Fig. 6). ICT firms mostly acquired other, smaller ICT firms (start-ups), which means that their expansion of technological competencies was closely related to their core business. They added specific energy-or grid-related technologies to their portfolio through the acquisition of small start-ups with a dedicated smart grid focus. The acquisition of Arch Rock by Cisco is a good example: Cisco holds a strong position delivering technology such as routers for the backbone of communication networks. This technology had little or no specific functionality related to electricity grids. Arch Rock, however, owned communication technology for the distribution grid that exactly filled this gap. Like adjacents, incumbents also acquired small ICT start-ups. Unlike adjacents, these acquisitions targeted new technological terrain for incumbents. Transmission and distribution incumbents like Siemens or ABB acquired software start-ups, whereas meter incumbents like Landis\u00feGyr acquired both software and communication start-ups. A good example is ABB's acquisition of Ventyx and Obvient in 2010 and 2011. Both acquisition targets are software companies in the field of business intelligence and analytics, with resources and capabilities rather unrelated to ABB's core business. Examples for acquisitions by a meter incumbent are the communication-related acquisitions of Enermet and Cellnet Hunt as well as the software-related acquisition of Ecologic Analytics by Landis \u00feGyr. Typically, the acquisitions of communication technologies by metering incumbents were targeting PLC and RF Mesh technologies, with which they compete against technologies owned by ICT firms (see Section 5.2). To summarize these developments, Fig. 7 maps the position and movement of different actor types to the architecture of the smart grid. It shows how different firm types occupy the empty spaces in the architecture. Incumbent firms move upwards in the architecture into the communication and software layer, whereas ICT firms mainly enhance their resources within 'their' layer. The incumbents, in other words, pursue more explorative strategies while the ICT firms exhibit a rather exploitative approach so far. It seems that ICT firms want to focus on their current role(s) in the emerging field, while incumbents want to cover the whole field. The latter can be interpreted as an attempted to keep large ICT players out of the electricity sector. Incumbents' choice of acquisitions as a way to close a competence gap also points to a perceived time pressure (Eschen and 18 Very few projects have a installed a separate software system so far. The installation of such a system is often done in separate projects after the meter rollout. 19 General contractors manage large and complex system integration projects, such as nation-wide meter roll-outs. They are the sole contractual party to the electric utility. All other suppliers are subcontractors to the general contractor. For the utility this reduces complexity, but also concentrates the risk to one party-the general contractor. Bresser , 2005). The growing presence of ICT firms, which we could show in our analysis, is likely to be one reason for this perceived pressure.",
            "Conclusion": " In this paper we have studied the role of ICT firms in the sectoral transformation towards a smarter electricity grid. Our data shows that an almost equal number of incumbents, adjacents and start-ups entered the field of smart grid. While incumbents dominate the field, the presence and influence of ICT firms is growing especially in large and more complex projects. We also found evidence that ICT firms create variety in terms of technology (communication networks and software) and business models. In addition we could show the strength of adjacents to win an increasing share of deployment projects with their alternative solutions. Furthermore we could show the changing role of incumbents in the transformation. The rising number of M&A transactions by incumbent firms and their exploratory nature shows that they are not passive or even opposed to the transformation of the field as previously suggested by literature (Christensen, 1997;Geels et al., 2008). However, we also have to note that they are under pressure by the entrance of large and potent ICT firms. From a theoretical perspective, we can conclude that an actor focus and the explicit distinction of adjacents as an actor can group provide additional explanatory power for sectoral transformation processes. We can also conclude that adjacents can be important catalysts for sectoral transformation through the variety they create and through their strength to withstand selection pressures. Adjacents are part of the trajectory and path dependencies of their own sector. With this 'heritage' they bring variety to the focal sector in a powerful way, i.e. with many resources and a stable embedding in their existing structures. Thereby they challenge the established trajectory of the focal sector. Beyond this, we found that adjacents can have a transformative capacity by triggering a reaction of incumbents. If adjacents successfully enter a sector and exert increasing influence, they start to compete with incumbents. Adjacents therefore represent a potential or actual threat. Incumbents therefore need to make strategic decisions about their desired role in the emerging field. A 'wait and see' strategy or a strategy of active opposition to transformation entails more risks for incumbents. The transformative capacity of adjacents is therefore stronger than of start-ups, who enter the field with little resources and less embeddedness. Existing literature on sectoral transformation could gain explanatory power if it would more explicitly include the transformative capacity of certain actor types and specifically the role of actors from a different sector. The multi-level perspective could incorporate the transformative influence of other regimes and their actors. This would allow the MLP to explain the influence of other regimes and their actors on the existing regime and its institutional structures (e.g. on technological standards). Similarly, the concept of sectoral transformation (Dolata, 2009) could consider the transformative capacity of technology together with the strategies and resources of actors who own it. Our research also provides insights for policy makers. If adjacents can act as catalysts for transformation, policy makers and regulators should consciously take this group of actors into account, e.g. in the design of policies and technological standards. It seems to be essential that the interests of both incumbents and adjacents are equally represented (e.g. through industry associations), where new regulations are to be developed. More importantly, policy making has to understand and take into account the implications of policies and technological standards standards on these heterogeneous types of firms (Schmidt et al., 2012). Communication technology, for example, might require resources that one actor group already has access to (like mobile phone networks) while another actor group has not. The selection of one standard over another has therefore not only technological consequences (e.g. interoperability and connectivity to other services) also repercussions for the organizational and industry structures that emerge in the field. Finally we would like to discuss the limitations of our research and provide an outlook for future research. Our findings are explorative in nature this limits their transferability. Further research therefore should be to conduct additional case studies on transformations in other sectors to observe whether adjacents play a similar role there. The role of battery suppliers in the car industry would be an example. Moreover, we suggest in-depth case studies of adjacents' strategies or adjacents' role in distinct projects to achieve a more detailed understanding about the effect of adjacents on innovation and transformation, but also the possible challenges that might arise for the transformation through the entrance of adjacents in the field. Sectoral transformations are processes that develop over significant time spans of 30-50 years (Geels and Schot, 2007;Markard, 2011). The transformation of the electricity grid towards a smart grid only started ten years ago. We could therefore analyze just the beginning of the development, which is helpful for policy making because things are still in flux. For more solid contributions to theory however we recommend further research once the development of the transformation can be observed in its entirety."
        }
    },
    "10.1016/j.enpol.2010.07.048": {
        "file_name": "10 Is carbon lock-in blocking investments in the hydrogen economy",
        "title": "Is carbon lock-in blocking investments in the hydrogen economy? A survey of actors' strategies",
        "abstract": "The difficulty of introducing hydrogen and fuel cells in the market stems from the fact that they are not an evolutionary innovation such as biofuels or hybrid cars. Instead they create a disruption in technological utilization. The domination of oil technologies sets a socio-economical context favoring actors involved in the current paradigm, and gives less opportunity to alternative fuels to develop and challenge the status quo. If this hypothesis is correct, then companies interested in the hydrogen economy would not become active because of an unstable context or contradictory interests concerning the replacement of the present system. A review of actions and announcements of main actors shows that technology readiness and the absence of infrastructure are the major justifications to delay investments. Some measures are discussed, which could be deployed in order to reduce uncertainties, such as regulation of carbon emissions from cars, technological subvention, and partnerships for infrastructure implementation.",
        "label": "Qualitative",
        "text": {
            "Introduction": " CO 2 emissions must be reduced in all sectors between 50 and 85% by 2050 compared to 2000 levels in order to stabilize the temperature increases at 2-2.4 1C above the pre-industrial average and avoid disastrous consequences (IPCC, 2007). In the transport sector, raising worldwide motorization rate obliges a more severe reduction in the range of 80-90% compared with the reference in 2050 (IEA, 2009). Some experts believe that 50% reduction is already possible by enhancing the efficiency of current cars with proven technologies such as engine hybridization (IEA, 2009;Sch\u00e4fer et al., 2006). Deeper emission cuts may be unavoidable thus requiring the introduction of radical innovations such as electricity or hydrogen. The cost of the hydrogen fuel cell car depends heavily on the fuel cell itself, as well as on the onboard storage of hydrogen. The cost of the fuel cell has been lowered to $ 60/kW close to the cost of the internal combustion engine ($30/kW). 1 These estimates, however, assume a combined output of 500,000 units; otherwise, the current cost is $3000 per kW. In addition, the cost of storing gaseous hydrogen at 700 bar (10,000 psi), which enables a smaller tank that can fit more easily in the car and still contains enough energy for 500 km, has been estimated between $250 and 350/ kWh, albeit this is far from the US Department of Energy's objective of $2/kWh to be achieved by 2015. 2   Most skeptics believe that hydrogen suffered from a 'hype' effect which has been lately running out of steam by the frustration of expectations created around its use (Romm, 2004;Bakker, 2009). Others argued that the lock-in to the incumbent technology is blocking the diffusion of hydrogen in very specific situations such as the lack of infrastructure (Greaker and Heggedal, 2007) or the difficulty of manufacturers to finance losses with the first cars (Conrad, 2004). This article investigates the existence of an institutional lockin to fossil technology delaying investments in disruptive technologies such as hydrogen. Firstly, we analyze the institutional reasons for a resistance to change. Secondly, we review the impact of the present carbon domination on the strategies of the actors (energy companies, oil companies and car manufacturers) relating to the transition towards a hydrogen economy. The study ends with a discussion about possible solutions for lock-ins preventing firms from investing in hydrogen and fuel cells.",
            "Institutional lock-in framework": " Modern technological systems, such as telephone and electricity, are embedded in existing institutional structures (Hughes, 1983). The interaction between technological and institutional factors makes changes more complicated.",
            "Path dependence and institutional stability": " The economist Douglas C. North has analyzed institutions, the way they operate and their impact on the economic performance. According to North, institutions are constructions of human actions that structure political, economic and social interactions (North, 1990(North, , 1991)). They consist of formal (e.g. laws and property rights) and informal norms (e.g. tradition and culture). The purpose of institutions throughout history has been to introduce some order and to reduce uncertainty in transactions (North, 1991). For that reason, institutions were based on mental models of culture and beliefs shared collectively (North, 2005). Agent decisions are governed by beliefs and oriented by the opportunities offered by the context. Nonetheless, their understanding of the reality is limited (Simon, 1959), and they must decide in a constantly changing and non-predictable world (North, 2005;Arthur, 1989). Hence, error is a normal output and multiple equilibriums are possible. This complex set of institutions can be decomposed into three main components: political structure, forming and aggregating choices; property rights which determine the economic incentives; and social structure including informal norms and conventions (North, 2005). This infrastructure defines the structure of incentives and opportunities in the economy, thus the array of choices available at each moment for actors (North, 1991). Choices are affected by the interactions between agents and institutions. On the one hand, organizations are continually investing in new knowledge and skills to remain competitive (Nelson and Winter, 1982). On the other hand, competition determines the types of skills and technologies seen as providing the highest profits (North, 2005). Investments and competition constrain the perception of the actors about new opportunities in the future. Still, the agent does not passively receive signals from the market, he responds to changes in the environment by taking into account his own stock of knowledge and technologies acquired in the past (Nelson and Winter, 1982). This in turn affects the evolution of institutions, which reflects the beliefs accumulated over time (see Fig. 1). Institutional interdependencies produce significant increasing returns (North, 1990). Indeed, the evolution of institutions is characterized by learning, network externalities, scale and scope economies, informational increasing returns, and technological interrelatedness, which contribute to consolidating the existing system (Arthur, 1989). Thus, operational costs of organizations are reduced with experience, the prolonged use of formal and informal arrangements reduces the uncertainty on these frames, and induced investments produce significant effects of coordination. Socio-technological change is therefore incremental and conditioned by previous choices (North, 2005). It is incremental in the sense that major transformations are likely to confront resistance from economic actors who see a threat to their profits and the evolution of institutions is path dependent in the sense that change is consistent with the existing institutional matrix (David, 1985). In this context, technological change is easier when achieved gradually and by integration into the existing structures. Aoki (2001Aoki ( , 2007) ) analyzes the mechanisms (internal and external) of institutional change. A new architecture comes to substitute the former one by a process similar to the creative destruction of the Schumpeterian entrepreneur-innovator. But social norms embedded in several areas can slow this movement down by introducing elements from the past (Aoki, 2007). In the absence of complementary institutions and skills support, transition becomes very difficult. Institutional failures in both demand and supply sides can block the formation of new technological systems (Jacobsson and Johnson, 2000). On the demand side, potential consumers may be unable to express their preferences in terms of quality, price and performance regarding the new innovation. On the supply side, the process of local search for new technologies could prevent the adoption of innovations very different from those that are currently used (Dosi, 1988). Moreover, the resistance of installed firms whose interests are connected to the dominant paradigm could delay the adoption of new technologies. Thus, it is important to encourage firms to enter the market in order to educate consumers to the innovation and influence favorably the institutional context, but also because uncertainty and risk associated with the new technology make it difficult for them to raise funds in the capital market (Murphy and Edwards, 2003). Policies aiming to promote technological variety, e.g. subsidies for R&D, are normally prescribed in order to reduce barriers to the development of new systems (Jacobsson and Johnson, 2000). In short, existing institutions can make the technological change more difficult. However, even after the process of change begun, the institutional framework continues to protect the dominant technology (North, 2005). In the field of energy, it has been argued that current technologies based on fossil energy are currently blocking the development of ''green'' innovations.",
            "The difficulty of carbon lock-out": " Oil dominance has been the subject of several studies that considered it as a barrier to the transition towards a low carbon society. Unruh (2000Unruh ( , 2002) ) argues that industrialized economies have been locked into fossil fuels by a process of technological and institutional co-evolution in the presence of increasing returns of adoption. The lock-in to energy technologies that emits carbon dioxide ('carbon lock-in') would be the result of changes at many levels (technological, organizational, industrial, institutional and even social), which laid down the basis of a techno-institutional complex (TIC) based on fossil fuels (Unruh, 2002). The TIC may be defended by dominant firms, e.g. oil industry is compared to the 'preferred groups' of the collective action theory (Olson, 1965), which benefit from their reduced number to coordinate action in order to resist the threats of substitutes for oil (Unruh, 2000). The existence of such a technical and institutional carbon lockin blocks the diffusion of clean technologies, even when those technologies are competitive in terms of cost (Kemp et al., 1998). The TIC would thus be responsible for delaying innovations to enter the market. The diffusion of internal combustion engines-first in the United States and then worldwide-is an example of the constitution of a technological lock-in the transport market. 3 In the early twentieth century, three propulsion technologies disputed the market: steam engine, electric motors, and the internal combustion engine. The electric car emerged as a simple, quiet and clean method of locomotion. However, this technology had the disadvantage of a long period of immobilization for recharging, limited refueling locations, and short autonomy. Steamers had the disadvantage of requiring both a fuel infrastructure and a water supply infrastructure. Despite these drawbacks, electric motors and steam engines were the dominant technologies at the turn of the twentieth century (Geels, 2005). Later, with the advent of mass production by Henry Ford on his Model T, the cost of petrol cars decreased drastically, making them accessible to a larger proportion of the population. Furthermore, petrol cars benefited from the existing gasoline infrastructure for domestic uses, which contributed to consolidate its domination over the other types of vehicles (Melaina, 2007). The advantages of the internal combustion engine in terms of availability of fuel, price of the car and autonomy were finally more important than the disadvantages such as noise, pollution and starting problems of early models. Increasing returns to adoption have played an important role throughout the process that led to the domination of the internal combustion engine. Scale and learning economies augmented the benefits of gasoline cars, becoming more competitive, which gradually locked the market through a process of path dependence. This has resulted in a complete domination of the market, making the emergence of fuel alternatives more difficult. Major changes are not usually initiated by dominant players, but rather new actors who introduce radical innovations (Geels, 2005). Installed agents may be interested in defending the existing technology against radical innovations. As soon as the technological dominance is threatened by a new technology, incumbents have an incentive to quickly improve the performance of the established technology with 'off the shelf' innovations. This situation is known in the literature as the 'sailing ships' effect (Geels, 2005). 4 Improvements in the existing technology are a mechanism for slowing down the diffusion of an emergent radical innovation. Because of their role in the current paradigm, automakers and oil companies may be tempted to behave like 'gardes du temple' of fossil fuels and conventional cars, thus limiting radical change in personal transportation. Car manufacturers have expertise in internal combustion engines and have previously responded to the threat from new fuel alternatives by improving engine efficiencies and reducing tailpipe emissions (McNutt and Rodgers, 2004).5 However, this strategy may be challenged by the growing internalization of the negative externalities of cars (e.g. air pollution and climate change), and by approaching the physical limits of the technology. On the other hand, oil companies may have the interest to sustain their core business and maximize the return on investments in the existing infrastructure, but the prospects of expensive oil could force them to prepare a future less dominated by oil.",
            "Actors' strategies concerning the hydrogen economy": " The main actors interested in a hydrogen economy can be found in the personal transportation sector, as well as industrial gas firms, fuel cell manufacturers and electricity and gas companies that are mostly interested by stationary applications. Even though firms can have similar drivers to enroll in hydrogen, there may be differences in the perception of first-move advantages. On the other hand, any strategy is currently constrained by uncertainties surrounding the hydrogen business, namely in terms of technological progress, demand evolution, or infrastructure implementation.",
            "Car manufacturers": " Recent estimates indicate that the world car fleet will triple by 2050 primarily due to growth in emerging countries such as China and India (IEA, 2009;WBCSD, 2004). This growth will reinforce global warming and air pollution in cities, which may contribute to greater demand for cleaner cars. Meanwhile, carmakers face increasing competition from new manufacturers in South Korea, India and China. In the presence of a general overcapacity, carmakers pursue the movement towards concentration and partnership in order to accompany the technological evolution, while the product becomes more homogeneous and the competition global (CAS, 2008). It is this context that manufacturers must choose the technologies that will eventually replace the conventional gasoline car. All major car manufacturers have a program to develop hydrogen cars and almost all brands have already presented at least one model in a motor show. Most of these prototypes are equipped with a proton exchange membrane fuel cell (PEMFC) using compressed hydrogen (at 350 or 700 bars) stored onboard, with the exception of BMW which uses an internal combustion engine dual-fuel (gasoline and liquid hydrogen), and Mazda's rotary engine also using both fuels. The fuel cell is sometimes provided by a specialized firm (e.g. Ballard) or developed in-house by the auto company. A recent estimate of the expenditure on the development of hydrogen cars by the most active companies (Daimler, General Motors, Honda and Toyota), indicates an annual budget of around 100 million US$ per manufacturer since the year 2000 (Sperling and Gordon, 2008). Demonstration projects, currently on the road, are consistent with that level of investment, e.g. Daimler and GM account over a hundred fuel cell cars each globally (Table 1). Daimler is one of the most active brands in the development of fuel cell cars. The German manufacturer equipped the fleet of the European hydrogen demonstration in public transportation, i.e. the Clean Urban Transport for Europe-CUTE program, with 30 Citaro buses between 2006 and 2009-meanwhile the program has been extended to other cities in China and Australia. 6 Daimler owns one of the largest fleets of hydrogen fuel cell cars, with over a hundred vehicles (based on the Mercedes A-Class). In January 2009, the carmaker introduced the new BlueZERO F-Cell (in the base of the Mercedes B-Class) equipped with a 90 kW fuel cell from the Automotive Fuel Cell Cooperation Corp. (AFCC), the former transport division of Ballard which was recently taken over by Daimler itself. General Motors (GM) is another major actor in the development of hydrogen vehicles. GM showed its first pickup truck powered by a fuel cell in 1968. The brand has been the source of other major innovations such as the chassis type ''skateboard'' which integrates the fuel cell and the hydrogen storage in a flat floor, or the concept ''drive by wire'' where the traditional mechanical and hydraulic parts of the car were replaced by electronic systems. In March 2010, GM had already delivered 119 Chevrolet Equinox Fuel Cell vehicles for the Project Driveway in California, New York and Washington DC. 7 The company from Detroit announced plans to deploy 1000 fuel cell cars in California in 2012, before being caught up by the economic crisis which forced GM to submit itself to the protection of the bankruptcy law in order to restructure its activity. The crisis also produced job cuts in its hydrogen division (Fuel Cell Today, 2009a). 8  Honda and Toyota have been early pioneers in hydrogen fuel cell vehicle technology. Both started to rent fuel cell cars in California in December 2002 (Solomon and Banerjee, 2006). At the end of 2008, Honda began a small-scale 3-year leasing the FCX Clarity in Los Angeles and Tokyo. The Japanese company plans to lease 200 cars worldwide during the next 3 years. Honda expects to reduce vehicle costs to 65,000 h in 2018 mainly as a result of ramping up production of fuel cells (Beuzit and Meillaud, 2007). Toyota launched the SUV 'Highlander Fuel Cell Hybrid Vehicle-Advanced' (FCHV-adv) in 2008. This vehicle was announced as one of the longest range hydrogen cars, with a range of 830 km (Fuel Cell Today, 2009b). The Japanese company recently confirmed plans to start the commercialization of fuel cell cars by the year 2015 with a price target of $ 50,000 (Fuel Cell Today, 2009c). In 2001, Toyota, Honda, GM andFord (in 2002) have announced very optimistic plans to launch the commercialization of fuel cell cars in three years (Bakker, 2009). These announcements occurred after Daimler declared in 1997 plans to commercialize 40,000 fuel cell cars in 2004, and 60,000 in 2006 (Reuters, 1997). Indeed, companies have repeatedly inflated expectations albeit all evidence indicating the commercial stage was still year away. It is possible that companies were pursuing specific interests with those announcements. Optimistic statements about the fuel cell cars readiness may had been used with the purpose to obtain funding for R&D and demonstration activities, alternating with a more realistic discourse intended to avoid changes in environmental regulation and to moderate the expectations of government agencies regarding the current state of the technology (Suurs et al., 2009). These declarations contributed to inflate public expectations about hydrogen fuel cell vehicles during the first half of the decade. Successive postponements of the launching date had provoked a general disillusionment about the ability of the hydrogen car to become a reality, which led some analysts to refer it as the 'hype' about hydrogen (Bakker, 2009;Romm, 2004). The economic crisis has pushed manufacturers to accelerate the deployment of clean technologies. In the face of the collapse in the automobile market, as well as raising uncertainties on the evolution of both oil prices and environmental regulation, carmakers diversify their offer with new technologies that can be deployed in the short term. 9 Some companies intensified development activities in order to anticipate the launch of: hybrid  (Gross et al., 2007), others point out the fuel cells readiness to justify the focus on technologies deployable in the short term (e.g. BMW, Ford).",
            "Energy companies": "",
            "Oil companies": " Oil companies already know hydrogen since they have long been using it for refining crude oil. This new fuel is seen as a possible successor to oil in transportation, and thus ensuring business continuity. Table 2 presents a non-exhaustive summary of worldwide demonstration projects of fuel cell vehicles, where oil companies have participated by opening hydrogen stations. BP and Royal Dutch Shell were the first two companies to open an internal division dedicated to hydrogen in 1998 and 1999, respectively. In the early 2000s, BP has tried to show its commitment in promoting alternatives to oil with the slogan 'Beyond Petroleum'. The company then launched demonstration projects related to hydrogen, but these took only a meager share of all the investments in alternative energies whose budget reached 1.4 billion dollars in 2009 (Financial Times, 2009). In addition, BP and Rio Tinto established a joint venture named ''Hydrogen Energy'' for the construction of coal plants producing power and hydrogen with carbon capture and sequestration. Shell published in 2001 a vision of sustainable energy for 2050 where hydrogen played an important role in the energy mix. Since then, the Dutch company has allocated over one billion dollars on research and promotion of energy applications using hydrogen (Solomon and Banerjee, 2006). The company participates in various demonstration projects around the world, usually by opening a service station, e.g. in Reykjavik in Iceland which was one of the first stations in the world. The collaboration with GM in the United States served as the basis for the opening of several hydrogen stations in the USA. In 1999, Shell joined the California Partnership for the promotion of fuel cells (CaFCP) together with BP, ExxonMobil and Chevron, and they started to build up a network of stations in the State. In turn, BP is involved in several other demonstrations around the world such as the project 'HyFLEET: Cute' for the demonstration of hydrogen in transportation. 12 Total opened two hydrogen stations in Germany (Berlin, Munich), and another one recently in Belgium (Brussels). The French company recently signed a memorandum of understanding with Daimler, Linde, some gas companies and Shell for the 12 http://www.fuelcells.org. development of an infrastructure for hydrogen in Germany starting in 2011 (Daimler, 2009). Unlike car manufacturers, an oil company has fewer reasons to engage before the others in the hydrogen for energy business (van Benthem et al., 2006). Recent increases in the price of the barrel increased the profitability of oil activities. Moreover, the last scandal about the evaluation of Shell reserves has shown the importance of oil related activities on the market value of firms. Hence, companies have more incentives to secure a return on existing investments rather than to develop a new infrastructure for hydrogen (production, delivery and stations). In 2009, Shell and BP closed their hydrogen units the same time that they underwent a strategic redeployment in core business activities (Financial Times, 2009). 13 Rising prices makes oil exploitation and production more profitable at a time when foreseen profits in hydrogen are dependent on the uncertain increase of the demand. Nonetheless, both companies have so far declared the intention to keep open existing hydrogen stations.",
            "Prospects of new markets for industrial gas suppliers": " Producers of industrial gases such as Linde, Air Liquide, Praxair and Air Products & Chemicals collaborate with oil companies to build hydrogen stations all over the world. There are currently 103 stations including 58 in the United States, 16 in Canada, 12 in Japan, 7 in Germany and 5 in Korea. 14  Global consumption of hydrogen was 450 bn m 3 in 2003 of which 84 bn m 3 in the USA and 61 bn m 3 in Europe. The consumption of the latter was estimated at 76 bn m 3 in 2008 (Roads2HyCom, 2007). In Europe, captive production of hydrogen represents 64% of the total, followed by secondary production (27%) and the production of industrial gas companies (9% or about 10 bn m 3 per year) (Roads2HyCom, 2007). Linde, Air Liquide and Air Products own 15 major hydrogen pipelines running across almost 1600 km in Europe. Linde and Air Liquide are the largest companies in the world, with approximately 40% of the global industrial gases market and a revenue of 11 billion h each in 2009. 15 The prospect of expanding hydrogen uses to the energy field explains the interest of the sector in this regard. Indeed, the hydrogen economy opens new opportunities to value their skills and to expand markets in the future. Nevertheless, those companies may not want to remain confined to the production of hydrogen. For instance, Air Liquide is also pursuing activities in the production of fuel cells with its division Axane. However, this market is suffering from a slow start and independent fuel cell companies accumulate deficits, which raises the question about the disposition of the mother firm to continue bearing the losses of its subsidiary firm.",
            "Electricity and gas utility companies": " Energy utility companies are also interested in hydrogen technologies, which may open new opportunities to diversify their activities in the future. On the one hand, gas companies may be concerned by the prospect of natural gas infrastructure being used to deliver hydrogen. In addition, fuel cell technology may open high value markets for natural gas such as electricity generation. On the other hand, electricians are interested in the possibilities of fuel cells in terms of affordable, efficient, clean and decentralized power generation. Decentralized networks may play an important role in the newly built capacity under the liberalizing European market, reinforcing local supply without the need of capital intensive and risky investments in central plants or complex investments in the regulated transmission network (Glachant and Le \u00b4v\u00eaque, 2009). Moreover, carbon regulation and renewable energy obligations pave the way to the diffusion of clean technologies such as fuel cells. Electric and gas companies are active in the major programs of fuel cell deployment for stationary applications in Japan and Germany. The Japanese government together with some energy companies has implemented a wide-scale demonstration program of small stationary fuel cells (1 kWe) of the PEMFC type and (less) of the SOFC type, for residential uses (Adamson, 2007). This program began in 2005 under the coordination of the 'New Energy Foundation' (NEF) and is funded by the 'New Energy and Industrial Technology Development Organization' (NEDO). Between 2004 and late 2009, more than 4800 residential fuel cells had been installed in Japan (Aki, 2009). Companies enrolled in the project-mostly oil and gas companies such as Tokyo Gas, Osaka Gas and Nippon Oil-were asked to install the fuel cells and to cover the difference between its cost and the government subsidy (Adamson, 2007). Meanwhile, those companies have established diverse partnerships with fuel cell manufacturers such as the one between Sanyo Electric and Nippon Oil, or Matsushita and Tokyo Gas. In Germany, the Ministry of Transport, Construction and Urban Development, in cooperation with nine industrial partners, launched in September 2008 a major program of pre-commercial demonstration of domestic heating systems based on fuel cells called Callux'. 16 Three manufacturers of fuel cell systems are involved-BAXI INNOTECH, Hexis and Vaillant-as well as five electric and gas companies-E.ON Ruhrgas, EWE, MVV Energie, VNG Verbundnetz Gas. One hundred fuel cells have already been installed from the 800 initially planned for the first phase running until 2012. The cost of the project is estimated to be 86 billion euros from which 46 billion are supported by industry partners and the rest by state subsidies. In addition, utilities forge collaborations between manufacturers of fuel cells all over the world. GDF Suez expanded its agreement with Ceramic Fuel Cells Limited for the development and deployment of micro cogeneration (mCHP) units of 2 KW of electricity and hot water in France. Or even the agreement between Ceres Power and Centrica (British Gas) to develop fuel cells of the SOFC type with 1 kWe+1 kWth of capacity and using natural gas, for the United Kingdom market with commercialization starting in 2011 (Campanari and Rose \u00b4s, 2009). Cost remains a major obstacle to the diffusion of fuel cells, although the level of competitiveness is less rigid in the stationary market than for mobile applications: 2000 h/kW for mCHP comparing to 50 h/kW in transportation (HFP, 2007). However, there is an intense competition in the stationary market (turbines, diesel generators, etc.). More recently, interest has again focused on the prospects for electric car batteries in transportation. For instance, the French utility EDF is currently engaged researching better batteries, as well as the deployment of electric outlets to assist the diffusion of electric cars in large cities. See Table 3 for more examples.",
            "Fuel cell manufacturers": " Fuel cell companies-either those specialized in components, such as membranes, or systems integrators-are facing problems with the transition of the innovation from the laboratory to the market. At the beginning of the decade, optimistic prospects seeing a rapid development of the market incited new companies 13 Meanwhile, high BP executive members have also joined the board of the project ''Better Place,'' which intends to implement infrastructure to support the diffusion of electric battery vehicles. to raise money in the stock exchange. Meanwhile, the market is slowly starting to emerge and listed companies make successive losses. Indeed, the technology is still at the stage of large demonstrations or in the final stage of R&D. In the case of mobile markets, fuel cell manufacturers depend on orders from auto manufacturers, which are constrained by the current cost of fuel cells and the lack of hydrogen infrastructure. In addition, there are many examples where the fuel cell is produced internally by the carmaker itself (Honda, Nissan, Toyota and Daimler who bought out Ballard's transport division). Fuel cells are already competitive in very few niche markets (e.g. 'backup,' forklifts, auxiliary power unit (APU) for boats), not generating enough revenue to continue the development of the technology. Repetitive annual losses oblige firms to revise their plans or even to close their doors. This was the case of Millennium Cell-specialized in energy storage by hydrogen cartridges for portable uses-who bankrupted in 2008. The specialist of PEM fuel cells, Ballard, sold its transportation division to Daimler in 2007 following an internal restructuring, despite the fact that the company provided the fuel cell to many vehicles that have been demonstrated globally (Fuel Cell Today, 2009d). In May, the Canadian company has also terminated its collaboration with the Japanese Ebara for the sale of cogeneration systems in Japan. Nevertheless, Ballard is working with Hydrogenics and Dantherm in the Canadian-Danish project, 'Candan,' for the development and deployment of fuel cells for transportation (including forklift trucks and small cars), unit power systems (UPS) and backup generators. A dozen companies are focused on the market for large stationary power, including the two largest UTC Power and FuelCell Energy. Even though this market is experiencing sustained growth, financial needs raise serious questions for both companies (Fuel Cell Today, 2008). HydroGen felt recently obliged to lay off two thirds of its workforce, while Siemens chose (again) to exit the market. In a different segment, major manufacturers of fuel cells for portable applications changed their financial structure just as the market shows signs to ramp up (Table 4). Indeed, CMR Fuel Cells, Medis and MTI Micro Technologies delisted or are preparing to withdraw the stock exchange listing (Fuel Cell Today, 2009g).",
            "How to reduce institutional uncertainties and unlock the market for hydrogen?": " Returning to our initial framework, the oil dominated context influences the perception of actors-such as oil companies and carmakers-about new opportunities in the future, at the same time that strengthens the present institutional framework and blocks the diffusion of greener technology. On the one hand, those innovations cannot share the same learning effects that benefitted the incumbent technology in the past. On the other, the absence of infrastructure clearly impedes the entry of hydrogen vehicles in the market, even if the price differential with a conventional car becomes small (Greaker and Heggedal, 2007). Given that actor decisions are interdependent, e.g. fuel providers expect that car manufacturers supply hydrogen vehicles and users buy those cars, the challenge is then to improve the institutional framework for investments in hydrogen technologies. In particular, stability is needed in order to create a suitable environment for investments (North, 2005). In the following points, some measures are discussed may reduce the uncertainties on the hydrogen technologies and address the infrastructure problem.",
            "Increase the production of hydrogen technologies": " Current costs of fuel cells, especially for mobile applications, are high and difficult to assess, but they are expected to go down significantly with the augmentation of production, allowing the concretization of scale and learning economies. The reduction in costs is necessary in order to boost adoption and further decrease costs over time until they approximate competitive levels (Arthur, 1989). Thus the goal is progressing into technology deployment. The diffusion of environmentally sound technologies in the transportation sector depends heavily on the implementation of market and regulatory measures. The regulation of car emissions could accelerate technological change through increasing pressure on car manufacturers to consider more seriously radical innovations such as electric cars and hydrogen. The European legislation on CO 2 emissions from cars was recently reinforced, substituting the previous voluntary agreement with automobile manufacturers. After intense discussions between the European Commission and member states with an important domestic automobile industry, e.g. Germany and France, the European Parliament finally approved a compromise solution which in practice limits CO 2 emissions to 130, 120 and 95 gCO 2 /km, respectively in 2012, 2015 and 2020. 17 At these levels, actors may be more interested on adopting cost competitive technology instead of developing radical innovations like hydrogen cars capable of drastically reducing emissions. In the case of California, carmakers are required to deploy zero emissions vehicles, which explain the impressive number of hydrogen vehicles demonstrated in the State. 18 But technological uncertainties surrounding electric vehicles, as well as fuel cell vehicles, have resulted in multiple revisions to the regulation over time, reducing the number of zero emission vehicles required. 19 Also, the application of such a legal obligation in the European Union may not be feasible because of approval and coordination problems that its implementation would raise. A specific support scheme beyond emissions regulation may be necessary in order to start the deployment of hydrogen technologies in transport. A type of financial support mechanism, or subvention, should address the high additional cost of the vehicle since it is the major obstacle to adoption (regions and companies could initially support the cost of the fuel). 20 This policy support should be periodically revised in order to adapt to the improvements of the technology, though updates have to be clear and predictable, e.g. decreasing progressively over time or with the number of units deployed. In markets where fuel cells are closer to early commercialization, such as small stationary, there are already countries like Japan, Germany or Korea, providing incentives for the acquisition of domestic systems with thousands of units deployed. As for Japan, a thousand fuel cells were on average per year since 2004, bringing the costs down from 8 to 3.5 M JPY during this period (Aki, 2009). 21  In the case of transport applications, the subvention could start niches where hydrogen technologies are closer to commercialization, like buses, where the additional is smaller to the alternative technology hybrid diesel. Moreover, the deployment of vehicles has to be coordinated with the build-up of infrastructure. Thus bus operators and fleets are well positioned to become first markets for hydrogen vehicles since they can provide sufficient demand, at the same time minimizing logistical requirements. 22",
            "Implement initial infrastructure": " The absence of the hydrogen infrastructure is a clear obstacle to the entry of hydrogen in the market. An early infrastructure, in particular refueling stations, is necessary in order to allow the deployment of hydrogen vehicles. However, the size of investment requires a long recovery period, and the uncertainty about its utilization may redirect investors to more profitable projects in the short term. The social returns of the initial projects can be internalized by means of incentives to invest in infrastructure, such as grants or tax credits, compensating actors for losses generated by its underutilization. In California, the Air Resources Board (ARB) organizes competitive bids to concede grants for new refueling stations to serve as part of the ''California Hydrogen Highway Network''-a state initiative with the purpose to establish a network of hydrogen stations along major California highways. 23  There are currently 21 hydrogen stations in the State, and a dozen more are expected soon. 24 These hydrogen stations will assist the deployment of the fuel cell vehicles that carmakers are mandated under the zero emission vehicle program-reducing at the same time the risk to station owners-which underlines the complementarities between different policy measures. In comparison, recent studies suggested that a network of 1000 stations would be sufficient to support about one million of fuel cell vehicles in Germany with a cost estimated between 1.5 and 2 billion Euros (Stiller and Wurster, 2010)-this compares with the 5 billion Euros that cost the German car scrappage scheme in 2009 (BBC News, 2009). Assuming that the government co-funded 50% the cost of the first 100 stations, this measure would cost on the order of 75 and 100 million Euros allowing the deployment of 100,000 cars at least.",
            "The need for collaborative arrangements to enable investments": " The discussion in point 3 showed that each agent focuses on the activities close to their core business, but the transition is only possible if decisions become coordinated among actors in terms of R&D, market entry and infrastructure implementation (Nygaard, 2008). When the transaction needs the establishment of a long term, very specific investment, the number of intervening firms is reduced and thus a party may be dependent upon its contractual counterparty, e.g. the viability of a hydrogen station depends on the number of cars that carmakers make available. This dependency amplifies the risk of opportunistic behavior which increases the cost of transactions governed by the market (Williamson, 1985). A cooperative engagement may be put in place in order to manage the problems with opportunism and uncertainty (Me \u00b4nard, 2004). 25  In the case of hydrogen, hybrid organizations started with some time-limited agreements, such as research collaborations between manufacturers and public laboratories, and gradually moved towards the formalization of partnerships as the technology approached the commercialization stage and agents' decisions may rely more upon other agents' investments. In the United States, the US Department of Energy conducts programs of R&D and demonstration in collaboration with industry, universities and national laboratories (e.g. National Renewable Energy Laboratory or NREL), in order to overcome technical obstacles to the commercialization of hydrogen and fuel cells in 2015. The Presidential Initiative for the promotion of hydrogen in transport has invested 1.5 billion dollars between 2004 and 2009. The budget for fiscal year 2010 was finally restored by the US Congress, despite the initial proposition of the progress. 19 The number of hydrogen fuel cell vehicles requested in the State was lowered to 4307 (previously 25,000, this number dropped to 7500 in 2008), companies may accomplish their obligations mainly with plug-in hybrid cars (CARB, 2009). 20 The deployment of 100,000 fuel cell vehicles is needed in order to reduce additional costs of hydrogen fuel cell vehicles to 10 hct/km-taking into account both vehicle and fuel costs-a level which is competitive with gasoline cars in some countries like Denmark if the hydrogen vehicle is exempted from registration taxes (HyLights, 2009). Thus the point is to find incentives to deploy enough number of cars. 21 In 2009, government supported half of the cost of the microcogeneration (mCHP) system (installation included) up to 1.4 M JPY, the manufacturer sell the fuel cell to the energy utility who install it onsite and pays the reminiscent part of the cost. 22 For a discussion of the potential of niche markets in Europe, see HyLights (2009). new administration to substantially reduce the budget particularly in mobile applications of fuel cells. Also in the United States, the 'California Fuel Cell Partnership' (CaFCP) was established in January 1999 with the aim to promote the commercialization of hydrogen technologies in transportation. Members of the partnership (public agencies, carmakers, energy companies) estimates that more than 700 hydrogen FCVs will be on the road by 2011, increasing to over 4000 by 2014 and reaching about 50,000 vehicles by 2017 (CaFCP, 2009). The 'Japan Hydrogen and Fuel Cell Demonstration Project' (JHFC) was launched in 2002 by the Ministry of Economy, Trade and Industry (METI), in partnership with major Japanese and foreign carmakers (Toyota, Honda, Nissan, Daimler and GM), and energy companies (e.g. Tokyo Gas and Shell). This program supported the opening of 12 hydrogen stations to assist the demonstration of nearly 60 hydrogen cars. 26 More recently, an association of 13 private companies (mostly oil and gas utilities, as well as industrial gas suppliers) started a collaboration to study the construction of the hydrogen supply infrastructure necessary to achieve its commercialization by 2015 (Aki, 2009). 27 In South Korea, the national government collaborates with Hyundai-Kia in the demonstration of fuel cell vehicles and supports the implementation of infrastructures with 5 hydrogen refueling stations already built throughout the country (Nahm, 2009). The European Commission and the industry also foresee the commercialization of fuel cell vehicles in 2015, and annual sales of 58,000-750,000 units in 2020, corresponding to a fleet of 0.4-1.8 million fuel cell cars by that time (HFP, 2007). It is far from the 2003 vision that aspired to 2% of the 190 millions of cars expected in Europe for 2020, i.e. 3.8 million fuel cell vehicles. Collaboration between public and private companies has recently evolved into a technology program to promote hydrogen and fuel cells, i.e. the 'Joint Technology Initiative' (JTI). This program began in 2008 for a period of 4 years with a budget of 1 billion h-financed equally by public funds and private companies. 28  Because European funds are not foreseen beyond the demonstration phase, deployment costs have to be shared by member states, regions, companies and end-users. This could be done in the framework of regional and national public-private partnerships for the deployment of hydrogen technologies. On the national level, governments are concerned with climate change, security of supply and national competitiveness. On a more regional level, pollution emissions, as well as local industry and employment are the main drivers for action (HyLights, 2009). Regions are already co-financing important projects in Germany (e.g. Berlin and Hamburg in the framework of the CEP project), in the United Kingdom (e.g. London Hydrogen Partnership), in Italy (e.g. H2CNG project) and in the framework of the Scandinavian Hydrogen Highway Partnership. These projects have an expected budget of approximately 250 million Euros for the period to 2015 of which around 50 million from the regions (HyLights, 2009). 29  The intervention of national governments may still be necessary in order to create the required interconnections (''hydrogen corridors'') ensuring a minimal degree of comfort and freedom in the car use. As the technology progresses in the deployment phase, there is a growing need for more formal and specific commitments. It concerns in particular: funding, demand and incentives from public authorities; number and location of refueling stations from fuel providers; number of vehicles from carmakers; and costs and performance from fuel cell manufacturers. The German collaboration between public and private actors in order to deploy hundreds of hydrogen stations in Germany before 2015, ''H2 Mobility,'' is an example. 30  Table 5 summarizes the plans of the more active regions promoting hydrogen and fuel cell vehicles.",
            "Conclusions": " The current domination of incumbent technologies influence the incentives structure which in practice impedes clean technologies, such as hydrogen and fuel cells, to develop and to enter into the market. This institutional lock-in can be explained by several factors. Incumbent technologies like petroleum cars had benefited from scale and learning effects in the past allowing  in 2008in (FCCJ, 2008)). 28 According to the European roadmap for hydrogen 'HyWays' (2008) a large demonstration should start right after 2010 with an initial fleet of a thousand cars to be deployed before 2015. The same ''roadmap'' advocates for 400 stations located in the largest cities at the same time, complemented with 500 more stations in major European motorways creating a ''corridor'' for hydrogen. 29 The European Regions and Municipalities Partnership for Hydrogen and Fuel Cells (HyRaMP) coordinate the efforts of several committed EU regions and prepare for the large-scale demonstrations co-financed by the European funds. See: http://www.hy-ramp.eu. 30 In September 2009, Daimler, Linde, EnBW, OMV, Shell, Total, Vattenfall and the National Association for the Advancement of Hydrogen and Fuel Cells ('NOW') have launched the initiative ''H2 Mobility'' for the development of the hydrogen infrastructure starting in 2011. This collaboration aims to create hundreds of hydrogen stations in Germany before 2015 (Daimler, 2009). This program comes in the sequence of the agreement signed between the car manufacturers Daimler, GM, Honda, Toyota, Ford and Hyundai, for the commercial launch of fuel cell vehicles and the hydrogen infrastructure by 2015, and a total of hundreds of thousands of vehicles sold worldwide shortly after (Fuel Cell Today, 2009h). current low costs. On the other hand, conventional technologies are supported by a ubiquitous infrastructure, while incompatibility with the existing infrastructure raises more obstacles to the diffusion of hydrogen technologies. The analysis of actors' strategies gives some indications about the way those obstacles acts in reality. Players who would be the most likely involved in a hydrogen economy are at the same time at the centre of the current technological paradigm. However, incentives to enter into the new technological system are not the same for all of them. Automakers see more interest in being the first in the new market, while oil companies have more benefits to amortize existing investments. Nevertheless, the latter group may be pressed to act by the possibility of a major change in transportation towards electrification. Finally, industrial gas suppliers, gas companies and utilities may play a larger role in the future, though they would not take the first step alone. In this context, governments should act on the institutional framework in order to reduce uncertainties and open the market to hydrogen and fuel cells, through the implementation of policies and agreements capable of influencing the incentive structure. Some measures were discussed in this article. Firstly, a stricter regulation on CO 2 emissions from cars is essential to open the market for hydrogen technologies in transportation by increasing pressure on the industry to develop cleaner technology. Secondly, deployment incentives are an important instrument to create market for fuel cells, especially in market niches where they are closer to commercialization. The increase in production generates scale and learning gains which further decrease costs, approximating fuel cells to commercialization. Finally, public-private partnerships could reduce the risk of investments and make available more resources for the construction of the initial infrastructure. The coordination of measures may enhance the effects of each instrument. More importantly, a technological policy should be predictable and stable over time in order to increase confidence among investors in the innovation. The cost of those policies will depend on the market potential of hydrogen technologies. It would therefore be interesting to analyze the evolution of the demand for hydrogen using, for instance, past experience with other technologies such as diesel vehicles."
        }
    },
    "10.1016/j.eist.2011.10.005": {
        "file_name": "100 Breaking out of sustainability impasses",
        "title": "Environmental Innovation and Societal Transitions",
        "abstract": "We combine frame analysis and transition theory into a thinking tool in sustainability science and analyse three serious and persistent problems in global health subject to sustainability impasses: HIV/AIDS, malaria, and indoor air pollution. Frame analysis identifies how problems are encased by scientific understandings and captured by transition barriers: policy cooptation, techno-institutional lock-in, and knowledge trap. Transition theory locates the transition barriers on a temporal scale and a conceptual level: landscape, regime, and niches. Frame analysis reveals how problems are embedded in particular narratives while reframing stimulates alternative understandings and problem solutions. Boundary work facilitates knowledge integration across units and transition management promotes actor oriented problem resolution. The thinking tool unites critical with problem solving research and ties reframing to analytical and temporal understandings of social change. The aim is dual: to advance methodology while stimulating critical problem solving in the quest for environmental innovations, social justice and sustainability.",
        "label": "Qualitative",
        "text": {
            "To that end it seeks and suggests integrated approaches for dealing with social-ecological causes and consequences of climate change, biodiversity loss, land use changes, water scarcity, major epidemics and other sustainability challenges (J\u00e4ger, 2009). As an emerging field it recognises multiple perspectives and approaches in science and society for tackling urgency, spatial scales, temporal inertias, non-linearity and functional complexity between actors, sectors and structures in a range of processes. In addition, it has a trans-disciplinary ambition to span disciplines, cross boundaries between science, policy and practice, and transcend science itself into stakeholder dialogues (Kates et al., 2001).": " To that end it seeks and suggests integrated approaches for dealing with social-ecological causes and consequences of climate change, biodiversity loss, land use changes, water scarcity, major epidemics and other sustainability challenges (J\u00e4ger, 2009). As an emerging field it recognises multiple perspectives and approaches in science and society for tackling urgency, spatial scales, temporal inertias, non-linearity and functional complexity between actors, sectors and structures in a range of processes. In addition, it has a trans-disciplinary ambition to span disciplines, cross boundaries between science, policy and practice, and transcend science itself into stakeholder dialogues (Kates et al., 2001). In reaction to scientific specialisation and disciplinary fragmentation (Sherren et al., 2009) sustainability researchers collaborate in broad interdisciplinary initiatives to overcome methodological barriers (Leach et al., 2010). Furthermore, sustainability scientists structure knowledge in new ways (Kumazawa et al., 2009;Ness et al., 2010) and attempt to bridge critical research with problem solving research (Cox, 1981) in order to deal better with sustainability challenges (Jerneck et al., 2010). Inspired by this, we explore how progress towards sustainability is hampered, but can be promoted, in the case of three serious, widespread and persistent problems in global health: HIV/AIDS, malaria and indoor air pollution (IAP). The three selected examples are interesting and relevant for social justice (particularly HIV/AIDS), environmental management (particularly malaria) and poverty reduction (particularly in-door air pollution). They all represent global health challenges where progress, we argue, is hampered by the current scientific framings and their corresponding actions and interventions. They also have implications for climate change and the environment, especially malaria and indoor air pollution, thereby reaching beyond global health and into the structuring of knowledge on environment and climate change. In terms of data and research design the article is based on secondary data that we generated from multiple methods such as policy and text analysis, a bibliographic survey and an extensive literature review. Our primary data is rooted in repeated field work in Kenya (2007Kenya ( -2011)). Climate change, land use change and land degradation affect the well-being of large populations in the global south and the situation is predicted to get worse (IPCC, 2007;Andersson et al., 2011). In addition, there is a mounting burden of disease in these areas (Patz et al., 2005). In response to such sustainability challenges, and as a sign of functional complexity, climate change policy is increasingly interlinked with food and energy policies. In parallel, there are signs that global health policies are currently changing profoundly with implications for how climate change-induced health challenges can be met. The international development community has acted forcefully on the fact that many people in developing countries are plagued by three major diseases: HIV/AIDS, malaria and tuberculosis (McCoy et al., 2009;Ravishankar et al., 2009). Meanwhile, a range of widespread but neglected tropical diseases have not yet benefited from such political and financial support and interventions (Hotez et al., 2007;Esser and Bench, 2011). As an example, every year over 1.6 million people globally die of respiratory diseases from in-door air pollution (IAP) from cooking over open fire and the victims are mainly women and children (WHO, 2002;Ramirez-Venegas et al., 2006). This demands action and research. In this article, we use global health as an example to demonstrate a \"multiple method of inquiry\" (Saunders, 2003) for dealing with sustainability impasses. In our view, the term sustainability impasse refers to a situation of inaction owing less to lack of awareness, knowledge, technology or resources and more to a suite of other reasons like economic priority or human cognition, social neglect and denial (Rees, 2010). In the analysis we study three sustainability impasses by combining frame analysis and reframing with transition theory and transition management. The examples on HIV/AIDS and malaria relate to transition theory while the example on IAP relates to transition management. Transition theory is already at the core of sustainability research (Grin et al., 2010) while frame analysis is now developing in this context (Leach et al., 2010). Our findings show how the three persistent problems are subject to sustainability impasses resulting from, among other things, inadequate use of science; competing interests and values; a disconnection between science, practice and policy; or any combination thereof. In the analysis, we give priority to the three persistent problems but we also identify four strategic organisational shifts in global health which may have serious effects on the environment and on adaptation to climate change. In research, we first apply frame analysis and then transition theory to identify and locate three types of multi-layered barriers to progress, which we conceptualise in both descriptive and explanatory terms: policy cooptation, techno-institutional lock-in and knowledge trap. The idea of policy cooptation is not new and here we use it to describe a situation where a particular policy is seized for the sake of advancing a particular interest that it was not intended for in the first place. One pertinent example is when seed companies seize policies and discourses on poverty and famine for promoting the use of genetically modified seeds such as in the case of AGRA (Alliance for Green Revolution in Africa) (Holt-Gimenez et al., 2006). The concept of techno-institutional lock-in can be found in the literature on transitions and socio-technological systems (Foxon, 2007;Smith and Stirling, 2010). Here we show how it can be used in a slightly different way. The concept of knowledge trap is rather general and has many meanings. We use it to describe the gap between available versus necessary knowledge for solving a particular problem. In the frame analysis and the reframing process we discuss alternative frames and then locate where boundary work can translate emerging knowledge into action that opens up sustainability pathways out of impasses. Below, we introduce our multiple method of inquiry by briefly engaging with the literature on boundary work, frame analysis, transition theory and transition management. Then we analyse three sustainability impasses in global health and draw conclusions from that.",
            "Boundary organisations": " A mismatch between science and society can be foreseen when interdisciplinary knowledge meets cleavages and compartmentalisation in institutions and organisations. Two examples from the United Nations show that the FAO divides its organisational responsibility for agriculture into major but separate food and fibre production systems while the WHO divides its organisational responsibility for global health primarily into major diseases. This compartmentalisation goes against the complexity of crosscutting sustainability challenges, which call for new types of multilevel governance/governing for sustainability (Adger and Jordan, 2009;Biermann et al., 2009). As an additional element of the problem, scientific and other knowledge producing communities in society may apply different criteria for what counts as 'reliable evidence and convincing arguments' (Cash et al., 2003). For effective sustainability transitions, we may thus need boundary organisations to promote communication and perform boundary work between science and society (Clark, 2003). The concept of boundary organisations was coined by Guston (Guston, 1999) for the task of aligning the 'relatively distinct domains of politics and science' (Beratan et al., 2004). In theory, boundary organisations span the realms of science, practice and policy as well as the gaps between agencies and organisations informed by and adhering to strong but different knowledge frames. Via mediation, translations, and the creation of arenas for debate, boundary organisations can engage in building responsive, trust-based and long-lived relationships between science, policy, practice, stakeholders and the general public (Beratan et al., 2004). In so doing, boundary organisations should meet the sustainability requirement of performing iterative and collaborative processes. Thus, they must keep the interest of all parties in mind, while being accountable in distinct ways to each of them, and remaining stable against external forces. The dependence of a boundary organisation is thus as important as its independence (Guston, 2001) meaning that its mandate is to be 'partially responsible to both -but not expected to operate fully by the norms of either' (Clark, 2003). Yet, in reality, many scholars point to the difficulties in 'meshing different knowledge systems for collaborative research and policy making' (Larson et al., 2009). The increasing research on boundary networks reflects the complexity and high demands on flexibility in boundary work (Schneider et al., 2003). The literature refers to boundary spanning individuals who facilitate interaction within and between actors (Miller, 2009) and who serve as brokers, interpreters and policy entrepreneurs in linking knowledge to action (Williams, 2002). In sum, boundary work performed by individuals, organisations or networks serves several functions: it facilitates the bridging of organisations; it filters information and thereby buffers organisations against external exposure; and it feeds information flows to the outside in order to exert external influence. In case of stress, conflict and ethical dilemmas boundary work can cause friction or imply powerful gate-keeping (Aldrich and Herker, 1977;Fennell and Alexander, 1987). In our analysis, we refer to boundary work that is facilitating.",
            "Frames, framing and reframing": " Analytic frames emerge from theory and serve as starting points for generating questions, hypotheses or propositions. Frames influence the choice of research design which guides data construction and interpretation (Ragin, 1994). Without frames research would proceed slowly. Frames tend to be fixed in quantitative research, flexible in comparative research and fluid in qualitative research (Ragin, 1994). We use a flexible analytical frame and transition theory to investigate and compare how sustainability impasses emerge and can be resolved. In social research the way in which a research problem is formulated in relation to theory is called the act of analytic framing (Ragin, 1994). Similarly, within psychology, the way in which a party describes or defines a conflict is known as problem framing (Spangler, 2003). Methods for interpreting and translating empirical observations into research questions can also be seen as framing. From the 1930s, several scholars have offered insights into the meaning and use of frames (Burke, 1936;Mills, 1940;Bateson, 1955;Goffman, 1974;Coyne, 1985). Frames can be descriptive, explanatory or prescriptive; perpetuated, modified or changed. They can be distinct, rigid and static or ambiguous, open and dynamic. Frames are often embedded in narratives that start defining the problem and then elaborate its consequences and outline its solutions (Roe, 1994). Frames and their narratives are scientifically and politically important because they define how we understand the issue at hand, which may, in turn, have implications for the policy options and interventions that we choose (Leach et al., 2010: 49). In sum, analytic framing is the practical use of theory on a certain topic, for some purpose and for the sake of: asking certain questions, including or excluding certain aspects or linking sometimes unrelated issues and concepts. When we observe frames and then reframe issues in this article, we follow Lakoff (Lakoff, 2006a) who suggests that 'frames are mental structures that allow human beings to understand reality'. This means that frames are fundamental to our thinking and equally important in everyday life, politics and science. From this follows that reframing, whereby issues are shifted between frames, is fundamental and has real social implications. We proceed from the idea that frames are more than a system of concepts; a frame is 'a conceptual structure used in thinking' (Lakoff, 2006a). This underlines dynamic interactions between language (words, concepts) and cognition (thinking) meaning that words evoke frames; language evokes moral and conceptual frames; the negation of a frame evokes the frame; and the evoking of a frame reinforces it (Lakoff, 2006b). Lakoff and Ferguson stress the importance of framing and remind us that 'each framing defines the problem in its own way' (Lakoff and Ferguson, 2006). Lakoff also points to how framing is used for supplying alternative stories and scenarios that can help change and replace existing views (Jarratt and Mahaffie, 2009). Hence, we see that frames, like theory, come from somewhere, serve a purpose and are never neutral (Cox, 1981). Framing builds on constructivism meaning that the world can be described and understood in various ways with each frame resting on certain assumptions. From this follows that reframing is a process of shifting one's thinking into a different system and structure of concepts, language and cognitions. It is also clear that reframing can trigger redefinitions of problems, dilemmas or conflicts and thus reveal new facets that may support resolution. Well-known questions can be reformulated whereupon hidden aspects emerge while the fundamental meaning and certain facts remain (Spangler, 2003). Problem solving and the posing of questions are therefore generic to reframing. This makes reframing powerful because it changes perceptions of what to ask, how to investigate, and how to act upon a subject. Thus, it has performative implications. If no single available frame is optimal for understanding or solving the problem, then reframing can serve to show the complexity and diversity of an issue; point out possible driving forces and interpretations; and shape practical solutions to act upon. In reframing the capacity to associate across theoretical, empirical and disciplinary divides is therefore highly valued. Owing to strong paradigms in the natural sciences, reframing may therein be seen as alien or even unscientific. However, in history and the social sciences reframing is a common research strategy for reconfiguring core problems, dilemmas or clashing paradigms. Take the polemic development debate as an example where development can be seen as a stage in a linear process (modernisation theory), or as an asymmetrical relationship (dependency theory), or as an invention of the West imposed on 'the Rest' (post development theory). In addition, questions on how a country grows rich (modernisation theory) can be turned into an inquiry of why a country stays poor (structuralism) or why a country ends up in a downward spiral of getting even poorer and underdeveloped (dependency theory). The distinct variation between frames in development theory emerges from the underlying ideology and ontology of grand theory. But despite the consensus across many development theories that development should entail a broad vision of liberation, freedom and poverty reduction (Martinussen, 1997), a stiff analytical frame may still emerge and give rise to competing goals, means and targets. In sum, the 'acceptance of a frame allows its user to perceive, identify, and label the events that are occurring, but it may also involve taking a particular attitude toward them' (Coyne, 1985) (337-338). This means that frames can offer distinctly different perceptions of and answers to the question 'what goes on here'. The act of formulating a frame for an ambiguous situation is therefore not neutral and this has 'important implications for what follows' (Coyne, 1985: 338). This resonates with Lakoff and Ferguson (Lakoff and Ferguson, 2006) who show how the rhetoric around an issue, i.e. an issue-defining frame, includes certain aspects while precluding others, thereby pre-empting many considerations from entering the debate and blocking fuller understandings. An observer viewing through a narrow frame may think that all aspects are included in the discussion while reframing would disclose that the problem runs (much) broader and deeper. Such context stripping means that the issue is not properly contextualized in time, space and theory thus leading to deliberate or non-deliberate misinterpretations (Guba and Lincoln, 1994). Overall, we distinguish three types of reframing: interpretative approaches in conflict resolution (Spangler, 2003), semantic approaches in discourse analysis (Doremus, 2000) and structural approaches for uncovering underlying themes, stressing suppressed aspects and tracing power contents. Drawing mainly on Lakoff (Lakoff, 2006b), and by combining semantic and structural reframing, we will change the ontology describing the problem (what exists?) and the epistemology explaining it (what and how can we know about it?). We thus shift issues from dominating or competing frames into a new analytical or empirical context that may offer new scopes, data and results that challenge previous understandings. Moreover, and as a further analytical step, the transition barriers that hamper progress will be located on/between the analytical levels (and temporal scales) of transition theory.",
            "Transition theory and transition barriers": " Social and economic change entails profound alterations in structures, institutions and social relations and as a result, society, or a subsystem thereof, starts operating according to new assumptions, rules and practices. Rooted in social theory and technology systems studies, transition theory is an approach, i.e. a middle range theory, for understanding long term social transformation (Rotmans et al., 2001;Foxon, 2007;Grin et al., 2010;Geels, 2011). Transition research comprises three important components, the multi-level heuristic (landscape, regime, niches), the multi-phase scheme (pre-development, take-off, acceleration, stabilisation) and transition management. The multi-level heuristic deals with structural arrangements and interactions in transition problems and processes while the multi-phase scheme deals with the sequencing and temporal aspects in transition processes. Transition management refers to how actors obstruct or promote change and how they adapt to and learn from transition processes. (Loorbach et al., 2010). A multi-level perspective and the transition theory heuristic can be used to identify overall institutional arrangements, locate deep structures or patterns and analyse the dynamics between ideas, values and interventions (Geels, 2011). It has three interacting analytical levels: landscape, regime and niches. The landscape involves slowly changing bio-geo-physical, political and social structures such as the natural environment, infrastructure, international institutions and macro-economic conditions. Structures on this level are not easily changed by any single actor or event. The politics of global health, as discussed here, is mainly defined and located on this level. The regime level interacts with the landscape level and consists of a complex web of actors, structures and institutions governing, supporting and reinforcing the predominant practices. In our case the implementation of health care is located and thus defined on this level through health care systems supported by science and education. The niches level refers to actors, groups of actors, whole professions or technologies operating according to particular knowledge and practices (Rotmans et al., 2001;Geels, 2002). While niches belong to the system, they embody the possibility of change and thus have ability to mobilize resources, power, for the sake of challenging dominant actors, practices, institutions and structures (Avelino andRotmans, 2009, 2010). Changes on the landscape level can facilitate or trigger such niche initiatives, or vice versa, thus an example of multilevel interaction and dynamics in transition theory; often for the purpose of challenging the regime level. In our example health care clinics, practitioners and those of their technologies that challenge the dominant practice represent niches. Regarding the persistent problems in global health that we observe here, interactions trigger processes that result in sustainability impasses. Inspired by transition theory, transition heuristics and transition management, we show in the analysis how impasses in global health result from interactions within and between levels and at different temporal scales. As described in Section 1, we suggest a typology of three types of transition barriers causing the sustainability impasses: policy cooptation, techno-institutional lock-ins, and knowledge traps. The barriers can coincide and reinforce each other as we will discuss in the analysis. We argue that policy cooptations take place at the landscape level when new interests interfere with, divert or take over a particular policy area and subsequently influence the regime. A policy cooptation will influence the regime and orient it towards specific goals and issues while ignoring others. The fact that international trade and commercial interests influence global health policies is an example as we show below. Techno-institutional lock-ins will develop between the regime and the dominant practice and technology that they support. Lock-ins involve mutually reinforcing interaction regarding technology, infrastructure, knowledge and institutions. Techno-institutional lock-ins are primarily driven by path-dependence of sunk costs (Pierson, 2000;David, 2001) or increasing returns to scale (Unruh, 2000;Foxon, 2007). The large scale development intervention of distributing insecticide treated bed nets as malaria prevention (WHO, 2009) serves as a telling example. Knowledge traps are primarily found between a niche and the regime level where researchers and practitioners operate within certain scientific disciplines, organisations, paradigms or knowledge realms, and may result from too much disciplinary and/or organisational specialisation, or what we called compartmentalisation in the introduction. For the purpose of change and transformation, the transition management cycle encompasses a sequence of tasks starting from the initial strategic and tactical phase of (re)structuring the problem, envisioning sustainability pathways and setting up a transition arena followed by the operational phase of organising and performing experiments in the transition arena. This, in turn, is followed by a reflexive phase serving to evaluate and feed new learning into the cycle to be repeated and monitored (Loorbach and Rotmans, 2006;Loorbach, 2010). Proceeding from these concepts we move on to the global health discussion.",
            "Reframing three sustainability impasses in global health": " Given that social change starts at different spatial and temporal scales in society we need a range of theories to locate, interpret and explain such emerging change. Here framing and reframing enter the picture as they help us switch between perspectives and give prominence to a variety of theories and scientific understandings. In the analysis we will identify frames, locate transition barriers and show how reframing can be used on sustainability impasses in global health using HIV/AIDS, malaria, and Indoor Air Pollution (IAP) as illustrations. As an entry point, we offer a brief account of the current frames in global health policies. International health policy is a relatively recent phenomenon initiated by the World Health Organization (WHO) in the late 1970s (Kickbusch, 2000). Since then it has shifted to become Global Health (GH) referring to health needs of all peoples regardless of nationality. This shift increased both the scope of health issues that society deals with and the range of actors involved, from governments to a wide range of private, public, private-public partnerships and non-governmental stakeholders of national or international origin (Brown et al., 2006). There are competing views, in fact frames, on GH as illustrated by a range of metaphors that describe and frame global health policies: GH as security; GH as foreign policy; GH as a market; GH as investment; GH as public health; GH as charity; GH as social justice; and GH as human rights (Stuckler and McKee, 2008;Kickbusch and Told, 2009). Using transition theory we identify four instances of policy cooptation at the landscape level: First, there has been a shift from national and publicly funded health care systems towards private actors (Ollila, 2005;Prah-Ruger, 2007) who act independently or in public-private partnerships (Reich, 2000). Secondly, there is a shift in global health policy from health organisations, such as the WHO, to financial organisations such as the World Bank, the IMF and the WTO (Koivusalo, 1999). This is reflected partly in the fact that the World Bank in 1993 devoted the World Development Report, called 'Investing in Health', to the issue of how improvements in global health should be financed (WorldBank, 1993). In addition, the influential Commission on Macroeconomics and Health (CMH), initiated by the WHO in 2000 (Sachs, 2001), resulted in a comprehensive and concrete plan for advancing a global health policy resonating with the World Bank view from the WDR 1993 (Waitzkin, 2003). While only three persons in the CMH represented medicine and health, fifteen of the eighteen commissioners were economists or business people, and fifteen of the commissioners had ties to international or national financial institutions (Sachs, 2001). Thirdly, the USA is becoming a dominant player in global health policy, especially since the 9/11 event in 2001 when the US turned global health into a national security issue (Kickbusch, 2002). The metaphor 'war on disease' was coined already in the 1990s but was used increasingly after 2001, inspired by George W. Bush's 'war on terror' (Fidler, 2004). In Fig. 1, we show the increase in the occurrence of the 'war' metaphor in scholarly documents related to health, since 1991. Fourthly, from 2000 the Millennium Development Goals (MDGs) influence the framing of global health policies. The MDGs have been instrumental in shifting the emphasis of health policies from broad based systems of health services aimed at general disease prevention towards focused interventions on a few infectious diseases, notably HIV/AIDS, malaria and tuberculosis (Ollila, 2005;Marchal et al., 2009). In addition to these policy cooptations -wherein GH has been framed, focused and financed in certain directions -GH is characterised by several techno-institutional lock-ins. They have all emerged due to enormous sunk costs in laboratory and other research infrastructure and the long term nature of vaccine research requiring at least eight to ten years of clinical trials for each vaccine candidate (Cohen, 2008). This, in turn, triggers knowledge traps that prevent alternative understandings and practices. We now proceed to our reframing of three sustainability impasses in global health. In Table 1, we summarise the dominating frames, the transition barriers and the new frames that appear after the reframing process. For our purpose here, we have identified four main strategic and organisational shifts regarding global health, which may have serious consequences for adaptation to climate and environmental change. Firstly, the shift from comprehensive to specialised health care focusing on specific diseases (Ollila, 2005). Secondly, the shift from preventive to curative health care (Esser, 2009). Thirdly, the shift from state actors to public-private and private actors as agenda setters and funders (Ollila, 2005;Prah-Ruger, 2007). Fourthly, the shift from health agencies to financial actors as policy drivers (Koivusalo, 1999;Birn, 2009). The global HIV incidence probably peaked in the late 1990s but is declining very slowly and at a very high cost. With the current trend, costs will increase threefold and there may still be one million new infections by 2030 (Hecht et al., 2009). Even if effective treatment is available, the cost of universal access to it is unrealistic (Bongaarts and Over, 2010). This calls for new ideas for approaching the HIV/AIDS pandemic. In industrialised countries, HIV/AIDS is mainly contracted by individuals, of both sexes, who are drug users and sex workers or by men who are homosexual whereas none of these groups dominates in the HIV/AIDS statistics in sub-Saharan Africa (UNAIDS, 2009). If HIV/AIDS is an infectious disease that is theoretically fairly easy to avoid compared to an airborne disease like tuberculosis or a vector borne disease like malaria, then it is pertinent to find out why HIV/AIDS is so widely spread throughout the population in sub-Saharan Africa. As an infection, HIV/AIDS is caused by a virus that is transmitted from person to person through exchange of bodily fluids, mainly semen and blood. Prevention can thus be a matter of using vaccine and/or condoms. This is reflected in the overwhelmingly strong consensus in the medical research community that we should address the HIV/AIDS pandemic by promoting the use of male/female condoms and ultimately by developing a vaccine. Even if all medical expertise seems to agree that finding a vaccine for HIV/AIDS will be enormously difficult, time consuming and expensive, there seems to be an agreement that a vaccine is the only solution (Desrosiers, 2004;Simon et al., 2006;Titti et al., 2007) as clearly illustrated by Walker stating that 'the global need is absolutely desperate, and this is an endeavour that must be pursued, now with greater passion than ever' (Walker and Burton, 2008). The debate on vaccine is thus epitomised by Bernstein's claim that 'there cannot be any alternative' (Bernstein, 2008). In transition theory terms, the regime consists of a strong alliance between medical and pharmaceutical research, funding organisations, health services and corresponding governance systems such as ministries, regional authorities and/or NGOs. A closer look at the data on the HIV/AIDS prevalence shows that women in SSA have a much higher prevalence than men and in some countries young women are up to eight times more likely to be infected than men (UNAIDS, 2010). For biological reasons women are to some extent more vulnerable to HIV/AIDS but this is not enough to explain the staggering figures (Mukherjee, 2007) especially not in South Africa where young women (15-24) account for ninety per cent of new infections (UNAIDS, 2007). In a multi-country study in 2005, the WHO reported horrifyingly high levels of violence against women (Garc\u00eda-Moreno et al., 2005). If we reframe HIV/AIDS from a virulent disease only to the symptom also of a social problem, then the spread of the disease can be seen as the result of violence against women with unwanted sex, even rape, as one way of transmitting the disease (Dunkle et al., 2004;Mukherjee, 2007;Kalichman et al., 2009). Gender mainstreaming is common in programmes for HIV/AIDS prevention but often with a focus on girls and young women as vulnerable groups while ignoring men as agents. A further reframing along the lines of intersectionality could shift the focus from girls and young women as victims to men of all ages as potential perpetrators of sexual violence (Barker and Ricardo, 2005). A focus on law enforcement and crime preventive measures for perpetrators of violence against women combined with awareness raising among (young) men could be a means to fight the proliferation of HIV/AIDS (Barker and Ricardo, 2005). This underlines the role of governance and legal enforcement and is thus a task for the regime level. A vaccine or a protective gel, which currently seems to be the most promising technology (UNAIDS, 2010), may solve the medical problem but it would leave the social problem of violence against women unaffected whereas a feminist perspective may consider the epidemic as an opportunity to rid society of this type of violence against women as a structural problem. In sum, we argue that fighting violence against women as a preventive measure may be a promising and more persistent way forward than fighting the virus (only). Anti-violence campaigns would involve many beneficiaries already at the very start while the development and deployment of a vaccine would bring beneficiaries only in the longer term. This draws attention to temporal aspects and dimensions of social justice. Besides, we would avoid the problem of drug resistance, because with pharmaceutical solutions the race against resistance starts immediately and this is now the most serious barrier for effective containment of the disease through antiretroviral drugs (Simon et al., 2006). Finally, there are enormous ancillary benefits from ridding society of violence against women as a long-lasting physical and mental social conflict with multiple causes and consequences. The occurrence and prevention of a major disease, like HIV/AIDS, can thus, as illustrated here, be conceptualised and understood in numerous ways such as in terms of biomedicine or psychology; cognitive and behavioural models; political economy of health and lifestyles; or power perspectives and feminist theory. Any one frame thus shifts the meaning and generates a different set of key questions, understandings and actions (Zierler and Krieger, 1997). In the UN system there are at least three main units for addressing violence: the WHO, the UNICEF and UNESCO. We argue that boundary work across these entities could harness the differentiated knowledge and experiences in the organisations and create effective ways for alleviating the double menace of HIV/AIDS and violence against women. In February 2010, the UN appointed the former EU Commissioner Margot Wallstr\u00f6m a 'Special Representative for Sexual Violence'. This position can be seen as one facilitating boundary organisation for fighting the violence against women. We argue that the general policy cooptation in GH has created a strong regime dominated by a medical understanding involving heavy investments in bio-medical R&D and the promotion of drugs and vaccine. Important as this may be, it also creates techno-institutional lock-ins and knowledge traps where alternative understandings of fundamental social relations could have contributed solutions and important ancillary benefits. From an organisational and institutional point of view, and as a positive note on this impasse, there is a closer connection between the medical and the social analytical frames of HIV/AIDS discussed above than between the chemical and the ecological frame on malaria to be discussed below.",
            "Reframing the fight against malaria from chemistry and medicine to ecology": " Malaria is the most important vector borne disease in the world and as one of humankind's oldest diseases it has plagued us for at least 4000 years (Cohen, 2009). The geographical area affected by malaria has shrunk significantly over the last 100 years, from about 58 to 30 percent of the global land area (Hay et al., 2009). But in terms of reported cases of malaria in the core areas, mainly tropical Africa, the numbers are a staggering 243 million clinical cases and 863 000 deaths in 2008 (WHO, 2010). Malaria has been fought within different scientific frames and mostly within one single frame at a time. In a vector borne disease the pathogen is carried from one host to another by a vector such as a mosquito, a fly or a worm. From a treatment point of view, vector borne diseases can be approached either through the vector and its natural habitat or through the pathogen inside or outside the human body. The earliest successful measures were entirely based on land use change and physical planning that aimed at ridding an area of the vectors including their breeding grounds. Notably, the implementing institutions were responsible for land use planning and infrastructure rather than health. There are several good historical examples of this like the protection of the town Selinus in Sicily by the flooding of a nearby marshland in the fifth century BC; rural development in southern Italy in the early 20th century (Martin and Najera, 1972); the integration of malaria control and economic development in the Tennessee Valley in USA in 1933-1979(Gartrell et al., 1981)); and pre WW-II integrated measures in Malaysia (Field and Reid, 1956) and Indonesia (Snellen, 1988). Improvement in these cases was long-lasting but costly in terms of capital, labour and time. The innovation of DDT in 1942 completely changed the malaria fight and its framing from ecological means to chemical (Sharma et al., 1991). Starting in 1948, the WHO embarked on a wide-spread international campaign to control and eradicate malaria through DDT. The implementing organisations were aligned with science in a common frame wherein the pesticide-oriented eradication policy was informed by an overly strong faith in certain scientific claims, such as: Pasteur's idea that man could eradicate all parasitic diseases; Chapin's idea that any disease that could be prevented in part could be prevented entirely; or that elimination of a disease from one area could be scaled up indefinitely (Najera, 1989). But malaria eradication failed in the 1960s due to widespread resistance, armed conflicts and population mobility (Hamoudi and Sachs, 1990;Sharma et al., 1991;Sharma, 1996). In the early 1990s, the WHO vaguely mentioned the ecological method of vector control in 'A Global Strategy for Malaria Control' (WHO, 1993). Yet, the subsequent 'Roll Back Malaria Programme' (RBM) starting in 1998 was entirely focused on the use of insecticide treated nets (ITN) and had very meagre if any results; some scholars even argue that the problem worsened (Yamey, 2004). The RBM was a top-down initiative to increase the funding for insecticides, drugs and bed nets as epitomised by the Jeffrey Sachs statement on malaria fighting: 'if you invest money, you get results' (Carter, 2002). In 2008, vaccines, drugs and insecticides were combined in a new attempt to eradicate malaria (Roberts and Enserink, 2007;McNeill, 2008;Kappe et al., 2010). The fight against malaria was thus reframed from a chemical into a pharmaceutical and medical issue. Like previous attempts, it is based on a massive deployment of technology underpinned by a strong conviction that global management and control is possible and can be executed by a few influential actors. Hence, in the new attempt there is a tight alignment between different parts of the regime such as funding (the Bill and Melinda Gates Foundation), science (bio-technology) and action (the WHO). However, the evolution of resistance, either among the vectors or the parasites, is a problem whenever chemical and pharmaceutical solutions are deployed. The risk of resistance can be reduced by restricting the use of chemicals and pharmaceuticals to a minimum. If the fight against malaria is reframed from a medical issue to an ecological issue we can use the analogy of integrated pest management in agriculture (Kogan, 1998). Integrated vector management could then become a new frame for fighting malaria. Such attempts are emerging but only slowly. An Internet search on scientific papers in March 2011, gives 770 700 hits for 'integrated pest management' and only 750 hits for 'integrated vector management'. Integrated pest and vector management is a complex and comprehensive process for managing pest populations but we argue that it offers more opportunities for action against malaria. It includes: planning and managing ecosystems to reduce the breeding grounds of vectors; continuous monitoring for early detection of epidemics; protecting humans from the vectors in order to break transmission paths; early diagnosis; plus careful use of pesticides in order to minimise the risk of resistance. It would reduce the proliferation of resistance to chemical and pharmaceutical control measures and create a number of ancillary benefits for communities in malaria prone regions. Last but not least, history shows that the only examples of long-lasting elimination of malaria were achieved by combinations of ecological, chemical, technical (bed nets) and pharmaceutical measures (Sharma et al., 1991). Moreover, such management would provide the enormous ancillary benefit of turning people who are poor from passive victims of malaria in need of international aid into active agents participating in prevention work through ecosystem management. From an organisational point of view, there are no global agencies today that are suitable for handling such integrated approaches. In the UN system there are at least four key units in the puzzle: the WHO for medical and human health issues, the FAO for land resource issues, UNEP for environmental issues, and UNHABITAT for issues related to human settlements. We argue that scientifically and practically informed boundary work can provide necessary transfer of knowledge, experience, technology and funds between the entities; thus a simpler and more productive way forward than creating new organisations for fighting malaria. We have now seen how the fight against malaria has shifted over time between ecological, chemical, pharmaceutical and technical frames in various attempts either to eradicate the vector and/or the parasite or prevent the vector from reaching and infecting humans. A techno-institutional lock-in may develop on the regime level when there is a mutual reinforcing relationship between the regime and the dominant practice. If distribution of insecticide treated nets is the dominant practice for fighting malaria, then the regime gears all its efforts into creating the necessary infrastructure for effectively manufacturing and distributing these nets, thus blocking alternative practices. As a consequence, a knowledge trap may develop preventing the acceptance of initiatives from the niche level because the dominant practice has resulted in too high specialisation of practitioners. This calls for more integrated approaches as mentioned above. In response to global health issues like HIV/AIDS, malaria and other infectious diseases the international community has reacted forcefully, although not always successfully, with drugs, vaccines and bed-nets. In-door air pollution (IAP), however, is still a neglected health hazard with very little progress as discussed below.",
            "Reframing cooking from an energy and deforestation issue to a health issue": " In-door air pollution (IAP) is a sustainability impasse causing respiratory diseases killing almost twice as many people annually as malaria (WHO, 2009). Every year over 1.6 million people, mainly women and children, die of respiratory diseases from IAP owing to cooking over open fire (Ramirez-Venegas et al., 2006). But the problem is preventable. A majority of the world's poorest rural, peri-urban and urban households cook over open fire encased by three stones. In the 1970s and 1980s, the inefficient use of fuel wood was framed as a rural energy and deforestation problem (Eckholm, 1975;Allen and Barnes, 1985) and as a result, the distribution of fuel efficient wood stoves became a popular activity for many development agencies in their quest for solutions to deforestation (Manibog, 1984). However, low adoption rates of the fuel efficient stoves meant that only marginal progress was achieved (Wallmo and Jacobson, 1998;El Tayeb Muneer and Mukhtar Mohamed, 2003). We argue that the failure was rooted in the scientific framing of deforestation. Foresters as regime players dominated the field with their knowledge and saw the improved stoves mainly as fuel efficient energy savers that could reduce deforestation. This resulted in a knowledge trap. The three stones arrangement is not only fuel inefficient but also smoky. A review of a large number of improved cooking-stove programmes around the world indicate that many more programmes were aimed at promoting energy saving for forest conservation than smoke reduction for health purposes (Wallmo and Jacobson, 1998). Although energy use efficiency and forest conservation are legitimate reasons for intervention, this means that science at that time prioritized energy efficiency over health improvements by framing cooking-stoves mainly as an energy-issue relating to deforestation. More recently, improved cooking stoves are regarded much more favourably by the scientific community when seen not only as energy savers but also as health improvers (Ezzati and Kammen, 2002;Ezzati et al., 2004;Sinton et al., 2004;Bailis et al., 2007;Sagar and Kartha, 2007;Berrueta et al., 2008). The health effects of cooking in smokeless kitchens compared to the 'three stones' are wide ranging and we here list four of them: (1) decreasing illness, particularly respiratory diseases, and thus lower health expenses; (2) less time needed for collection of fuel wood leading to increasing opportunities for children and youth to attend school and for women, given the intersectional labour division, to plan and perform more productive tasks, or to experience more leisure time; (3) lower demand for wood resulting in less deforestation and reduced greenhouse gas emission; and (4) improved conditions for biodiversity and other environmental qualities. Results from our intervention research in western Kenya in 2007-2011, where we collaborate with peasant farmers in small-scale experiments on domestic energy efficiency, show that subsistence farmers are eager to adopt an improved stove if reframed from an energy issue (fuel efficient stoves) into a health issue (smoke free kitchens with flue-piped stoves). The project 2 that we initiated, builds on local conditions, materials and expertise in subsistence farming and two main conclusions can be drawn. First, users were more likely to adopt stoves when these were reframed into a health issue while energy saving followed as an ancillary benefit. Secondly, we have facilitated the adoption of the smokeless kitchen with the help of a local person who performs boundary work. We assisted him in how to combine scientific insights with a community based scheme for financing, installing and following up the social learning generated from the use of the stoves (Olsson and Jerneck, 2010). Given the severity of IAP and the availability of simple and effective solutions, it may seem strange that there is no global initiative addressing IAP. At the landscape level of the transition heuristic, there is a void meaning that IAP is neither addressed nor seized. In a scenario where 'GH as a market' is a dominating frame, the lack of a global initiative is logical because no easily defined international market players can reap the benefits. These benefits would instead be shared by at least one billion people who are poor and cook under health threatening conditions. In a scenario dominated by either of the frames 'GH as public health' or 'GH as social justice', let alone 'GH as human right', the IAP issue would be a very worthwhile health initiative. The project demonstrates that co-production on transition arenas with experiments and learning processes (Loorbach and Rotmans, 2006) can be successful but also very demanding. First, and as a precondition for co-production, we did intensive field work on subsistence farming as a social-ecological system. Secondly, and as an outcome of the project, the diffusion of stoves with flue-pipes for the smokeless kitchen needs sustained support and feed-back from science, practice and policy. Apart from its health effects and ancillary benefits the initiative would be highly cost effective (Olsson and Jerneck, 2010) and it may have a range of interesting and positive gender effects (Jerneck and Olsson, 2011). Inspired by the transition management cycle (Loorbach, 2010), as mentioned at the end of Section 4, and other iterative social learning processes such as Integrated Sustainability Assessment, ISA, (Weaver and Rotmans, 2006) we set up an experiment with peasant farmers on smoke-free kitchens to address the persistent problem of IAP. Participants in our research project in subsistence farming all suffered the discomfort from smoke and the health effects of the persistent problem of IAP and everyone articulated the same problem. Based on this perception, we sought out the underlying causes of the problem, structured the local knowledge around it and envisioned possible short term and long term solutions with the smoke free kitchen as a common vision and image. As researchers cooperating with and drawing on local expertise and competencies we were instrumental in problem structuring, in envisioning change, in designing a transition agenda and in mobilizing actors who would work in favour of the image of a smoke-free kitchen. In the critical selection of frontrunners we identified: Rose as a potter for constructing the stove, her husband Leonardo as a carpenter for building the kitchen, Boaz as a local welder and a tinsmith for welding the fluepipe, a handful of women in the village for testing the new stove with a flue pipe to be installed in their kitchen, and Benson as a technician for coordinating the activities and fine-tuning the actors' individual plans. According to Loorbach (Loorbach, 2010) transition experiments need continuous monitoring and feedback to participants on their actions, interactions and responsibilities. Equally, monitoring involves collective reflections on the process and its progress. In this particular setting we were successful in identifying the problem by envisioning a more sustainable future with smokeless kitchens, in performing the participatory experiments on the transition arena and in showing how change can emerge on niches level if we build on and support community capacity. However, due to the local context of poverty, ill-health and weak physical infrastructure we are not yet able to perform all the procedures. The longer term idea (and hope) is that participants will learn from the experiment and translate this into further problem solving, like water harvesting, and possible up-scaling.",
            "Conclusions, implications and procedures": " In this article we used frame analysis and reframing as well as transition theory and transition management as a multiple method of inquiry for thinking and theorising about persistent problems and sustainability impasses in global health. Moreover, we related the persistent global health problems to environmental innovations as well as to climate change impacts and responses. In the discussion, we used frame analysis to identify how the problems are encased by certain disciplinary understandings. We then used the transition theory heuristic to locate three types of transition barriers in relation to the landscape, regime and niches level. Finally, we used reframing to change the perspective (ontology, epistemology, theory) from which we study the problems or to relocate and change the empirical context of the problem, or both. Such redefinitions and relocations serve the purpose of thinking about problems in new ways and uncovering aspects that may facilitate problem solving. To that end we also identified how boundary work across knowledge barriers may serve as a bridge between knowledge producing units and how transition management, when applicable, can involve stakeholders in experiments and social learning. Concerning frame analysis, philosophers and linguists have discussed the implications of the layering between and within frames as well as the interaction between layers (Coyne, 1985;Lakoff, 2008). The differentiating between frames, their layers, messages and messengers is demanding and time consuming. This complexity makes frame analysis somewhat heavy and inaccessible and it can be hard to determine when the full picture of a problem has emerged. In addition, reframing presupposes lateral thinking across disciplinary, interdisciplinary and transdisciplinary boundaries. Nevertheless, the 'polymorphous quality' of frames (Coyne, 1985: 340) is a strong reason for identifying and examining the actual frames that circumscribe our thinking and postpone sustainability transitions. Regarding the process of problem understanding, reframing as a critical method is productive for: seeking its roots; identifying agents; making hidden structures, actors and power relations visible; reaching a fuller scientific understanding of an issue and its drivers; finding alternative explanations and presenting them within frames conducive for problem resolution. Regarding the process of problem resolution, reframing as a critical method is productive for: revealing incomplete solutions and/or undesirable consequences of incomplete solutions; discovering missed opportunities and identifying additional benefits of alternative solutions; assessing potential solutions, identifying agents of change and suggesting action. Reframing is thus a powerful tool for linking critical research with problem solving research (Cox, 1981) as we did here. In order to illustrate reframing in practice we include a procedural scheme in Fig. 2. On a final note, the article contributes to methodology for sustainability science by combining frame analysis and reframing with transition theory and transition management into a thinking tool for sustainability challenges. The analysis demonstrated how three persistent problems in global health, impasses, relating to environmental and climate change can be understood in new ways when studied through alternative scientific frames. Thereby, we can conclude that reframing is a creative process that may open up new pathways towards sustainable solutions."
        }
    },
    "10.1016/j.eist.2014.07.001": {
        "file_name": "101 See no evil, hear no evil",
        "title": "Environmental Innovation and Societal Transitions",
        "abstract": "Various scholars have critically reflected upon transition management, some explicitly called for thinking beyond existing paradigms of institutional and deliberative democracy. Taking up this challenge, this paper seeks to explore inherent democratic tensions of managing (socio-technical) transitions. To this end, it presents a \u2018post-foundational\u2019 understanding of democratic politics, contrasting it to traditional notions of democracy that dominate transition approaches. To explore the relationship between transition management and post-foundational democracy, the paper first empirically explores how the democratic politics of an urban regeneration process play out in a Dutch delta city (Rotterdam's city ports). This case illustrates that contrary to traditional conceptions of democracy, a more \u2018extra-institutional\u2019 transition management process can create space for a different type of democratic governance. We argue that post-foundational democracy reframes our understanding of the politics of governing (socio-technical) transitions.",
        "label": "Qualitative",
        "text": {
            "Introduction": " This paper addresses the democratic politics of transition management (TM) by exploring inherent democratic tensions of TM. Transition management (Loorbach, 2010;Rotmans et al., 2001), as a concept and a governance approach, has been adopted in the Netherlands and other countries in the last decade (e.g. Smith and Kern, 2009). This approach provides strategies and tools to reflectively address contemporary challenges (e.g. energy crisis) and develop alternatives at the margins of traditional institutions and incumbent regimes (e.g. by privileging frontrunners and change agents). Various scholars have picked up this concept and critically reflected upon the transition management approach, its practice and its broader political implications. In the broader debates around governance and democracy, as well as in critical discussions about the (lack of) democratic quality of TM, the central issue is the extent to which decision-making processes are inclusive and open or whether decision making processes suffer from a 'democratic deficit'. More specific, some contributions called for thinking beyond existing paradigms of democratic institutions and deliberative democracy (Walker and Shove, 2007;Hendriks and Grin, 2007;Hendriks, 2009;Vo\u00df et al., 2009). In this paper we argue that all democratic decision making processes need to be selective and exclusive to some extent to be productive. But also that it should be possible, from a TM perspective, to be more transparent and thoughtful about the selection and exclusion, and to create more diverse and open processes and democratise dominant conception of decision-making itself. In doing so, we argue that TM can potentially be more democratic than institutionalised democracy, using insights from post-structuralist political theory (e.g. Laclau, Ranci\u00e8re, Lefort) and an illustrative empirical case of urban water transition management in Rotterdam's waterfront regeneration. In many cases of research on socio-technical transitions (e.g. urban water systems), traditional notions of democratic politics seem to be dominant, if they are addressed at all. This is unfortunate, because an alternative conception of democracy can enrich our understanding of socio-technical transitions and their governance. In this paper, we argue that the concept of post-foundational democracy addresses some of the pertinent challenges of the relationship between the management of (socio-technical) transitions and democracy, thereby offering an approach to TM that understands transformative change and radical alternatives in terms of democratic politics. So, instead of presenting transition management as undemocratic in one way or another (technocratic, non-transparent, etc.), we argue that transition management can potentially be highly democratic exactly because it is not firmly rooted in institutionalised democracy. The article is structured as follows. After some general principles of transition management presented in Section 2, the paper zooms in on scholarly contributions that problematise the politics involved in transition management in Section 3. Section 4 discusses some scholarly work that particularly explore the democratic politics of transition management. Building on some suggestions articulated by these scholars and informed by literature on radical democratic theorists, Section 5 presents a post-foundational understanding of democracy that addresses some of the blind spots of traditional notions of democratic politics. Additionally, this section deconstructs an institutionalised conception of democratic politics in transition management scholarship, which opens up the conceptual field for an alternative conception of 'democratic transition management'. Section 6 presents an empirical case of how transition management ideas and practices were introduced and played out in recent activities to regenerate the Rotterdam harbour area (City Ports). The City Ports programmewhich serves as a critical case (cf. Flyvbjerg, 2006) -consists of five strategies aimed at strengthening regional economic structures and improving local working and living environments in a 1600 ha. area of Rotterdam's waterfront. We particularly focus on a strategy aimed at creating sustainable floating houses and working environments (the 'Floating Community strategy'). This empirical case is illustrative, as it expresses how transition management was employed at the intersection of democratic institutions on the one hand (i.e. local government and incumbent networks) and more informal networks and 'extra-institutional' knowledge, imaginaries and practices on the other hand. Section 7 reflects on the empirical case and explores some conceptual linkages between transition management and post-foundational democracy, sensitising transition management as being potentially more democratic than institutionalised democracy. To conclude, we raise some issues of this understanding of democratic transition management.",
            "Transition management: a prescriptive governance approach": " Transition management has been co-developed and adopted by the Dutch government since 2001 (cf. Rotmans et al., 2001;Kemp and Rotmans, 2009). The underlying idea of this approach is that both top-down planning and market-based strategies are insufficient to deliver fundamental and accelerated changes that are needed in areas where our societies face so-called persistent problems: in e.g. energy systems, food production systems, regional and urban area development. The transition management approach combines the insights into the dynamics of transition processes in complex societal systems with new insights from governance theory to formulate so-called guiding principles for governance of transitions (Kemp and Loorbach, 2006;Loorbach, 2007;Loorbach, 2008: 5). Transition management has been further operationalised towards a governance methodology based on selecting particular actors (change agents, frontrunners, policy entrepreneurs) and engaging them in long-term strategic envisioning of sustainable imaginaries, network formation, experimentation and continuous reflexive learning (Loorbach, 2007). Transition management is presented as a prescriptive governance concept that enables contemporary governments and social actors to address and tackle complex problems they are confronted with (often framed as 'sustainability challenges'). As such, transition management can be seen as a particular approach within the wider field of transition studies, using a particular set of assumptions and concepts (Markard et al., 2012;Lachman, 2013). Transition management \"conceptualises the role of agency in transitions and can be used to analyse possibilities for influencing. Transition management therefore necessarily builds on an understanding of transitions from a complex system perspective as basis for development of governance strategies\" (Loorbach, 2007:18). The way in which the complex systems frame is linked to a reflexive governance approach is explicated as follows: \"The basic steering philosophy underlying transition management is that of anticipation and adaptation, starting from a macro-vision on sustainability, building upon bottom-up (micro) initiatives, meanwhile influencing the meso-regime. Goals are not fixed but developed (through a search and learning process) by society and the systems designed to fulfil these goals are accordingly created through a bottom up approach using incremental steps directed towards a long-term goal (e.g. directed incrementalism)\" (Loorbach, 2007: 81). Transition management, in this sense, is an approach that combines hands-on and hands-off tactics and techniques. This means that direct control turns into indirect influence, and predicting 'the future' turns into experimentally exploring 'different futures'. Transition management, as a normative approach for governance activities and socio-political action, consists of a number of different activities and practices. In order to present TM activities, we cluster them for the sake of clarity, informed by the work of Loorbach (2007Loorbach ( , 2010)): \u2022 Strategic: problem structuring and envisioning A key issue at the strategic level is problematisation, which leads to a \"shared conceptualization of the system at hand and the problems it is confronted with, and thereby also create a stronger sense of urgency to act. This broader, systemic conceptualisation and 'problematisation' of a societal problem provides the basis for reframing a societal problem and thus for developing new solutions and strategies\" (Loorbach, 2007: 116). This 'step' is highly relevant as it enables actors to reflect on the very necessity and significance of perusing a specific transition in the first place. \u2022 Tactical: development of sustainability images, pathways, and a transition agenda Changes in perspective, captured in the new discourse that is able to create transformative change at a systemic level, should be further translated to and made concrete within various networks, organisations and institutions at a less abstract level (Loorbach, 2007: 117). This suggests making tactical coalitions with specific organisations and actors that share a similar sense of urgency and are willing and able to further the ambition of realising a (desirable) transition.",
            "\u2022 Operational: initiation and experiments of transition experiments and mobilisation of actors": " This operational level of transition management has the ambition to create spaces for niches and alternative ideas and practices. As Loorbach (2007: 122) describes it: \"Part of the strategy is to involve a broad array of individuals and organisations, even citizens in general, in various forms: through debates, concrete projects, through communication, events, by drawing attention to individuals' initiatives and by calling on people's own responsibilities regarding sustainable development\".",
            "\u2022 Monitoring and evaluating the transition process": " Reflection is a key element in managing transition. This enables one to observe unforeseen consequences and contextualise one's own role. This dimension of \"evaluation and adaptation is (. . .) an explicit part of the transition management model and is used to stimulate modulation and further refinement of the transition management activities at all levels\" (Loorbach, 2007: 123). TM is a set of activities that are not based on these 'formal steps', rather it is a complex process of transformative changes in which dynamic agency plays are pivotal. An exemplary concept is the so-called 'transition arena'. A transition arena can be defined as: \"an innovative participatory process of envisioning, searching, learning and agenda-building aimed at social learning as a means to achieve (sustainable) social change\" (Loorbach, 2007: 44). It is a particular site in which the practice of managing transitions takes place. These arenas should be understood as a model that can be connected to a specific sector (mobility, or health), or to a region. It remains crucial that fundamental change is part and parcel of the process and should be engrained in all the transition management activities. This brings us to political dimension of transition management.",
            "Transition management and its politics": " Recently, various scholars have critically reflected upon socio-technical transitions, their management and broader political implications. For example, Shove and Walker claim that transition management needs to explicate its \"obscure politics\" because of: (1) the high level of abstraction in its theories and practice ('systems', management of the 'it'); (2) the unknown institutional side-effects of managing transition; and (3) the unclear role of the vague and depoliticised notion of 'sustainability'. They also argue that \"there is a politics to transition management, a playing out of power of when and how to decide and when and how to intervene, which cannot be hidden beneath the temporary illusion of 'post-political' common interest claims of sustainability (Swyngedouw, 2007: 5)\". Smith and Stirling state that it \"is unclear how transition management processes sit in relation to prevailing policy institutions and political activities\" (Smith and Stirling, 2010: 9). And as Kern argues: \"If transitions are to a large degree political processes resulting from decisions by multiple actors, then political dimensions should be at the heart of the analysis\" (2010: 26). Similarly, the unclear meaning of the political aspects of sustainability transitions and their management is articulated by Verbong and Loorbach stating that experiments related to transition management, strategic niche management, transition monitoring innovation systems \"raise questions about and prompt debate in the scientific arena (for example related to normative orientation of researchers, legitimacy of interventions and lack of attention to power and politics), and in turn lead to adapted and new strategies\" (Verbong and Loorbach, 2012: 16). This paper focuses on one of the key political challenges of TM, i.e. its link to the idea and practice of democracy.",
            "Debunking democratic transition management": " Research on the governance and democratic politics involved in TM has called for thinking beyond existing paradigms of democratic institutions and deliberative democracy (Hendriks and Grin, 2007;Hendriks, 2009;Vo\u00df et al., 2009). One of the issues these scholars address is the temporality at different systemic levels and localities. That is to say, they highlight the conflicts and tensions that emerge between planning embedded in (traditional) democratic institutions and reflexive governance that is linked to sustainability-led and long-term transformations. We briefly discuss two exemplary contributions that centre-stage such and other concerns in relation to the democratic politics of transition management (Hendriks, 2009;Vo\u00df et al., 2009). Hendriks (2009) discerns three democratic storylines in the Dutch Energy Transition discourse. The dominant storyline, according to Hendriks, was a technocratic-managerial or elitist understanding of democracy (transition 'for the people') highlighting technological innovation and socio-technical solutions. The two other storylines were 'more' democratic; a representative democratic approach by which experts advise elected politicians and authorities; interest group pluralism/neo-corporatism based on the representation and participation of 'relevant stakeholders'. All storylines refer to a specific understanding of democracy providing specific criteria to assess how democratic transition management actually is. Consequently, Hendriks' analysis showed that steering (socio-technical) transitions downplay certain democratic principles. Hendriks proposes to understand 'transition networks' in relation to 'network governance', rendering visible the democratic tensions between everyday practices in transition network and representative institutions (Hendriks, 2009: 257-258). According to Hendriks, transition management practices (e.g. selective participation, organising arena's, assessing experiments) have a difficult relationship with democratic approaches. Hendriks argues that \"[t]hese storylines will need to be expanded if we want democratic considerations such as legitimacy and accountability to be taken seriously in transition processes\" (Hendriks, 2009: 358). For Hendriks this means that \"arguments in favour of democratic transition management may need to be couched in epistemic terms, for example, by arguing that more inclusive and diverse participations can potentially capture more knowledge for innovation\". To this end \"more discursive and agonistic (conflictual) versions of democracy, networks might deepen democracy (see Hendriks, 2008;S\u00f8rensen and Torfing, 2005). For example, networks could open issues up to new participants and ideas (W\u00e4lti et al., 2004), and if radical enough, they might even foster pluralism and dialogue (Bevir, 2006) (Hendriks, 2009: 357)\". Hendriks proposes to engage in more 'polycentric democratic landscapes', referring to the fractured and dynamic character and sites of democratic deliberations and political decision-making. Three types of solutions put forward by Hendriks are to: (1) explicate linkages between official democratic representations and transition networks; (2) to include a wide variety of elites, institutions, actors and materialities in the political process; and (3) to foster the public character of transitions and long-term politics. A similar argument has been made by Vo\u00df, Smith and Grin (2009). These scholars thematise democratic politics of TM in terms of long-term policy and share much of Hendriks' argument. For them \"[t]he difficulty to help 'rational discourse' to unfold and prevent it [TM] from corruption is of general interest when it comes to enriching representative democracy; especially with a view to mitigate myopia and sectoralization. Finding adequate ways to embed long-term policy design in a (changing) framework of democratic institutions is an important area for future conceptual and practical thinking\" (Vo\u00df et al., 2009: 287). Vo\u00df et al. state, for example, that alternative democratic practices should be facilitated by convening \"different transition arenas for dissenting voices, rather than [to] get everyone around the same table\" (Vo\u00df et al., 2009: 293). So, having put democratic politics on the agenda, these scholars address a key political concern for transition management. Hendriks and Vo\u00df et al. propose 'alternative frameworks' and argue that democratic transition management should engage in a 'polycentric' democratic approach to enable the interaction between different types of democratic representation and deliberation in the context of (long-term) societal change. Even though these scholars hint at alternative democratic models (e.g. 'discursive and agonistic (conflictual) versions of democracy', Hendriks, 2009), this alternative -and its practical and conceptual relationship with TM -has not been explored. The contributions of these scholars take us to a new pathway to understand the link between democratic politics and transition management.",
            "The undemocratic fundaments of institutionalised democracy": " In order to reframe the link between transition management and democratic politics, we need to critically interrogate the underlying premises of democratic politics in transition scholarship. Often, democratic politics is understood through a particular socio-historical frame of what democracy entails, which then is employed as a 'grid' for democratic governance. An example Hendriks' proposal to 'extend' or 'expand' democratic deliberative spaces and intertwine formal and informal networks. Such a democratic frame rests on the idea that democracy is a relatively open institutional procedure through which all actors are be able to address their (public) concerns and propose solutions equally. This is not problematic in itself, to be sure, it is part of an intellectual tradition and historically developed socio-political organisations in many Western countries. However, such traditional 'institutionalised' notions of democracy rely on specific frames of democracy (e.g. representation, participation and deliberation). Importantly, whenever democratic frames are institutionalised, they start producing their own political blind spots. For example, to differentiate and oppose democracy against technocracy, assumes modernist and liberal schemes of a public demos that is unfree as soon as it is ruled by technical experience and expert knowledge. The same holds for construing an inherent conflict between transparency and public deliberation on the one hand, and informal or 'underground practices' on the other hand. To be sure, managerialism and technocratic rule are often non-transparent. However, there is no conceptual necessity to consider 'democratic deficits' as givens. It very much depends on one's conception of democracy, as democratic frames and practices articulate contingent boundaries between the democratic vs. the undemocratic. All these more traditional notions of democracy rely on institutional, procedural and/or liberal schemes of democracy 2 (Veeke, 2013). Perceiving transition management through such underlying schemes creates a certain yardstick to assess how democratic transition management might be. We do not argue that these conceptions of democratic politics are incorrect. However, we believe that in order to address some of the democratic challenges of transition management more productively today, we should address the 'undemocratic fundaments' of institutionalised democracy. That is to say, we have to take democracy outside its traditional frames and its comfort zone, i.e. beyond its taken-for-granted institutionalised understanding and governance arrangements. We have to strip democratic idea(l)s from their specific institutionalised semantics (grounded in e.g. 'representational' and 'deliberative' frames) in order to rethink the broader link between democracy and transition management. This 'deconstruction' of the democratic politics troubles the normalised link between (and conflation of) democratic idea(l)s one the one hand and their real world institutionalisation in specific democratic governance arrangements. In this sense, centre-staging a 'non-institutionalised' notion of democracy creates conceptual space to reframe the link between democracy and the management of transitions.",
            "A different entry-point: post-foundational democracy": " Instead of expanding traditional notions of democracy, we employ the concept of post-foundational democracy. This democratic conception moves away from traditional notions of democracy (e.g. representative democracy, pluralist democracy, deliberative democracy) and their a priori 'democratic foundations' (parliaments, ministers, political parties, stakeholder networks, etc.). Post-foundational democracy refers to insights from radical democratic theories, e.g. radical democracy or agonistic democracy. This approach calls into question the 'democratic fundaments' of democratic institutions and deliberative practices and participatory processes (cf. Deveaux, 1999;Fritsch, 2002;Laclau andMouffe, 2001: May, 2008;Ranci\u00e8re, 1999;Van der Veeke, 2013). Post-foundational democracy looks at how democratic 'fundaments', governance decisions and participatory spaces come into being, on the basis of contingent inclusions and exclusions. In our paper, following Hendriks and others (see Section 4), post-foundational democracy is contrasted with more traditional conceptions of democracy. The idea of post-foundational democracy takes as its starting point historical struggle, disagreement and antagonistic relations, not consensus. This approach thus argues that institutionalised forms of democracy are historically produced and contains undemocratic features. Notions like 'consensus', 'agreement', 'contract', 'support' or a 'win-win solution' might sound democratic, but often build on exclusions and produce new antagonisms. A crucial insight of post-foundational democratic politics here is that democratic practice welcomes these antagonisms and their disruptive forces, so as to suspend closure, hierarchy and power relations that emerge when criteria are formulated and decisions are made. Traditional notions of democracy and post-foundational democracy are presented as conflicting here. However, there are some important points of contact. For example, post-foundational democracy would agree with traditional notions of democracy that all members of a political community are equal, but they are equal because of their difference. Not one voter is the same. However, a major difference is that post-foundational democracy would argue that aggregating the demos in this way, the non-demos is excluded (e.g. people that do not have voting rights, illegal immigrants, animals, plants, even material objects). This would make it impossible to have 'true' democratic foundations for decision making. Furthermore, post-foundational democracy might also agree with more networklike frames of democracy, which assume that that the 'political sphere' (state) should not coincide with the 'public sphere' (civil society) for a vivid democratic culture. However, post-foundational democracy would argue that, again, the very criteria for rational deliberations and public debates (e.g. in Habermas' ideal), suppose that all individuals are accepted as equals in public discourse (Michael et al., 1994). Here, post-foundational democracy is clearly distinctive, arguing that all institutions and social formations are historically contingent and carry implicit normative and political assumptions about what is a rational argument, who should speak, what is expected to be said and who counts as a speaking subject (e.g. a voter, a contractor, a transition manager). So, even democratic institutions have undemocratic power relations. To institutionalise democracy is to create an oxymoron. Postfoundational democracy foregrounds excluded and historically marginalised voices and direct them at transforming a social order and its everyday rhythms. It should be noted that we understand postfoundational democracy as different from an anti-foundational or anti-institutionalist position (of which post-foundational democracy is often accused). And instead of understanding 'democracy', 'justice' or 'equality' as mere post-modern illusions or rhetorical trickery, post-foundational democracy would argue that a truly democratic practice foregrounds extra-institutional understandings of such political categories, unleashing their potential to subvert and transform (social, democratic, economic) institutions. Paradoxically, this is where transition management (often seen as post-political) and postfoundational democracy might resonate. The extra-institutional, here, refers to sets of voices, actors and specific concerns that are or have been marginalised by democratic institutions and conventional governance arrangements. This more post-foundational view of democracy is informed by an understanding of politics that is fundamentally different from traditional notions of politics. For example, Jacques Ranci\u00e8re calls social networks and institutionalised norms (including democratic institutions) not politics, but police: \"Politics is generally seen as the set of procedures whereby the aggregation and consent of collectives is achieved, the organization of powers, the distribution of places and roles, and the systems for legitimizing this distribution. I propose to give this system of distribution and legitimization another name. I propose to call it the police\" (Ranci\u00e8re, 1999: 28). For Ranci\u00e8re, politics is something else than struggle within the parameters of democratic foundations. Democratic politics refers to the immanent and un-institutionalised parts of a police (compare police with the conception of regime, Loorbach and Rotmans, 2006;Geels and Schot, 2010) and the insistence to radically transform societal regimes. As Ranci\u00e8re puts it: \"I now propose to reserve the politics [for] whatever breaks with the tangible configuration whereby parties and parts or lack of them are defined by a presupposition that, by definition, has no place in that configuration [created by the police]-that of the part of those who have no part (Ranci\u00e8re, 1999: 29-30). This understanding of politics is thematised differently in literatures on antagonistic politics and post-structuralist conceptions of democracy. Lefort, for example, argues that democracy is 'an empty place' that should always by empty in order to be truly democratic (Lefort and Thompson, 1986), Derrida highlights the virtual and ever sliding nature of democracy as 'a promise', i.e. 'democracy to come' (Fritsch, 2002). In short, post-foundational democracy appreciates conflict, tensions and insurgent action directed towards social change as democratic practice (e.g. Laclau and Mouffe, 2001). 3",
            "Traces of post-foundational democracy in transition research": " In the literature on transitions, such an approach is not totally absent. As mentioned above, Hendriks (2009) briefly speaks of 'discursive and agonistic (conflictual) versions of democracy', Walker and Shove (2007) highlight the contingent and ambivalent nature of 'sustainable development' in the sociotechnical transitions. Walker and Shove argue \"for an extended and more positive view of ambivalence as a normal rather than a pathological state both for individuals faced with changing and uncertain circumstances conditions and for societies working with liberal notions of democracy, debate and deliberation \" (2007: 223). For them, \"(. . .) the critical political challenge is to design forms of governance that foster and sustain ambivalence at the various locations and moments that it appears and emerges over time\" (ibid.). Post-foundational democracy centre-stages ambivalences and radical contingencies that reframe the ways in which democratic institutions and political systems 'do politics'. Not simply to create dissent voices and have 'broader input' based on the same premises and procedures, but also to let excluded forms of knowledge and voices be disruptive by advocating institutional experimentation. For the sake of clarity, we can contrast a post-foundational understanding of democratic politics with more traditional ones. The introduction of the notion post-foundational democracy should be able to assess what critical democratic tensions and challenges are involved in transition management. Before further exploring the relationship between post-foundational democracy and transition management more conceptually, it is instructive to understand how post-foundational democracy might relate to transition management practice.",
            "'Democratic transition management' in practice: city ports programme and floating communities strategy": " This section presents an empirical case to further explore democratic politics of transition management 'on the ground'. We present a strategy called 'Floating Communities strategy', embedded in a broader programme called City Ports aimed at a long-term sustainable transformation of Rotterdam's waterfront.",
            "Some methodological remarks": " We approach this case as a critical case of urban water transition management. By 'critical' we mean that one might expect transition management in this context to be another techno-capitalist transition narrative or at least driven by incumbent actors and socio-technocratic fantasies here (Shove and Walker, 2007;Scrase and Smith, 2009). This makes such a case highly relevant, i.e. as a critical case (Flyvbjerg, 2006), to empirically explore the democratic politics of transition management practice. The main argument of critical case selection is that if one finds X in this case (X = traces of post-foundational democracy, 'extra-institutional practices'), it is likely to find X in other cases (e.g. social movements). Furthermore, it should be noted that it is virtually impossible to discern transition management practices from other activities, as they often merge and intersect with other and prior discourses and types of planning, governance and social interventions. In our reconstruction and analysis of the empirical case, we therefore focus on how transition management discourse and practice merged and mixed into other discourses and practices, together shaping the direction of the democratic governance of the Stadshavens programme. In order to empirically explore democratic politics involved in this case more specific, we reconstructed the Floating Communities strategy, as part of the broader Stadshavens discourse, by focusing on texts and images (legal texts, policy documents, websites, brochures, etc.) (Pink, 2007;Wodak and Meyer, 2009;Rose, 2011). To reconstruct the City Ports programme, and floating communities discourse in particular, empirical material was derived from (policy) documents, semi-structured interviews of a number of key actors (both incumbent players and hidden voices; e.g. different policy makers, small and incumbent architect bureaus, harbour authorities) and website texts and images. The analysis of the floating community discourse is conducted using insights from critical discourse analysis (Fairclough et al., 2011;Fairclough, 1992). Critical discourse analysis (CDA) is instructive, as it pays particular attention to the ways in which texts and speech are treated as modes of action, and social actions are understood as semiotic (Fairclough, 2003;Van Dijk, 2008). Rather than only focussing on political parties and formal programmes, democratic institutions, policy texts and/or deliberative spaces, CDA is useful as it highlights contemporary social change in terms of dynamic interactions between hegemonic discourse and systems and marginalised identities and practices. This analytical approach resonates with transition research and makes it fruitful to describe and analyse both institutional modes of democratic practice and the dialectical relationship with marginal discourses and practices. 4 In other words, the CDA approach is particularly useful because it enables us to grasp institutional as well as extra-institutional democratic practices related to transition management (Geels, 2010). It is our intention to use CDA insights to merely analyse transition management discourse and practices in a specific Dutch urban water case, illustrating its wider democratic principles and practices informed by our theoretical framing of post-foundational democracy.",
            "Stadshavens Rotterdam: city-port conflicts and a transition management approach": " In the early 2000s, the municipality of Rotterdam started to perceive Rotterdam's waterfront as a site for spatial planning and urban development. This became salient after traditional industrial harbour activities started moving towards the estuary, already since the 1950s. The municipality, therefore, had to negotiate with Rotterdam's Port authority to establish new and de-industrialised port functions. 5 In order to plan and execute new plans for the 'post-industrial' waterfront, an organisation was established (OMSR). However, future plans of the Port authorities did not fit urban development plans for e.g. housing and environmental quality. Furthermore, the OMSR was expected to do its work relatively remote from its direct environment (e.g. the municipality and the Port authorities). The differing ambitions between port and city authorities resulted in a period of disagreement and discussions between port officials and city authorities about the future of Rotterdam's waterfront (2004)(2005)(2006). The two-faced nature of the aim to develop the harbour area as part of the city, resulted in a stalemate. A number of events enabled reconciliation and planning potential. First, the establishment of new area for harbour activities near the estuary (Maasvlakte 2) created actual physical space to regenerate city ports and reconsider antagonisms between the harbour 'versus' the city. Second, serious environmental concerns in the 2000s (mainly regarding CO 2 rates) created a sense of urgency to actually diminish traditional industrial harbour-related activities. Third, a new local political coalition and new personnel around the OMSR project management created momentum to leave old dichotomies and distrust behind and start anew (Daamen, 2010). In 2007, the city of Rotterdam Council and the Port of Rotterdam Authority established a dedicated temporary office to develop a strategy for the area. This office (Bureau Stadshavens) worked independently but adopted a transition management approach also informed by the Dutch Research Institute For Transitions, linked to the Erasmus University Rotterdam. Bureau Stadshavens started to organise a broad transition arena process involving over 150 participants that were personally invited. The selection was based on achieving a broad representation of different backgrounds (multi-actor) and personal competences and skills. These actors were often non-experts and had unconventional visions and expectations about meaning role and future of the city ports of Rotterdam. Many of them were not part of the 'usual suspects' that have been working on Rotterdam's waterfront developments in the previous decades. Over the course of six months, this network discussed in various forms and around different themes which kind of 'sustainability challenges' should become central in the urban water development strategy and which type of development and planning process was needed. Combining the diverging interests of the city and the port head on but remote from formal decision-making procedures, a lot of new ideas and future images emerged. These discussions were facilitated by Bureau Stadshavens based on the idea that the area could not be developed in a traditional way through blueprint planning but should be developed in a more experimental and organic way through public-private collaborations and extra-institutional projects (Frantzeskaki et al., 2014). This process created a new understanding of the meaning of Rotterdam's port and a new, more experimental, frame to govern the waterfront. After these extra-institutional consultations, informed by transition management discourse, it became clear that the general ambition of the Bureau Stadshavens was a long-term transformation of Rotterdam's (de-industrialised) waterfront into an vital working and living environment centred around sustainable innovations in the domains of water, energy and mobility (Programme Bureau Stadshavens Rotterdam, 2008b: 2). Not only did the temporal horizon shift from short-term planning to a long-term transformation (2025 and 2040), but a sector-specific focus (industry, or economy) opened up and became more integral and multi-domain. This was expressed by common challenges were climate change, land scarcity, urban CO 2 emissions, maintaining international competition of Port of Rotterdam, increasing population density and lack of proper accessibility and integrated mobility systems. The Stadshavens Rotterdam website states that it: \"wants to develop into a quality port and excellent location, not only for port and transport related industry, but also for innovative businesses and knowledge institutes. Rotterdam is also creating an image of itself as a trendsetter in the fields of sustainable energy and climate adaption, with the aim of attracting professionals and pioneers keen to try out these new trends. Stadshavens can provide them with everything they need for setting up their businesses, along with exceptional residential developments, cultural amenities and good educational facilities\". 6   The vision for a long-term and multi-domain waterfront regeneration was presented as a matter of 'urgency' and 'opportunity'. Some legal requirements and regulatory procedures were bypassed in order to create space for institutional and project-based experimentation. For example, a legal exception was made possible by the so-called Crisis and Recovery Act, aimed at economic recovery in the wake of the economic crisis. 7 Additionally, knowledge institutes were involved in the design and creation of specific buildings and constructs (e.g. RDM Campus, Hogeschool Rotterdam, Albeda College). 8 The Stadshavens network tapped into old and newly created regulatory and knowledge repertoires. The long-term oriented programme consists of five strategies that materialise this key ambition of economic restructuring and urban regeneration: 9 4. Floating communities: creating floating housing, workplaces, recreation facilities to land scarcity and withstand climate change, also restructuring the urban economy and creating new social networks; 5. Sustainable mobility: creating a multi-modal system of mobility that also connects public transportation on land and water. These strategies are not presented in abstract ambitions, but envisioned spatially and physically (Programme Bureau Stadshavens Rotterdam, 2008a: 7). That is to say, the interrelated long-term strategies 'touch the ground' by differentiating specific themes in the following way: So, the extra-institutional informed a more long-term and multi-domain vision to reconnect Rotterdam's old port areas and its urban development through a number of 'sustainability challenges'. The new future image of a lively and more 'urbanised waterfront' was to be realised through a number of open and experimental spatial strategies. In order to grasp how such experimental and extra-institutional practices related to more institutional democratic governance, we zoom in on one of these strategies.",
            "Floating communities strategy: waterfront experimentation": " The strategic vision for the Floating Communities strategy is framed in relation to the idea that \"one third\" of the port area consists of water. Water, the vision states \"gives city life its own unique character\" (Programme Bureau Stadshavens Rotterdam, 2008a: 14). The potentiality of unused water is underscored: \"Basins where port industry has moved away are ideal locations for floating housing and workplaces. This will further enhance the quality of Stadshavens Rotterdam and benefit all the residents of Rotterdam\" (ibid). Many visual examples were created of how floating communities might look like. 10These visual images are supported by texts about what these floating buildings will actually do. The strategic document states for example: \"Floating constructions, like work spaces and pavillions, serve as boosters for development. Floating restaurants and other public facilities will be the centre of attraction in the Rijnhaven\". (. . .) \"There's a superb view from the many footpaths and cycle routes along the waterside, which pass by cultural attractions, floating cafes and restaurants and watersports facilities, including an open-air swimming pool\" (ibid). On the Stadshavens website the main idea of the floating communities strategies is presented as follows: \"Space will become available in Stadshavens for 5000 homes on or beside the water. This extraordinary residential environment should attract professionals and pioneers11 who want to stand out from the crowd. These people are needed to inject new life into Rotterdam's economy. The SS Rotterdam, a floating complex of conference, leisure and catering facilities, will be the first step in the process\". 12The floating pavilion was mainly built as a first test case and finished in 2010 by a number of key actors (mostly a combination of architects, constructors, policy makers, port authorities). In less than one year this project was realised, passionately supported by political and formal governmental actors. Their ambition was to showcase this piece of sustainable technology at the Shanghai World Expo and the Tour de France (both in 2010). During this period, a number of technical, legal and financial concerns emerged. For example, safety regulations demand floating houses require similar safety regulations as houses on land. Such high standards were problematic for an experimental construction link the floating pavilion. Furthermore, people from the Stadshavens programme wanted to make the floating pavilion available and accessible to the broader public. However, if this would be the case, there should be no fence around the pavilion and wheel chaired people should be able to access the floating pavilion. In practice, this was almost unfeasible given the specific location and circumstances of the floating construction. Additionally, due to the waterfront regeneration plans, 150 docks had to move and find a new location outside the city port area. In this case, a number of inland navigation organisations had to relocate further down the estuary, at the expense of the 'high quality location' of the docks and the convenient locations for their families spending time on the urban docks. Next to these spatial and physical concerns, some legal concerns emerged as well. One example was the legal status of floating houses in relation to financial support (mortgages). Few banks were actually willing to provide mortgage to houses that were too 'mobile' and have had unfixed locations. Since floating houses are neither boats nor houses, banks were often hesitant to sign a contract for any object or house that did not nicely fit in well-known legal and financial schemes. Eventually, financial support was provided by a bank. All of these small and big concerns emerged as 'lessons', since the floating pavilion was a test case to explore and map technical, legal and financial problems. The broader strategic of this experiment was to explore a new institutional horizon and find the potentiality for a de-industrialised urban port life. After this 'testing phase', the Stadshavens programme opened up a formal tender (in July 2013) to any proposal that would further experiment with floating houses and living spaces at a larger scale in a particular part of the City Port area (in the Rijnhaven area). Consortia were invited to propose plans that created innovate spheres for working, living and recreation. In this sense, this procedure invited extra-institutional initiatives and proposals for waterfront regeneration in general, and floating urban livelihoods in specific. The economic crisis and the newly created vision were conditions to open up the institutional terrain for external consultation. All 'extra-institutional submissions' were expected to transform a waterfront area of 21 hectares, based on a number of criteria set by city authorities. Potential initiatives were expected articulate economic restructuring on the other hand, and sustainable and inclusive areas on the one hand. Consortia were, for instance, expected to organise their own financial means for the next 30 years, sustainability was to be part of the plans, and should be open to the public services and improve local employment rates. 13 A clear focus of this tender was the role of open public services for everyone (e.g. swimming, sports, etc. with discount for underprivileged parts of the urban population). This particular part of the floating communities strategy, as part of the broader Stadshavens programme, was to reconnect heterogeneous parts of the city, both geographically and socio-economically. To ensure fair competition, the tendering procedure was based on fair competition and secrecy. Cooperation between partners and freely exchanging ideas and plans was forbidden, but often seen as an obstacle for collaboration and to create new and creative ideas. Another problem of the formal procedure was its implicit unequal playing field, since some consortia were simply more experienced with such constructions and technologies than others, but also had more financial leverage. Furthermore, despite some consultations with local entrepreneurs and residents, an extensive public participation trajectory was not organised. A number of actors that were involved in this process, however, clearly highlighted the accessibility of floating houses and activities for local and lower-class populations in surrounding deprived urban areas.",
            "Reflections on the case: transition at the edge of democracy": " If we return to our more analytical question of democratic politics, what do we see? The participatory process led by Bureau Stadshavens, informed by a transition management approach, might suffer from all the 'democratic deficits' identified by criticisms on transition management as summarised in Section 4. It was based on selective participation, outside formal democratic institutions without much attention for the role of power and (hidden) lobby or interests. In this sense, one can say that the Stadshavens programme in general, and the floating communities strategy in particular, seem to circumvent institutionalised forms of democracy. In short, the transition management process that created long-term oriented and experimental waterfront governance was undemocratic. However, this brings us to the relationship between institutionalised democracy and its extra-institutional and marginalised counterparts, as discussed earlier. First of all, in the early 2000s, the formal democratic system could not reach a joint decision because of conflicting interests about the role of a traditional industrial harbour economy vis-\u00e0-vis 21st century global cities. This necessitated a different and 'shadow-like' process in which a much broader and unconventional variety of stakeholders (and interests) could be invited (including a TM discourse). A new time-horizon (2040) was taken as a starting point for explorative discussions and opened up new debates for marginal interests and small innovative actors. This more 'informal' status of the process created space for exploration and inclusion of more radical and innovative ideas (like the floating city idea and reconnecting different urban areas), while ensuring more formal institutional checks vis-\u00e0-vis democratic institutions. An iteration took place between the institutional procedures and extra-institutional ideas and initiatives. The envisioning and strategy-building process did stimulate participants to take up new activities themselves (or within their organisations). The more step-by-step philosophy that was taken up, ensured possibilities for intermediate adjustments or alternatives. One example is the floating pavilion and its legal and financial 'lessons'. In the end, the outcomes of the transition management process led to a variety of decisions taken, also in more traditional democratic procedures and spaces. The overall vision was approved and accepted by the city council, as were the intermediate strategies. Parts of the proposed projects and experiments were indeed formalised in public/private partnerships and concrete projects that challenged traditional legal, financial, governance and political institutions. These projects, in turn, were approved after stakeholder involvement and internal decision making within the policy departments as well as involved partners such as universities and companies. However, it is too early to state that experimental learning took place, since the long-term and multi-domain transformation process just started. In terms of extra-institutional democratic experiments, they were not enforced by the formal democratic bodies, nor were they simply done by 'the public demos' (as Habermasians would like to see it). Rather, the governance process of the Stadshavens case shows how unconventional and seemingly 'undemocratic' actors and practices were foregrounded and transform the socio-economic meaning and accessibility of the newly created waterfront, in relation to institutionalised democracy and authorities. Despite circumventing specific regulations, public debate and market-based solutions (Kenis and Mathijs, 2012), a number of extra-institutional practices subverted traditional waterfront governance. The transition management discourse enforced a break with traditional democratic and governmental norms regarding port management and waterfront development (e.g. familiar building concepts, safety regulations, separating urban geographical districts). As we have seen, these aspects indeed resonate with some of the principles of post-foundational democracy, such as pursuing social change and seeking new identities and social relations, informed by marginal(ised) ideas and practices. This 'democratic mismatch' was underscored by the fact that new democratic questions emerged at the margins of institutional democratic governance, e.g. concerning 'market consultation', level playing field, procedural transparency, etc. Given the fact that we employed this empirical case as a critical case (Flyvbjerg, 2006), it is noteworthy that we can observe how the transition process of Rotterdam's waterfront regeneration enabled a unconventional form of democratic governance. We could argue that the transition management discourse and practices that emerged in the mid-2000s, seemed to have opened up institutionalised democracy around Rotterdam's waterfront and created extra-institutional imaginaries and practices in the early 2010s.",
            "Conclusions and discussion: bringing together transition management and post-foundational democracy": " The objective of this paper was to explore the democratic politics of transition management, both conceptually and empirically. After reviewing existing literature on transition management and its politics, the paper presented a perspective of post-foundational democratic politics. Based on this perspective, and more traditional notions of democracy, an empirical case of transition management practices was explored. This empirical analysis illustrated that this particular case contains both democratic and undemocratic principles and features, depending on one's framing of democratic politics. The empirical case showed that some decisions indicate breaking out of dominant waterfront networks and practices, such as de-industrialising Rotterdam's city ports, using unorthodox design concepts, centre-staging (social) sustainability as a guiding principle for spatial development, ensuring the use of public facilities, temporarily bypassing some regulations and benefiting unprivileged populations and deprived Other aspects resonate with traditional institutions and dominant regimes, such as formulating clear economic objectives for global competiveness, employing engineering practices and technology-led sustainability, seeking approval from formal democratic procedure and choosing market consultation over public participation. This elucidates that and how this case of transition management in a context of urban water is ambiguous in terms of its 'democratic character'. But what does it mean to say that transition management is both democratic and undemocratic in this particular case, and what does this imply more generally? As mentioned earlier, traditional notions of democracy seem to approach transition management sceptically in terms of its democratic politics. However, our deconstruction of institutionalised democratic practice creates space to reframe the link between democratic ideas and democratic practice. Informed by insights from post-foundational democracy, this more radical understanding of democracy also resonates with a number of conceptual and normative orientation associated with transition management, e.g. on transformative change, contingency, ambivalence, flexibility and experimentation (Walker and Shove, 2007;Loorbach, 2007;Hendriks, 2009). Regarding our case, this also means that some of the Stadshavens initiatives and practices that take place 'outside' democratic procedures and institutions are not necessarily undemocratic. In other words, not all technical practices and economic projects are undemocratic. However, not all radical and innovative practices are democratic. We should be much more precise in understanding and empirically unravelling how, for instance, technical and economic practices relate to democratic practice, beyond traditional notions of democracy (e.g. in relation to Hendriks' polycentric democratic landscapes). This also implies that transition (management) approaches should engage more critically with insights from post-foundational democracy to explore and reimagine the relationship between TM and democracy. This, obviously, also prompts new theoretical and empirical questions about who counts, and when and where they count in view of everyday transition management practices and contemporary sustainability challenges more broadly. Future research should further such questions and compare different (socio-technical) transition management contexts, not only differing in terms of relative distance from state and democratic institutions, but also different national and regional contexts (Figs. 1-4).",
            "(Post-foundational) democratic transition management": " Based on our explorations, we argue that transition management in some ways could potentially provide more democratic contexts than formal democratic institutions. Democratic transition management can and should address antagonistic tensions and foregrounding blind spots of governance processes, i.e. cultivating the excluded margins that have been produced by institutionalised democracy as such. However, democratic transition management should not simply adhere to informal networks with architects, professionals and policy makers (as elitist technocracy). Rather, it should direct is democratic potential beyond traditional frameworks of democratic governance and highlight how a different framing of time-horizons, problem spaces, and new socio-technical, socioeconomic and socio-ecological combinations could render possible more democratic transformations (Swyngedouw, 2011). One of the strong points of the transition management approach, in a sense, is its 'undemocratic' nature (from a traditional democratic perspective). Transition management in its operationalised form is inherently selective and therefore exclusive, based on the premise that structural large-scale change is contrary to the interests of (at least a part of) established powers and interests. It therefore focuses on involving change agents based on an socio-political diagnosis of a specific field in which more fundamental change is perceived as necessary. Based on the extrainstitutional nature of the process as well as upon the understanding of social change as the outcome of individual and collective actions (not only formal policies or institutional action), the process approach mainly seeks to achieve internalisation of ideas amongst participants. In other words, that participants develop a new understanding of the complex issues they relate to and a new action perspective which shapes their (professional) practices. Democratic and even technocratic powers, then, might construe new arrangements and alliances to counter dominant legal, economic and democratic regimes and practices. This might make a 'democratic institution' in transition contexts an oxymoron, but more importantly, the concept of post-foundational democracy highlights how transition management   might relate to democratic practice without adhering to legal-administrative regimes and political procedures. In this way 'democratic transition management' seeks to create mental, discursive and organisational space for developing ideas, ambitions and experiments that are hard to produce through formalised processes, even within a traditional democratic context. As a transition process has no 'formal status', it only impacts reality when involved actors follow-up on it. One might consider this 'undemocratic' (e.g. a deciding to invest in floating communities, a research group deciding to invest floating technologies, an environmental NGO deciding to promote floating green infrastructure), but we argue that facilitating contexts in which such decisions are exchanged, negotiated and developed in meaningful interaction is something that does not sufficiently take place in current institutional settings, but should be. As such, 'shadow processes' are partly produced by institutionalised democracy and in the end need to critically negotiate formal rituals through more regulated and institutionalised decision making (be it in a policy sense or within an organisational context). We argue that transition management, instead of contrary to current democratic institutions, could potentially be more democratic than traditional and institutionalised forms of democracy. "
        }
    },
    "10.1016/j.eist.2012.10.004": {
        "file_name": "102 Transforming dumps into gold mines. Experiences from Swedish case studies",
        "title": "Environmental Innovation and Societal Transitions",
        "abstract": "This article discusses the transformation of landfills from dumps to an alchemist's dream \u2013 gold mines \u2013 by highlighting five Swedish case studies where the landfill has been extracted. It is shown that landfills are embedded in broader socio-technical systems, including technology, policies, culture, norms, markets, and networks. These artifacts have aligned into mutual dependencies under the notion that landfills are garbage dumps, which has entrapped the landfill in the prevailing \u201cdump regime\u201d. At the present time there is a window of opportunity to escape the \u201cdump regime.\u201d Dumps are being challenged by the circular economy, which has established instability in the regime. However, for landfills to transform into \u201cgold mines\u201d creative entrepreneurs with the capacity to understand the emergent properties of deposition \u2013 i.e. giving rise to a resource base \u2013 will be key. For further transformation, specialized mining actors, collaboration and further exogenous changes such as higher metal prices are necessary.",
        "label": "Qualitative",
        "text": {
            "Introduction": " Landfills are commonly defined as a site for the disposal of waste. Such a treatment method assumes that the waste simply has no value, i.e., it is useless and therefore buried and shielded from the economy. Accumulated waste, however, is not only worthless; it can even have a negative value and pose a serious threat to humans and the environment, including the leakage of hazardous substances (Baun and Christensen, 2004) and methane emissions (Bogner et al., 1995). Hence, the orphaned, abandoned and neglected waste \"bites back\" (Tenner, 1997) on the society that created it. Meanwhile, for some, especially birds and birdwatchers, landfills may be considered an important ecological oasis in the urban environment, sometimes more popular than city parks. Increasingly, waste is defined as surplus material (Gourlay, 1992); a byproduct; material we have failed to use. From such a perspective, disposal is commonly regarded as a lost opportunity and a waste of resources. What is often forgotten in this context, however, is that the isolated events of deposition combined make a new potential resource base, which to some extent can be compared to traditional mines in terms of quality and quantity (Kapur and Graedel, 2006;Johansson et al., 2012). Research in industrial metabolism (e.g. Graedel et al., 2004) has shown how resources and metals in particular are extracted from the lithosphere, turned into products, consumed and then usually end up in landfills. In countries like Sweden, where incineration has largely replaced landfills, significant amounts of metals end up in ash, which is commonly landfilled (Kuo et al., 2007). However, landfills contain not only metals such as gold (Ongondo et al., 2011) like conventional mines but are also filled with plastic, wood, paper and other valuable resources. The potential extraction of secondary minerals 1 has been conceptualized through various mining concepts such as urban mining (Brunner and Rechberger, 2004), technospheric mining (Johansson et al., 2012) and waste mining (Ayres, 1999). However, these concepts focus on recovering metals from either traditional waste streams or all the stocks of secondary minerals including for example tailing ponds. 2  Landfill mining (Krook et al., 2012), on the other hand, focuses on landfills in isolation by excavating and recovering deposited waste. Hence, it revives what is buried by digging up a landfill and gives the waste a new chance. However, mining the technosphere and landfills in particular is not common practice in developed countries 3 (Johansson et al., 2012) and typically surrounded by many uncertainties of economic (Fisher and Findlay, 1995), technical (Dickinson, 1995) and legal (US EPA, 1997) nature. In evolutionary economics path dependency processes are usually observed, where traditional technology persists, like the VHS video recorder (Arthur, 1990), pesticide use (Wilson and Tisdell, 2001) and fossil fuel-based technologies (Unruh, 2000;Walker, 2000), even in the face of competition from potentially superior substitutes. Lock-in emerges when disciplines such as technology, markets, law, science, culture, and policy co-evolve in tandem and align into a regime (Dosi, 1982;Rip and Kemp, 1998;Geels, 2004). Such mutual dependencies establish stability around the system with an exclusion effect for dissenting innovations. Despite system inertia, new innovations can nevertheless emerge if exogenous changes at the macro level establish instability and tension in the existing regimes (Arthur, 1988;Cowan and Hulten, 1996;Freeman and Louc \u00b8 \u00e3, 2001). More recently, by studying conflicting regimes in the waste sector, waste, like technology, has proven to be a highly embedded, dynamic phenomenon (although with properties of inertia). For example, Gille (2010) has showed how exogenous changes have pushed institutions' perceptions of waste over time and enlisted policy, technologies and economics into various waste regimes. Furthermore, Lane (2011) and Lepawsky (2012) have demonstrated the obstacles in transforming the collection schemes by allowing the involvement of informal actors and implementing producer responsibility, respectively. Whether regimes can be applied to landfills and theoretically explain the origin of the uncertainties remains to be studied. The point here is not to engage in a comprehensive historical analysis of landfills, since the aim is normative, or more precisely: to uncover a new \"landfill regime\" in which landfills, containing gold and other minerals, are not the end station for material but the starting point. In a sense, we are thereby approaching a classical alchemical experiment, 4 the Magnum opus, to understand how valueless material can be transformed into gold and other valuable commodities. However, no chemical 1 Minerals once already extracted, and therefore found not in the lithosphere but in the technosphere. 2 For further discussion on mining concepts, see Johansson et al. (2012). 3 Scavengers at landfill sites have probably been around ever since people started to deposit valuable resources (Rathje and Murphy, 1992). 4 The art of transformation or of possibilities. experiments will be performed. 5 Instead, the aim of the article is to study the materiality of dumps, in order to provide knowledge on how to transform such valueless piles of junk into the alchemical dream, gold mines. This is done by reviewing five Swedish landfill mining (LFM) cases and analyzing how the variety of uncertainties typically surrounding such LFM projects was addressed. The outcome of the cases and why some projects were successful while others failed is discussed by analyzing the socio-technical nature of the system surrounding Swedish landfills. Key challenges and critical factors essential to transforming landfills into a new \"landfill regime\" are then identified.",
            "Method": "",
            "Selection of cases": " Based on the definition of landfill mining, a typical case includes, at a minimum, excavation of a landfill and recovery of deposited resources. From this basis, five cases have been identified through snowball sampling and contact with authorities, experts and researchers. Cases were searched until the same cases kept recurring. All proposed cases were included in the study, except one where information collection was prevented by a lack of documentation and failure to contact possible respondents. Since two cases, Ringstorp and Stentippen are located in the same city, Helsingborg, these two cases are referred to in the article by the landfill name, while the other cases are referred to by location: Malm\u00f6, Str\u00e4ngn\u00e4s, and Landskrona. The cases differ significantly in terms of main drivers, scale and time, as seen in Table 1. All landfills are owned and managed by the municipality or publicly owned waste companies. In general, the main objectives of the cases have been to remove the landfill or parts of it. All cases have been problem driven, where an identified problem has been the reason behind exhuming the landfills. This problem, i.e., the process of excavating the landfill, has then mainly been addressed in two crucially different ways: (1) by remediation, where the waste has simply been excavated and then moved to a more appropriate location, with some of the exhumed waste used as construction material; or (2) through resource recovery, where the waste has been excavated and then recovered in terms of metals recycled and combustible energy recovered. The scale of the projects differ, ranging from international affairs such as a bridge connection between two countries, with major financial power, or municipalities searching for new land to pilot studies initiated by innovative waste managers with limited budgets. The fact that the projects were implemented in varying time periods, from the 1980s to the present, should also be considered since the prevailing conditions, such as regulation and markets, have varied.",
            "Data collection": " A review of landfill mining literature was initially done to guide the collection of information from the case studies. In this review6 six main types of barriers/challenges were identified as remaining to be addressed before landfills can be transformed into mines: Prospecting, Technology, Market, Regulation, Attitudes and Feasibility. Research focusing on waste composition of landfills has shown, even within specific sites, large variations in physical and chemical characteristics as well as material composition (Cossu et al., 1996;Reith and Salerni, 1997). This makes prediction of the content and thus determination of valuable resources or hazardous components in the landfill difficult. Such a figuratively uncertain black box makes prospecting a key challenge. Previously reported case studies (e.g. Dickinson, 1995;Reeves and Murray, 1997;Zhao et al., 2007) have shown difficulties in sorting out the deposited waste into desired pure fractions. Few recycling agents are interested in accepting unsorted masses. The availability and performance of technology thus becomes another critical question. A further recurring conclusion from the reported cases is that the obtained quality of exhumed materials, soil excluded, is often not good enough to compete with virgin as well as secondary resources from traditional waste flows. The market for excavated deposited waste is thus uncertain, i.e., is there any demand for products from a landfill? What safety, administrative and regulatory requirements landfill mining will involve, and how such demands will influence its viability, is also largely unclear, although authorities will most likely require an approved safety and health plan (Cossu et al., 1996;US EPA, 1997). For example, should re-deposited waste, once excavated, be interpreted as \"new waste\" and thus subject to waste tax and waste bans? Is permission required at all, and if so, which regulations are applicable? Although the previous cases had low impact on environment and health,7 it remains unclear how the excavation is perceived by local residents. Overall, actors involved in the cases are hidden as well as the cultural values driving the mining operations. So, which actors need to be involved/committed to the process and what attitudes are featured in landfill mining? Some reported cases were considered cost-effective (e.g. van Passel et al., 2012) while others were not (e.g. Dickinson, 1995). These evaluations have however been site-specific, performed in different regions and under varying conditions and objectives. Hence, conclusive information on the feasibility of landfill mining operations is still lacking, i.e., is landfill mining profitable business? Based on the six main types of barriers/challenges identified above, an interview guide was established framed by the overall question: How did the projects address these six typical challenges for landfill mining? General questions relating to drivers, initiator, actors and objectives were also asked. The interviews were conducted with those responsible for the projects, as decided by the actors themselves. In Landskrona and Str\u00e4ngn\u00e4s the responsible waste managers were interviewed. In Malm\u00f6, Stentippen and Ringstorp officials were singled out as project managers. The data for the case studies was gathered during 2010 by conducting semi-structured interviews and analyzing documents such as project proposals and project evaluations. The empirical result was categorized according to the main types of challenges and is presented in Section 3, explicitly in Tables 2 and 3.",
            "Analysis": " We first describe how the cases have managed the above uncertainties/challenges, on which the success of any LFM project rests (Baas et al., 2010). The result of the cases and the reason for success or failure are then analyzed, based on a framework suggested by Gille (2010), relating the sociotechnical conditions of the cases to the materiality of deposited waste. The outcome of this analysis is then used to identify the current regime surrounding landfills. From a multilevel perspective (Rip and Kemp, 1998;Kemp et al., 2001;Geels and Schot, 2007;Gille, 2010), factors emphasizing individual and collaborative processes are then identified, which for the cases seem to be crucial to escape the regime and transform landfills into mines.",
            "Socio-technical landfills": " To make it more interesting, let us start at the wrong logical end: the outcome of the cases. The cases where the excavation was based on remediation and simply moved deposited masses to a more appropriate location seem to have been successfully implemented. In Malm\u00f6, the landfill was remediated and the \u00d8resund Bridge has been stable since then. Stentippen in Helsingborg was excavated, the leakage stopped and the remaining pool may, if the city architect has his way, be used for outdoor concerts. The land where Ringstorp was located is currently being sold for housing. The purpose of remediation, removing contaminated soil so as to allow redevelopment of the land, was in all cases fulfilled. On the other hand, the cases which aimed to recycle, reuse and recover the masses from the landfill were never completed. In Str\u00e4ngn\u00e4s, only pilot studies were conducted, since the politicians did not want to finance large-scale resource recovery projects. The project in Landskrona met the same fate. Instead, the conventional method of capping and closing the landfills was chosen. Hence, the landfills in Landskrona and Str\u00e4ngn\u00e4s have been capped and waste for deposit sent to neighboring landfills. The outcome of the different cases, i.e., the failure of the resource recovery projects in Landskrona and Str\u00e4ngn\u00e4s as well as the success of the remediation projects, may more or less be regarded as rational. Covering the landfill and sending small quantities of waste for deposition to a nearby landfill turned out to be a cheaper alternative than excavating the site, recovering the resources and bottom sealing the landfill. At the same time the need for landfill space had also drastically decreased due to landfill bans/taxes, which obviously reduced the need for additional capacity. The stakes were high and strong economic forces also supported the remediation operations; in Malm\u00f6 a bilateral infrastructure project was at risk, and in Helsingborg the city's long-term expansion and groundwater supply was threatened. By analyzing how the cases managed the previously identified challenges and comparing conditions for resource recovery with remediation, the outcome and rationale can, however, be further explained by the socio-technical context of landfills.",
            "Prospecting": " Information about a landfill's composition is commonly absent, since waste has been deposited over time without any documentation. Waste has not been deposited in order to facilitate future extraction, but instead according to what has been considered to be effective and safe (OECD, 1994;European Council, 1999). The first step in the excavation of a landfill is thus to identify the landfill's interior. In general, the cases used a combination of several methods to map the composition, as seen in Table 2. Qualitative methods, for example interviewing staff with long experience and analyzing historical documents such as old invoices or shipping documents provided an historical overview of the landfill structure. For example, in Landskrona old sludge pits could be identified through aerial photos, which thereby could be avoided during excavation. Historical flashbacks of the formal operation in landfills are, however, only half the story. People commonly take the liberty to unofficially deposit their own waste, if they discover open dumps. Therefore, to verify each case it became crucial to collect primary data of the current landfill interior through test pits (Malm\u00f6, Str\u00e4ngn\u00e4s and Landskrona) and/or well logging (Malm\u00f6, Landskrona, Ringstorp and Stentippen). For example, in Malm\u00f6, 2300 Fig. 1. An overview of how different types of waste have been deposited in Lernacken (Malm\u00f6) was provided through conducting interviews, examining historical documents, sampling and test pits. Note that the height scale is greatly exaggerated (based on M\u00f6ller, 1999). test pits measuring 2 m \u00d7 2 m \u00d7 4 m were excavated to map the interior. The distance between each test pit was about 10 m. If nearby pits showed dissimilarities, boundaries between the masses were further investigated. But even with the combination of methods, at best an overall understanding is reached where household, industrial waste, slag and sludge, i.e., different waste groups are positioned, as illustrated in Fig. 1. Such a general image is likely to be highly adequate for remediating landfills since it is primarily the pollution levels that matter rather than the materials. In such cases, the mapping of material types is primarily important to ensure a safe excavation process. The same image, however, is inadequate for resource extraction in many ways. For example, detailed information on where valuable units, such as copper, iron, aluminum and timber, i.e., the ore, is located is not reported. This information is important both in order to estimate the potential profit and to determine where to dig. In some remediation cases, an overview of the material composition may even prove to be redundant. For example, in Ringstorp, as seen in Table 2, sampling alone without any need for additional pre-studies proved to provide sufficient information to identify the composition of the landfill. Such sampling is commonly based on different physical and chemical speciation methods (Baun and Christensen, 2004), including primary metals dissipated from their original material in the primary form of free metal ions (McCarthy and Zachara, 1989). Speciation methods do not however provide a complete picture of the metal content in a landfill, since they exclude solid metals remaining in everything from car doors to cutlery and are therefore insufficient for resource extraction. In sum, the available methods for pre-studies seem to better match the needs of remediation than resource recovery.",
            "Technology": " Excavators were used to exhume the waste in all case studies. Excavated quantities were then transported by wheel loaders to the intended destination. Depending on the approach (remediation or resource recovery), different separation techniques were selected, as shown in Table 3. Separating the excavated waste is a relatively simple procedure for remediation; a gauge, as in Stentippen, can analyze pollution levels from which waste is sorted accordingly into different categories. The cases that aimed for further resource recovery primarily separated the waste by a screener according to the size of the waste. This technique proved successful, for example in Str\u00e4ngn\u00e4s, in achieving a soil fraction and reducing landfill volume, but far less efficient for obtaining homogeneous recyclables. The different size fractions became highly heterogenic and a backhoe was necessary to pick out certain materials, for example combustible material that was sent to incineration. The only parts that could be recycled without manual sorting, except soil, were ferrous metals with the help of a magnet.",
            "The market": " The possibilities for using the sorted waste varied between the cases and over time. The potential use of fractions after remediation is clearly defined, since the Swedish EPA has issued guidelines for assessment of contaminated soil (e.g. SEPA, 2009), which makes it easy to find specific applications. If the masses are relatively clean, they can be used for \"sensitive land use\" including housing or farming, a level that only the cover soil of Ringstorp (fraction number 3) passed, as seen in Table 3. Masses with a moderate pollution level, which parts of the masses in Malm\u00f6 and Stentippen reached, can be used for \"less sensitive land use\" such as roads or industries. The masses must be deposited if these criteria are not fulfilled, which, however, means that they can be used as construction materials during landfill operation such as establishing embankments. It becomes more difficult if the fractions have been separated by size or resource type. Although the market is currently converting to recirculation of materials, it is likely that goods from a landfill may be more difficult to accept for both recycling operators and consumers. The cases including resource recovery submitted only small quantities of metals and combustibles during the pilot studies. Thus, it is uncertain whether the recyclers and incinerators are willing or even have the capacity to receive larger quantities of excavated waste competing with often higher-quality material obtained from waste source separation programs. The cost of submitting combustibles is furthermore high,8 and will rise if the combustibles are of poor quality, for example with high moisture content (Hammar, personal communication, 2010). Therefore, in Landskrona the combustibles were planned to be re-deposited in anticipation of lower prices, as shown in Table 3. Whether this would have been consistent with the landfill ban on organic or burnable waste (SCS, is however uncertain. Applications for the excavated and separated resources such as organic combustibles are thus not easily determined. Consumers may furthermore be more likely to accept heating and electricity from incinerated deposited waste. It will probably be harder, however, to accept previously deposited material directly around us, such as cans or bottles, even if the contamination levels are approved.",
            "Regulation": " Malm\u00f6, Stentippen and Ringstorp sought permission for remediation of contaminated land, as seen in Table 2. Ringstorp and Stentippen applied for a permit in accordance with the Ordinance on Activities Dangerous to the Environment and Protection of Health (SCS, 1998:899). Malm\u00f6 applied however before the Swedish environmental legislation was combined in one code, and therefore two different permits and courts were included. Str\u00e4ngn\u00e4s lacked permission. However, after the pilot test had been going on for a while the authorities in Str\u00e4ngn\u00e4s demanded that methane should be collected, as seen in Table 2. But measurements showed low levels and the requirement were never implemented. In Landskrona, permission for resource recovery was sought as a part of a larger application for operating the whole landfill according to the Environmental Code (SCS, 1998:808). Issues of interest to authorities during the permission process included: amounts, location, timeframes, technology, exhumation methods, sorting methods, and how to address, for example, odors, explosion, water, noise and dust. The Environmental Code also requires, through the knowledge rule, that the operator must know the landfill composition. Regardless of time period and approach the permits have been granted in compliance with a control program focusing on the excavation process involving procedures for management of hazardous waste, systematic monitoring of air quality, safety plan, trained and well-equipped workers, and so on. Many of the case studies had existing permits for landfill operations, with conditions for example about odor, noise and leakage, which naturally were also in force for excavation of the landfill. Hence, the process for remediation is clearly defined in current law (e.g. SCS, 1998:899) which makes the application process and demands on the operator relatively predictable. Excavation and recovery of deposited resources are, however, not mentioned in Swedish regulations and therefore legally uncertain.9 ",
            "Attitudes": " All cases were problem-driven. The majority of cases did not even discuss the possibilities of recovering the deposited waste and chose instead to simply move the waste to a safer place. Two of the cases, Str\u00e4ngn\u00e4s and Landskrona, did however, as mentioned above, attempt to recover deposited waste. All projects were however operated by the initiators without any broader collaboration with actors from universities, governmental agencies or recycling operators. Consultants responsible for excavating, sampling and applying for permission were nevertheless involved. The locals were, to some degree, also concerned. During the permit application consultations where all the interested parties are invited to express their opinions are a statutory requirement. In addition, a series of monthly meetings was held both in Ringstorp and Malm\u00f6 with all stakeholders, including local residents as well as authorities. Every week local newspapers published news item and newsletters were sent to local residents to provide advance notice of work. The excavation in Malm\u00f6 was also visited by school children as well as members of the European Parliament. Despite openness and limited impact on the environment,10 the projects were nevertheless met by protests. In Ringstorp, worried parents from a preschool nearby started a petition to postpone the planned excavation. During the excavation of Lernacken in Malm\u00f6, which was closely linked to the controversial construction of the \u00d8resund Bridge, activists chained themselves to the machines and poured sugar into the tanks on excavators.",
            "Feasibility": " The financial conditions have varied in the cases. Essentially, there were no direct revenues from any of the cases. During the pilot studies with resource recovery, however, revenues were received for metals, less construction material had to be purchased with resulting savings, and more landfill space was attained. For the cases based on remediation, the benefits were primary indirect; the abutment of \u00d8resund Bridge could be built at Lernacken, improving the communication between Sweden and Denmark. The leakage from Stentippen was drastically reduced and the land at Ringstorp could be used for housing, thus fitting better into the urban environment. Major revenue may however be involved if the land is sold after completion of the projects. Thanks to high revenues from selling the land, Ringstorp in Helsingborg could show a profit (the only case to do so), although no fractions were sold, except soil. The cost of the cases is very diverse, ranging from 4 D /ton to 35 D /ton. In the resource recovery cases, the costs of preliminary studies, bottom sealing, exhuming and recovering the waste were compared with the cost of final cover, monitoring over a 30-year period and transporting waste for deposit to an active landfill. You already know how it ended: capping proved more cost effective. Cost effectiveness, however, is never an objective criterion. Cases are evaluated against a typical standardization. Cases involving resource recovery were evaluated based on one actor's individual economic horizon.11 ",
            "Table 4": " The material nature of the prevailing socio-technical system surrounding landfills, here referred to as the \"dump regime\", and a potential alternative; the \"gold mine regime\".",
            "The dump regime": "",
            "The landfill is stuck in a dump": " The process of excavating the landfill is in many ways similar for resource extraction and remediation; the same excavation equipment such as excavators is needed and similar problems such as protest are faced. The difference, which seems to determine the success, lies in the perception and management of the excavated waste. It is clear that remediation with redeposition of the waste and probably also capping the landfill are more in line with the current socio-technical system surrounding landfills in terms of technology, market, law, culture, science and policies which obviously facilitates the implementation. Resource recovery, on the other hand, is a mismatch (Freeman and Perez, 1988), thus an unconventional method, challenging the current socio-technical system surrounding the landfill. What resource recovery is challenging more precisely is a socio-technical system based on landfills as a garbage dump. In Landskrona, for example, the managers applied for grants from the EU LIFE program12 to develop technology for extracting resources from a landfill. The application was denied, however, since resource extraction and the perception of the deposited resources as an opportunity (a \"mine\") was considered to be contrary to EU principles of how landfills should be managed: landfills should be enclosed and secured. After all, the regulation body surrounding landfills is explicitly adapted to landfills as a dump, a linear end station for material, as seen in Table 4, including rules (e.g. European Council, 1999) based on the classification of landfills by their hazard level, leaching control, closure and after-care. The landfill tax (SCS, 1999:673) is another example, which was designed to reduce deposition rather than hinder resource extraction by taxing the masses in need of re-deposition. Furthermore, landfill researchers have long underpinned the economic (e.g. Nelson et al., 1992) as well as environmental (e.g. Bogner et al., 1995) and health risks (e.g. Elliott et al., 2001;Baun and Christensen, 2004) associated with landfills. As demonstrated above, landfill technology and sampling equipment are also primarily designed to handle a garbage dump and for example deposit waste and control pollution levels. Simultaneously, it is easier to determine a market for the excavated waste if the masses are interpreted as a pollution problem. Finally, economic evaluations are typically based on certain standardization which fosters a particular trajectory (Unruh, 2002). For remediation projects, grants as well as deductions are available. Such projects are also evaluated from a wider perspective, including societal benefits, which changes the margins for expenses and revenues. In sum, the current socio-technical system surrounding landfills facilitates remediation or capping of landfills, since such operations accept the definition of landfills as a worthless dump, aiming solely to clean and move the dump to a more appropriate location or cover it, respectively. Just like other systems, landfills too seem to be situated in a stable equilibrium, which cannot easily be changed since systems are embedded in wider socio-technical dimensions, termed \"socio-technical regimes\" by Geels (2004). From such a perspective, the landfill and its content is thus entrapped in a \"dump regime,\" where technology, markets, terminology, culture, laws, science and policies surrounding landfills have co-evolved and been enlisted into a dominant regime based on the perception of landfills as a garbage dump. Landfills are useless, literally nothing, and if they have any value it is primarily negative, as seen in Table 4, demonstrated for example by their negative impact on the property values of nearby residences (Nelson et al., 1992). Hence, a simple redefinition of the landfill and its materiality according to an alchemist's dream into a \"gold mine regime,\" as visualized in Table 4, means that the entire socio-technical system established around the \"dump regime\" including, for example, its actors, relations, investments and knowledge, in short, its existence, is challenged. However, since such entrapment arises in most socio-technical systems (Rip and Kemp, 1998;Geels, 2004;Geels and Schot, 2010), it should furthermore mean that there are probably lessons to be learned from transition theory and other transformations subject to lock-in.",
            "The dump regime is challenged": " In order for transformations to take off, the prevailing \"dump regime\" has to become insufficient and unable to provide a satisfactory function (Arthur, 1988;Cowan and Hulten, 1996;Freeman and Louc \u00b8 \u00e3, 2001). Such instability is often initiated by exogenous changes. For example, Gille (2010) demonstrated that regime shifts in the Hungarian waste sector were preceded by economic reforms, policy change and the politicization of environmental issues. Indeed, the \"dump regime\" has become unstable and deficient under previous norms; active, capped, as well as proposed landfills have come into question, according to the presented case studies. For example, the establishment of new landfills has become increasingly difficult such as in Str\u00e4ngn\u00e4s, where citizen resistance made it impossible to find a proper location for a new landfill. Even closed landfills have been contested. In Malm\u00f6 and Ringstorp enclosed landfills stood in the way of progress and the development of infrastructure and urban expansion, respectively. In Stentippen, the pollution level in the leakage water was, despite being previously capped, above authorized levels. The management of active landfills has also been limited and complicated due to more stringent regulation. In Landskrona, the landfill did not meet the requirements of the Landfill Directive (European Council, 1999). Above all, regulations, such as landfill bans and taxes, and the of the circular economy have made landfills generally redundant. For example in Sweden, deposition of municipal waste has decreased by 97% by weight since 1994 (ASWM, 2011a). In sum, these exogenous changes, beyond the control of landfill owners, have made deposition of waste and the landfill in the form of a dump insufficient, which has opened up an opportunity for change, a \"window of opportunity\" (Kingdon, 1995). By analogy, the reported cases provide examples of how the waste sector responded to the tensions mentioned above in the current \"dump regime\". The common practice to regain stability has been like in Landskrona and Str\u00e4ngn\u00e4s, to close and cap landfills. In Sweden, over 70% of all landfills open in 1994 have today been capped (ASWM, 2008). In cases when capping and treatment of the effluents proved insufficient, like in Stentippen, remediation and removal of waste to secure landfills became the alternative solution to tackle the instability. These solutions are a small modification of an incremental nature. Capping in particular minimizes change to the system in its form of an end-of-pipe solution. The problem is simply covered, leaving existing infrastructure in place with a focus on the outflow from the system, i.e., treatment of emissions with add-on technologies. Remediation simply means that the waste is moved to a more appropriate landfill (dump) for safer deposition. The incremental strategy is not surprising given that actors embedded in regimes see only the obvious and follow traditional paths (Nelson and Winter, 1982). However, innovation is possible within the given framework. For example, many Swedish cases of capping resulted in methane capture and recovery, 13 which Bill Clinton refers to as \"gold mines\" (Ragir and Oliveira, 2011). Clinton may be right; recovering methane from landfills could be a first step to transform the dump into a gold mine. Since this method is more in line with the current socio-technical system, policies, infrastructure and the landfill as such remains intact. Hence, it is primarily the effluents from the landfill that are targeted in this transformation rather than the socio-technical system surrounding the landfill and its mineral content. There are, however, as the case studies demonstrated, some radical exceptions, attracting little public attention, in which the current socio-technical system and the \"dump regime\" have been challenged.",
            "Transforming dumps into gold mines": " Although most actors tend to follow traditional paths, this is not true for all. Employees collect attractive deposited waste for their own needs and thus challenge the materiality of landfills (Reno, 2009). This self-organized, often spontaneous, approach seems to have no influence on either culture or landfill policy; on the contrary, it is against company policy and therefore hidden from \"the boss.\" According to many researchers (e.g. Bass, 1990;Kingdon, 1995) the idea of a transformation needs instead to be initiated by a key person in a position and with the ability to persuade policy makers, at a precise time when those in power are open to new ideas. Key individuals are also assumed to be particularly important in the initial phases of technical transformations, referred to as system builders (Hughes, 1979), by creating legitimacy, mobilizing resources and unifying diversity (Giddens, 1984;Carlsson and Jacobsson, 1997). In both Landskrona and Str\u00e4ngn\u00e4s individual leaders (in this case, waste managers) initiated the idea that the landfill could be extracted and deposited waste recycled as a way to meet the tensions in the \"dump regime.\" In Str\u00e4ngn\u00e4s, the size of the current landfill began to reach limits specified in the permit. A political controversy arose regarding where the new landfill would be constructed, which opened up a possibility for innovation. The previous waste manager realized, as an alternative to establishing a new landfill, that the lifetime of the old landfill could be extended if the waste was excavated and recovered. In Landskrona, unlike many other owners, who capped and closed landfills in response to the landfill directive, the waste manager started to investigate extraction of deposited waste and sealing the bottom. Hence, the waste managers become spokespersons (Callon, 1986) 14 for the landfills (in form of mines). Although local decision-makers were persuaded to finance the projects, changes on the macro level including regulation, institutions and values were never reached, exemplified by the rejection of the EU application. One of the reasons may be the lack of cooperation with actors outside the initiators' own sector. In political theory, it is argued that advocacy coalitions (Sabatier, 1988), i.e., networks with actors from different sectors, are crucial for changing institutions and policies. For example, Jacobsson and Bergek (2004) suggest that Germany's lead in renewable energy such as wind energy is mainly due to horizontal networks between different actors. These networks have challenged the carbon lock-in (Unruh, 2000) by creating legitimacy, aligning institutions and pushing for economic incentives. Hence, to achieve policy change, cross-sector networks, similar to the consortium in Belgium (Craps and Sips, 2011), should engage in politics, influence public opinion and demonstrate that landfills in the form of \"mines\" can solve wider policy concerns. For example, landfill mining can create jobs (Jones et al., 2012), reduce carbon emissions (Fr\u00e4ndeg\u00e5rd et al., 2012), prevent future leakage, postpone metal scarcity and by relying on anthropogenic stocks of metals increase the autonomy of governments. Besides collaboration outside the sector, more cooperation inside the sector would have facilitated the transformation. For example, Lane (2011) has shown how the lack of sharing the available resources, between formal and informal actors in waste collection, has hampered effective recycling prior to dumping and the transition to the resource recovery regime. Such regressive forms of cooperation were also obvious in the transformation to the \"gold mine regime\" In these cases, it proved difficult to allocate the deposited resources fairly among involved actors and equitably distribute costs and revenues. In Landskrona, for example, the effect of the current model was that the major cost of combustibles was supposed to be solely borne by the initiator, while the revenue for produced heat would end up at the incinerator. Hence, the general rule of resource management; that resources should be shared between actors in partnership (Ostrom, 1990), seems also apply to waste management. There have been no connections either between the cases and other reported landfill mining projects (e.g. Dickinson, 1995;Reeves and Murray, 1997;Zhao et al., 2007); these have been limited, isolated projects implemented by actors with other core business. There has thus been little transfer of knowledge and experience between cases and actors. Each case had to start from scratch in their efforts to reduce uncertainties and transform the landfill into a mine. Therefore, actors specialized in extracting waste, rather than burying waste probably need to emerge, i.e., division of labor, ready to invest in further experiments and learning processes. This would also make it possible for resource extraction from landfills to not only be an innovative solution to traditional management problems related to landfills such as lack of landfill space, which was the case in Str\u00e4ngn\u00e4s and Landskrona as well as other documented cases (e.g. Dickinson, 1995;Reeves and Murray, 1997), but the primary driving force. Furthermore, since the initiator of the mining cases in this study, the municipal waste manager, had other core activities and responsibilities under law, it may seem unfair to expect a sudden change of focus, efforts to mobilize actors and representation of the transformation at the macro level. Hence, specialized actors who are involved in more than single cases would probably be a more suitable spokesperson for landfills in the form of \"mines\". Even if all these conditions are in place, including passionate individuals, advocacy coalitions, partnerships and specialized actors, it may nevertheless be problematic to overcome one specific obstacle: cultural attitudes. For someone living in the vicinity of a landfill, it can be difficult to grasp the benefits of reduced carbon dioxide emissions and increased metal supply, given that landfills are a typical NIMBY situation (Rasmussen, 1992). All the negative impact from deposition, i.e., smell, noise and transportation, which affects the locals, will revive if the waste is exhumed (Craps and Sips, 2011). Certainly, technical solutions may reduce these impacts, but never to a degree that avoids controversies. In fact, the cases with most transparency and participation, Ringstorp and Malm\u00f6, were also the cases that faced most opposition. As long as the waste is buried, the content seems almost irrelevant. However, when the deposited waste is excavated it suddenly becomes tangible, a potential risk, as it previously did not exist. Or, as one concerned parent put it in the local media, not to argue for remediation of the risk but to suspend the excavation of Ringstorp, \"We do not know with certainty what is hidden in the masses. There may be toxins\" (Bergstr\u00f6m, 2007). Thus, it is not likely that the transformation will be initiated by social movements. However, to facilitate the operation, locals should be invited to participate in the management to represent the locals (Craps and Sips, 2011) and provide solutions (Lane et al., 2011), rather than simply be given the opportunity to express concerns.",
            "Conclusion": " The circular economy is currently challenging the societal function of the dumps, as the recirculation of waste makes landfills redundant. Such instability brings opportunities for new solutions to emerge. However, to initiate a radical transformation, exogenous changes can not only establish instability in the current regime, but must make the radical solution the most viable alternative. Otherwise, a solution that minimizes system change will scale up to restabilize the regime. For example, to stabilize the \"dump regime\" in Sweden, landfills are usually capped and monitored. Even cases where capping proves insufficient and the landfill need to be exhumed such as the one in Ringstorp will survive perfectly without resource extraction. Since the value of the land commonly exceeds the value of the content in a landfill (van der Zee et al., 2004), this could make extraction of resources redundant. Therefore, exogenous changes may be required, which not only destabilizes the \"dump regime,\" but also makes the \"gold mine regime\" more attractive. For example, if the circular economy would align with even further resource scarcity, it would probably force us to not only look at waste but also landfills, the pyramids of waste, as an alternative resource base. For the impatient, shortcuts are nevertheless possible if the emerging approach can be made more compatible with the old regime (von Bertalanffy, 1968). For example, resource extraction could be integrated with landfill remediation projects. After all, it is difficult to separate such remediation and resource extraction projects from each other; pure soil elements can be used as construction material in landfill remediation projects, while resource recovery projects would decrease the risk for leakage of heavy metals. Given the present waste management policy and legislation, it is even unlikely that resource recovery from landfills can be realized without any remediation and site-restoration efforts. In countries with less strict and formal waste management than Sweden, landfills are often situated in parallel regimes. Landfills are simultaneously dumps and mines. Waste companies dump waste in the landfill, whereupon waste pickers collect deposited waste that is valuable. It would therefore be interesting to investigate how these \"landfill regimes\" can work side by side and where mining initiatives are not doomed to fail. Finally, it is important to note that the extraction of resources from Swedish landfills did not fail because it was just another case of fool's gold. Landfills are made up of much more than the metal content alone, i.e., a socio-technical system based on the notion that landfills are garbage dumps; the dump regime. Hence, for dumps to transform into goldmines, it is not the actual landfills that have to change, but the socio-technical system surrounding them. This suggests that the realization of the alchemist's dream, transforming worthless materials into gold, is not necessarily found in exoteric substances but externally, in social dimensions. If our attitude to dumps can change, mines bursting with precious metals including iron, copper and gold are available."
        }
    },
    "10.1016/j.eist.2013.08.001": {
        "file_name": "103 Pioneer countries in the transition to alternative transport fuels",
        "title": "Environmental Innovation and Societal Transitions",
        "abstract": "Efforts to develop alternative transport fuels and vehicles are found in countries varying tremendously in their level of economic development. In this paper, we compare the alternative fuels transition, focusing on ethanol, in three countries: Brazil, Malawi and Sweden. Each can be described as a pioneer in developing the physical and institutional infrastructure and stimulating innovation towards alternative transport fuels. We assess the transition in these pioneer countries based on niche formation and interaction with regime and landscape levels. Particular reference is made to spatial and temporal path dependencies and to the significance of cross-scale and cross-sector effects that impact the innovation process. As other countries and regions develop programmes to address the twin challenges of energy security and climate change, they can benefit from a better understanding of linkages between techno-economic and socio-technical factors in transition paths of pioneer countries, across different scales and different stages of economic development.",
        "label": "Qualitative",
        "text": {
            "Introduction": " The use of alternative transport fuels, particularly alcohol fuels, was widespread in Europe and the Americas before World War II but fell out of favour with the low oil prices of the 1950s and 1960s (Kovarik, 1998;Knothe, 2001). The oil price shocks of the 1970s spurred renewed interest in the U.S. and worldwide in stimulating a transition to alternative fuels. Some developing countries, Brazil foremost among them, recognised that biofuels could improve energy security, save foreign exchange and contribute to agricultural development. In addition to the U.S. and Brazil, several other countries committed themselves to biofuels (only alcohol fuels at that time), including Argentina, Costa Rica, Malawi, Swaziland, Sweden and Zimbabwe (Gowen, 1989). Yet after a century of experimentation, alternative fuels provide less than 2% of global road transport fuels, and are heavily concentrated in just three regions-Brazil, the European Union (EU) and USA. Alternatives to liquid biofuels such as biogas, electric vehicles and fuel cell vehicles have barely moved beyond pilot stages. The transition away from fossil fuels has proven much more difficult in the transport sector than in other end-use sectors; oil dependency reveals the classic features of path dependence and technology lock-in that create barriers in the energy transition (Gr\u00fcbler, 2004). More recently, a new tripartite rationale-energy security, climate change and rural development-has been driving biofuels programmes in developed and developing countries alike (Sorda et al., 2010). In addition to the EU, other regional bodies have been developing biofuels policies, such as the Southern African Development Community (SADC) and the Economic Community of West African States (ECOWAS) (Lerner et al., 2010;Jumbe and Madjera, 2012). Biofuels markets and policies have become a multi-scale phenomenon playing out at national, regional and global levels. Consequently, significant new interdependencies have arisen across these scales: the EU Renewable Energy Directive (EU-RED) in particular has had significant repercussions for global biofuels markets and policies (Johnson, 2011). Only a few countries, however, have pursued consistent biofuels policies over several decades: Brazil, Malawi and Sweden are noteworthy for their efforts to maintain the newly established markets even after the oil price collapse of 1986. They are also noteworthy in terms of environmental impacts compared to the large biofuels programmes in the U.S. and Germany, where the key options (maize ethanol and rapeseed biodiesel, respectively) have poor energy balances and are not environmentally innovative. In contrast, sugarcane ethanol as used in Brazil and Malawi (and imported in significant amounts in Sweden) is noted in both EU and U.S. legislation as having the best energy and GHG balance among first generation biofuels (EC, 2009;US-EPA, 2010). The environmental sustainability of different biofuels is not, however, the focus of this paper. Nor is the focus here on the overall sustainability transition in the transport sector, since this would require a much broader assessment covering both demand and supply sides and addressing systemic transitions (Geels, 2012). We are interested instead in analysing transition pathways across different levels of economic development for countries that engaged purposefully in stimulating the shift away from fossil fuels in the transport sector: How does the nature and scope of transition pathways vary with differing economic development realities and priorities? We therefore choose three countries-Brazil, Malawi and Sweden-spanning three different world regions and three different levels of economic development. Given that transition studies have been concentrated in a few European countries, this paper offers new geographical breadth. These countries have been regional \"pioneers\" or market leaders (global leader in the case of Brazil) in establishing ethanol as a transport fuel. The paper aims to place this role of market leader in a comparative developmental/institutional context in which temporal and geographical linkages are considered through a socio-technical lens. The rationale and approach are outlined in the next section, followed by a review of fuel ethanol market development in the three countries and a comparison of key drivers, actors, policies/programmes, infrastructure requirements and institutional foundations. The paper draws on several different conceptual frameworks and thus none of these can be explored and/or applied on its own in great detail; the paper emphasises instead the overall biofuel-development pathways pursued by the three countries. The paper adds a socio-technical lens in analysing the evolution of the fuel-vehicle (and ethanol) systems so as to complement conventional analyses on techno-economic changes and/or political-economic drivers.",
            "Rationale, framework and approach": " An historical analysis that crosses different regions places the transition to alternative fuels in its global market context while the national-level comparison considers how the transition process itself is influenced by economic development priorities. The rationale is three-fold. First, by considering the evolution over several decades-and at the same time choosing countries that are engaged in comparable pathways-we highlight the temporal dimensions of energy transitions across changing economic and political conditions. Second, our choice of three countries (Brazil, Malawi and Sweden) with quite different resource endowments and levels of economic development facilitates a comparative institutional assessment in the global transition away from fossil fuels and/or towards modern bioenergy (Silveira, 2005). Third, the comparison illustrates the increasing importance of spatial and economic linkages between technological systems and actors at national, regional and global levels and suggests a useful role for a socio-technical lens in analysing the shift to alternative fuels. Adding a spatial perspective recognises the multi-scalar nature of modern sustainability/energy transitions (Raven et al., 2012), which is especially relevant for bioenergy. It widens the geographical reach of transition studies, which have tended to focus on a few European countries (Coenen et al., 2012). In this section, different conceptual frameworks are briefly reviewed to structure and inform the choice of case studies, followed by an explication of the methods and approach.",
            "Energy transitions and alternative pathways": " Although the long-term viability of the fossil economy was questioned more frequently after the 1973 oil crisis, sustainability entered the policy debate mainly after the Brundtland report and the Rio Conference (WCED, 1987;UN/Rio, 1992). The increasing reliance on non-renewable resources in combination with a rapidly expanding global population in a changing climate has led to new perspectives on the role of energy in the economy. Non-renewable carbonaceous fuels will constrain economic growth and development unless the transition to renewable energy can be accelerated (Stern, 2006). Bioenergy has a special role in the transition as the stored (non-intermittent) form of solar energy and because of its flexibility in applications. Energy transitions take place over many decades and involve a variety of symbiotic relationships across conversion technologies, fuels and end-user applications (Gr\u00fcbler, 2004). The historical transition towards large-scale fossil fuels, hydropower and nuclear power involved a long period of experimentation and learning with respect to appropriate scale and end-user needs (Wilson and Gr\u00fcbler, 2011). However, this techno-economic characterisation of energy transitions is less useful for bioenergy compared to other energy resources, since bioenergy crosses all energy carriers and varies in efficient scale and scope: Economies-of-scale are much more spatially and application-dependent compared to other energy classes (Hall, 1991). Technological clusters and networks of actors are even more important for bioenergy, due to the complexities of the biomass feedstock supply chain and associated infrastructures. A socio-technical perspective is thus quite useful in analysing bioenergy transitions. Energy transitions are complicated by path dependence, which can lead to lock-in of sub-optimal technologies or systems. A new technology or system can grow quickly and gain significant market share, regardless of its superiority over alternatives arriving at a later stage (Arthur, 1989). The internal combustion engine itself is sometimes cited as an example, given the higher efficiency of other power trains (van den Bergh and Oosterhuis, 2008). Path dependencies in the fuel-vehicle system also arise from spatial clustering in socio-economic development (e.g. proximity to highways, parking, etc.) and the socio-cultural dependence associated with mobility. Path dependence also results in time lags as new actors engage in ongoing socio-technical struggles, such as biofuels actors dealing with well-established oil and auto industry actors (Gee and McMeekin, 2011). The dominance of the internal combustion engine insures some role for biofuels in the nearterm, at a minimum as bridge fuels while other infrastructures develop. The notion of \"two-world technologies\" becomes useful: biofuels extend the current system but can also facilitate eventual transition to fuel cells or electric vehicles, and even to greater public transit-by altering consumer choices between short and long-range transit (Meadowcroft, 2009;van den Bergh and Kemp, 2008). A similar perspective is that of hybridisation in which a technology/system niche expands through an existing regime rather than competing with it (Geels and Schot, 2007). It is also important to recognise that a given pathway affects the innovation process via problemsolving and problem sequences, which arise as some problems are solved and new problems emerge (Metcalfe and Ramlogan, 2008;Gee and McMeekin, 2011). Actors face \"reverse salients\" along the innovation path that threaten collapse of the new technology/system, requiring adjustments and/or shifts in the path and the dominant actors (Hughes, 1983). A related idea is that of \"path creation\" in which initial conditions are constructed rather than given and a particular path constitutes a provisional stabilisation rather than a technological lock-in that will only respond to exogenous shocks (Garud et al., 2010). Similar to the innovation sequence perspective, under path creation actors are intimately involved in shaping expectations but are also behaving strategically and thus embedded in ongoing developments and not only reacting to external shocks.",
            "Lead markets": " Stricter environmental regulations can encourage eco-efficiency and innovation as early movers seek competitive advantage (Porter and van der Linde, 1995;Beise and Rennings, 2005). Ecoinnovation strategies have consequently been based on the idea that governments can act as political entrepreneurs in introducing environmental technologies and creating a \"lead market\" that spreads to other countries (Cleff and Rennings, 2012). Pioneer countries play an important role by establishing lead markets for environmentally innovative technologies and thereby demonstrating their compatibility with economic competitiveness (Huber, 2008). The president of the European Commission, Barroso (2008) has stated that EU leadership on renewable energy technologies will improve competitiveness and maintain the \"first-mover advantage.\" An oft-cited example is Denmark's investment in wind power, which allowed its manufacturers to maintain a leading position as the global market expanded (Kamp, 2007;Brandt and Svendsen, 2006). The lead market concept arose in part from the notion of first mover advantage at the firm level that occurs when a firm gains information and experience that facilitate strategic competitive advantage (Lieberman and Montgomery, 1988). Whereas a firm has to internalise the risks, governments can spread the risk across all taxpayers. Another distinction is that in the case of global sustainability transitions, a gradual loss of market leader advantage is often desirable, since it can facilitate diffusion to other regions. In the case of fuel-vehicle system innovations, empirical evidence suggests that market leader advantages require that performance improvements accompany environmental benefits (Beise and Rennings, 2005;Geels, 2012). In this paper we are not concerned with first mover advantage at firm level but instead with lead markets arising at national level. In the case of alternative fuels and/or bio-based fuels, lead markets should be considered in relation to implementation and deployment of the fuel-vehicle systems rather than technology development. The location of feedstock sources is flexible, since the raw bio-based materials are widely available although nevertheless spatially dependent. The example of Sweden is noted in this respect, since it has been highly innovative in alternative fuels market development even though it has generally imported a majority of the ethanol used (Chen and Johnson, 2008;Sand\u00e9n and Hillman, 2011). Nor is the location of production of the various technologies (e.g. engines, distilleries) of high relevance, since these are dictated by economies-of-scale in a global economy. Lead markets here can thus be viewed as those that have implemented alternative fuel-vehicle systems in an innovative and more sustainable manner.",
            "Strategic niche management and multi-level perspective": " Path dependence relegates changes to the margins of the dominant system, further locking in the associated infrastructure, in this case the fossil fuel-vehicle system. In order to stimulate broader introduction of new technologies, markets or management processes, a \"niche\" can be created and protected in its early stages through coordinated policies and institutions. Thus, Strategic niche management (SNM) has been proposed, involving: \"the creation, development and controlled phase-out of protected spaces for the development and use of promising technologies by means of experimentation\" (Kemp et al., 1998). SNM attempts to integrate the interests and perspectives of stakeholders in a broader platform for interaction rather than previous technology-push approaches (Schot and Geels, 2008). The unpredictability of technological trajectories underlines the importance of niches in articulating demand and promoting learning (Rip and Kemp, 1998). Three elements have been emphasised in SNM: shaping expectations, network building and learning processes. Learning processes allow for feedback, which also requires measuring, monitoring and reporting (van der Laak et al., 2007). Expectations are important for consumer acceptance of alternative fuels, since reliability and performance are key concerns for car owners. Expectations are quite important on the feedstock supply side in the case of biofuels, especially in developing countries where biofuels offer a new rural livelihood. A highly promoted biofuel in Africa has been jatropha; experience in countries like Tanzania illustrates the difficulties of creating a critical mass of growers (van Eijck and Romijn, 2008). Network building is complicated by the fact that some of the required actors have strong vested interests in the dominant (fossil) system and therefore it is necessary to include newer actors to help overcome that inertia (van der Laak et al., 2007). The recognition that niche experiments cannot transform markets without the presence of broader interactions at higher governance levels contributed to the development of the multi-level perspective (MLP) on technological transitions (Geels, 2002). Niches can be supported during their formative phases, while incumbent and dominant social groups affect the linkages that contribute to wider diffusion of technologies (Geels and Schot, 2007). The role of organisational structures and behaviour affect innovation and are characterised by social-technological co-evolution (van den Bergh and Bruinsma, 2008). A multi-level socio-technical perspective on energy transitions fits well with the multi-scale nature of biomass resources. Spatial constraints along with the greater complexity of organisational structures favour local biomass resources in some applications but physical and economic factors favour international trade in other applications. The policy and regulatory landscape is defined by key driving forces that establish the overall framework in which policy-makers and private actors set priorities. The energy and transport actors translate these priorities into policies, programmes and demonstration projects and collectively define the regime that governs technology implementation. Technological or market niches serve to introduce the new technology/system in a structured and/or protected manner. The driving forces lead to varying degrees of policy emphasis according to fluctuation in exogenous variables (e.g. oil prices, perceived climate impacts). The actors involved in the energy-transport regime cross multiple resource sectors (agriculture, forestry, etc.) and economic interests or industries (oil, autos, farmers, etc.). Cross-sector interactions (energy-agriculture-transport-environment) complicate the transition process and create a larger set of stakeholders compared to other energy sources. Niches might be defined in terms of a technology (e.g. flex-fuel vehicles) or an alternative end-use application (e.g. cooking). Niches may be linked in socio-economic and political terms to the energy, transport, agriculture and environmental regimes, which in turn are impacted by the policy landscape. Other applications, technologies and markets may offer complementary, supplementary or competing options. Competing technologies may be spatially disconnected, e.g. biogas vehicles may dominate in a different region, whereas complementary technologies may in fact be co-located (e.g. heat and power). The MLP and SNM help to structure the comparison in the three country case studies, although it is important to note that the MLP and SNM complement the overall conceptual approach here rather than being the primary organising framework for the comparison.",
            "Spatial dependence and differentiation": " The MLP and to some extent the literature on Technological Innovation Systems (TIS) have been criticised for paying scant attention to the geography of transitions (Coenen et al., 2012;Truffer and Coenen, 2012). The effect of this exclusion can be to relegate spatial aspects to an exogenous element in transition analysis. A related concern is the tendency for both the MLP and the TIS to be applied at national level, even though there are multi-scalar developments that appear to play a significant role in niche development and transitions (Raven et al., 2012). Cross-scale effects are important for biofuels, due to the fact that local economies for biomass feedstock may differ significantly from the national and regional economies associated with end-user markets. Socio-technical factors arise as these markets are emerging due to the strong expectations of key actors in the supply chain for secure biomass supply and infrastructure. Spatial dependence has been observed in the overall orientation of key actors, based on the geography of energy resources. An interesting example is found in comparing biofuels market development in Sweden and the Netherlands. As a neutral country with no fossil resources that is also somewhat geographically isolated, alternative transport fuels in Sweden have been accorded a high priority among both public and private actors (Ulmanen et al., 2009). Interest was lower and progress slower in the Netherlands, which has its own fossil resources (natural gas) and is also a major energy trading hub within Europe. There has been no strong energy-transport network of actors in Netherlands as there has been in Sweden (Lovio and Kivimaa, 2012). This type of spatial interdependence can also be associated with renewable energy technology diffusion more generally, due to the interplay between market segments, transactions and user profiles (Jacobsson and Johnson, 2000;Dewald and Truffer, 2012). Sub-national divergence in innovation pathways may exhibit spatial dependencies that affect technology system development and deployment (Raven et al., 2012). Regional differences within Brazil and Sweden have affected the pace and nature of technology diffusion (Compe\u00e1n and Polenske, 2011;Sand\u00e9n and Hillman, 2011). Cross-scale connections between national and regional levels can be significant, for which EU renewable energy legislation serves as a prominent example (EC, 2009;Johnson, 2011). An integrated market such as the EU thus takes on new spatial dependencies that directly affect the actor networks as well as the physical infrastructure for alternative fuels.",
            "Approach and methods": " In this paper, we use these conceptual frameworks in analysing alternative transport transition pathways in the three countries, focusing especially on fuel ethanol programmes and policies. The moderately long timeframe of the analysis-covering almost four decades, in combination with the considerable geographical spread-spanning three regions/continents-places some special requirements on the approach. We have drawn on a wide range of published literature in developing the conceptual framework and shaping the country analyses, which have also been informed by the authors' experience in both professional and research capacities. Each of the authors has more than fifteen years of experience with biofuels in the three regions. The approach taken here thus draws on interactions over many years with a wide variety of both public and private sector actors involved in all the links of the biofuels chains. Interviews, discussions and seminars with key actors therefore provided \"deep background\" for the research and have facilitated insights not easily accessible through published literature.",
            "Fuel ethanol programmes and policies of pioneer countries": " Ethanol has emerged in the past decade as the most significant among the various alternative fuels or fuel-vehicle systems that have entered the market (Sorda et al., 2010;Hira, 2010;Lamers et al., 2011). In addition to Brazil, global biofuels market expansion is attributed to EU and U.S. biofuel mandates (EC, 2009;US-EPA, 2010). The fuel ethanol market has also been analysed as a strategic investment for Least Developed Countries (LDCs) in relation to energy security and climate mitigation (Pacini and Batidzirai, 2012;Batidzirai and Johnson, 2012). More than twenty-five countries have legislation related to blending of ethanol and/or biodiesel (Sorda et al., 2010). We do not evaluate the global market in this paper, but focus instead on the three pioneer countries, which effectively provided country-wide demonstrations that have influenced regional and global markets and policies. Consequently, the case studies-from three regions and three levels of economic development-form a useful lens on the evolution of the global transition to alternative fuels.",
            "Market leader par excellence: the Brazilian experience": " The story of ethanol in Brazil is among the best-known-and the most successful-of all renewable energy programmes in the world. The Brazilian story is unique in terms of the \"innovation journey\" that has resulted in the replacement of more than 50% of petrol for Otto cycle (fuel ignition) vehicles. It is neither feasible nor necessary here to recount the details of Brazil's ProAlcool programme and subsequent market development, which are well-documented elsewhere (Moreira and Goldemberg, 1999;Goldemberg, 2007). We focus instead on a few key elements to facilitate the country comparisons and illustrate the role of pioneer countries. A brief summary of the programme and the market restructuring of the 1980s and 1990s is followed below by a section on flex-fuel vehicles, which provided the key innovation driving the recent rapid ethanol market expansion.",
            "Brazilian National Alcohol Programme": " A key issue in Brazil's agricultural development in the early 1970s was the volatility in sugar prices, which made it difficult for producers to recoup recent modernisation investments. At the same time, high oil prices after 1973 constrained economic growth and created major trade deficits. A number of programmes were initiated to reduce oil import dependence: nuclear, vegetable oils (ProOleo) and ProAlcool (Rosillo-Calle and Cortez, 1998). The ProAlcool programme for ethanol was initiated in November 1975, with three main objectives (GoB, 1975): (i) reduce national dependence on oil imports; (ii) promote technical and industrial development through ethanol fuel production; and (iii) strengthen the sugarcane and sugar sectors. The original legislation and research were aimed at two crops: sugarcane and cassava (manioc). In terms of social development, cassava-the crop of poor farmers-was preferable to large-scale sugarcane. In commercial terms, it soon became clear that sugarcane was far superior and consequently there was little further experimentation with cassava. Furthermore, the stabilising effect on sugar producers' incomes from having two major commercial products became a key rationale (Moreira and Goldemberg, 1999). The emphasis on sugarcane was a clear choice in favour of rapid market development over the redistributive effects that might have been realised with cassava (Saint, 1982). This choice also facilitated the clustering of innovation around S\u00e3o Paulo that ultimately left Northeast Brazil behind in technical terms (Compe\u00e1n and Polenske, 2011). The shift in the locus of development also revealed significant spatial dependencies in the evolution of the sugar-ethanol innovation system: the network of private actors that later came to dominate that system became more and more concentrated around S\u00e3o Paulo (Furtado et al., 2011). ProAlcool was comprehensive in addressing industrial development, financing, infrastructure, and agricultural research within one broad programme. A special challenge in the early years was establishing the transport and distribution infrastructure, which required close collaboration with the state-owned oil company, Petrobras. Pipelines were alternately used for oil and ethanol to supply S\u00e3o Paulo, requiring innovative methods to avoid corrosion and undesired mixing (Demetrius, 1990). In a vast country such as Brazil, it was necessary to adopt a phased approach to ethanol blending: gradually increasing mandates were established in the sugar centres of S\u00e3o Paulo and the Northeast, followed by introduction in other major urban areas. The initial target of 3.5 billion litres for 1980 was achieved by 1982. The production of neat (ethanol) vehicles in Brazil facilitated the creation of a market for hydrous (95%) ethanol, which lowers the cost by avoiding dehydration technology. The automobile manufacturers signed an agreement in 1979 with the government to produce ethanol-only vehicles, which were also prioritised for government fleets (Demetrius, 1990). The second oil crisis led to a long-term government policy aim to replace all gasoline with ethanol (Cordonnier, 2008). At the same time, the mandate for blending secured the near-term market for anhydrous (99%) ethanol. The coordinated approach taken in Brazil can be contrasted with the regulated approach adopted for ethanol in the USA around the same time (Gee and McMeekin, 2011). By careful coordination of supply and demand, the market penetration in Brazil quickly surpassed the USA, whose fuel ethanol market did not develop in earnest until two decades later.",
            "Market restructuring": " The ethanol market initially grew quickly but the collapse in oil prices in 1986 posed considerable challenges and producers were forced to respond to the changing economics. During the period from 1987 to 1990, the average ethanol production cost declined at more than double the rate experienced in the previous ten years (Moreira and Goldemberg, 1999). Yeast recovery, water recycling, and improvements in energy economy were among the highly innovative measures taken on the industrial side. Another important development in the Brazilian sugar-ethanol complex, which began in earnest in the early 1990s, was the leadership role played by the private sector in pushing the sugarcane innovation system forward at a time when government support was weakening due to financial and institutional pressures (Furtado et al., 2011). Private sector actors took over major roles in agricultural research as well as the more traditional roles in industrial production and distribution. The major role played by the private sector in agriculture was unusual for a developing country and provided the competitive edge that made Brazil a world leader in sugar and ethanol markets (Furtado et al., 2011). Government continued to play its role in terms of prices, infrastructure and regulations. However, the recovery of world sugar prices in the 1990s presented additional policy challenges as the regulated price of ethanol was too low compared to production cost, thus encouraging producers to shift towards sugar and away from ethanol. Brazil became the world's main importer of alcohol fuels for several years, including even methanol since there was insufficient ethanol available on global markets (Moreira and Goldemberg, 1999). The sale of ethanol cars plummeted, not only due to fuel price differentials, but also in response to a reduction of taxes on gasoline cars. Consumer confidence was affected by a series of government policy reversals in taxation and regulations (Rosillo-Calle and Cortez, 1998). Price deregulation was initiated in the 1990s to wean ethanol and sugar producers off guaranteed prices. A producer cartel was temporarily able to manipulate prices, which increased at a faster rate than petroleum prices, and additional measures were needed to restore competitiveness (Hira and de Oliveira, 2009). These new challenges-organisational and economic as well as technical-might be described as \"reverse salients\" that were holding back the ethanol market expansion (Gee and McMeekin, 2011;Hughes, 1983).",
            "Technological innovation: flex-fuel vehicles": " The low and/or stable oil prices of the late 1980s and 1990s contributed to what appeared to be a plateau in the Brazilian fuel ethanol market. The mandated blend created a market floor, but without any prospect of significant expansion, the previous dynamism in the sector seemed unlikely to return. Without dedicated ethanol vehicles, the only possibility for any major market expansion was to devise ways to increase the share beyond the 25% maximum. The development of electronic fuel injection systems in the 1970s paved the way for using different mixtures of ethanol and gasoline, but the appropriate combination of hardware and control software to allow a variable mixture would take many years to develop. The hardware sensor developed by Bosch was rejected by automakers and the software-based solution developed by Magneti Marelli was the first to be adopted in Brazil and was able to gain half the market share in the early years (Yu et al., 2010). The launch of flex-fuel technology during 2003-2004 was a game-changing solution and marks another successful phase in the problem-innovation sequence (Gee and McMeekin, 2011). It virtually eliminated the issue of consumer confidence, as car owners would henceforth have flexibility in choice of fuel. As the sixth largest automobile manufacturing country in the world, Brazil's automobile manufacturers provided the major testing ground for investing in the new flex-fuel technology. At the same time, the long experience with ethanol in Brazil and the maturity of its supply and end-use infrastructure facilitated rapid consumer uptake of the new flex-fuel vehicles (FFVs), which now account for over 90% of new car sales in Brazil (ANFAVEA, 2011). The popularity of FFVs resulted in the consumption of ethanol exceeding gasoline in Brazil as of 2009. There are still some regional and seasonal differences in prices and availability and car ownership is affected somewhat by income constraints (GAIN, 2011).",
            "Regional innovator: bioethanol in Malawi": " Malawi is a small country in southern Africa that depends heavily on subsistence agriculture, with an estimated per capita income of 800 USD/year and a population of 15 million. It is among the most densely populated of the Least Developed Countries (LDCs) in sub-Saharan Africa, and faces increasing pressure on biomass resources due to the overwhelming dependence on biomass and especially fuelwood, which accounts for nearly 90% of its primary energy needs (Juma, 2007;Johnson and Jumbe, 2013). Although Malawi has some coal, it depends entirely on imported petroleum products. It was among several African countries that developed ethanol programmes in the 1970s for reasons similar to those of Brazil. However, Malawi is the only one that has been blending ethanol continuously since its start (in 1982). In this section, we review the evolution of the programme and identify some noteworthy features.",
            "Establishing domestic ethanol production": " High oil prices are especially serious for a landlocked oil-importing country such as Malawi, affecting the prices of all imported goods and the costs of getting their own products to export markets. Transport costs in Malawi account for an estimated 14% of total product costs, compared to the world average of 6% (UNCTAD, 2011). Malawi's single-party political structure made it possible to quickly translate energy security concerns into tangible results through a new ethanol blending programme. The country's first ethanol plant, ETHCO Ltd. (Ethanol company of Malawi), opened in 1982 and has operated continuously, with annual production of fuel-grade ethanol ranging from 10 to 20 million litres (Chanje, 1999). The plant uses sugarcane molasses from the neighbouring Dwangwa sugar factory as feedstock. Since irrigation water is available from Lake Malawi, production was not susceptible to climate-induced interruptions such as that which affected Triangle Ltd. in neighbouring Zimbabwe (ESMAP, 2005). However, the company has faced difficulties in reliable supply of feedstock (molasses). ETHCO is owned separately from the adjacent Dwangwa sugar factory, resulting in the need for price negotiations and creating uncertainties (Chanje, 1999). This factor along with spare plant capacity and the desire to maintain blending targets, prompted ETHCO to secure additional sugarcane molasses supply (as much as 40%) from the Sucoma sugar factory, located several hundred kilometres to the south. Ironically, use of diesel trucks to transport molasses from Sucoma reduced the otherwise positive environmental and economic benefits of ethanol substitution for gasoline (ESMAP, 2005). A new distillery was opened in 2004, achieving cost savings by avoiding molasses shipment. However, the new plant was also encouraged by the Department of Energy for energy security reasons and to facilitate the broader reach of the ethanol market nationally (GoM, 2004). The new factory has been upgraded with modern molecular sieve technology for dehydration, which is also planned for the ETHCO plant. Although it has higher upfront capital cost compared to the traditional azeotropic distillation process, the molecular sieve technology prevents chemicals from coming into contact with the ethanol, improving the company's market prospects for potable ethanol due to high purity standards (Leal, 2012;CARD, 2012). Molecular sieves also have better energy economy and have the additional advantage of achieving higher dehydration levels, resulting in extra dry ethanol (99.95% purity) that is more suitable for fuel blending (Leal, 2012).",
            "Ethanol fuel blending in Malawi": " Public-private partnerships and market coordination (for blending, distribution, transportation, etc.) facilitated the implementation of the Malawi programme, and in fact there was no mandatory blend during the first two decades. In order to create an incentive for oil companies and fuel distributors, the price of ethanol has always been pegged slightly lower than the cost of imported gasoline (GoM, 2009). As a result, there has been a changing gap between fuel ethanol price and production cost, enabling profits to be made depending on oil prices and ethanol blending volumes. In the early years (before 1986 oil price collapse) high blends above 20% were sometimes used, and there were some performance and reliability issues with older vehicles (Chanje, 1999). The oil price collapse in 1986 and the lower oil prices of the 1990s led to market adjustments. The ethanol producer (ETHCO) entered the other end-use markets for ethanol, namely industrial, pharmaceutical and potable ethanol. These markets obtain higher prices than fuel ethanol and offer a means of diversification in final products. With growing demand and decreased supply due to the competing markets for ethanol, the level of blending decreased in the ensuing years, averaging closer to 10% rather than 20% (Chanje, 1999). ETHCO had actually exhibited a clear preference to discontinue the blending programme due to low profitability, but was pressured by the government to maintain the commitment with the rationale of energy security (CARD, 2012). A number of changes ensued with the higher oil prices of the 2000s. The available domestic supply expanded with the opening of the second distillery in 2004. At the same time, health and environmental concerns began to enter the rationale. Unleaded fuel was introduced in Malawi and thus ethanol gained a new role in replacing lead as an anti-knock agent. A mandatory minimum blend of 10% was introduced through legislation enacted in 2004 (GoM, 2004). Regulations to enforce the required blend were finally implemented in 2008-2009 by the Malawi Energy Regulatory Agency (MERA, 2009). The energy security issue seems omnipresent in the form of highly disruptive physical shortages as well as financial constraints; the first author of this paper observed long queues at filling stations during a visit to Malawi in October 2012, with some stations completely out of petrol and diesel. The economic and political pressure to expand ethanol blending has led to renewed government commitments to do so (Johnson and Jumbe, 2013). In recent years, the political approach to biofuels has matured significantly. A Stakeholders workshop was held in November 2008 and a Biofuels Advisory Council was created (Wambua, 2011). A non-profit organisation, the Biofuels Association of Malawi, was formed in 2009, with an initial focus on oil-based crops for biodiesel, particularly jatropha. The emphasis is understandable since the ethanol industry is well-established and operates at a larger scale; however, there could be benefits for small sugarcane growers (CARD, 2012). Technical standards have been developed for ethanol and biodiesel through the Malawi Bureau of Standards, which is funded through fuel levies on energy products (MERA, 2009). The technical standards will improve reliability in domestic markets, facilitate trade and help to set standards elsewhere in Africa.",
            "Multiple products and applications": " An innovative technical feature of the first distillery was the integrated design, which included facilities for multiple processes and products. Stillage waste (vinasse) from ethanol production was to be turned into biogas, using an anaerobic digester funded by the Dutch government. At the time, biogas from vinasse was not a well-proven technology in comparison to the well-known procedures for running an ethanol distillery. A lack of training and standardised operations resulted in the biogas plant being shut down without ever having operated for more than a few days at a time (Chanje, 1999). Interestingly, the same type of project is now being investigated as a CDM project in Malawi and other countries; significant emissions savings are possible by producing biogas and avoiding open discharge ponds that release methane (Khatiwada and Silveira, 2011). Another by-product is the provision to farmers of fertilisers derived from the vinasse effluent from ethanol distilleries. The vinasse continues to present a disposal problem, as its volume is quite large, more than ten times the amount of ethanol produced; in the past, it was often simply dumped on nearby (dirt) roads as a type of inexpensive paving material (Cornland et al., 2001). The development of the fertiliser programme has helped with the disposal problem while also providing a value-added product to nearby small farmers (ETHCO, 2010). An alternative application that has recently been explored is the use of ethanol for cooking. Malawi has experienced an accelerating rate of deforestation, which is exacerbated by the high population density and the 95% of households that rely on wood and charcoal (GoM, 2009). Tests have been conducted on several stove designs, with good results in terms of performance (Robinson, 2006). However, there seems to be resistance on a social and cultural basis to cook without wood or charcoal. This significant socio-cultural component provides an illustration of the potential value of taking a socio-technical perspective in efforts to stimulate innovations in this market segment.",
            "Multiple paths to alternative fuels: the case of Sweden": " The story of alternative fuels in Sweden began in earnest after the first oil crisis in 1973, at which time Sweden had become heavily dependent on imported oil, not only for transport, but also for industrial cogeneration, petrochemicals, power generation and household heating. In fact, only about 20% of oil was used in the transport sector whereas today it is the opposite, with more than 80% of oil being used for transport (SEA, 2011). The development of alternative fuels has undertaken a rather winding road since that time, first emphasising methanol, and later focusing on biogas, ethanol and electric vehicles in varying proportions. In this section, we consider the significance of some key elements of the programmes and relevant policies.",
            "From methanol to ethanol": " The Swedish alternative fuels programme in the 1970s emphasised methanol, based on the recommendations of a working group that created Svensk Metanolutveckling AB (SMAB), which was owned in part by Volvo and the government. Methanol received more than 75% of research and development funding for alternative fuels in the ensuing years, while SMAB was later reconstructed as a technical consulting group (Sand\u00e9n and Jonasson, 2005). During the following decade, various implementation schemes were considered for blending methanol (M15 and M20) as well as M100 in fleet vehicles. Support for methanol waned due to the lack of economically viable domestic production along with the oil price collapse of 1986. Ethanol as a fuel was promoted by farmers and their interest groups in the late 1970s, and new connections developed with agro-industrial players in Sweden and abroad. A new fermentation technology (Biostil) was developed by the Swedish company Alfa Laval, who participated in a demonstration project (Sand\u00e9n and Jonasson, 2005). The political sentiment against nuclear power in Sweden benefitted biomass R&D in both the heat and power and transport sectors. Ethanol was allocated more than one-third of alternative fuel R&D during 1993-1997 while biogas received a somewhat greater share. In the initial years when methanol was favoured, the fossil fuel route was envisioned while research on gasification of wood and peat was expected to eventually provide renewable feedstocks. The lack of progress on methanol contributed to the ideas for producing ethanol from wheat, with the idea of later switching to cellulosic ethanol production. Farmers and their allies were successful in bringing the wheat ethanol programme to the fore, and a pilot plant run by Agroetanol AB opened in 2001 using a special tax exemption that was eventually approved at EU level (Sandebring, 2004). There has long been an assumption in Swedish energy/transport policy that lignocellulosic conversion was necessary for the long-term viability of an ethanol fuel market. Strong domestic political support along with interest from the EU research directorate and international investors contributed to the inauguration of a pilot plant in \u00d6rnsk\u00f6ldsvik in 2004 and detailed studies such as the NILE project (NILE, 2010). However, the pilot plant has closed due to completion of the pilot testing phase and lack of sufficient funds for a commercial-scale plant (SEKAB, 2011).",
            "Fleet vehicles and market development": " Starting in the 1980s, a research, development and testing programme was initiated under which bus engines were re-designed to run on ethanol by SCANIA. The first ethanol bus was introduced in 1985 and by 1996 there were 300 ethanol buses operating in Sweden, covering about 6% of the total fleet. By 2010, there were over 600 ethanol buses in Sweden, including 400 in Stockholm (Milj\u00f6f\u00f6rvaltningen, 2010). The third generation design of SCANIA ethanol buses has been introduced in recent years, for which GHG savings have been estimated at 90% (SCANIA, 2010). There are also a number of trucks running on ethanol in modified engines. These large-scale demonstrations with fleet vehicles served to promote and spread experience with the new fuel among customers, distributors and other actors across a number of regions and municipalities. For the passenger car market, the classic chicken and egg problem arises: no one will buy the cars unless there are filling stations to provide the new fuels, but fuel distributors cannot justify the additional cost with so few customers. Cooperation between the oil distributor OKQ8 and the Swedish Ethanol Fuel Foundation (SSEU) addressed the issue in the early 1990s. A number of filling stations were established as demonstration sites and flex-fuel vehicles (FFVs) were imported from the USA for pilot testing. In 1996, OKQ8 and SSEU joined an environmental train tour around Sweden, which was organised by the Natural Step Foundation, offering a challenge to local authorities and companies: OKQ8 would put up an ethanol filling station if they would purchase at least ten FFVs (Sand\u00e9n and Jonasson, 2005). A little over a year later, there were 30 pumps and 300 FFVs in various locations around the country. Municipal procurement programmes in the ensuing years together with tax incentives resulted in purchases of several thousand FFVs by 2004-2005. The most active among municipal players is Stockholm city, which launched its Clean Vehicles Programme in 1994; by 2009, 40% of newly registered vehicles the environmental standards and more than half of these were ethanol FFVs (Milj\u00f6f\u00f6rvaltningen, 2010).",
            "Multiple pathways and local initiatives": " Although the initial phase emphasised one option (methanol) and a second phase embraced ethanol, later phases embraced multiple options to avoid closing off pathways needing time to mature (Sand\u00e9n and Jonasson, 2005). Ethanol first entered the picture through a repositioning, in which it was lumped together with methanol as \"alcohol fuels\": legislation and policy were developed through the Motor Alcohol Committee (MAC, 1986). This shift signalled a transition phase away from the single pathway approach. Along the same lines, the SSEU was renamed the Bioalcohol Fuels Foundation (BAFF). Use of the term \"alcohol fuels\" also illustrates how social discourse affects technical adoption: the inclusion of ethanol already in the early 1980s (when methanol was the sole priority) gave it a foot in the door that its supporters could later build on (Ulmanen et al., 2009). Biogas and hybrid/electric vehicles started to enter the picture in the late 1980s. The rise of biogas illustrates how multiple factors must intersect to overcome the network externalities of competitors (i.e. biogas requires separate infrastructure). One was the link to compressed natural gas in vehicles coupled with plans for natural gas imports. Another factor was increasing interest from municipalities in alternative fuels as a way to reduce air pollution and improve waste disposal (Sand\u00e9n and Jonasson, 2005). Yet another factor was that the number of actors involved was relatively small with the focus on bus fleets and since local wastes were controlled by municipalities. Biogas offered a quadruple win that made it politically popular: waste disposal, reduction of local air pollutants, replacing non-renewable imported fuels and GHG reduction. The development of multiple pathways benefited from regional diversity in combination with the active role of municipalities and national investment. Availability of natural gas in western Sweden facilitated introduction of compressed natural gas buses-and by extension-biogas buses. The Local Investment Programme established in 1998 provided 250 million SEK to municipalities for clean energy and transport projects (Rehnlund et al., 2004). The environmental vehicles (mij\u00f6fordon) programme established in 2006 provided tax exemptions and incentives (such as free parking) for \"environmental cars.\" Efficient and/or smaller diesel vehicles were included in the definition, which drew criticism from environmental groups (Gr\u00f6na Bilister, 2012).",
            "A biofuels market leader": " After Sweden joined the EU in 1995, its alternative fuels market had to be harmonised with EU policies, which affected the eligibility of financial incentives and initially constrained Swedish biofuels development. EU payments for agricultural surpluses reduced the incentives for domestic production, while at the same time the tax exemption for the wheat-ethanol plant had to be negotiated with the EU (Sandebring, 2004). Initial advantages for Sweden were few, due to stable oil prices in the late 1990s and the EU funding focus on biomass for heat and power rather than transport. At the same time, the European-wide social networking and funding that comes with EU membership enhanced the stature of the Swedish programme considerably. Stockholm city's Clean Vehicles initiative coordinator, Gustav Landahl, noted that his agency's expanded role came about \"almost by chance\" due to a meeting in Brussels that led to the groundbreaking ZEUS project (Zero and Low Vehicle Emissions in Urban Society) in 1996 (Milj\u00f6f\u00f6rvaltningen, 2010). As EU renewable energy policies began to emerge, Sweden's early efforts began to pay off: it was one of just two countries to meet the Biofuels Directive target of 2% in 2005 (EC, 2011). The number of FFVs and ethanol fuelling stations increased rapidly between 2002 and 2005, even though the EU targets were voluntary (Nykvist and Whitmarsh, 2008). Sweden was also involved in many EUfunded alternative transport programmes; it was well-poised to play a leading role since so many Swedish actors had acquired experience not only in RD&D side, but also with implementation and policy aspects-which were relatively unexplored in other EU member states. The city of Stockholm provided a leadership role in the global diffusion of ethanol vehicles through the EU-funded BEST project during 2006-2009, involving the expansion of vehicles and infrastructure in 8 cities in Europe, China and Brazil (BEST, 2011). When biofuels returned to global agendas with a vengeance in 2007-2008, Sweden was well-poised to integrate its programme with the EU agenda and take a leadership role, in spite of its modest size among EU Member States. Sweden gained headlines in 2006 when its \"Commission on oil dependency\" (Kommissionen mot oljeberoendet) stated the goal of being oil-independent by 2020, although the goal was not fully clarified (Regeringskansliet, 2006;Chen and Johnson, 2008). Sweden has already met the 2020 EU-RED requirement of 10% renewable energy in transport, although this is due to doublecounting provisions in the EU-RED for biofuels made from wastes (EC, 2009). Analysis suggests that rather stringent measures on both the supply and demand side would be required to achieve total oil import independence, with (second generation) ethanol playing a significant role (Lindfeldt et al., 2010).",
            "Comparison": " In spite of the significant differences in resource endowments, there are many similarities in the transition pathways and the respective roles of the three countries as pioneers or market leaders. A breakdown of key characteristics and examples is summarised in Table 1; the early phase corresponds roughly to the late 1970s and most of the 1980s, whereas the later phase refers mainly to the period starting in the late 1990s. The era of low and/or stable oil prices of the late 1980s until the late 1990s might be considered as a middle era when change was slower and thus is not included in the table. The \"landscape\" factors related to international trade are quite different in the three cases: whereas Brazil has global market power in resources (sugarcane), end-use products (ethanol) and end-use devices (vehicles), Sweden has much less market influence and Malawi as an LDC has very little. However, Sweden and Malawi do have some influence with respect to regional policies. The goal of energy security was common across all three countries and still remains prominent, while Sweden as a major environmental actor has since emphasised climate change and \"oil independence.\" New actors entered in the later phases in all cases, and the comparison is interesting between Brazil and Malawi, which both became more democratic; farmers, civil society and other groups gained a greater voice. Financial incentives have been applied to vehicles in Brazil and Sweden, and to fuels in all three, while various types of R&D support have been important in Brazil and Sweden. As a direct result of the ethanol programme, Brazil has introduced advanced methods in the agricultural sector such as agroecological zoning that have wide applicability (Strappason et al., 2012) whereas agricultural spin-offs have been more limited in the case of Malawi and Sweden. On the industrial and infrastructure side of the equation, there are some clear differences. Fuel blending was practiced in Malawi without a mandate, whereas Brazil implemented fuel blending through regulatory requirements and Sweden later followed EU targets. Brazil with its large market initially aimed for ethanol-only vehicles, which eventually set the stage for flex-fuel vehicles (FFVs) (Yu et al., 2010). The market for FFVs was incentivised through the environmental vehicles programme in Sweden, while Malawi has only begun to experiment with FFVs. A key difference in terms of competing options is that Sweden promoted clean vehicles, regardless of fuel, whereas Brazil and Malawi focused only on ethanol. Unlike the EU market, in Brazil biodiesel is aimed mainly at heavy duty vehicles (e.g. trucks, buses) since diesel cars are uncommon. The dynamics behind these differences and similarities are analysed further in the Discussion section below.",
            "Discussion": " In this section, we draw on the three case studies to identify five dynamics or lessons that are relevant to the nature and/or significance of the innovations achieved in the alternative fuels transition: niche development, variety creation and compatibility, social/organisational network evolution, cross-scale and cross-sector effects and the duration and timing of the transition. Reference is made to experiences in each of the three countries in relation to key elements from the conceptual framework (given in bold) as summarised in Table 2. \u2022 Network of public and private actors was initiated. \u2022 Malawi's role as a regional market leader encouraged pilots for FFVs. \u2022 Climate complications reduced confidence in ethanol-only cars. \u2022 Spatial dependence exhibited by fleet vehicle approach, due to energy security concerns in urban areas. \u2022 FFVs allowed social learning promoted by Stockholm city.",
            "Variety creation and compatibility": " As discussed in Section 2.1, attempts to consciously stimulate new fuels/vehicles must invariably contend with the question of whether an inferior option might be prematurely adopted as the front runner, gain market share and eventually become entrenched or locked in. A related issue is how to insure compatibility with long-term transport infrastructures that are envisioned as desirable or likely, such as hydrogen infrastructure and fuel cell vehicles. Such issues entered the debate in Sweden at an early stage, as is fitting for a social democracy that emphasises bringing all sides to the table. The mix of options that received funding and support included not only the various biofuels (methanol, ethanol, biogas, RME and others) but also electric and fuel cell vehicles along with hybrid options of various types. Compatibility with a future hydrogen economy also became a selling point in the debates among interest groups in the 1990s (Sand\u00e9n and Jonasson, 2005;J\u00f6nsson, 2006). The end result was the creation of a variety of options as the basis for experimentation and learning. In stark contrast to Sweden, the developments in Brazil and Malawi resulted in rapid convergence on ethanol. Both Brazil and Malawi had authoritarian governments at the time they started their programmes; there was little democratic political pressure to engage in wide consultations or create linkages with civil society groups. Brazil and Malawi were thus able to fairly quickly replace 5-25% of gasoline with ethanol, whereas it took Sweden more than thirty years to reach a 5% share for ALL alternative fuels. The quick start in Brazil had a strong economic rationale due to the well-established sugar industry, but it was clearly not sufficient to guarantee success, which came only after the more coherent Brazilian programme of the 1990s by which time democratic rule was well-established. A more inclusive biofuels programme with extensive stakeholder involvement has now been established in both Brazil and Malawi, especially in their socially oriented biodiesel programmes (Hall et al., 2009;Wambua, 2011). The political popularity of the Malawian programme led to consistent support from the government, as championed through the Malawian Department of Energy (Mhango, 2011). In Sweden, the market structure and consumer response reveals greater risk aversion to ethanol as a long-term solution compared to Brazil, with consumers exhibiting greater price sensitivity (Pacini and Silveira, 2011). At the macro-level, Sweden as a rich country seems to more easily absorb higher oil prices: the Swedish experimentation with different alternative fuels revealed mush less sense of urgency compared to Brazil and Malawi. The Swedish approach is a hybrid-seeking compatibility through an emphasis on alcohol fuels, but maintaining variety creation through investment in biogas, electric vehicles and hydrogen/fuel cells. However recent incentives, such as \"green vehicle\" premiums/rebates, favoured options that are compatible with existing infrastructure: diesel and flex-fuel vehicles have overwhelmingly dominated sales under these premiums (Gr\u00f6na Bilister, 2012). Partly in response to criticism over the fact that \"clean\" diesel vehicles received 60% of \"environmental\" rebates in 2011, the government allocated 200 million SEK for so-called \"super eco-car premiums\" starting in 2012 to vehicles emitting less than 50 g CO 2 /km (Regeringskansliet, 2011). The infrastructure issue in Malawi illustrates one advantage of being at an earlier stage of development. There are relatively few personal vehicles and relatively few filling stations. Only a small number of blending depots were required, in which gasoline and ethanol are blended before arriving at the filling stations all over the country (ETHCO, 2010). The blending approach used in Malawi served as a demonstration for other countries in southern Africa (Johnson and Matsika, 2006). Infrastructure compatibility in Brazil represented a considerable challenge, considering the vast size and diversity of the country. Early involvement of the state oil company Petrobras guaranteed proper fuel distribution while agreements with automobile manufacturers helped establish a rapid pace for the transition (Cordonnier, 2008). The government's heavy hand and the oil price issue resulted in little political opposition. Again it is interesting to contrast the case of an authoritarian regime with a social democratic regime (Sweden). The infrastructure changes needed in Sweden had to be carefully coordinated from the ground up, such as by convincing municipalities to offer incentives or by alliances between fuel distributors and supporters.",
            "Niche development": " Technological niches are distinct from market niches, as the latter tend to be aimed at extracting price premiums rather than achieving market transformations. However, this distinction becomes blurred in the case of alternative fuels, since the relevant focus is on the fuel-vehicle system. Furthermore, innovation in one or even two of the key sectors (agriculture, energy, transport) does not guarantee that the fuel-vehicle system will evolve in the same direction. Hence niche development is connected to the notion of innovation in implementation and deployment (Section 2.3). Brazil and Sweden actively promoted various fuel-vehicle niches, while Malawi's small market constrained use of fuel-vehicle niches, although fuel production niches were pursued in upgrading factories to allow multiple products (Section 3.2.1). Three types of niches are especially relevant for ethanol and/or alternative fuel-vehicle systems: dedicated vehicles/markets, fleet applications, and hybrid/flexible engines. Dedicated ethanol vehicles (E100 or E85) build the market more quickly and can take advantage of the higher compression (octane) obtained using ethanol. In Brazil, the government's promotion of ethanol vehicles was initially aimed at replacing all gasoline consumption. The eventual failure of ethanol-only vehicles was due to landscape pressures in the form of low oil prices and ineffective policy coordination after democratisation (Hira and de Oliveira, 2009). The use of E85 in earlier FFVs in Sweden was promoted using U.S. FFV imports, but this niche market did not develop significantly and the key actors shifted the focus to heavy-duty vehicles. For passenger cars, technical complications in colder climates required a supplementary gasoline tank and complicated the ethanol-only engines in Sweden and even in some colder areas of Brazil (Moreira and Goldemberg, 1999). Fleet applications allow technical and market experimentation, while avoiding the negative publicity that can occur in the general market. Fleet applications also help in determining which actors are prepared to champion the new fuel/vehicle and push for further adoption. In Brazil, ethanolonly vehicles were included in government fleet procurements. Public vehicle fleets are too small in Malawi but experimentation is underway (Wambua, 2011). In Sweden, fleet applications were based on ethanol engines for heavy duty vehicles (buses and trucks) that were promoted for energy security reasons-to insure that buses and trucks could run in the event of a shortage (MAC, 1986). This type of niche derives from Northern European style urban planning, which relies heavily on mass transit. Surprisingly, despite wide use of buses in urban areas and for regional traffic in Brazil, introduction of ethanol engines in Brazilian bus fleets was only considered much later (BEST, 2011). Flexible fuel vehicles (FFVs) have clearly been the game-changer, particularly in Brazil and Sweden where the end-use infrastructure was well-developed. By allowing any mixture of ethanol and gasoline, consumer confidence was enhanced while also facilitating a more seamless infrastructure transition from gasoline to ethanol. The FFVs thereby \"unhitched\" the ethanol market somewhat from political decisions and \"hitched\" it more closely to international markets, especially sugar and oil prices. In Brazil, the transition was even more rapid than expected, with over 90% of vehicle sales now FFVs. In Sweden, the market response has been reasonably good, but the government policy of technology neutrality in classifying vehicles as \"environmental\" has ironically shifted the majority market share (as of 2011) to fossil diesel cars (Gr\u00f6na Bilister, 2012). Malawi has been experimenting with FFVs since 2007 on a pilot basis (ETHCO, 2010).",
            "Network evolution": " A key aspect in the evolution of actor networks is found in the changing role of the big industrial players-oil and automobile industries-within a modified energy/transport regime that puts their product or market at risk. Brazilian government pressure placed on oil and auto companies resulted in a \"purposive\" transition in which the authoritarian regime wielded political power that would be impossible today (Lehtonen, 2011). Such pressure could also be coordinated with stateowned Petrobras to provide infrastructure. Negotiations with the government pushed the automobile manufacturers' towards ethanol-only vehicles, and demand was created through public procurement (Cordonnier, 2008). The traditional reluctance of oil companies has re-emerged in recent years, while non-profit organisations expressed concern about the impacts of biofuels on food security, again illustrating problem sequences in the innovation process (discussed in Section 2.1) due to \"reverse salients\" (Gee and McMeekin, 2011;Hughes, 1983). Some of these actors specifically aimed to discredit the perceived sustainability of the new path (ethanol) and destabilise its supporting networks (Pilgrim and Harvey, 2010;Garud et al., 2010). In the case of Malawi, the government had limited market power and could offer oil distributors additional margins by increasing the blend (Chanje, 1999). The persistent high cost of ethanol in Malawi is due in part to the difficulty of stimulating competition in a small LDC (Mhango, 2011). In Sweden, the auto manufacturers and oil companies resisted change until a specific opportunity presented itself in the form of the Scania ethanol bus programme. In this case, the most effective pressure on oil and auto companies came not from the national government, but from the municipalities, with some cooperation from oil distributors, based on sustainability strategies in response to Agenda 21 (Sand\u00e9n and Jonasson, 2005). Another long term network effect is associated with how new constellations of actors-farmers, NGOs, technical consultants, entrepreneurs and others-became integrated into the overall network and began to exert influence. It is interesting to note which country's alternative fuels programme seemed to be most influenced by farmers-not Malawi or Brazil, where farmers make up a large share of the workforce-but where farmers make up an extremely small but politically powerful group. However, the ethanol programme in Brazil contributed to overall agricultural modernisation in S\u00e3o Paulo, and greater political freedom later facilitated wider participation. In both Brazil and Malawi, farmers and NGOs have subsequently influenced the direction of their respective biodiesel programmes (Wambua, 2011;Hall et al., 2009). The influence of the new networks extends far beyond their own countries: ethanol, sugar and bioenergy consultants from Brazil are in high demand all over the world (Goldemberg et al., 2004). Independent consultants from Sweden have worked extensively abroad, providing a mobile form of institutional memory (Sand\u00e9n and Jonasson, 2005). The city of Stockholm led a number of EU-financed clean vehicles projects and networking through EU-financed projects became an important element of international alternative fuels programmes (BEST, 2011;Milj\u00f6f\u00f6rvaltningen, 2010). Analogous developments are found in Malawi, which has become a regional example for southern African countries (SADC, 2006). The technical expertise in Malawi is highly valued; ethanol companies elsewhere in Africa have tried to recruit Malawian staff (ETHCO, 2012). The Malawian example illustrated that poorer countries can mobilise their own biofuels actor networks and do not need to wait for global agreements or foreign support (Batidzirai and Johnson, 2012). The role of transnational networks is an important area for future transition research as it connects spatial characteristics to niche development and transition pathways (Raven et al., 2012).",
            "Cross-level and cross-sector linkages": " The technological and market niches that developed for alternative fuels-mainly ethanol in the three cases analysed here-are linked to developments at regime or sector level (especially energy, transport, agriculture) as well as to global markets and institutions. The relation to agriculture, rural development and climate adds dimensions that were previously missing in the fossil-based energy/transport regimes of the post-WWII oil economy. Consequently, new actors have emerged in developed and developing countries alike and are increasingly crossing the boundaries from local to national to global. These new actors have influenced the international debate, which has in turn enabled them to enhance their public visibility (Pilgrim and Harvey, 2010). In all three countries, high oil prices and the political instability of oil-exporting countries were key elements at landscape/policy level in the early years. The Brazilian programme suffered a severe setback with the low oil prices of the late 1980s, while the Malawi programme was scaled back from 20% to 10% blending. The small Malawian market meant that private sector producers had to find alternatives, which they did, through the potable and industrial ethanol markets. The influence of the Malawian Department of Energy thus became important in maintaining the blending commitment amidst such internally competing markets in combination with lower oil prices (CARD, 2012;Mhango, 2011). Sweden's leadership role on environmental issues allowed other concerns to enter the policy void created by low oil prices: air quality and later climate change became major driving forces. Nevertheless, lower oil prices affected the pace of alternative fuels development, since other measures could address air quality, such as end-of-pipe controls and fuel quality adjustments (Sand\u00e9n and Jonasson, 2005). The relation to the agricultural regime clearly went through a transformation in all three countries. Agricultural actors gained influence in Sweden and Malawi through the technical and market niches established for ethanol, but also due to the wider recognition that domestic biomass resources had an important role in future energy shifts. The purposeful shifting of the agro-industrial sugar complex in Brazil to S\u00e3o Paulo from the Northeast was aimed at achieving a radical re-organisation of the industry into a sugar-ethanol complex (Compe\u00e1n and Polenske, 2011;Furtado et al., 2011). This shift was politically significant enough that it led to new policies to address fundamental economic inequities in the two regions (Lehtonen, 2011;Compe\u00e1n and Polenske, 2011;Furtado et al., 2011). The oligopolistic sugar-ethanol regime centred in S\u00e3o Paulo also created political pressures to take a more socially conscious route in designing the Brazilian biodiesel programme (Hall et al., 2009). Cross-sector linkages also enter through the existence of multiple (energy and non-energy) coproducts, thus exploiting economies of scope as well as economies of scale. Experimentation with different combinations of sugar cane juice and molasses allowed technical-economic optimisation between sugar and ethanol outputs (Macedo, 2005). At the same time, these physical linkages came into play with the price liberalisation of the 1990s: ethanol suppliers could decrease production in response to relative price changes, i.e. by diverting potential ethanol feedstock into sugar production. Consequently, the economic flexibility that helped build up the programme in the 1980s became a liability in the 1990s when resulted in significant ethanol imports and the government opted not to intervene (Hira and de Oliveira, 2009). Other important co-products include cogeneration, animal feeds and fertilisers. Even when coproducts do not initially result in new markets, they can leverage financing, reduce environmental burdens and cultivate local benefits. Bagasse cogeneration in Brazil offers a co-benefit that is wellrepresented among CDM projects (UNEP/Risoe, 2011). Co-products can provide value even if they are never formally commercialised: in Malawi, the provision of fertilisers to local farmers at no cost brings good will towards the private sector (ETHCO, 2010). In Sweden, animal feeds are a co-product from wheat ethanol production, and serve to offset the environmental/climate burden of imported soya, thereby reducing GHG emissions (B\u00f6rjesson, 2009). Other non-energy co-products can offer additional economic incentives to producers: examples include the provision of carbonation for soft drinks in Malawi's distilleries (Chanje, 1999) or the production of bioplastics from sugarcane byproducts in Brazil (Leal, 2012). These co-products provide stabilising factors for the ethanol regime through economic flexibility while also creating new actor networks that gain an interest in the success of the new regime.",
            "Duration and timing of transitions": " Sweden has been engaged in this path as long as Brazil, but has achieved only 8% replacement of oil in transport, compared to more than 25% in Brazil (or more than 50% if only gasoline is counted) and 10-20% in Malawi. Although Sweden has been a leader in this area, early efforts focused on research whereas implementation was not well-addressed until the late 1980s. The deliberative nature of Swedish social democracy and later, accommodation to the EU agenda, may have drawn out the transition process. The timing of policy changes in relation to the phase of economic development is important: the emergence of a middle class in Brazil brought a tremendous increase in personal automobile ownership and provided the engine of growth to support the expanding market niche for ethanol in the 1970s (Lehtonen, 2011). The authoritarian regimes in Malawi and Brazil at their respective stages of development could kick-start their ethanol programmes in a manner that is not possible in Europe, due to political plurality as well as economic maturity. It can also be observed that even in a wealthy and environmentally advanced country like Sweden, the more \"radical\" and costlier supply-side innovations such as electric vehicles and fuel cell vehicles have been marginalised to those that fit better with the fossil fuel regime-biofuels and biogas (Nyqvist and Whitmarsh, 2008). An interesting question for future research is thus whether radical innovation in energy/transport transitions is less feasible in mature economies. Consequently, the dominant energy/transport regime remains fairly intact in all three countries. Indeed, the key economic-political advantage of ethanol is the capacity to co-evolve alongside minor changes in existing infrastructure and institutions, somewhat analogous to the two-world solutions discussed by Meadowcroft (2009). Thus all three countries have gone down the path of co-existence rather than radical transformation and it can be argued that it was the only feasible path given overwhelming oil dominance and its lock-in effects. However, the Brazilian market is still expanding due to the popularity of FFVs whereas a plateau may have been reached in Sweden and to some extent in Malawi. The weaker political agenda in Sweden is due to greater dependence on EU policies, stable world oil prices and pressing issues such as the financial crisis, which together have prevented \"oil independence\" from being fully incorporated into energy/transport planning (Lindfeldt et al., 2010;Johnson, 2011). Although Sweden placed special emphasis on ethanol, it is nevertheless a leader in terms of exploring and supporting multiple alternative fuels/vehicles pathways. However, since it started its transition at a much more advanced stage of development, the economic urgency was lower compared to Brazil and Malawi. Furthermore, biofuels in Sweden-as well as in the EU and some other OECD countries-has entered a state of limbo, contingent on advances in the commercial feasibility of second generation ethanol, which would undoubtedly lead to more enthusiasm from industrial actors. The lack of competitive domestic ethanol production has in some respects become an Achilles heel in the Swedish programme. Policy leadership grounded in improved competitiveness is important for the next wave of biofuels expansion and consequently a deeper analysis on the political economy of past and future trajectories poses a useful topic for future research. It is interesting to note the relative independence and strongly national character of the trajectories in the three countries, which originated in the security reasoning of the 1970s. Market developments and actor networks have become less isolated since that time, due to increasing globalisation and also the increasingly transnational character of the actor networks (as discussed in Section 4.3). It should nevertheless be recognised that in spite of globalisation the unique role of pioneer countries at early stages of experimentation and market development suggests that national-level policies and programmes remain crucial for the innovation process (Huber, 2008). This is especially true for new fuel-vehicle systems given the omnipresence of energy security concerns.",
            "Conclusions": " Each of the three countries-Brazil, Malawi and Sweden-can be regarded as a pioneer with respect to alternative fuels in their respective regions, and each one ascribed a special role for fuel ethanol, although the Swedish approach was more pluralistic. Developing countries as diverse in size and resources as Brazil and Malawi have moved fairly quickly on the path to alternative fuels, albeit focusing on biofuels and strongly kick-starting ethanol, due to their natural resources base and for the sake of compatibility and cost. Sweden and other EU countries-with greater infrastructure and vested across many different agricultural, energy and industrial actors-are moving much more slowly. We find little evidence to support expectations of a fast (i.e. one or two decades) transition to alternative transport fuels in the EU, whereas oil-importing developing countries have a better chance due to stronger incentives and lower path dependence. Regardless of the speed of such transitions, these three pioneer countries have demonstrated innovative deployment of niches for fuelvehicle systems, while also establishing well-functioning actor networks to integrate sector objectives and thereby lay the foundation for a sustainable transport transition regardless of the eventual role of specific fuels and technology platforms. It is interesting to note that the three market developments were hardly linked to each other at all: each country had a strong national focus grounded mainly in energy security concerns. The public interest rationale was later supplemented with co-benefits, especially air quality, climate mitigation and rural/agricultural development. This period of isolation in the evolution of alternative fuels programmes-and the strong national focus that it engendered-has been waning somewhat in the face of growing international trade and the integration of transport and communication systems. The strong economic influence even of the global market leader (Brazil) is tempered somewhat by influential international actor networks that arose in part due to these three market leaders and those that followed in each region. Consequently the socio-technical dimensions of the transition to alternative fuels have advanced considerably, with each of these countries initiating new hubs for expertise and networking and putting greater pressure on the dominant fossil-based regime. The spatial linkages in this transition have also become more pronounced over time, revealing a sub-national dichotomy in the largest country (Brazil), geo-political pressures in the northernmost country (Sweden) and facilitating greater geographical breadth in the network of actors in the case of Malawi. Nevertheless, in spite of multi-scalar effects and transnational actor networks, the role of pioneer countries and the associated national-level innovation policies and programmes remain highly significant precisely due to path dependencies in early stages and the complexities of new path creation. Furthermore, the comparison here reveals the strong linkage between alternative transport fuel transitions and overall economic development priorities: such alignment was decisive in all three countries in spite of the wide differences in the levels of economic development. In all three pioneer countries the interplay of a coordinated network of public and private actors was crucial. In the case of Brazil, although the initial strong framework was established through an authoritarian government that pursued its goals unilaterally, serious landscape pressures led to concerted action by the new network of private actors, which is widely credited with preventing the collapse of the Brazilian ethanol market. Government actors were quite strong in Sweden, especially at local or municipal level, but the ultimate success of the two crucial niche developments-ethanol buses and flex-fuel vehicles-relied on alliances with key private sector actors in vehicle technology development and fuel distribution. In Malawi, fuel and auto companies were brought into the discussion and private actors have managed the sugar/ethanol operations to high international standards, while at the same time an increasingly open dialogue with government has been accompanied by public pressure when needed. The experiences of the three pioneer countries provides evidence that strong national policies, when accompanied by the nurturing of a broad public-private alliance of actors, can play a decisive role and accomplish alternative fuel transitions at different stages of economic development. Although fuel ethanol is only one element in the complex and multi-faceted transition to sustainable transport and mobility, it is arguably one of the few segments where tangible progress has been made, and thus offers a valuable historical record that can inform the design of energy, transport and mobility policies and programmes. the research. Any views expressed in the paper shall be attributed solely to the authors. The authors acknowledge valuable contributions from the responsible Editor and two anonymous reviewers."
        }
    },
    "10.1016/j.eist.2011.12.001": {
        "file_name": "104 Explaining regime destabilisation in the pulp and paper industry",
        "title": "Environmental Innovation and Societal Transitions",
        "abstract": "A transition to a carbon neutral society will require a shift from fossil to renewable resources. This will affect the conversion of biomass and related industries such as the pulp and paper industry. The purpose of this paper is two-fold: first, to describe and analyse the transformation processes in the Swedish pulp and paper industry and the adoption of biorefinery options, and second, to demonstrate how conceptualisations from strategic management can be used to describe regime destabilisation. The industry's adoption of biorefinery options has been modest so far, but there is development along two trajectories. The first centres on gasification and the second on separation and refining. Such diverging strategies in response to external pressure can be explained by differences that exist between firms. Signs of increasing firm divergence, or \u2018regime fragmentation\u2019, might indicate the entry into a phase of regime destabilisation, and a critical point in a transition.",
        "label": "Qualitative",
        "text": {
            "Introduction": " A transition to a carbon neutral society that is less dependent on finite resources will require a massive shift from fossil to renewable sources of energy and materials. This in turn, will require radical change in many large socio-technical systems. One system of global significance is the system for conversion of biomass from forestry. In Sweden, bioenergy has a prominent position due to the large domestic resource base. Over the last 20 years, the use of bioenergy in Sweden has doubled, and in 2009, bioenergy accounted for 22 per cent of total energy supply (Swedish Energy Agency, 2010). 1While 95 per cent of the bioenergy was used for heating, there is a growing interest in converting biomass also into electricity and fuels as well as chemicals and materials previously produced from fossil feedstock. The development of biomass conversion is strongly linked to the pulp and paper industry since this industry is in control of a large share of the Swedish biomass flow and has extensive knowledge of biomass conversion as well as a capital intensive technical system in place for these processes. The industry is a large actor not only in Swedish society, where it contributes to 12 per cent of exports, but also in the world as Sweden is the second largest exporter of pulp, paper and sawn timber (Swedish Forest Industries, 2010a). A pulp and paper mill that converts biomass to chemicals, materials and energy together with, or instead of, conventional fibres for paper products is referred to as a biorefinery (Larsson and St\u00e5hl, 2009). Thus, the biorefinery concept is analogous to an oil refinery, which converts crude oil into a range of products. The development of technologies that can be integrated in biorefinery configurations has been going on for decades, but implementation in commercial plants is still modest. However, the combined effect of several broad trends is now putting the industry under pressure to cut costs and find new business opportunities. Biorefinery concepts offer new opportunities, but some are radical and challenge core ideas in the industry. Radical transformation of industries, or more broadly, of socio-technical systems (that explicitly include user practices, culture and institutions), has been termed socio-technical transitions (Rotmans et al., 2001). These transitions have been framed as multi-level change processes where a relatively stable socio-technical regime is challenged by changes at a broader societal (or landscape) level and by the emergence of novel technological options in niches (Rip and Kemp, 1998;Geels, 2002;Geels and Kemp, 2007). While many empirical studies within the multi-level perspective (MLP) tradition have focused on the emergence of novel technologies in niches and the role of outsiders, it is recognised that regime change can take many pathways (Smith et al., 2005;Geels and Schot, 2007). It has also been observed that incumbent actors may have critical roles in radical change processes (Malerba and Orsenigo, 1996;Geels and Schot, 2007). We argue that incumbent firms are of particular importance in scale-intensive industries (Pavitt, 1984) where tight relationships with suppliers of specific raw materials abound. While for example wind energy and solar energy firms can make use of resources that have not been used before, new biomass conversion technologies need to be linked up to biomass flows already governed by mature industries. Hence, an analysis of the strategies of incumbent firms is required to understand the transformation of such industries. In much of the literature on socio-technical regimes, the regime is described at a highly aggregated level, as one stable coherent structure (Geels, 2002;Geels and Schot, 2007;Holtz et al., 2008). But the incumbent firms that are normally viewed as the backbone of a regime, in fact, show large differences. We argue that acknowledging this diversity is essential for an understanding of regime transformation. This is recognised also by Geels (2010) who argue that findings from the strategic management literature could enrich the MLP framework. A more fine-grained analysis that takes firm behaviour into account could potentially help describe and explain regime destabilisation. One aspect of, and a possible starting point for regime destabilisation is when firms begin to develop along diverging trajectories in response to external pressure. In the remainder of this text we will refer to this as regime fragmentation. A deeper understanding of this process is of importance for innovation and transition policy, since the effectiveness of any policy intervention will depend on how firms respond. The primary purpose of this paper is to describe and analyse the transformation processes taking place in the Swedish pulp and paper industry with regards to the adoption of biorefinery options. In the analysis we apply concepts from MLP and the strategic management literature. An additional purpose is to contribute to the transition literature by providing a case that demonstrates how conceptualisations from strategic management can provide more fine grained descriptions and analysis of regime fragmentation and destabilisation. The next section introduces the analytical framework employed in this article. Section 3 describes the methodology. Section 4 analyses changes at a landscape level that generate a pressure on the pulp and paper industry. Section 5 analyses industry's response to this pressure, including development along different technological trajectories. Finally, the conclusions are summarised in Section 6.",
            "Theoretical points of departure": " An industry can be conceptualised in different ways. The choice of conceptual model is important since it guides decision makers that seek to affect industry trajectories. In the widely proliferated model stemming from neoclassical economics, an industry, in the ideal case, is viewed as a set of similar firms reacting only to changes in relative prices. In contrast, within the fields of innovation and transition studies it is stressed that the inertia of established industries caused by a wide range of factors is of crucial importance for the direction and speed of change. This section outlines how the concept of socio-technical regimes can be used to explain inertia, how the multi-level perspective on transitions may be used to explain regime destabilisation and its role for industrial transformation and, finally, how regime destabilisation can be operationalised with concepts from strategic management.",
            "Inertia and socio-technical regimes": " Scholars in the fields of evolutionary economics, economics of innovation and science and technology studies stress that incumbent firms in an industry do not evaluate all available options, and that options are not evaluated in purely economic terms. Furthermore, the many uncertainties associated with the adoption of novel and disruptive technology create large risks of failure for pioneers (Olleros, 1986). As a result, it is observed, that incumbent firms tend to focus on incremental innovation along a trajectory within the prevailing technological paradigm (Dosi, 1982;Nelson and Winter, 1982). Incumbents seem to be unwilling to make radical changes and often adopt the strategy to enter markets late, free riding on efforts made by early entrants. This rigidity, or technology lock in, is partly due to the risk aversion and bounded rationality among the involved actors (Dosi, 1982;Simon, 1991), but also to historical factors skewing the cost balance between options. Entrenched technologies benefit from sunk costs in large investments, decades of learning by doing and positive externalities emanating from technological interrelatedness (Frankel, 1955) and adapted educational systems (Unruh, 2000). The relation between performance and cost of novel technologies is only improved over time and increased adoption, through exploitation of learning and scale economies (Marshall, 1890;Arthur, 1994). This inertia creates stability. A concept often used to describe this relatively stable structure is 'regime'. It is based on Nelson and Winter's (1977) 'technological regime' which was further developed by Rip and Kemp (1998). Geels (2004) define a 'socio-technical regime' as the set of shared and coherent rules (or institutions) that are carried by a group of actors. Others, such as Holtz et al. (2008), include not only rules (or institutions) in the regime definition, but also other linked socio-technical elements such as actors and technologies. Similarly, Kemp et al. (1998, p. 182) define a regime as 'the whole complex of scientific knowledge, engineering practices, production process technologies, product characteristics, skills and procedures, and institutions and infrastructures that make up the totality of a technology'. In this paper, we define a regime as a well-established socio-technical system that provides a function or a set of products. The socio-technical system is comprised of elements such as actors, artefacts, knowledge and the regulatory, normative and cognitive rules deciding what is allowed, desirable and sensible. While in principle, regime actors include not only the incumbent firms in an industry, but also consumers and other involved actors, our focus in this study is on the industry, or production side of the regime. In the presented case, the function is to convert biomass from forestry into refined products via processing plants. At present the pulp and paper industry fulfil this function. Thus, regime changes in this article refer to changes in this industry. In the current phase of change and with the stated aim of the study, we believe this is an acceptable limitation. As is commented upon in Section 5.2.3 a full transition in the area of biomass refining will likely involve also other industries (as well as changed consumption patterns).",
            "Industrial transformation and regime destabilisation": " Even if the regime is stable and change is sluggish in the short term, over longer time frames the economy is characterised by periods of emergence, development and decline of different industries (Malerba and Orsenigo, 1996;Freeman and Louc\u00e3, 2002). This industry dynamics is linked to both the emergence of novel technologies and to broader trends in society. Rip and Kemp (1998) suggested a three-layer model of technical change, further developed by Geels (2002) and Geels and Schot (2007), to explain the dynamics of technological transitions, i.e. 'major, long-term technological changes in the way societal functions are fulfilled' (Geels, 2002). At a micro level, new technological options grow in niches, which work as incubators where technologies can evolve without disturbance from mainstream market selection (Geels and Schot, 2007). Over time, these may challenge the existing regime (residing at the meso level) and form new systems or transform the existing system. It is argued that such shifts are made possible by changes at a higher, society wide, macro level termed the 'socio-technical landscape', which put pressure on the regime and destabilise it and thereby opens windows of opportunities for niche technologies (Geels, 2002). While the role of outsiders is important, it has been recognised that incumbent actors may also have critical roles in radical change processes (Geels and Schot, 2007). We argue that incumbent firms need to take an active part in the transformation of industries, in particular industries producing bulk materials with tight relationships with suppliers of specific raw materials. New biomass conversion technologies for example, need to be linked to biomass flows that are already governed by mature industries. Hence, it may be more likely that change in such industries is associated with a 'transformation path' (Geels and Schot, 2007), rather than more disruptive transition patterns. If such a transformation path is to be guided by policy, it is crucial to develop a more refined description of regime dynamics. In much of the MLP literature 'the regime' tends to be treated at a highly aggregated level, as a more or less homogenous unit. The stylised neoclassical model assumes homogeneity in the population of firms -the representative firm (Marshall, 1890). Similarly, the regime concept stresses alignment (Geels, 2004) or coherence (Holtz et al., 2008), among regime actors. Regime homogeneity and alignment is indeed important to explain stability. However, when it comes to explaining change, we suggest that a closer examination of industry diversity is required. Possibly, a description of differences among incumbent firms in combination with the presence of multiple landscape pressures and multiple novel technological options, could explain regime fragmentation and the initiation of a regime destabilisation.",
            "Regime fragmentation and firm strategy": " We suggest that a more detailed description of regime fragmentation can be made by applying some fundamental ideas from the strategic management literature. In this paper we make an attempt in this direction. First, Porter's five-force model is used to translate broad trends, or landscape changes, into forces that put pressure on the regime, i.e. on the incumbent firms in the industry. Porter (1985) explains a firm's competitive strategy by utilising an analytical framework based on the attractiveness of the industry and the competitive position of the firm within this industry. The industry's profitability is affected by five competitive forces; bargaining power of buyers, bargaining power of suppliers, threat of new entrants, threat of substitute and rivalry among existing firms (Porter, 1985). Second, within the regime firms can use different strategies to respond to this kind of external pressure. According to Porter (1985), to be profitable, a firm should seek to engage in an attractive industry and within this industry a firm should strive to create a unique and valuable position by low cost production or differentiation. To sustain a competitive position a firm should try to make all its activities consistent with the overall strategy, which will make it hard to imitate since it would require an imitation of the entire chain of activities (Porter, 1991). Depending on how firms are positioned, they will be more or less exposed to different pressures. One could assume that an increased pressure could force firms into more diverse positions in order to maintain profitability, and thereby widening the gap between firms. A complementary perspective is offered by the resource based view on strategy. Grant (1991) claims that a firms' competitive position is best explained by its resources and capabilities. Therefore, firms should identify its internal resources and skills and match these against the opportunities and risks created by its external environment. Hence, one would expect that firms with different resources (hardware and competences) would search for new opportunities in different directions. Incumbents often find it difficult to adapt to changes in their environment if it requires changes that are not aligned with its core capabilities (Leonard-Barton, 1992). An approach to maintain or reach a competitive position, as well as to align a firm's resources with its environment, could be to change the firm's boundaries, i.e. increasing or decreasing its degree of vertical integration. Another approach for handling a potential radical technological shift is to form an ambidextrous organisation, i.e. the firm forms a specific division that is separated from the existing research and development organisation and thereby enabled to focus on a novel concept (Tushman et al., 1997). Additionally, in contrast to the basic assumption of neoclassical economics, decision making and strategy formulation is not perfectly informed and rational (Sadler, 2003). Instead, managers, as all humans, are guided by mental models, which are used as a filter to simplify reality and enable decision making (Foster and Kaplan, 2001). These models are based on successes and failures of previous actions, but are seldom explicit. Hence, we assume that the response of different firms to external pressures would not only depend on their resources, skills and strategic positioning, but also on less tangible things like company culture, moulded by the unique history of every firm.",
            "Methodology": " For this study, data was collected in 2009 and 2010 in 13 semi-structured interviews with representatives from the Swedish pulp and paper industry, research companies and universities. The interviewees from industry are technical directors or senior managers with experience from strategic technical development in seven pulp and paper firms that together represent more than 75 per cent of the pulp and paper production in Sweden. No firm that only produces paper was interviewed for the study, since our focus is the conversion of biomass. The study is mainly focusing on the companies' operations in Sweden, even though it is sometimes hard to isolate multinational companies' strategies and actions to one country. The interviews lasted for up to 2 h and all but two were face to face. The interviews with firm representatives informed us about what changes in the firms' environment that has affected the industry most in the last 10 years, if and how firms are involved in the development of biorefinery options, and what they think of the future development of this technologies. Interviews with research companies and universities informed us about changes that have affected the industry during the last 10 years, how the attitude to development of biorefinery technologies has changed in the industry, and the latest developments of biorefinery technologies. Data has also been collected from many other sources, such as databases, articles and reports. All information received from interviews has been triangulated with data from other sources in order to avoid misinterpretations.",
            "Landscape changes translated into industry forces": " In interviews, representatives from the Swedish pulp and paper industry frequently state that the industry is under pressure. One movement at the landscape level that may contribute to this pressure is the increased attention to energy and environmental issues. However, this is not the only source of pressure. The rise of ICT and economic growth in South America and Asia are also landscape changes that induce change in the industry. While none of these three pressures have purely negative effects on the industry, they all require some response that could constitute a starting point for more radical change. The debate on climate change has escalated in the last decade (Fig. 1). Concern for climate change and security of energy supply has resulted in a set of policy measures that have subsequently affected energy and feedstock prices. Increased demand for bioenergy from heat and electricity production has led to increased prices on biomass feedstock (Fig. 1). The industry has also faced a drastic increase in electricity price. Since there is a tax exemption on electricity for industry in Sweden, this is not a direct effect of environmental regulation but mainly of the deregulation of the electricity market, the associated supply and demand relationships and the European carbon cap and trade system (Ericsson et al., 2011). On the other hand, the introduction of green electricity certificates has opened a new revenue stream for pulp and paper companies that produce electricity in their plants. European policy targets to increase the fraction of biofuels in the transport sector (European Parliament and Council, 2009), have also mobilised substantial public funding for demonstration plants that produce fuels from lingo-cellulosic materials (second generation of biofuels). Moreover, the debate on environmental issues has increased the demand for personal care products, packaging products and timber products based on renewable raw materials (J\u00e4\u00e4skel\u00e4inen, 2009). The pulp and paper industry has gone from being an industry mainly considered to cause environmental problems to one that is part of the solution (Wiklund, 2009). For an energy intensive industry based on biomass conversion, concern for the environment and energy security is obviously an opportunity as well as a threat. While the debate on environmental issues might have increased demand for some products it is believed that competition from electronic media has lead to decreased demand for news-print on the European, North American and Japanese markets (J\u00e4\u00e4skel\u00e4inen, 2009;Andersson, 2010). Andersson (2010) describes how the industry has for long believed that \"the sound of the rustle of newspaper pages turning\" would be impossible to replace, but that this has now been proven wrong as the electronic media has taken over more than 20 per cent of the sales of advertisement in only a couple of years. However, the statistical evidence of a downturn in demand for newsprint is not compelling. The demand for newsprint in Europe remained stable at 11-12 per cent of total paper demand between 2005 and 2009 (Swedish Forest Industries, 2010b) (see also Mitchelstein and Boczkowski (2010)). The rapid economic growth in other parts of the world has opened potential new markets. This implies a geographical shift of future markets, from Europe and North America to Asia and Latin America (Axeg\u00e5rd, 2009;Wikstr\u00f6m, 2009). However, increased production capacity in South America and Asia reduces the possibility for European companies to take advantage of these emerging markets. Instead, the pulp and paper industry in Europe now meets increased competition from firms in countries outside Europe with lower production and feedstock costs. The span of biomass raw material costs is wide. For example, the softwood prices in Scandinavia are the world's highest. In the third quarter 2009 the price was USD 350/tonne, compared to USD 90/tonne in South America (Fornell, 2010). The pulp from the mills in South America costs USD 400/tonne compared to USD 600/tonne in Scandinavia and North America (Fornell, 2010). Despite this, the European firms seem to remain in a strong position on the European market, e.g. in 2009, Asia, Africa and South America collectively only delivered around one per cent of the paper consumed in Europe (Swedish Forest Industries, 2010a). To summarise, three exogenous trends, or landscape changes can be translated into forces that directly affect the profitability in the industry. Four out of five forces in Porter's model are developing in a direction that should drive down profits. The bargaining power of suppliers is increasing, resulting in higher prices for input goods such as energy and biomass feedstock. The threat of substitutes (such as electronic media) is increasing for some products, which reduce the possibility to raise prices to increase revenues. The development in South America and Asia increase rivalry among existing firms in Europe and creates a threat of new entrants on the European market. Data from the Swedish National Accounts verifies that profitability is dwindling (Fig. 2). Between 2000 and 2008, the operation surplus almost vanished due to limited growth in output (in economic terms) and continuously growing costs for input goods. The landscape changes considered here have been present for some time and it is highly unlikely that their importance will decrease in the coming decades. However, for the industry, they not only bring threats, they also create new opportunities, e.g. to increase efficiency in production, expand on growing markets overseas, and exploit a growing demand for 'green', or carbon neutral, products, e.g. by turning pulp plants into biorefineries.",
            "Industry responses": " Firms are exposed to the forces, and react to threats and opportunities in different ways, depending on resources, position within the industry and previous experiences (Fig. 3). Hence, the landscape changes could magnify the initial diversity and set in motion a process of escalating regime fragmentation. In this section, we describe responses that we observe in the industry. While some responses, such as efficiency improvement of current processes, take place in the whole industry, the more radical responses display greater diversity.",
            "Incremental improvement of efficiency": " The energy efficiency of the mills has improved continuously since the oil crises in the 1970s (Andersson, 2009;Lundkvist, 2009). The oil use per SEK of value added decreased by a factor of ten between 1970and 2009(Swedish Energy Agency, 2009a). The fact that fossil fuel use still varies a lot between different mills indicates that there is room for further improvement (Ericsson and B\u00f6rjesson, 2008). The electricity intensity increased by some 30 per cent between 1970 and 1998, but thereafter the intensity has declined and is now back at the levels of the 1970s, presumably a response to higher electricity prices. Increased efficiency (not only energy efficiency) has been reached by improvements at individual mills (Berntsson, 2010), and through structural change in the industry. During the last decades, the number of pulp and paper mills in Europe has decreased, and smaller mills in particular have been forced to shut down (CEPI, 2010). In Sweden the number of pulp mills decreased from 72 to 41 between 1980 and 2009 (Swedish Forest Industries, 2010a). At the same time, total production grew 32 per cent. Hence, the output of the average mill increased by a factor of 2.5, see Table 1.  ",
            "New technological trajectories and 'the biorefinery'": " A more radical response to increasing pressure caused by landscape changes would be to enter new value chains. In principle, biomass can be converted into a very broad range of products. 'Biorefinery' is used as an umbrella term for mills that convert biomass not only to conventional fibres for paper products, but also to other materials, chemicals and energy carriers. Biorefinery concepts offer new business opportunities for firms in the Swedish pulp and paper industry, but they also represent a challenge. They entail large investment in new process technology, knowledge and networks required to enter new markets. Many biorefinery configurations challenge current business models (Chambost and Stuart, 2007), and some even challenge the production of pulp and paper. Over time the development of biorefinery options could imply that firms from the pulp and paper industry enter into or form new industries. There are many different process options available, and there are many products that in principle could be produced in a biorefinery. Table 2 provides a list of some technologies and related products that currently are under consideration. Many of these technologies have been developed by niche actors during many decades, supported mainly by public funding (Sand\u00e9n and Jonasson, 2005;Hellsmark, 2010;Sand\u00e9n and Hillman, 2011). Research on biomass gasification as well as ethanol production via hydrolysis and fermentation started in the late 1970s and some processes have over the years been tested in pilot and demonstration plants. While production of fuel and electricity from the large biomass resource of the Swedish forests has been a primary target for Swedish Energy Authorities since the 1970s and 1980s, the Swedish pulp and paper industry has demonstrated little interest (Sand\u00e9n and Jonasson, 2005;Hellsmark, 2010). From the interviews it is clear that even today few companies regard the development of biorefinery options as more than a complement to their existing efforts to become best in class in core operations. However, given the increased pressure, industry actors now seem to be more interested in new options (Berntsson, 2010). While few companies have gone so far that they have actually started to implement radically new technologies, many are becoming engaged in research and demonstration projects to investigate options that can convert their mills into biorefineries. In some cases explorative units are created and separated from other business units, i.e. some firms have what Tushman et al. (1997) termed an 'ambidextrous organisation'. An example of this is Holmen's centre for biorefineries, initiated in 2008. The time for the establishment of a unit like this could be used (beside patent statistics, etc.) to indicate when a firm's interest for new options has become manifest, long before evidence in the form of large investments is present. At this point, we can distinguish two main trajectories or paths of development: (1) gasification and fuel production and (2) separation of products with high added value. These reflect choices concerning technologies, products and business models.",
            "Gasification and fuel production": " The first trajectory is centred on gasification technologies. Black liquor2 from a chemical mill3 or solid biomass can be used as raw material. The output from gasification is a 'syngas', a gas mainly composed of carbon monoxide and hydrogen. These components can then be synthesised into various compounds. Companies that are interested in gasification tend to focus on production of biofuels rather than chemicals and bioplastics, which could equally well be produced from syngas. In most cases, the companies are interested in gasifying low grade biomass in parallel with continued production of pulp or paper. Both gasification of solid biomass and black liquor will require that more biomass is added to the pulp mill. This could be achieved through increased extraction from the forest or reduced production of pulp. Stora Enso motivates their preference for solid biomass gasification technology with the argument that it is flexible in the choice of end product and in the choice of raw material, thus different raw materials could be used at different geographical locations (J\u00e4\u00e4skel\u00e4inen, 2009). For example, grasses, bagasse or sugarcane can be used in Africa or Latin-America, while forest residues are used in Scandinavia. The preference for transportation fuels is motivated by a belief that biofuels, in comparison to bioplastics, can contribute much more to mitigation of climate change. This preference leads to and reinforces a partnership with Neste Oil, a company with extensive competence in fuel production (J\u00e4\u00e4skel\u00e4inen, 2009). Smurfit Kappa, argues that transportation is the only area left until the whole pulp and paper industry is sustainable and biofuels are needed to complete the transition (Lundkvist, 2009). While implying major investments in new technology, the change in business model is minor. According to Chambost and Stuart (2007), for many pulp and paper companies, the traditional business model is based on the manufacture of large volumes of commodity products at low cost. The business model behind the gasification-fuel strategy mimics this model and relies on the production and sale of large volumes of fuel in a similar way as pulp and paper are produced and sold today. Taking this one step further, following the argument that biofuels are more important than biomaterials, it would be possible to gasify all incoming biomass and replace pulp production with production of syngas. However, in current strategies, the core business of producing pulp and paper is not questioned.",
            "Separation of products with high added value": " The processes employed in the second trajectory are typically enzymatic processes, hydrolysis and fermentation. Compared to gasification technology, the choice of process is linked more directly to a specific product. It is primarily companies with chemical mills that have been interested in these technologies. However, as the pressure on the industry has increased, mechanical mills are also starting to investigate how small flows of by-products can be refined into high value products (Mahmoudkhani, 2010). Companies on this trajectory have a broader perspective on the kind of products they may produce in the future: chemicals, materials and possibly fuels. The business model linked to the production of chemicals and materials focuses on the possibility to sell small quantities of these products at a high price. S\u00f6dra's implementation of a lignin extraction technology and Domsj\u00f6 Fabriker's production of specialty cellulose for production of viscose, ligniosulfonate and ethanol are examples of development along this trajectory. S\u00f6dra has investigated many different technological options, all driven by a wish to increase the efficiency in the mills to enable more added value per unit of biomass input (Andersson, 2009). LignoBoost is a technology that extracts pure lignin and thereby enables increased pulp production. The development of the technology started in 1996 as a joint project between Innventia and Chalmers University of Technology (Metso, 2010). In 2003, the design principles were verified and 4 years later a demonstration plant was built. S\u00f6dra has now secured funding to integrate the process in a mill and test it at a commercial scale. Lignin can be used in many ways (Table 2), and research on different applications is still ongoing (Metso, 2010). Domsj\u00f6 Fabriker is a unique company in the Swedish pulp and paper industry, which operates only one mill that is virtually a fully operational biorefinery. At Domsj\u00f6, the cellulose fibre is not extracted for paper production, but for the production of textiles. Some specialty cellulose is also produced for the food and pharmaceutical industries. Domsj\u00f6 claims that materials produced from forest products, like viscose, could offer a more environmentally friendly solution than cotton and provide a larger resource base for textile production for a growing world population (Blomqvist, 2010). Lignin was initially extracted only to increase the capacity of pulp production. It is now converted to ligniosulfonate and sold on a global market mainly to be used as an additive in concrete (Blomqvist, 2010). In the future, Domsj\u00f6 hopes that even more refined products can be produced from lignosulfonate (Blomqvist, 2010). Finally, some ethanol is produced through fermentation of wood sugar and biogas is produced from digestion of residues. Despite Domsj\u00f6's relatively short history, the firm is created by individuals that have been active in the industry for a long time. Thus the firm can be considered to be an incumbent actor that seeks a unique position rather than an outsider and typical niche actor. Since the amount of raw-material needed for realisation of options along this trajectory does not have to be large, the original pulp producing process could be affected to a smaller extent and additional biomass is not necessarily needed. Only a minor part of the biomass flow needs to be redirected to production of valuable chemicals or materials. Hence, companies can create more value from the same input. However, there are radical technological options along this trajectory that could involve the entire raw material flow. At Domsj\u00f6 they do not produce pulp for paper anymore but they still utilise the fibre. An even more radical step that has not yet been taken would be to produce ethanol and other chemicals, not only from by-products, but also from the cellulose fibre itself.",
            "Crossing industry boundaries": " It is uncertain what technologies that will be employed and what products that will be produced in the future by the group of firms that we currently name 'the Swedish pulp and paper companies'. It is equally uncertain what positions these companies will take in new value chains. The pulp and paper companies that want to produce (from their point of view) new products need to develop new competences. At the same time, the pulp and paper companies are not the only large incumbent actors with a growing interest in biorefineries. Various energy companies, e.g. G\u00f6teborg Energi, that, hitherto, have converted biomass to heat and electricity are now planning large demonstration plants for production of biofuel. The development of different types of biorefinery concepts for production of chemicals and fuels also attracts the chemistry industry, the oil and gas industry and the car industry. The increasing number of industrial actors involved in this field adds to the number of potential future competitors. To reduce uncertainties and overcome knowledge barriers, also new cooperation is formed across industry barriers (Hellsmark, 2010). One example is the joint venture between Stora Enso and Neste Oil for development of gasification technology and transport fuels (J\u00e4\u00e4skel\u00e4inen, 2009). The developments of biorefinery technologies are overlapping many industries, or regimes. One can expect that this over time will induce a blurring of industry boundaries and a questioning of identities. Bennett and Pearson (2009) provide examples of boundary crossing in their description of the transition from coalbased to petrochemical feed stocks in the UK . A thorough analysis of the implications of the biorefinery as 'boundary crossing innovation' (Raven and Verbong, 2009) with implications for multiple 'regimes', 'industries' or 'sectors' (Konrad et al., 2008), would be of great interest but is beyond the scope of this study.",
            "Explaining industry response": " To understand the response from the pulp and paper industry, it is important to observe the initial heterogeneity among the firms. The companies have different characteristics and prerequisites for development and implementation of biorefinery options and as a result they try to match their individual situation with the new technological options in different ways. In this section we present some explanations to the firms' different responses. However, even though we can point to some factors explaining the differences in firm behaviour, it is not possible to fully explain why each individual firm is reacting as it is, since this would require a more in depth analysis of each firm. Firms react differently since they have different prerequisites in terms of resources and capabilities for development of biorefinery options. An important resource in this case is the technical system, i.e. the type of mill is important for the attractiveness of different biorefinery options. There are mechanical mills and chemical mills, some produce only pulp and some integrate pulp and paper production. In mechanical pulp mills the raw material is ground, a process in which up to 95 per cent of the dry weight of the wood is converted into pulp (Smook, 2002). Thus, since the major part of the raw material is converted into the main product, only a small flow of by-products is available for alternative use. In chemical pulp mills, the raw material is treated with chemicals and heat to degrade and dissolve the lignin from the cellulose and hemicelluloses. Only about half of the raw material is transformed into pulp (Smook, 2002). The rest of the raw material, mainly lignin, is dissolved in the black liquor and burned in the recovery boiler, which recycles chemicals and produces heat for the processes. The incentives and technical possibilities to implement biorefinery options are largest in non-integrated chemical pulp mills due to their positive energy balance and availability of large amounts of byproducts (Berntsson, 2010). 4 Holmen can be mentioned as an example of a firm that have restricted possibilities to develop biorefineries due to its technical system. The firm produces mainly mechanical pulp and focus on development of its products and maintain a good position on existing markets. However, at the firm's only chemical mill Holmen has started a group that it investigating biorefinery options. Competence and knowledge base influence the response. For example, one key argument for development of the second trajectory is to use the full potential of the fibre in biomass. The industry has traditionally done a lot of research on cellulose fibre and utilising knowledge about cellulose fibres for production of materials and chemicals relates to one of the industry's core competences. Cooperation in clusters also reveals in what direction firms are seeking new knowledge. One example is the knowledge network between S\u00f6dra, Innventia and Chalmers in which there is a shared belief in the development of high value products that can be produced in parallel with the existing pulp process. Another example is Domsj\u00f6 that cooperates with a research company, universities and municipalities in a local network, in the development of 'the biorefinery of the future'. Furthermore, firms have different positions within the industry and are therefore exposed differently to the pressures. Some firms increase their degree of vertical integration, i.e. they expand their ownership to a larger part of the value chain, as a strategy to reduce vulnerability to increased feedstock prices and limited supply and to gain access to high value downstream markets. The degree of vertical integration varies a lot in the industry (Fig. 4). SCA5 has a high degree of vertical integration as the company in addition to intermediaries such as pulp produces a large part of the wood that is uses as feedstock as well as a range of consumer products (Fig. 4). It seems to have been a successful strategy for this firm to keep its forests and at the same time pursue a vertical integration towards personal care products (Andersson, 2010). This strategy seems to make the firm less exposed to the external pressures, which might explain why it has shown little interest in development of biorefinery options. Billerud is another example of a firm that shows a tendency to extend its vertical integration as they have initiated a co-operation with both producers of corrugated boxes and fresh produce companies, which contributes to increase Billerud's access to the market for transportation of fruit and vegetables (Wikstr\u00f6m, 2009). Also Billerud has been little involved in development of biorefinery options. There is also a global dimension to this. In order to access the growing markets and low-cost feedstock in Asia and South America (see Section 4) some Scandinavian companies expand internationally and establish mills on these continents. This mainly concerns large companies such as Stora Enso. Fig. 4 illustrates that the firm size varies greatly, which affects their relative ability to act globally. For example, while Domsj\u00f6 Fabriker operates one pulp mill with 350 employees, Stora Enso is the second largest global producer of paper and paperboard with 27 000 employees worldwide, including 6600 in Sweden (Domsj\u00f6 Fabriker, 2010;Stora Enso, 2010). Stora Enso is interested in development of a flexible gasification technology that can be adjusted to different raw material at different geographical locations. An argument like this does not apply for a smaller firm, with a more homogenous raw material base. Finally, one explanation for the difference in firm response could be that different mental models that are based on successes and failures of previous actions are used as a filter to simplify reality and enable decision-making (Foster and Kaplan, 2001). One motivation for S\u00f6dra's development along the second trajectory instead of the first could be their early involvement in gasification technology and the disappointment from the unsatisfactory performance of a small gasifier operating at one of their mills (Andersson, 2009). Another example of this is the creation of Domsj\u00f6 Fabriker that took place in 2000 when a small group of people bought the pulp mill from the corporation MoDo that was planning to shut it down. In contrast to the former owner, the new owner group had an alternative mental model and was convinced that the unprofitable pulp mill could be transformed into a modern biorefinery, in which all parts of the raw material was used to produce a range of new products (Norlin, 2010). Instead of focussing on competitiveness in the pulp and paper industry, the starting point of the new owners was that the future global production of cotton would not be able to meet supply, thus there would be a market for viscose. One reason for this alternative perspective was that several of the owners had long experience from working abroad and another was the influence of a knowledgeable advisor with parts of his activities outside of the industry, in academia (Norlin, 2010).",
            "Conclusions": " In the last decade, landscape changes in terms of increased attention to energy and environmental issues, the rise of ICT and economic growth in South America and Asia have induced tension in the Swedish pulp and paper industry. The industry's reactions to these changes have been modest so far and are characterised by incremental change of current operations, i.e. a typical regime response. However, development along two new technological trajectories is also identified. These trajectories are characterised by choice of technology, but also choice of products and business model. The first trajectory is based on gasification for fuel production with a business model similar to the current model characterised by production of large volumes of commodity products at low cost. The second focuses on separation and refining of high value products that requires a modified business model. This development opens up potential for exploring new possibilities and involvement in new value chains. The idea of biorefineries also attracts other industries such as the energy and chemistry industries, which could lead to a blurring of industry boundaries. This development could be seen as regime fragmentation, i.e. that firms within the industry are developing in different directions, which could initiate a phase of regime destabilisation and constitute a critical point in a transition. The diverging reactions can be explained by the differences in prerequisites and characteristics that exist between firms. Firms are limited by or benefit from their current position and resources, including aspects such as knowledge base and type of mills. Moreover, different mental models based on historical experience guide managers in this highly uncertain situation. From a policy perspective it can be concluded that even though there is pressure from policy to utilise the biomass resource in applications other than pulp and paper (e.g. fuels) this pressure alone has not been enough to stimulate the industry to take action. However, the combined pressure from several changes at the landscape level has created a tension in the industry that urges firms to react. This response is not unidirectional. Rather it can be characterised as uncoordinated experimentation in many directions. Policymakers that aim at stimulating a transition need to consider that firms are diverse and that there exist multiple pressures as well as multiple new opportunities. This will cause firms to react very differently to any policy that is implemented. In a situation of great uncertainty, such diverse experimentation may be desirable. In this article, we have made a modest attempt to combine literature on the multi-level perspective and strategic management to gain a more detailed understanding of change at the regime level. With Porter's five-force model we have analysed how changes at landscape level put pressure on firms at the regime level. The firms' resource base, position, vertical integration and mental models have been used to describe the response of the firms to this pressure. We conclude that the strategy literature can help describe and explain the incumbent firms' reaction to multiple changes at the landscape level and adds a more nuanced view of the regime. However, since the firms' response at this stage is only visible as research and development projects a more in depth analysis of each firm would be required to give a more precise description and explanation of firm behaviour. In addition, the approach taken in this article could be further developed by describing the linkages between different levels (e.g. firm, technology, niche, regime/sector and landscape) in more detail. This could be done by incorporating additional useful concepts from the literature on strategic management and innovation systems. Furthermore, the understanding of regime fragmentation would benefit from studies with a broader temporal scope, i.e. the ideas presented here could be applied to historical cases. Finally, while this article has focused on one industry, a possible next step could be the study of strategies of firms in different industries that are involved (or could be involved) in the development of a new technology such as the biorefinery."
        }
    },
    "10.1016/j.eist.2015.07.005": {
        "file_name": "105 The role of lock-in mechanisms in transition processes",
        "title": "Environmental Innovation and Societal Transitions",
        "abstract": "This paper revisits the theoretical concepts of lock-in mechanisms to analyse transition processes in energy production and road transportation in the Nordic countries, focussing on three technology platforms: advanced biofuels, e-mobility and hydrogen and fuel cell electrical vehicles. The paper is based on a comparative analysis of case studies.  The main lock-in mechanisms analysed are learning effects, economies of scale, economies of scope, network externalities, informational increasing returns, technological interrelatedness, collective action, institutional learning effects and the differentiation of power. We show that very different path dependencies have been reinforced by the lock-in mechanisms. Hence, the characteristics of existing regimes set the preconditions for the development of new transition pathways. The incumbent socio-technical regime is not just fossil-based, but may also include mature niches specialised in the exploitation of renewable sources. This implies a need to distinguish between lock-in mechanisms favouring the old fossil-based regime, well-established (mature) renewable energy niches, or new pathways.",
        "label": "Qualitative",
        "text": {
            "Introduction": " The concept of lock-in has been extensively used to explain the persistence of fossil fuel-based technological systems despite the fact that their well-known environmental externalities contribute to climate change. Moreover, this 'carbon lock-in' inhibits the diffusion and adoption of carbon-saving technologies (Frantzeskaki and Loorbach, 2010;Unruh, 2000). Lock-in can be defined as positive feedbacks or increasing returns to the adoption of a selected technology (Arthur, 1994b;Unruh, 2000Unruh, , 2002)). As a result, incumbent technologies have a distinct advantage over new entrants, not because they are necessarily better, but because they are more widely used and diffused. Positive feedback mechanisms decrease production costs and create additional benefits for users. A stable incumbent regime is the outcome of various lock-in processes and it favours incremental as opposed to radical innovation. The cost and performance of a new technology are more uncertain compared to incumbent technologies (Sand\u00e9n and Azar, 2005). The discussion of lock-in mechanisms in this paper is motivated by our interest in transition processes, especially transitions towards more sustainable energy and road transportation systems. In this regard, initially \"minor changes and marginal developments may evolve into massive structural configurations that then restrict the variety of directions to future changes\" (Vo\u00df and Kemp, 2006:13). Such transition processes are, therefore, path-dependent. In this paper, we do not focus on processes of path-creation, but rather on the lock-in mechanisms that set the preconditions for these new paths. 1 Lock-in mechanisms are conceptualised as mechanisms, which reinforce a certain pathway of economic, technological, industrial and institutional development and can lead to path-dependency. A core argument of our paper is that the persistence of existing socio-technical systems can be explained by using more specific concepts than niche, socio-technical regime and landscape as provided by the multi-level perspective (MLP) (i.e., Geels, 2004;Kemp et al., 1998). In the MLP framework, the concept of a regime is defined as: \"the rule-set or grammar embedded in a complex of engineering practices, production process technologies, product characteristics, skills and procedures, ways of handling relevant artefacts and persons, ways of defining problems-all of them embedded in institutions and infrastructures\" (Rip and Kemp, 1998:338). It is argued that the different elements of such a complex system -the material, organisational and conceptual dimensions of the system (Sand\u00e9n and Hillman, 2011) -are aligned with each other. Thus, the existing socio-technical system has a stabilising influence on innovation dynamics and technological change and prevents the introduction of radically new technological trajectories. However, a key critique of the MLP framework is that it describes lock-in in a rather totalising way, with few specifications of the specific mechanisms through which lock-ins become manifested. We argue that distinguishing between various technological and institutional lock-in mechanisms improves our understanding of the persistence of the dominant sociotechnical regimes and the difficulties for emerging niches to upscale. Thus, this specifies the ways in which existing regimes set the preconditions for the development of new transition pathways. As different regimes are characterised by different lock-in mechanisms, the opportunities for upscaling a given niche depends on the specific characteristics of the relevant regime. A comparative perspective on lock-in mechanisms in ongoing transition processes helps develop a clearer understanding of transition processes as being the result of an \"interplay of path dependence, path creation and path destruction\" (Martin and Sunley, 2006:408). In this paper, we analyse the transition from fossil energy to renewable energy-based road transport systems in the Nordic countries and we specify the role of various lock-in mechanisms in this transition process. We focus on possible transition pathways towards more sustainable energy and transportation systems in four Nordic countries -Denmark, Finland, Norway and Sweden -and pose the following research question: How do different lock-in mechanisms of socio-technical regimes influence new transition pathways? The paper is based on a comparative analysis of case studies of four Nordic countries. We selected one technology platform for each country: advanced biofuels for Finland and Sweden, battery electrical vehicles (BEV) for Denmark and fuel cell electrical vehicles (FCEV) and hydrogen for Norway. The paper is organised as follows: in the next section, we review the academic literature on path-dependency and lock-in mechanisms and develop the analytical framework for the comparative analysis. In the third section, we describe the methodological approach and data used. In the fourth section, we discuss the technological and institutional lock-in mechanisms at work in the selected technology platforms for each country. Section 5 discusses the lock-in mechanisms across the different cases and the value of the concepts of lock-in mechanisms when analysing transition processes. Finally, we draw conclusions for further research.",
            "Theory: lock-in mechanisms revisited": " There have been a number of studies of technological change and innovation in economics and in organisation and institutional research, which attempt to conceptualise different lock-in mechanisms in economic, institutional and organisational development. Early studies by Brian Arthur and Paul David have focused on increasing returns of adoption, positive feedbacks and path dependency (Arthur, 1988(Arthur, , 1989(Arthur, , 1994b) ) and on the role of historical small events and elements of chance in achieving a dominant market position to realise economies of scale and decreasing cost conditions (David, 1985). While neoclassical economic theory is built on the general paradigm of diminishing returns and equilibrium of prices and market shares, Arthur argues that resource-based sectors and knowledge-based sectors follow different logics. Resource-based sectors and factor-intensive technologies, like agriculture, bulk goods production, mining and power generation are mostly subject to \"diminishing returns,\" while the knowledge-based parts of the economy are subject to \"increasing returns\" of adoption (Arthur, 1990(Arthur, , 1994a(Arthur, :25, 1994b:3):3). This difference is explained by large initial investments in research and development and tooling in the knowledge-based economy, where rather cheap follow-up investments in incremental innovation are sufficient to improve the processes and products (ibid.). As a result, the cost of producing high-tech products falls over time, while the benefits of using them increase. This gives the producer an advantage because of several mechanisms such as (a) being able to produce greater numbers of products at lower cost; (b) developing higher quality products and improving processes by incremental innovation, and; (c) achieving a kind of early de facto standard setting in networks which require compatibility. Arthur calls these mechanisms 'network externalities'. Increasing returns mechanisms can also cause economies to become locked into an inferior development pathway, which is difficult to escape (Arthur, 1990(Arthur, , 1994b:10):10). Technologies which have been chosen for sound engineering reasons become locked-in because of user externalities and, therefore, adopting more advanced and more appropriate technologies becomes more difficult (Arthur, 1994a:25). Sunk costs, learning effects and coordination costs contribute to such locked-in trajectories (Arthur, 1994c). Later contributions from other social science fields such as organisation theory, institutional theory and transition theory, have addressed lock-in mechanisms from a different perspective. Importantly, Foxon (2002) emphasises that technological lock-in should be distinguished from institutional lock-in. Foxon follows Pierson (2000) in his understanding of the interlocking effects of technological and institutional lock-ins, which compound the interaction between technological systems and governing institutions. Also in institutions, increasing returns are at work, but here they are related to the acceptance of institutions and their adoption by organisations (Lachman, 2013). North points out that symbiotic relationships exist between institutions and organisations that have evolved as a response to the incentives put in place by those institutions and that these symbiotic relationships favour incremental changes instead of radical changes (North, 1990:7). Following North's work on institutional change (1990), Foxon identifies the following factors as institutional lock-in mechanisms: \"the central role of collective action; the high density of institutions; the possibility of using political authority to enhance asymmetries of power, and the complexity and opacity of politics\" (Foxon, 2002:3). Geels et al. (2004:6f.) summarise the mechanisms which lead to increasing returns to the adoption of a technology and finally to path dependency as, \". . .economies of scale, leading to lower cost, learning-by-using, network externalities, informational increasing returns, and technological interrelatedness\". They also find that institutional aspects are important, including user routines, cognitive routines and formal regulations. Firms have sunk investments and built-up capital to consider, while suppliers and users have developed interdependent networks. Lastly, consumption patterns, user practices and lifestyles also contribute to path dependency (B\u00fcttner and Gr\u00fcbler, 1995;Kallis and Norgaard, 2010;Marechal, 2009). In summary, we find that literature from different disciplines focuses on various types of lock-in mechanisms. While empirical studies have underlined the importance of these lock-in mechanisms individually, a synthesising analytical framework of lock-in mechanisms has not yet been established. We argue that such a framework is particularly important in order to understand transition processes that are highly complex such as road transport systems since multiple lock-in mechanisms may be important in explaining path dependencies. Specifically, we distinguish between nine lock-in mechanisms. These are presented below and their operationalisation in the current study is also explained.",
            "Learning effects": " Learning effects are a central lock-in mechanism for reinforcing path-dependencies in the Nordic countries and they favour the selected technological trajectories to different degrees. They are based on the industrial specialisation of the four countries: the deployment of wind technology in Denmark and related efforts to manage the variable electricity production, the forest and pulp and paper industry in Finland and Sweden, the automobile industry in Sweden, and the oil and gas industry and electro-chemical industry in Norway. Learning effects also occur in the replacement of fossil fuels by biofuels, both in Finland and Sweden. These effects are reinforced by public funding priorities for research, the development and demonstration of new technologies, the education of technical personnel, favourable consumption patterns, and the formation of knowledge clusters around central companies, especially in Finland and Sweden.",
            "Economies of scale": " Economies of scale have influenced the four cases differently. The significant Norwegian oil and gas industry favours the use of fossil fuels over hydrogen, while large hydroelectric power capacity for production favours e-mobility with BEVs. Swedish hydroelectric power and nuclear power production favour e-mobility over bioethanol. In Finland, there is a large incumbent pulp and paper industry, which tries to exploit the potential of advanced biofuels on a large scale. In Denmark, wind energy production is large and growing and the cost of off-shore wind power is decreasing, which, in combination with a densely populated country may favour e-mobility including the deployment of BEV recharging and smart grid infrastructure. However, the low number of BEVs on the road has contributed to the underutilisation of the existing charging infrastructure and dis-incentivises further infrastructure development.",
            "Economies of scope": " To date, economies of scope have mainly been achieved in the bio-economy, but product diversification is still much less developed than in the fossil economy. However, economies of scope are becoming increasingly important in all four cases and are easier to achieve for smaller economies than economies of scale. This can be explained by the crisis of the traditional pulp and paper industry and product diversification of the up-coming bio-refineries, niche markets for hydrogen technologies and the co-location of recharging infrastructure with parking facilities, service stations and amenities. Product diversification towards higher value products in bio-refineries may, however, also have a negative impact on the production of advanced biofuels that are of relatively low value. In Sweden, bio-refinery operators are, thus, increasingly regarding biofuels as less profitable by-products.",
            "Network externalities": " The fossil transport fuel infrastructure is well developed in all four countries and biofuels are used as a drop-in and are, therefore, well-integrated in the infrastructure. The nature of infrastructure systems for transportation is important here as these systems are not just national, but cross borders and have to integrate the transport system of several countries. There is an interplay between the different infrastructure systems (Frantzeskaki and Loorbach, 2010). The supplementary infrastructure system for hydrogen competes with the fossil fuel and the biofuel infrastructure (i.e. providing very different types of fuels), but the co-utilisation of infrastructure systems is also possible. For e-mobility, we highlight the co-evolution of the charging infrastructure and the electricity system, and the co-utilisation of smart grid infrastructure to fulfil different tasks and to allow adaptation to fluctuations in net demand. Standards are important in most of the cases: The Swedish automobile industry contributed to national and EU standard setting for biofuels, while Norwegian companies and other actors have been active in international networks, which developed safety standards for H 2 /FCEV infrastructure. In Denmark, the deployment of EU standards for charging BEVs will allow network integration and network externalities for BEV users crossing the Danish borders. This will contribute to reduced investment costs.",
            "Informational increasing returns": " Informational increasing returns can be achieved by becoming more visible to the public through different channels: (1) Information campaigns by public and private actors; (2) Public debate on the advantages and disadvantages of the competing technologies; (3) Access to different vehicle models and related infrastructure; (4) The development of user forums and mobile phone applications, and; (5) The education of maintenance personnel. However, concerns regarding the sustainability of a solution, high costs, range anxiety, safety and health issues and economic constraints inhibit informational increasing returns. Compare this also with Dijk et al. (2013) who identified range and price as being important consumer preferences. The cases show different effects of this lock-in mechanism. For BEVs in Denmark, public acceptance has improved while biofuels have been well received in Finland. In Sweden, sustainability concerns for first generation biofuels and limited knowledge of advanced biofuels had a negative effect on the deployment of the latter. In Norway, hydrogen and FCEVs are still marginalised and activities are visible mostly in the capital region.",
            "Technological interrelatedness": " Technological interrelatedness between conventional fossil fuel cars and biofuel cars is a general advantage of biofuels relative to e-mobility, as changes in refilling, engine design, driving style or range are minimal. Thus, users perceive the step from conventional fossil fuel to biofuels as relatively small, while the deployment of BEVs has to overcome bigger barriers, such as range anxiety and different refuelling systems. However, also for e-mobility, such technological interrelatedness may become favourable due to the co-utilisation of the charging infrastructure and the electricity system (compare Network externalities) and access to greater flexibility in the electricity system. However, sub-optimal BEV charging practices may hamper the deployment of BEVs. BEVs and FCEVs deploy the same type of electrical drive train and, therefore, both alternatives may gain momentum from technological interrelatedness. Technologies related to transport and the storage of hydrogen may gain from competencies and experiences regarding natural gas technology.",
            "Collective action": " The Nordic countries are based on norms which support individual car use, high mobility, and well developed road systems, but do not support to nearly the same extent collective solutions or shared ownership models. Regulations underpin these norms. However, there are differences between the countries and tendencies for change. Car ownership is lowest in Denmark compared to the other countries. In Danish cities, cycling is popular and is supported by infrastructure. The share of passengers using collective road transport solutions is higher in Denmark and Finland than in Sweden and Norway. Collective actions are strengthened by favourable taxation of alternative vehicles and fuels, public procurement of more sustainable public transport vehicles and coalition building between consumer organisations, environmental NGOs, local authorities, business actors and academia. Emerging e-mobility operators can take advantage of rather low operating costs for BEVs and these lower costs can, therefore, give e-mobility a new momentum (Dijk et al., 2013). However, range anxiety hampers the wider deployment of BEVs.",
            "Institutional learning effects": " Policy coordination between different policy domains such as energy, transportation, environment, climate, taxation and research can contribute to institutional learning effects despite the inertia of institutions regulating car use. Such policy coordination is developed to varying extents in the four countries. A significant and coordinated policy-push was initiated by the Swedish government to promote first generation biofuels and by the Finnish government to promote advanced biofuels. These efforts were based on taxation, research policy and policy targets for biofuels use. Involvement of local and regional authorities can reinforce such policy initiatives. Alternatively, local authorities can initiate such policy in the absence of national policy coordination, as illustrated by the case of hydrogen in the capital region of Norway. Collaboration between public and private actors in joint projects can have a positive effect on institutional learning, as shown by the BEV case in Denmark. 5.1.9. Differentiation of power Asymmetries of power are often reinforced by state regulation favouring the incumbent transportation regime. Yet the cases highlight how the national governments have promoted sustainable transport pathways in different ways, including setting targets for alternative fuels (to adhere to EU policy), providing tax rebates and exemptions, and funding RD&D on alternative fuels. There are clear differences regarding the involvement of strong industrial actors and the emergence of small and medium-sized enterprises in these new pathways, which allow different degrees of symbiotic relationships. Biofuels have received a lot of attention from industrial actors, especially in Finland and Sweden, but in different ways: the Finnish government did not support first generation biofuels, but now has much higher biofuel targets based on advanced biofuels (Lovio and Kivimaa, 2012). In Sweden, the initial success of first generation biofuels (Hillman and Sand\u00e9n, 2008;Hillman et al., 2008) has turned into a barrier to advanced biofuels (Hillman, 2011). The development of hydrogen and FCEVs has suffered under asymmetries of power since strong industry players have not supported these technologies nor have they been prioritised in national policy. In the case of BEV in Denmark, various forms of state and municipal support for e-mobility have been in line with the interests of large power companies as well as smaller industry actors involved in BEV charging and operation; yet the recurring debates over the extension of the electric vehicle tax exemption suggests an underlying tension between state (i.e. tax revenue) and industry interests that is likely to intensify as, or if, the number of BEVs grows to a significant share of the Danish fleet.",
            "Differentiation of power and institutions": " Asymmetries of power, institutional complementarities and symbiotic relationships contribute to institutional lock-in. Asymmetries of power means that strong political actors can impose rules on others and force changes to the rules to enhance their power (Foxon, 2002). Institutional complementarities means that different institutions are complementary when the enhancement of one assists the provision of the other (Ostrom et al., 1993). For example, complementarities exist between corporate governance and labour regulations. Institutions and organisations develop symbiotic relationships as a response to the incentives put in place by those institutions and favour incremental instead of radical changes. Here we studied national targets regarding the use of renewable sources in road transport, the use of tax exemptions and other incentives for alternative cars and fuels, and the existence of strong state-owned industry players specialised in production of electricity, cars, and biofuels which encourage/discourage new trajectories for sustainable road transport.",
            "Methodological approach and data": " The paper is based on a comparative analysis of case studies on the role of lock-in mechanisms for path-dependencies in four Nordic countries. We draw on the results of selected case studies in a joint project as examples of the influence of lock-in mechanisms in transition processes: e-mobility in Denmark based on (Borup, 2014) and a follow-up documentary and data review, advanced biofuels in Sweden and Finland (Hansen and Coenen, 2013;Wessberg and Eerola, 2013) and hydrogen and FCEV case studies in Norway (Scordato and Klitkou, 2014). When selecting the cases, our intention was to cover the most advanced, but also different technology platforms in the respective countries. Besides the selected case studies, we draw from a number of other case studies on advanced biofuels in road transport (Amer and Bolwig, 2013;Bolwig and Amer, 2013;Ericsson et al., 2013;Fevolden, 2013a,b;Klitkou, 2013;Wessberg and Eerola, 2013), on BEVs (Iversen et al., 2014;R\u00f8ste, 2013), on FCEVs and hydrogen (Ihonen, 2013), which inform our discussion of lock-in mechanisms for the selected cases. The case studies are based on a review of the relevant literature and semi-structured interviews with key actors in industry and stakeholder organisations, although the Danish case is mainly based on documentary reviews, while drawing on interviews with participants in a large BEV demonstration programme in Denmark carried out as part of the InnoDemo project (Klitkou et al., 2014). The reviewed literature includes corporate reports and presentations, industry analyses, data files, media reports as well as academic literature. The interviews focused on attempting to understand the barriers and opportunities for the wider diffusion of the given technology platforms. This included specific attention to the role of industrial characteristics, up and downstream actors and the institutional context. Table 1 lists the number of firms and stakeholder organisations interviewed. Each of the four case studies gives the empirical background for the discussion of the nine lock-in mechanisms specified in the theoretical framework.",
            "Case analyses": " This section discusses the main lock-in mechanisms of the Nordic countries' energy-based road transportation systems and concentrates on three technology platforms: (a) advanced biofuels in Finland and Sweden; (b) renewable electricity and BEVs in Denmark, and; (c) hydrogen and FCEVs in Norway. We discuss the role of technological and institutional lock-in mechanisms for energy production, road transport and related infrastructure. Further, we distinguish between the negative and positive effects of the lock-in mechanisms on the development of the technology platforms thus highlighting how the preconditions set by the lock-in mechanisms may also support a transition towards sustainable road transportation systems.",
            "BEVs in Denmark": " The high and increasing share of wind power in the Danish energy system favours solutions, which can help to level out the variable electricity production, e.g. e-mobility and smart grids. There have been significant learning effects within this area: The Danish regime is keen on stimulating learning processes related to energy storage and flexible demand due to a highly variable renewable energy source (wind). This regime trait favours electrical vehicle system integration. A high share of public RD&D funding has been allocated to electricity transmission and distribution and the Danish government and the European Union have supported several RD&D projects on electric vehicle systems, infrastructure and smart grid integration over the last 5-10 years (Borup, 2014). The Danish Energy Agency funded electric vehicle pilot projects with a total of DKK 50 million over the period 2008-15 with the aim of gaining practical experience with BEVs and related infrastructure. This includes a demonstration project to test 200 BEVs over four years including the automated collection of geo-referenced data on the operation of BEVs as well as technical and behavioural analyses (Klitkou et al., 2014). The Danish Transport Authority also supports several BEV initiatives including the latter as well as the use of BEVs in car sharing arrangements. Moreover, e-mobility is often a key component of learning processes taking place through 'smart' and 'low-carbon' city projects. Concerning economies of scale, the fact that Denmark has a denser and more evenly distributed population compared to other Scandinavian countries makes the establishment of nation-wide charging infrastructure for BEVs more feasible. Denmark was the first European country to implement Better Place BEV infrastructure. Between 2010 and 2013, the company installed 17 battery switch stations, 8 fast-charging stations and 1400 charging points (plugs) (Borup, 2014). However, Better Place failed to attract enough customers for their new service infrastructure, which eventually led to the firm's bankruptcy in 2013. Today, Denmark has around 500 publicly accessible charging stations (see below), which only service around 3000 vehicles. Economies of scope in BEVs are created by the combination of conventional forms of electricity distribution and the operation of EV charging infrastructure. Denmark's largest electricity distributor, Dong Energy, was one of the main shareholders in Better Place before the bankruptcy. Today, electricity companies dominate public EV charging infrastructure: E.ON Denmark operates 341 normal charging stations plus 13 fast chargers. Five Danish utilities jointly own the company CLEVER, which operates 346 charging points, of which 330 are fast chargers. Ownership of parking facilities and amenities (service stations, restaurants, etc.) in cities and along major highways offers economies of scope for the placement of recharging infrastructure, which is illustrated by new collaborations between charging infrastructure owners and municipalities and vehicle fuel retailers. Regarding network externalities, Denmark has no automobile producers and, therefore, little influence on standards for electric vehicles. Worldwide different, mutually incompatible systems for recharging of electric vehicles exist. The European Commission has stipulated that Type 2 together with the Combo2 plug be the common European standard for both slow and fast charging connections and that Member States must incorporate this standard in their national policy by the end of 2016. The introduction of this standard will reduce investment costs and increase user access. Informational increasing returns have been hit by the bankruptcy of Better Place, which contributed to uncertainty among potential EV users in Denmark. However, the increasing number of charging stations and car models on the market is likely to have increased Danish consumer interest in BEVs. A survey from 2014 suggests that since 2013 consumers have become less sceptical towards electric vehicles while sales have doubled. However, 69% of Danish consumers are still reluctant to buy a BEV as their next car (Michelin Nordic AB, 2014). At the end of 2014, there were less than 3000 BEVs on the roads with about three-quarters being owned by public or private enterprises, and only one-quarter by private households. Technological interrelatedness is of significant importance in Denmark as the electrification of the Danish energy system is driven by increased wind power and favours -and partly depends on -the electrification of road transport over, e.g. biofuels. In this regard, vehicles can be charged at times of relatively low net electricity demand (i.e., demand minus any fluctuating renewable production), which typically occurs at night. It has been estimated that it will be possible to charge 200,000 electric vehicles during the night in 2020 without adding extra capacity to the energy system (Christensen et al., 2012). Such intelligent charging will increase overall system efficiency, improve the economy of wind power, and put less strain on local electric grids (Ibid), although its implementation requires that consumers are incentivised to charge vehicles during off-peak hours through time variable tariffs or other means. Providing such economic incentives for optimal (from the view point of vehicle owners) charging will result in the increased intra-day flexibility of the power system, but not in increased storage or day-to-day flexibility (Delikaraoglou et al., 2013). The increasing number of private home-based photovoltaic systems can be used to charge electric vehicles in lieu of selling the electricity to the grid at a low price. There were 90,000 such systems installed in 2014. Formal regulation in terms of tax exemptions is the single most important type of collective action to promote the adoption of BEVs in Denmark. Electric vehicles are exempt from all registration fees and road taxes, and electricity delivered by charging stations is taxed at a lower rate than for private households. The tax exemption should be seen in the context of very high registration fees for conventional cars. The tax exemption is typically extended by 3 years with the current exemption running to the end of 2015. In late 2014, the Danish Energy Association and the Danish Electric Vehicle Alliance, together with E.ON, publicly voiced concerns that a decision to extend the tax exemption to the end of 2018 had not yet been made arguing that such a decision is essential for the future of BEVs in Denmark. A gradual reform of the vehicle tax system would over time favour BEVs as wind and other renewables replace fossil fuels in the Danish energy system. Public opinion generally supports these positions (YouGov, 2014). Emerging e-mobility operators can take advantage of rather low operating costs for BEVs thereby giving e-mobility renewed momentum (Dijk et al., 2013). The experience with Better Place has, nevertheless, shown that customers are hesitant to adapt these business models since it means renting and not owning the batteries. In sum, perceived delayed political action has created uncertainty in the EV market in the midst of careful optimism regarding BEV sales and consumer perceptions. A second key regulatory issue concerns the non-implementation of time-variable electricity prices, which, as noted above, means that BEV owners presently have no incentive to charge their vehicles at optimal times for overall power system flexibility and performance. Concerning institutional learning effects, municipalities and regional authorities have introduced BEVs in their fleets in order to reduce CO 2 emissions and local air pollution. Knowledge-sharing networks have existed for municipalities and regions since 2009 and since 2014 for private firms, while the Capital Region of Denmark has a secretariat dedicated to the promotion of electric vehicles. Demonstration projects such as the one mentioned above testing 200 BEVs have often been implemented through collaboration between a very wide range of stakeholders (Klitkou et al., 2014). At the national level, energy and transport are traditionally two separate policy domains, but some coordination regarding BEV deployment takes place, e.g. with support schemes. The overriding importance of tax exemption means that coordination is necessary between the two latter policy domains and that of taxation. A number of non-governmental institutions have been involved in building knowledge on EV systems, charging infrastructure and smart grid integration. These include the Danish national transmission system operator for electricity and natural gas, the Danish Energy Association, the Danish Electric Vehicle Alliance, energy companies and charging infrastructure operators, car rental and leasing companies and other fleet managers, as well as universities. These institutional initiatives have often been developed as a reaction to policy initiatives and have reinforced each other (Borup, 2014). Finally, with regards to differentiation of power, Denmark has no automobile producers so the main economic interests in e-mobility are related to charging infrastructure, smart grid integration, electricity production, EV imports and retailing, and EV fleet operation. Danish companies and knowledge institutions involved in these activities founded The Danish Electric Vehicle Alliance in 2009 under the Confederation of Danish Industry, which has 50 members including several large companies.",
            "Hydrogen and FCEVs in Norway": " Learning effects have contributed to early experiments with hydrogen in FCEVs. These learning effects come from two different technological trajectories: Statoil was mainly interested in using natural gas to produce hydrogen, while Norsk Hydro focussed on electrolysis to produce hydrogen from abundant hydroelectric power. Since the 1980s and 1990s, Norwegian companies have engaged in R&D on different fuel cell types, hydrogen production technology and hydrogen storage, with Statoil, Norsk Hydro and Kvaerner being the most prominent companies (Godoe and Nygaard, 2006;Klitkou et al., 2007). In the 1990s, despite co-funding from the public research funding agency, NTNF, the big industrial R&D projects -NorCell I and II and Mj\u00f8llner -failed (Godoe and Nygaard, 2006). The natural gas trajectory was dismissed, while the electrolysis trajectory developed further, but with much less economic funding than the natural gas trajectory and involving other actors. Some important public research organisations are active in the field of FC and hydrogen in Norway (Klitkou et al., 2007). However, the main challenge is that there is no strong domestic industry to support the ongoing research at the public research organisations. Competencies in some fields such as hydrogen storage and electrolysers have been developed by industrial actors and have contributed to the ongoing experiments with hydrogen and FCEVs in Norway. However, the maintenance personnel for vehicles and the refilling infrastructure are educated to serve the fossil fuel road transport system, while knowledge on the FCEVs and hydrogen filling stations is still limited to a number of projects with a small number of experimental filling stations, public fuel cell buses in Oslo and participation in European hydrogen projects. There have been some learning effects regarding the assessment of risks and safety issues. Here one of the main global certification bodies, DNV GL, has used competencies developed for the oil and gas sector. Economies of scale have dis-incentivised investments in hydrogen and FCEVs. Firstly, the significant Norwegian oil and gas industry favours the use of fossil fuels over hydrogen. Secondly, hydropower favours e-mobility with BEVs without the \"detour\" via hydrogen. Thirdly, Norway does not have a domestic car production industry to drive the development of hydrogen powered cars. However, economies of scope are becoming more important as some Norwegian firms have specialised in the production of some key products for realising FCEVs in Norway, such as hydrogen production units via electrolysis or via landfill conversion and composite tanks for the storage and transportation of hydrogen. Cooperation with other foreign niche actors, especially in Denmark, has been essential. Network externalities of the dominant fossil transport regime hinder the introduction of new infrastructure for hydrogen filling stations. However, standards for safety issues for hydrogen filling infrastructure developed in international projects with the participation of strong Norwegian actors such as DNV GL have also contributed to the early deployment of hydrogen and FCEVs in Norway. Informational increasing returns are limited to the capital region and are not so well developed. In Norway, all BEVs are marked with EL on their license plate and all FCEVs are marked with HY and fuel cell buses are decorated with large banners identifying them as FCEVs. Information campaigns for alternative vehicles are supported by the public transportation agency and regional and municipal authorities. This increases the visibility of the FCEVs, although there are still too few of these vehicles to have made an impact so far. If safety issues are clearly dealt with, public acceptance of FCEVs has the potential to be greater than for BEVs due to the longer range of FCEVs. Technological interrelatedness can be traced for firms engaged in technologies related to the transport and storage of hydrogen and other types of gas and related technologies. This interrelatedness results in some synergies for actors who are active in both fields such as Hexagon and DNV GL. Regarding collective action, society is based on norms which support individual car use, maximum mobility and road systems and less on collective solutions or shared ownership models. The share of passenger transport on land by passenger car is at 87.7% the highest in the Nordic countries. The regulations are mainly oriented towards privately owned cars. FCEVs have been rather expensive which has limited their use as collective transport solutions. Public procurement of a few fuel cell buses has been too limited to have made a difference to public transport. Interest organisations for hydrogen and FCEVs collaborate with local and regional authorities, researchers and the emerging firms, which strengthens their position. Institutional learning effects have dis-incentivised the introduction of FCEVs in Norway. Some public actors engage in the strategic prioritisation of FCEVS such as the Akershus regional authorities, and the transportation agency, which has funded demonstration projects. However, at the government level, this has a lower priority even though the Ministry of Petroleum and Energy and the Ministry of Transport Communications jointly established the Hydrogen Council in 2005 with the mandate to act as an advisory board in matters related to hydrogen. The government supports public R&D programmes on renewable energy and CCS, but does not prioritise R&D on sustainable transport and especially FCEVs. Differentiation of power occurs especially because of asymmetries of power which strengthen the fossil transport regime. However, the Norwegian government has imposed rules to promote more sustainable solutions. All fuel cell electric vehicles benefit from a number of incentives: they are exempt from purchase tax and VAT, receive a 90 % discount on annual road tax, pay no toll or municipal parking fees, get free ferry passage and have access to bus lanes. However, hydrogen is not free as opposed to the free electricity provided at public recharging points for BEVs. Both FCEVs and BEVs can make use of the very high share of E-RES (105.5% in 2011). An example of a symbiotic relationship is the close connection between the state-owned Statoil company and a number of R&D organisations, which favour R&D on oil and gas, while R&D on hydrogen and FCEVs is lacking business funding.",
            "Advanced biofuels in Finland": " The forest industry has been an important export industry in Finland since the 1600s and strong learning effects have contributed to the development of advanced wood-based biofuels. This wood processing expertise is used by the forest company, UPM, which started to produce wood-based biodiesel in 2015 in East Finland. The production plant is located next to a pulp mill and utilises tall oil as a raw material from the pulp mill. Another significant learning effect in Finland is the learning cluster in advanced biodiesels that has developed around the fuel industry, in particular the energy company Neste Ltd., which started in 1954 as an oil refinery processing imported fossil fuel. Neste's specialisation in diesel production has stimulated incremental competence development within biofuels. Neste Oil initiated the production of biodiesel from certified palm oil in the 2000s, and the company has recently started to cooperate with the Danish company, Inbicon, to produce advanced biodiesel from straw. The pulp and paper industry, and energy production related to it, have traditionally been an important industrial sector in Finland and has, hence, created economies of scale. Economies of scale lock-in mechanisms are also found around the existing fossil fuel based road transport regime-most of the vehicles used are ICE cars using fossil fuels or blends with biofuel. Energy production processes integrated with pulp mills create a large share of renewable energy production in Finland. It is, therefore, common to see pulp mills integrated with energy production as well as with transport fuel production. Transport fuel production is bulk production which takes advantage of large-scale production capacity and large markets with the potential for economies of scope emerging due to the potential of product diversification in pulp mill based bio-refineries. Network externalities of the dominant fossil transport regime inhibit the spread of other transport energy technologies such as electricity or hydrogen in Finland. However, fossil fuel cars and distribution network are available for drop-in (bioethanol or biodiesel blended fuels) and advanced wood-based biofuels. Biofuels are, hence, technologically well integrated with the existing fossil fuel regime. Concerning informational increasing returns, such drop-in biofuels are widely accepted by Finnish car owners. At first, in 2010, consumers were sceptical and wary of the 10% biofuel suitability of cars, but now they are used to it and believe that the biofuel will not harm their cars and that it is also usable at low temperatures. Finland is a large, sparsely populated country which is based on norms which support private car use (collective action) with the current regime favouring fossil fuel cars. However, in the four largest cities, public transport systems are well developed and are continually developing. Regarding collective action, the Finnish government has set a national target to increase the use of biofuel in road transport to 20% by 2020. Thus, contrary to Sweden (see below), the Finnish government has set a more ambitious target than that required by the EU. This represents a change as Finland is a latecomer to transport biofuel policy despite some early statements in the early 1980s (Kivimaa and Mickwitz, 2011). Support for first generation biofuels was lacking, but in 2009-10 Finnish policy changed dramatically and began to target advanced biofuels while Finnish oil companies decided to produce advanced biofuels (Lovio and Kivimaa, 2012:785). Due to EU regulations, biofuels from waste products can count twice. Tall oil is regarded as a waste product of pulp mills and, hence, a biofuel producer using tall oil can count biofuel factors twice, which makes the fuel production even more profitable. Concerning differentiation of power, there is a battle going on between the wood-based biofuel producers, such as UPM, and chemical industry actors who are trying to develop advanced chemicals made from wood, especially from tall oil. At the same time, the price of tall oil is increasing on the market, which reduces the profits of the chemical industry in particular. The forest industry is also worried that state subsidies may shape the energy system so that forest owners sell their timber to energy producers instead of the forest-based industries. Forest energy use may lead to an increase in the price of timber and timber processing side products and in that way affect the market.",
            "Advanced biofuels in Sweden": " Learning effects have been very important for the diffusion of bioethanol for transport in Sweden, in particular, the existence of relevant and related competencies within pulp and paper, an industry which is of key economic importance to Sweden. Sulphite pulping mills developed units to produce bioethanol as a substitute for imported fuels during World War II. Consequently, ethanol production was carried out at 32 Swedish pulp and paper mills in the middle of the 20th century. While pulp mills were gradually abandoning the production of ethanol for fuel use in the post-war period due to the renewed availability of imported petrol, a competence base had been developed. Building on this, substantial research activities into, firstly, methanol and subsequently ethanol fuel production have been conducted in Sweden since the 1970s. Designated research programmes for ethanol research funded by the Swedish Energy Agency have been running since 1993 (Joelsson and Tuuttila, 2012), and the share of public RD&D budgets on energy for biofuels is highest in Sweden. A important learning effect is the strong Swedish competencies within vehicle manufacturing. For example, the Swedish truck and bus producer Scania initiated an R&D project in the early 1980s which focused on developing bus engines specifically for running on ethanol, which led to the introduction of the first ethanol bus in 1985, which has since been improved successively (Johnson and Silveira, 2014). In summary, competencies from existing industries have significantly influenced opportunities for developing and diffusing bioethanol for transport in Sweden. Economies of scale have mainly dis-incentivised investments in lignocellulosic bioethanol for transport. Firstly, the significant Swedish hydroelectric power and nuclear power production favour e-mobility over bioethanol. Secondly, the pulp and paper industry has traditionally focused on large-scale production of a limited number of products with little attention to product differentiation. However, economies of scope are becoming increasingly important as the demand for paper decreases, opening up for further diversification. Still, the degree to which lignocellulosic bioethanol will take up a central position in the product portfolio of a diversified pulp and paper industry remains to be seen. Technological interrelatedness between conventional fossil fuel cars and bioethanol powered cars is a general advantage of bioethanol relative to e-mobility as it only entails minimal changes to engine design, refuelling, driving style and range. Thus, users perceive the step from conventional fossil fuel to bioethanol as relatively small. A related aspect, categorised as a network externality, which is of central importance to transport in Sweden is, as in most other countries, the existing fuelling infrastructure. In the Swedish case, the E85 pump infrastructure is well developed and integrated with conventional fuelling infrastructure, thereby significantly supporting the diffusion of bioethanol for transport. A second important network externality which influences the use of bioethanol for transport is that the Swedish automobile industry has been involved in standard setting for biofuels. As in most other countries, informational increasing returns have supported the diffusion of fossil fuel based cars in Sweden. While the growing visibility of bioethanol is likely to have supported the now significant diffusion of this technology in Sweden, a number of public debates continue to question the benefits. Firstly, the food vs. fuel issue continues to be debated, in particular because most of the ethanol is imported from developing and emerging economies. Secondly, questions have been raised concerning the negative effects on engines resulting from running on ethanol. Consequently, an increasing number of owners of flexible fuel cars are choosing conventional petrol over ethanol according to the Swedish Energy Agency. And thirdly, researchers have raised concerns regarding the health effects of using bioethanol in vehicles (L\u00f3pez-Aparicio and Hak, 2013;Sundvor and L\u00f3pez-Aparicio, 2014). Regarding collective action, individual car use is still the dominant norm in Sweden. Americanisation has significantly influenced Swedish society, including the perception of the car as a central element in everyday life (O'Dell, 1997). Furthermore, being a large and sparsely populated country, public transport and even to a large extent e-mobility cannot fulfil the transportation needs of a large share of the population. However, biofuel powered cars fit quite well into the dominant norm. The impact of institutional learning effects that follow from increasingly complicated regulation and coordination of all aspects of car use in Sweden are similar to many other western countries: the conventional fossil fuel car is firmly embedded in Swedish society. However, while the institutions regulating car use are characterised by inertia, a quite significant policypush has been initiated by the Swedish government in recent years to promote bioethanol. Many of these initiatives build on conditions described under the previous lock-in mechanisms, e.g. the Swedish Pump Act, which required larger gas stations to sell renewable fuels, or the public procurement of flexible fuel vehicles from the automotive industry. Finally, concerning the differentiation of power, the decision-making power on most key issues such as funding for the development and demonstration of new technologies resides with the central Swedish government. Still, like all other members of the EU, Sweden must fulfil EU requirements concerning the use of renewable energy in the transport sector, but the current use of first generation bioethanol allows Sweden to meet this obligation (Hillman and Sand\u00e9n, 2008;Hillman et al., 2008). However, this has been found to hamper the diffusion of advanced biofuels in Sweden (Hillman, 2011) as the EU provides no clear incentives to move beyond first generation bioethanol (see also the sister paper on path-creation: Hansen et al., in preparation).",
            "Discussion": " In the following, we discuss the results of the four case studies to answer the research question. The section has three main topics: (1) the importance of the different lock-in mechanisms for the transition towards a Nordic sustainable energy and road transportation system; (2) the interconnectedness of the lock-in mechanisms, and; (3) the implications for transition theory.",
            "Importance of the different lock-in mechanisms": " In order to summarise the effects of the lock-in mechanisms, Table 2 highlights the role of each of the nine lock-in mechanisms for each of the four cases. Importantly, the preconditions set by the lock-in mechanisms do not necessarily inhibit the development of a given technology platform, but may also effect it positively. Table 2 distinguishes between such positive and negative effects.",
            "The interconnectedness of the lock-in mechanisms": " The comparative analysis of the three cases has shown that while it is useful to distinguish between the nine lockin mechanisms for analytical purposes, it is evident that they are naturally interconnected. Unruh's (2000) work on carbon lock-in draws attention to the broader scope of lock-in than just technological lock-in, the connection to institutional factors, and the need for alignment between the lock-in mechanisms. Thus, it is interesting to note how these mechanisms relate to each other. Therefore, we highlight some of these interactions below. There are several interactions of learning effects with other lock-in mechanisms. Learning effects and technological interrelatedness can reinforce each other. A highly specialised economy and R&D and innovation system leads to learning effects, but also reinforces the development and deployment of complementary technologies as long as they do not hamper the dominant technological trajectory. Economies of scale and of scope increase learning effects while network externalities may also contribute to learning effects. For example, the high degree of integration of the E85 refuelling infrastructure with conventional fuelling infrastructure in Sweden has supported the diffusion of the technology, but also stimulated learning about consumption patterns. Thus, the absence of network externalities will also hinder learning effects. Informational increasing returns can reinforce learning effects and vice versa. Examples here are the learning of users in user forums and the education of maintenance personnel. Asymmetries of power can reinforce or weaken collective action. Governments can develop ambitious targets for the deployment of new technologies and can reinforce these targets with regulations favouring collective solutions such as the procurement of public transport vehicles, implementing sustainable solutions or they can simply establish the targets without underpinning them with regulations. The latter alternative shows weak political leadership. Symbiotic relationships between strong industry actors in the incumbent regime and important political and R&D institutions can undermine institutional learning effects of policy coordination since the actors of the incumbent regime will favour incremental changes and not radical changes.",
            "Implications for transition theory": " The MLP has been criticised for a poor delineation of niches and regimes (Berkhout et al., 2004). Berkhout et al. (2004) raised concerns that the multi-level perspective on transition processes does not sufficiently explain the processes, which destabilise the dominant regime and overestimates the role of emerging niches while underestimating the importance of regime transformation which is initialised inside the regime (p. 56). They point out that there is a need to reflect on the \"diversity and resilience of wider social commitments to different technological trajectories and the extent to which particular commitments might be withdrawn\" (p. 59), and call for more thorough analyses of regime change which combine the two analytical perspectives: the coordination of actors within the regime and the availability of resources for the change within or outside the regime. While more than a decade has passed since this call, we still have insufficient knowledge about how regime actors hinder or facilitate transition processes (Geels, 2014). While the MLP acknowledges the importance of lock-in and path-dependency, it problematizes lock-in in a rather totalising way. Our specification of the nine lock-in mechanisms helps overcome this weakness. Complementing the traditional MLP framework with the analytical perspective introduced in this paper facilitates a detailed understanding of the specific lock-in mechanisms that support the current regime as well as those that may promote future niche development. Some lock-in mechanisms are more or less pervasive across the globe, e.g. gas station infrastructure, which favours biofuels over BEVs or FCEVs (network externality). Other lock-in mechanisms are context-specific, e.g. dependent on competences in existing industries (learning effects). To understand the potential for sustainability transitions in specific places, it is important to focus on the latter. Our analyses highlight how the incumbent socio-technical regime is not just fossil-based, but can also include wellestablished, mature niches specialised in the exploitation of renewable sources as exemplified by hydroelectric power in Norway, wind energy in Denmark, and first generation biofuels in Sweden. This implies that there is a need to distinguish between lock-in mechanisms which favour, respectively, the old fossil-based regime, well established (mature) renewable technological trajectories, and new technological trajectories. This is in line with Martin and Sunley's argument that economic evolution is the result of a continuous interplay between path-dependency, path creation and path destruction (2006:408). Furthermore, the lock-in mechanisms which favour mature renewable energy technological trajectories may also reinforce radically new technological trajectories such as e-mobility or the use of hydrogen in transportation. However, even renewable technological trajectories can act as barriers to other more radical trajectories because they bind physical or financial resources. An example is the conflict over the use of bio-resources for the production of hydrogen versus advanced biofuels. Another is the conflict between tall oil for wood-based energy, chemicals or advanced biofuels, and a third is the competition over scarce RD&D funds between, e.g. biofuels and e-mobility.",
            "Conclusion": " This paper has discussed the role of lock-in mechanisms in sustainable transition processes, specifically for road transport in the Nordic countries. The analytical framework has been used to conduct a comparative analysis of case studies on battery electric vehicles in Denmark, hydrogen and fuel-cell electric vehicles in Norway, and advanced biofuels in Finland and Sweden. The paper identifies nine institutional and technological lock-in mechanisms that can affect sustainable transition processes such as the transition from a fossil to a renewable energy-based road transport system. In doing so, we drew on diverse literature mainly from the social sciences which revealed the specificity and potential importance of each mechanism and its possible connectedness with other mechanisms. The result, we claim, is an improved theoretical framework for understanding transition processes. We further argue that studies using variants of the multi-level perspective may benefit from such an approach by achieving a more detailed understanding of the specific lock-in mechanisms that support the current regime, as well as those important for niche development. By distinguishing between the nine lock-in mechanisms we can specify how the characteristics of existing regimes set the preconditions for the development of new transition pathways. Regarding our research question, we have identified quite different lock-in mechanisms at work in the four cases representing three distinct road transport technologies placed in different socio-technical contexts. These contexts concern especially the energy system, the industrial structure, actor constellations, and policy. Important lock-in mechanisms at work across all case studies were learning effects, (dis) economies of scale, network externalities, and public regulation at the national or EU level -whether in the form of collective action, institutional learning effects, or the differentiation of power. Economies of scope and technological interrelatedness were only important in some cases, while the case studies revealed little in terms of the importance of informational increasing returns. There were important interactions between the different lock-in mechanisms, reinforcing or weakening technological trajectories. These interactions need further research. At a more general level, the case studies suggest that the new technological trajectories do not develop undisturbed since all actors have to relate to and interact in a socio-economic context, which is influenced deeply by the incumbent sociotechnical regime. Furthermore, the incumbent socio-technical regime is not just fossil-based, but may also include mature renewable energy trajectories. This implies a need to distinguish between lock-in mechanisms favouring the old fossil-based regime, well-established (mature) renewable energy trajectories, or new emerging trajectories. We have shown that the preconditions set by the lock-in mechanisms do not necessarily inhibit the development of a given technology platform, but may also effect it positively. Finally, we observe that the lock-in mechanisms favouring mature renewable energy trajectories can reinforce radically new technology trajectories such as e-mobility or the use of hydrogen. However, new paths can act as barriers to other more radical paths because they bind financial or physical resources."
        }
    },
    "10.1016/j.eist.2012.12.003": {
        "file_name": "106 Gender and transition in climate governance",
        "title": "Environmental Innovation and Societal Transitions",
        "abstract": "This article demonstrates how gender is relevant to governance of a transition to a low-carbon economy. It does this through insights derived from gender and transition studies in combination, applied and illustrated through a study of climate governance in Sweden. The approach is constructive and uses as central concepts: transition arenas, niches, regimes and landscapes in combination with theories from gender studies. The article suggests that the two fields are linked through three processes that are necessary to make a transition: to strengthen participation, to deal with oppressive power relations and to challenge institutionalized norms. It illustrates how masculine norms seem to permeate the landscape of climate transitions and argues that gender regimes tend to dictate planning, measures and implementation. Finally, the article proposes that a gender perspective on climate governance would analyze participation in transition arenas and niches by asking who is included in climate governance and what ideas influence climate policies.",
        "label": "Qualitative",
        "text": {
            "Introduction": " The societal transitions assumed to be necessary for reaching the climate objectives set by governments, for example in EU member states, imply unprecedented challenges to political institutions and to society as a whole. Gender relations are likely implicated in such large-scale changes as gender is a crucial principle of social organization (Eduards, 2002;Hirdman, 1990Hirdman, , 2001;;Wahl and Holgersson, 2004;Walby, 2009). Hence, it is a relevant aspect to discuss in relation to ways of governance involved in re-organizing politics and society toward climate objectives. 1 This article uses a combination of transition and gender theories as a heuristic device to illustrate how gender relations are relevant for climate governance. It is neither intended as a critique of the theories2 nor as a way to develop theory. The objective is to present a constructive argument about the relevance and manifestations of gender at diverse levels of action contributing to climate policies and approaches. In making the argument I will address specific concerns that combine elements and insights from transition and gender theories. To do so, it is necessary to simplify and generalize what is actually a broad range of diverse perspectives and theories. This article concentrates on three specific suggestions or arguments deemed relevant in both theoretical fields. The suggestions are: that gender perspectives concern participation and involvement in climate governance; that gender perspectives call for the recognition of inequities and injustices in the power relations of climate governance and; that norms related to masculinity are highly relevant to understanding the role of gender in climate transitions. Both theoretical fields aspire to study change and often include a normative element. Generally speaking, the main aspiration of transition theory is to transition to a carbon neutral and sustainable society. This is particularly relevant for the work analyzed here, which is mainly from the Northern European sustainable transition research community. 3 The common vision for gender theory is the post-patriarchal society. Gender theory is a general term that includes research from feminist theorists, intersectional and masculinity studies. Gender concerns the social organization around the difference between men and women, masculinity and femininity (Connell, 2002: 9). Gender is expressed at many levels. It is related to individual identity, to knowledge production, to the interaction between individuals, to institutional and to cultural practices. It is both material and ideational. As a power relation, gender intersects and is interrelated to other forms of power and to differences in political agency and access to resources (Lykke, 2010). Gender scholars speak about a gender power order (Hirdman, 1990(Hirdman, , 2001) that structures policymaking and institutions. Walby (2009) uses the term 'regime' to delineate systems of inequalities, in which the gender regime is part of other complex systems. Albeit, stemming from quite diverse social theories and contexts, I argue that the two fields of theory can be linked via three arguments on what is necessary to make a transition: the need to challenge institutionalized norms and deal with oppressive power relationships as well as increasing participation.",
            "Three arguments combining insights from gender and transition studies": " The transition approach taps into a rich governance literature that can be analytical, normative or critical but which has a common interest in understanding processes of steering (Cajvaneanu, 2011). Governance involves a plurality of actors and governing processes at different levels including governments and administrations. The transition theories referred to in this study are a subset within the governance research field. Transition theories are particularly interested in governance for transformation often toward sustainability or climate objectives. It proposes three analytical levels; nichesthe setting where innovations take place, regimes -the networks and institutions with vested interests in the current order, and the normative or cultural landscapes in which the other two levels are embedded (Grin et al., 2011). Similar analytical levels can be found in the field of gender studies and are, to some extent, also related to different perspectives in feminist theory. Constructivist feminists tend to address the landscape or the gender order, materialist feminists the gender regime and liberal and standpoint feminists the role of participation. These links form the common structure for the article and the three arguments. The first argument relates to landscapes and norms. The work of, for example, Smith et al. (2005), Kemp et al. (2007a), Smith and Stirling (2008) and Smith and Kern (2009), identify relevant aspects to consider in looking at transitions and emphasize the need to recognize the context for transformation. Transitions always occur in some broader context of norms, institutionalized over time. Gender is also considered in terms of a normative power order most prominently among constructivist feminist scholars (Locher and Prugl, 2001). While the landscape level has been studied less extensively in transition theory, it is well-developed in feminist theory. At the landscape level, gender theory points to this broader context of norms and practices, namely how dominant images of men and expectations of a certain type of masculinity have become the norm for governance (Hooper, 2001). It can be argued that climate governance happens in a context -a landscape -in which masculinity is the accepted norm while this often remains unarticulated and invisible (Connell, 2001;Hearn and Husu, 2011). Research from Sweden demonstrates how masculine norms are deeply embedded in transport administrations (Wittbom, 2009) and in the transport sector (Polk, 2008; see also Hanson, 2010). The absence of explicit gender symbols or gender recognition is not the same as being gender-neutral (Hearn and Parkin, 2001). Hence, 'silences' or the lack of conscious and explicit reference to gender within institutions, organizations or in climate strategies does not mean that gender is irrelevant for the issue area. An important contribution from gender studies to the understanding of landscape dynamics is the notion that power can be expressed through 'silences'. When gender is understood as normative, it means that climate strategies that lack a gender perspective simply re-produce the existing landscape. The second argument focuses on the power of regimes. Power has been discussed in transition studies and while Avelino and Rotmans (2009) propose an elaborate framework for analyzing power in transitions, in most studies the emphasis is on how powerful actors, still part of or empowered by the current regime, capture the agenda. The problem is with the incumbent regime (Smith and Kern, 2009;Smith andStirling, 2008, 2010). Transition management strategies seek to weaken the power of the incumbent regime by encouraging niches outside the regime context. In niches new ideas that encourage transition can flourish and grow because they are outside the power of the existing regime (Schot and Geels, 2008). This is a perspective that looks at the power of actors in relation to the regime in which they are embedded. Transition theory is mostly concerned with how the powerful regime can be circumvented; gender theories focus on trying to understand the dynamics of the gender regime. Both have an interest in how to instigate regime change. The existence of powerful regimes structures the possibilities for transitions because they have developed over time and actors have been vested with power. Transition researchers focus on socio-technical regimes related to innovation, for example in transport and energy systems. They view 'old' technologies, investments and related institutions as constituting powerful regimes. The existent regime restricts what can be done often because the actors representing the interests of the regime influence or capture the agenda (Meadowcroft, 2009;Voss and Bornemann, 2011). Although the arguments proposed by transition and gender scholars are linked due to the importance they place on powerful regimes, transition theory seldom studies regimes in terms of the power of actors in relation to social categories. However, this is developed in gender theory (Walby, 2009). A focus on who the privileged actors of the regime are reveals that in climate-related issues they are often white men in the higher income bracket. The third and final argument centers on the call for participatory processes in niches or transition arenas where a diverse set of relevant actors can meet, deliberate and generate innovation leading to transitions (Kemp et al., 2007a,b;Loorbach and Rotmans, 2006;Loorbach, 2010). Transition theorists argue that, to bring about change, it is necessary to assemble different participants from various sectors and walks of life. The participants should represent different interests and agendas but must be willing to debate and discuss as well as have a desire to transform the current regime and to challenge vested interests. Participation as a way of working together for change is a key feature in transition as well as gender theory. Increased representation of women has been stressed as essential for including gender aspects in climate governance (Hemmati and R\u00f6hr, 2009). A gender focus points out that there is a need to ensure equal participation of men and women and assure them opportunities to engage and influence the agenda setting and policy-making processes of climate governance. The emphasis in gender theory is both on the need to ensure that participation is inclusive, but also that this presence is felt and makes an impact (Phillips, 2000). Similarly, as in transition theory, there is an argument among standpoint feminists (Harding, 2004;Hartsock, 1998) that there is a need to include feminist women who have an interest in changing gender relations, for instance, as change agents in niches. Furthermore, due to their experience and position in society, these women could bring vital knowledge to the transition process. A discussion of these three arguments follows. Each argument is substantiated with further elaboration on the theories and illustrated with specific examples, mainly taken from the case study.",
            "Sweden as the case study": " Using the case study of Sweden is a way to explore the three arguments and to illustrate the links between gender theory and transition theory in an empirical context. The results from the Swedish case are not to be considered generally applicable. However, the findings help indicate what type of research questions and theoretical insights can be useful for similar studies in other countries and contexts. Sweden remains particularly interesting since it would be expected that gender would be included in climate governance. As is true in other Scandinavian states, Sweden also has ambitious climate goals and strategies (Magn\u00fasd\u00f3ttir, 2012). Although not world-leading, Sweden has a fairly gender-balanced nominal representation both in elected bodies such as national parliaments and within other institutions involved in climate policy-making (Niskanen, 2011: 112). The Nordic countries also took the first steps to incorporate gender aspects in climate policy (Nordic Council, 2009; http://www.equalclimate.org). The Swedish case study was conducted between 2009 and 2011. Various methods were used: analysis of text and policy document on climate strategies and policies, interviews with climate policy makers4 and an investigation of gender balance in relevant committees and groups.",
            "Argument one: landscapes and masculine norms": " The concept of landscape is used in transition theory to denote that which is outside the regime; or \"that, which forms the environment of one particular social system\" (De Haan, 2010: book II: 27). As argued above, it can be related to important ideas in gender studies, particularly endorsed by gender theorists using constructivist perspectives that view gender as a normative order resting on specific constructions of men and women (Pr\u00fcgl, 2011). In the landscape we find dominant discourses that order society and culture, discourses with norms that give significance and legitimation as well as frame issues and discourses of regime actors (Geels, 2010(Geels, , 2011;;Smith et al., 2010). Avelino and Rotmans (2009) argue that the landscape is also expressed as a normative order that is deeply structural. The landscape level is also the slowest to change of the three levels, and as Smith and Stirling (2008) and Smith and Kern (2009) have pointed out, institutional factors create path-dependencies that impact and set some of the conditions for transitions. One such path-dependency of the gender order is the normativity of male and masculinity (Hirdman, 2001). The deep structural element of the gender order or the landscape is the dominance of masculinity 5 norms that have constitutive power, to the extent that it becomes the normal, and is perceived as natural and given (Hooper, 2001;Parpart and Zalewski, 2008). This naturalization of masculinity in the (gender) landscape is what creates path-dependence. As Raywyn Connell has argued, the gender order does not require any explicit politics to be maintained, the gender order is simply reproduced. Taking corporations and the state as examples, Connell argues that \"the routine maintenance of these institutions will normally do the job\" (Connell, 1995: 212). Because it is 'the normal' the masculinity norm does not have to be thematized, nor does it require any explicit politics. On the other hand, to change the landscape character or question the masculine as the normative requires active engagement. The following examples intend to illustrate this argument about the gender landscape by showing how masculine norms seem to slip into climate transition strategies, in the work with scenarios, in planning and in the use of statistics. In the climate governance field and in transition strategies it is common to use scenarios to model future possibilities, for example in roadmaps for climate neutral futures. 6 When scenarios are used to generate policy options, they influence the agenda for policy making. In the agenda-setting process certain issues become a matter for public and political concern while others are excluded (Bacchi, 1999;Kingdon, 2003). An image on the front page of a scientific report on governance for a low carbon society, exemplifies this. 7The illustration in Fig. 1 evokes a future that does not look so different from the one we are used to in the rich North. Energy is derived from wind-generated power and bioenergy plants. It is possible to discern that here are high-speed trains, bicycle paths and denser city life. It conveys the idea that we can make this transition without too much effort and without having to change our lifestyles. Overlooking this are two white men, middle-aged and fairly well off. We can assume this because they stand in front of a sports car equipped with the latest fuel and engine technology, maybe it is electric or a hybrid. It is clear that the two men are not simply admiring the view. They have an active role or even a stake in this. Perhaps, they are planners and are surveying their work, satisfied that it turned out according to the plans (rolled up under one man's arm) or dreaming of future projects. The two men exhibit agency and are at the center of the low carbon future envisioned. They seem to be actively taking part in its development. There are others who are not. Are they the 'losers' of the low-carbon society, bogged down with social reproductive work, or are they simply left out of the picture? Are they waiting in the car or tucked away in one of the houses or offices? In any case, only men have agency in this scenario. The picture illustrates how masculine norms find their way into discussions and projects for the future and how other voices, perspectives and actors are silenced. A multitude of scenarios and visions have been used in relation to strategies for climate change (S\u00f6derholm et al., 2011) and they can be excellent tools for thinking in a long-term perspective, creating support for a focus on transition. The picture analyzed is typical of the imagery that comes across from such studies. The scenarios used tend to focus on technological change. Social agency is hardly ever considered (Wangel, 2011). The use of scenarios and back casting is a form of planning, an important and beneficial tool for long-term climate governance (Giddens, 2009;Wilson and Piper, 2010), and for comprehensive transitions of regions, towns and urban areas (Kemp et al., 2007a,b). Behavioral change is rarely explicitly included in scenarios. When it is, it is usually limited to the call for changed transportation behavior. The implication is an affirmation of the existing gender order, as the example above showed. It reproduces the current (gender) landscape which is problematic because it closes the agenda and narrows the subjects and the actions considered possible for climate transition. An area relevant to climate governance is transport planning. In Swedish transport statistics the gender, or more accurately, the sex variable is often taken into account. Yearly, transport data reveals that women travel fewer miles with private cars, use public transportation to a greater extent, and take responsibility for short trips near their homes, while men travel much longer distances and more frequently by car. Rather than problematizing these by now well-known statistics that clearly point to gender differences, they tend to be treated in a static way as behavioral norms for women and men, respectively. As behavioral standards, the statistics on transportation patterns based on sex difference are often simply projected into the future via the norm of 'predict and project' (Henriksson, 2011;Lundin, 2008;Tenn\u00f8y, 2010). It becomes increasingly problematic when behavioral norms are normalized and serve as decision support for future projects. Statistics used in this way close the agenda and leave little opportunity to raise questions like: Why do car use tax deductions benefit high-income men in urban areas in particular? Or, why when a family owns a car, do men have more access to it? As suggested by the Swedish case, it is very important to address the landscape level in climate governance. If the middle-class man is the norm for transport then this does not require an explicit politics. The norms are simply maintained and reproduced within the relevant institutions through daily routine. Paterson (2007) explains this as being due to the embedded norms of masculinity, of freedom and autonomy in the ecological and cultural economy of the automobile. He writes: \"What is not usually recognized is that getting people to move from cars to buses, trains, bicycles, walking and so on is not simply a technical change but frequently a deep re-shaping of their daily habits and routines, their assumptions about 'normality\"' . . . \"and ultimately their sense of who they are in the world.\" (Paterson, 2007: 223). A gender perspective would thus address how who we are relates to what we do in terms of climate governance. When it becomes evident that in the landscape masculinity is normative, then institutions, practices and norms that guide solutions to climate change must also be actively scrutinized. As suggested by Paterson's (2007) work, material aspects i.e. ecology and economy are also important in shaping the possibilities of climate governance and such aspects will be discussed in the following section on regimes.",
            "Argument two: on power and regimes": " Transition scholars define a regime \"as the (network of) actors that exercise constitutive power\" (Avelino and Rotmans, 2009: 560). Constitutive power is the power to establish or enact a social order tied to a certain distribution of resources (Avelino and Rotmans, 2009: 552). The resources are vested in the institutions involved in climate governance. Thus, a regime consists of resources and institutions, and the power of regimes is exercised through practices that distribute privilege and resources, but also in more subtle ways by adhering to and applying the normative power of the social order of the landscape. This definition captures how gender theorists with a material perspective have discussed the gender system (Hirdman, 2001) and gender regimes (Walby, 2009). Gender is materially constituted in economic relations through the division of labor, for example into paid/unpaid and productive/reproductive labor. This division of labor benefits the interests of men as a group but it also conditions other social relationships. The material conditions of climate change, as evident in for example, production-consumption patterns and in the use of resources, reveal inequities and injustices that are related to intersecting power relations based on economic gender regimes but also on ethnicity, age, place, etc. largely due to unequal power relations and unequal exchange between regions, countries and groups (Jerneck et al., 2011). Inequalities are not exclusive to the rich-poor, north-south dimensions (Walby, 2009). In the rich North, there are also inequalities surrounding climate mitigation and adaptation within countries. Some examples from the case study looking specifically at CO 2 emissions illustrate this. There are notable differences in CO 2 emissions between single working-class mothers and middleclass men living in Sweden due to differences regarding consumption of food, use of energy (Carlsson-Kanyama and Lind\u00e9n, 2007) and transport patterns (Polk, 1998(Polk, , 2008)). There are discrepancies in energy consumption between middle-class ethnic Swedes and working-class immigrants living in the same area (Bradley, 2009). The tendency is that, as people become more economically empowered, their CO 2 emissions also increase. The income variable is what best explains the variance of CO 2 emitted within nations (R\u00e4ty and Carlsson-Kanyama, 2010). More broadly, it is clear that there are inequalities and injustices regarding material aspects of climate change (Terry, 2009;R\u00f6hr et al., 2008: 6). This suggests that women and men may have different interests in relation to climate governance, while also noting that those interests vary in relation to other social categories. By juxtaposing ideas in transition theory with the gender regime concept, it can be deduced that what we are dealing with here is a regime based on the interest of a certain group of men, connected to the productive sector, who benefit from the division of labor of the gender order. The case study analyzed Swedish climate strategy texts and demonstrated that a market-based vision is embedded in the solutions proposed. According to the Climate Bill (Prop., 2008/09: 162), the reduction of CO 2 is expected to come through reduction and elimination of emissions via economic instruments. Transformation will take place entirely via the productive sector and via 'carrots and sticks', for example through increased CO 2 taxes, and economic incentives for innovations of new technology and energy efficiency. Transitioning to a low-carbon society as it is articulated here, follows an emphasis on market solutions and technical innovations, requiring large economic investments in, for example, energy-and transport systems. Climate financing during 2008-2010 of 1 billion SEK went mainly to technical innovations, energy efficiency, biofuels, and wind power (Naturv\u00e5rdsverket, 2009b). Additionally, the program for sustainable cities focused on improving technology or introducing new technology in for example the treatment of waste and water. Resources have been devoted to the productive sector in order to increase production of biofuels, wind power and/or make current production more energy effective (Prop., 2007/08: 1). Recent studies show the importance of neo-classic economic values in the climate policy debate and the dominance of economic actors representing the fossil fuel consuming and CO 2 -intense industrial sectors in the policy process.8 Thus, the Swedish climate policy relies almost exclusively on economic rationality as the way to transform society (Kronsell and B\u00e4ckstrand, 2010). This topic is seldom raised in the discussion on regimes in transition theory. Change is expected to occur in niches where new production forms, new innovations and new 'green and sustainable' industries are represented with their ideas and interests. The transition regime concept does not problematize the focus on the productive sector. Some gender scholars are more critical and argue that a one-sided attention to market solutions and technological fixes is a highly problematic way to deal with climate issues. According to socialist feminists like Salleh (2009), by placing the focus only on production, gender as well as ecological efficiency, justice and other equity issues are excluded. According to her, these are the issues that ought to be central. The role of social reproduction, i.e. taking care of existing resources to ensure they continue to generate future resources, falls outside considerations that are solely focused on the productive sector, market and technical solutions. Salleh along with feminist economists, thus point to the importance of thinking hard about the relationship between social reproduction and the economic and market based logic (Bakker and Silvey, 2008;Peterson, 2003). Otherwise opportunities, ideas and solutions that do not fit this productive/economic frame tend to fall outside climate governance. The perspective of regimes leads us to ask which actors will benefit from this focus on production, on innovation, market solutions and technical innovations. Latham writes that the emphasis on large systems' changes and technical fixes in current climate policies may disempower, rather than empower women when public resources are devoted to technical sectors (Johnsson-Latham, 2007: 24; see also Nagel, 2012). Large investments in system change are not gender neutral. Learning from the case study, while there is reasonable gender parity in the political arena in Sweden, the private sector and particularly many areas of the transportation and energy sectors are dominated by men. Men with a background in the engineering profession control decisions on transport infrastructure investments (Hult\u00e9n, 2012: 297-299). Also more generally, men dominate the transport and energy sectors both in the labor force, the educational system and in management (for Sweden SCB, 2010). One of our informants9 offered an explanation as to why distributional aspects of climate policies have not been considered, saying that gender perspectives in combination with a class perspective are extremely relevant for climate governance. The critique voiced in this interview echoes the position of material feminists in the field of gender studies (radical socialist feminists like Mellor, 1997;Mies and Shiva, 1993;Salleh, 1997): \"the reason why it is not discussed or put on the political agenda is because the way that climate issues are dealt with reflects the power relations in society. Highly educated men with the highest incomes also have the highest emissions of CO 2 . He is the least likely to change his behavior, while women are more concerned about climate issues and also ready to do more.\" Although distributional aspects are seldom a concern in transition studies, translated to transition theory terms, distributional issues have to do with the power of regimes. Wealthy well-educated men are as a group part of the incumbent regime, vested with constitutive power that supports their views, needs and behaviors. Being part of the (gender) regime these men resist change by avoiding discussing, or recognizing the relevance of a gender dimension. Simultaneously, this same group of men is present and influential in the positions where climate strategies are developed. An example is in the energy regime, highly relevant in any climate transition. Energy companies in Europe are governed almost exclusively by a certain group of men. Carlsson-Kanyama et al. (2010) surveyed 464 energy companies in Spain, Sweden and Germany and found that 64 percent of the energy companies had no women at all on their boards and only 5 percent reached gender parity. It is likely that the composition of the board will impact decisions and policies. From the perspective of climate governance it is problematic because as Carlsson-Kanyama and her colleagues argue, research shows that the group holding power and control in these companies, i.e. white men, has also been shown to be the least climate risk aware group. The result of McCright and Dunlap's study (2011) is interesting here. They show that it is conservative white American men who are most skeptical toward climate change. These men question the relevance of scientific findings of climate change research and are reluctant to act on it. The attitude toward climate governance is very different across Europe hence McCright and Dunlap's findings need not be relevant for those men who occupy the energy company boards in Spain, Sweden and Germany. A report on a broad survey of the attitude and actions on climate issues among directors and politicians in 63 Swedish municipalities, built in part on McCright and Dunlap's work, found that 9 percent were what they called 'climate deniers'. The typical climate denier was a conservative man from a rural area (Carlsson-Kanyama and Friberg, 2012). Although only a small fraction, it coincides with their fairly privileged role in society as part of the dominant regime. To question any change in the current regime works in their interest. McRight andDunlap (2011: 1165) explain: \". . .conservative white males are likely to favor protection of the current industrial capitalist order which has historically served them well. Fiscally conservative white males have disproportionately occupied positions of power within our economic system, controlling stocks and flows of various forms of capital and benefiting from ample amounts of prestige, status and esteem.\" Hence, it is expected that they have an interest in conserving the current climate gender order. Moreover, through homosocial processes, or the tendency for men to choose men (Flood, 2008;Kronsell, 2012: 58-62;Lipman-Blumen, 1976), climate denial may become more widespread than what is evidenced in the numbers. Dominant masculinities become role models in homosocial processes such that less powerful or marginal men incorporate or display similar attitudes in order to identify with powerful men. With transition theory terminology, this is how the powerful regime gains constitutive power and enacts a social order that upholds the regime which benefits specific actors. Thus, it seems appropriate when studying incumbent regimes to also ask who the actors are and how they may be privileged by the regime in order to raise awareness of how regimes are related to interests and social hierarchies.",
            "Argument three: on participation in climate governance": " Research by Foxon et al. (2009) shows that broad participation is essential to the success of a transition strategy. Accordingly, transitions are possible if important groups and individuals are able to contribute, formulate questions and answers and be given a chance to actively take part in the process of governance. It is as Hendriks (2009) argues, to take democratic politics into account. Indeed, broad participation in governance processes is important to ensuring democratic values. It is also valuable as a way to tap into available knowledge and experience and to listen to alternative views and aspects. Such knowledge and views could be relevant to accomplishing the transition, in and through the generation of niches and arenas for innovation. Just as gender theorist do also deliberative democratic theory emphasizes the need for inclusive policy processes that allow a broad range of societal actors to be engaged in processes of communication and deliberation (Baber and Bartlett, 2005;Dryzek, 2005). The broad inclusion of various stakeholders, citizens together with experts and government representatives, can be a way to safeguard legitimacy for the kind of transitions required to reach climate objectives and to secure compliance and implementation of decisions taken (B\u00e4ckstrand et al., 2010;Dobson and Bell, 2006;Eckersley, 2004). Yet, others highlight the difficulties in reaching consensual positions through participatory and deliberative forms (cf. Mouffe, 2000Mouffe, , 2005)). Similar ideas have influenced practice in transition theory. Evaluations of different transition arena 'experiments' speak of the tendency that open deliberations in transition arenas often turn into more pragmatic, short-term solutions in the end (Smith and Stirling, 2008). This points to an important dilemma between the desire to have open, broadly participative deliberative processes and the risk of that agenda being captured by the most powerful actors representing the existing regime. To simply add new actors to the process does not necessarily guarantee the inclusion of actors who are considered representative or pro-transition. Gender theory as well as transition theory follow this line of thinking and argue the importance of participatory policy-making. However, both fields differ from many of the democratic and deliberative theories as both transition and gender theory emphasize the importance of including those who desire change rather than status quo and have been excluded from the politics of the current regime. According to transition management theories in particular, the most important actors to be included are the 'niche players' who have a clear interest in change and transformation of the current system, and who also have the expertise, knowledge, and motivation to work for this change. To assure women's presence in climate governance is an essential step according to gender theorists (Phillips, 2000). However, this is not enough. To be considered 'niche players' these female representatives should also make a substantial impact by bringing their ideas and different experiences to bear on the agenda and the decisions taken. Having said this, the experience is that nominal gender representation is already difficult to achieve. International climate governance has been slow to include gender equity dimensions and it has done little to facilitate women's agency in global climate politics (R\u00f6hr et al., 2008: 6). The United Nations Framework Convention on Climate Change (UNFCCC), adopted in 1992 at the UN Conference on Environment and Development completely lacked a gender perspective. Neither gender issues nor women's groups were included in the subsequent climate meetings (52nd session Commission on the Status of Women February 2008). Gender aspects have emerged on the global climate agenda only recently (Nordic Council, 2009). Is the situation in the international context also reflected in the national climate policy arena? Through the case study I explored the representation of women in climate governance using the national context of Sweden. I studied the composition of various committees and groups that provided background reports, studies and input to the bills. Three different committees were involved in drafting the background material for the climate bills. 10 First, the Parliamentary Climate committee with four men and four women representing all parties presented a lengthy report suggesting strategies for future climate politics (SOU, 2008: 24). Secondly, the government's commission for sustainable development with eight men and five women had an advisory function with the specific task of addressing climate change and a particular aim of strengthening collaboration between sectors in society. 11 This commission was supposed to consider social, ecological and economic aspects but was clearly dominated by an economic and industrial stakeholder perspective. Third, the scientific council for climate issues delivered a report providing input to the governments' work with the climate strategy (Milj\u00f6v\u00e5rdsberedningen, 2007). Members of this council were mainly researchers and the composition was gender balanced with seven men and six women. The Environmental Protection Agency is also important as the national administrative authority responsible for implementing the climate strategy and for distributing the resources allocated for climate measures. In the Environmental Protection Agency a group of 15 female and 11 male experts were responsible for climate issues and this group was also within the range of what is gender balanced. 12 In sharp contrast to what was argued about the international arena, the analysis at the national level showed that women and men were equally represented in Swedish climate policy-making. There is gender parity in terms of participation in climate governance in Sweden. While the result differs from the global picture, it is in line with the general pattern of balanced political representation in Swedish political bodies. This also holds true for the regional and local levels. 13  In Region Sk\u00e5ne a climate commission was set up from 2007 until 2009 and it had a genderbalanced group of politicians. 14 Their task entailed mapping the conditions of the southern region from a climate perspective, defining what would be the regional authority's responsibility (in relation to national/local) and proposing a strategy for climate mitigation and adaptation in the region. 15  In its outreach activities, the climate commission was inclusive and hosted numerous consultation meetings with researchers, stakeholders and citizens that all appeared fairly gender balanced. 16 This equal representation is likely viewed as satisfactory among liberal feminists, 17 but for other gender theorists and for transition theorists this is not the case. Participation in politics is not limited to having an equal share (or a seat) in policy and decision-making (see Phillips, 2000;Young, 2000). Participation also concerns the content and quality of decisions. Transition as well as gender theorists note this. Presence is important because it assumes that women will have political agency and will be able to influence politics with their specific views, ideas and concerns. Gender scholars call this substantial representation (Celis, 2009). Transition management theory emphasizes the potential that niche actors -who burn for the topic, are to think in new ways, different perspectives -participating in governance can break path dependencies and disrupt the regime. In the same way, women can be niche actors. Experiences, knowledge and ideas emerging from previously marginalized groups can be included in the agenda. Thus, I explored whether women's representation in policy-making also had a substantial impact on the climate strategies that were formulated by the groups investigated in the case study. To conduct the analysis I was inspired by Bacchi (1999) who suggests that policy studies focus on how problems get represented in policy proposals, asking what is included and what is excluded in the problem definition. I explored texts and documents coming from the work of the committees and groups. Through a text analysis, I looked broadly for references to a gender perspective, mentioning of effects on women and households, women's role, equality issues and when there were such references, analyzed more closely how such concepts were defined, framed, and limited. I also looked for any mention of men, masculinity or specific reference to social categories. The texts studied were the climate bill (Prop., 2008/09: 162) reports and documents broadly connected to the development of the policy (SOU, 2008: 24;Referat, 2008) followed by a text analysis of the Road Authority's Climate Strategy (V\u00e4gverket, 2004) as well as the Energy Authority's study and input to the climate bill (ET, 2007: 29). Surprisingly, these documents completely lacked recognition of gender equities or injustices. There was a complete silence on the topic. I then turned to the local level. Swedish municipalities are responsible for climate related fields like overall planning, energy, housing and transportation. I analyzed one municipal climate strategy. The strategy from Malm\u00f6 city (Malm\u00f6, 2007), the third largest city in Sweden, lacked gender awareness. Only at the regional level, in Region Sk\u00e5ne, was a gender perspective traceable. Part 1 of the report notes, \"Region Sk\u00e5ne represents the view that only with qualified gender analysis is it possible to reach sustainable solutions\" (My translation, Region Sk\u00e5ne, 2009, part 1: 9). Yet, the rest of the report (parts 2-5) does not live up to this promise. Even where gender seemed highly relevant it was left out, for example in part five where it describes in much detail the consultation process of the Region's climate commission. This was an inclusive process but gender aspects were not on the agenda, although the subjects were: public transportation, accessibility, individual and household responsibilities in energy efficiency and waste handling and consumption. The analysis showed that gender perspectives were not recognized in Swedish climate strategies. To follow up on this, in a set of interviews about Sweden's climate strategies for the future, we asked policy makers in the field of transport and energy whether they considered the gender perspective to be relevant for climate governance. The 39 informants who answered this question gave the overall impression that they were unsure about what a gender perspective on climate governance implied. Only eight were convinced of the relevance of a gender perspective. While three could say that it had no relevance, the remaining 28 lacked the insight, expertise and knowledge to answer the question and expressed this typically in terms like: \"it might be relevant\" or \"it could be important but I don't know exactly how\". They were not necessarily indifferent but most felt they did not have the expertise to answer the question, yet they often pointed to what they believed were important gender differences. As many as 26 of the respondents referred to gender in terms of behavioral differences between men and women and illustrated this either with personal observations regarding men and women's different behavior or by referring to transportation statistics on gender differences in the use of cars and public transportation. Nine informants related gender to women and men's different attitudes. However, most of these respondents were unsure what to do with such insight. Only a few respondents could name a gender strategy or policy within their field. Some references were made to equality objectives in the previous transport policy. While there appears to be an interest and concern for taking a gender perspective on climate governance among many of the informants, the knowledge about the gender relevance of climate issues and what a gender perspective would entail was rudimentary at best. This is also a lacuna in transition theory as little research has been dedicated to critically addressing whose knowledge or views count in transition management (Smith and Stirling, 2010) or to equity and democracy issues (Hendriks, 2009). It can be concluded from this exploration that equal formal representation, i.e. that women are equally included in the processes of deliberation on climate transitions, does not guarantee that knowledge of gender relations is taken into account. To make representation add substantial input, more knowledge among policy makers about gender aspects on climate issues seems necessary. Values and knowledge within feminist research for example on care ethics (Tronto, 1993) on the nature/gender dualism (Plumwood, 1993), on reproduction/production (Peterson, 2003) can be valuable knowledge as an input in transition arenas and in climate governance. This, together with the insight that, even in a fairly gender equal country Sweden, the views on the issue and the willingness to do something about the problem as evidenced in the EPA survey (Naturv\u00e5rdsverket, 2009a; see also Ergas and York, 2012) provides the basis for an argument that feminists could be important change agents or niche players in future climate governance.",
            "Concluding remarks": " This article set out to demonstrate the manifestations and relevance of gender to climate governance and particularly in relation to transition theories. The article combined insight and knowledge from transition theory with gender studies into three arguments related to the analytical levels: landscapes, regimes and niches. The conclusion is that gender sensitivity will not come about simply through the inclusion of women in policy-making. The practice of regimes, and the norms that constitute the social order of the landscape are all important to climate governance, and hence, they too, have to be actively scrutinized for gender and other injustices. The first argument focused on landscapes. The landscape is the environment in which niches and regimes are located and represents a societal order with norms that give significance and legitimation to all actions. Since the masculine norm is so dominant in the gender landscape the gender landscape is reproduced simply through 'normal' everyday acts. This was exemplified in the study, by how masculine norms seem to slip into climate transitions strategies, in the work with scenarios, in planning and in the use of statistics. The second argument consisted of a call for the recognition of inequities and injustices in climate governance regimes. A (gender) regime exercises power via practices that distribute privilege and resources. With gender theory it is possible to refine the analysis and point to the specific group, i.e. high income, well-educated men who dominate a regime and through it are vested with power that supports their views, behaviors and needs. Transition theory is concerned with incumbent regimes because they resist change. Furthermore, it was argued that the effect is amplified because these groups of men seek the company of each other, which further strengthens existing regimes and networks, while less powerful men incorporate or display, for example, climate skepticism because they identify with dominant men. In this way the powerful regime subsists. Hence, the article proposes that in studying incumbent regimes it is important to ask who the actors are and how they are benefitting from the regime. This could raise awareness of how regimes relate to social hierarchies. Finally, the article pointed to a common denominator between the two fields in the need to secure the participation of a specific set of actors -niche actors -in climate governance policy-making. The empirical analysis showed that gender perspectives were not recognized in Swedish climate strategies even though there was equal formal representation. That women are equally included in the processes of deliberation on climate transitions does not guarantee gender sensitivity. In line with transition theory, for equal representation to add substantial input, it requires the input from those actors who are knowledgeable about gender aspects on climate issues. Those actors interested in change and transformation, and those who represent groups who have previously been excluded from climate governance should also be included."
        }
    },
    "10.1016/j.eist.2014.12.001": {
        "file_name": "107 Towards an \u2018alternative\u2019 geography of innovation",
        "title": "Environmental Innovation and Societal Transitions",
        "abstract": "This paper highlights the hitherto unrecognised role of \u2018alternative\u2019 places in protecting different forms of sustainability innovation. The paper uses the concept of an alternative milieu to illustrate how a geographically localised concentration of countercultural practices, institutions and networks can create socio-cognitive \u2018niche\u2019 protection for sustainability experiments. An alternative milieu creates protection for the emergence of novelties by (i) creating ontological and epistemological multiplicity; (ii) sustaining productive spatial imaginaries; and (iii) supporting ontological security. These different dimensions of protection are explored with reference to an in-depth, empirical case study of Totnes in the United Kingdom. The paper concludes with some reflections on the theoretical implications of this research for the theorising of niche protection and for the geographies of innovation more generally, along with some recommendations for future areas of enquiry.",
        "label": "Qualitative",
        "text": {
            "Introduction": " Over the past decade there has been increasing interest in the complex co-evolution of sociotechnical systems which deliver key societal functions such as energy and transport in late capitalist countries. In focusing on 'systems innovation', much of this work has sought to explore the conditions under which new radical sustainability innovations are able to 'break through' and 'scale up' displacing existing socio-technical systems. As such, a range of different theoretical tools have been developed to not only explain such processes, but also to be deployed in order to support the development of 'radical' technologies (see Markard et al., 2012;Grin et al., 2010;Smith et al., 2010, or Kemp, 2010 for recent reviews of this literature). Within this literature, the concept of the protective niche has become a key theoretical metaphor. The idea that niches are significant in nurturing the development of new technologies has its root in evolutionary theories of technological change (Schot and Geels, 2007). Yet critical questions remain relating to how such protection should be understood and how it is created (Verhees et al., 2012;Raven, 2012;Smith and Raven, 2012). Within research on sustainability transitions there is a growing body of work which argues that most literature has overlooked the significance of geography (Coenen et al., 2012;Coenen and Truffer, 2012;Bridge et al., 2013;Truffer and Coenen, 2012). These authors make a number of linked arguments. First, there is a need to understand the uneven spatiality of socio-technical transitions and the way in which they are simultaneously geographical and historical processes. Second, whilst transition theory borrows geographical concepts -'space' and 'scale' being obvious examples -these are often underdeveloped particularly with reference to the relational turn within geography (Raven et al., 2012). Third, critics highlight the fact that (sub)disciplines such as economic geography and regional studies have already developed a number of concepts that may help to explain the uneven spatiality of transition processes, particularly related to socio-spatial embeddedness. A spatially informed, coevolutionary transition model would insist on the recognition that new 'green' niches arise from an inherently asymmetrical process of regional development (Truffer and Coenen, 2012). Accordingly, they suggest that a productive line of research would be to engage with how certain cities or regions provide protected 'spaces' for the emergence of sustainability innovations. This paper seeks to contribute to both the theory surrounding the nature of niche protection and this growing body of work on geographies of transition. It does so by describing how a geographical alternative milieu can produce forms of protection for nascent sustainability experiments. The paper argues that the presence of an alternative milieu -a localised density of countercultural institutions, networks, groups and practices -creates a particular form of geographical protection for the emergence of different forms of sustainability experiment. Alternative milieu can provide a range of different kinds of support for experimentation, including financial and practical, but this paper focuses in particular on the way in which the milieu creates socio-cognitive space for new experiments to emerge, arguing that there are three dimensions to this protection: (i) ontological and epistemological multiplicity; (ii) sustaining supportive spatial imaginaries; and (iii) creating ontological security. The way in which an alternative milieu can protect sustainability innovation is described with reference to a case study of an alternative milieu located in South Devon in the UK, focused around the town of Totnes. The paper proceeds as follows: Part two provides an overview of the theory relating to the geography of protective niches. Part three introduces the alternative milieu around Totnes and three examples of experimentation: grassroots innovation, market based innovation and conceptual innovation. Section 4 then describes the three dimensions of socio-cognitive space provided by the milieu. Finally, part five then draws together some conclusions, including some indications of areas of future inquiry.",
            "Geography of protective niches": " Strategic Niche Management (SNM) is the strand of sustainability transitions theory that helped to establish the concept of a protective niche (Kemp et al., 1998). Early proponents of SNM were interested in how technological niches could be constructed to provide protective space in which promising new 'green' experimental technologies, such as electric cars, could be developed and nurtured (Kemp et al., 1998;Hoogma et al., 2002). Niche has also become a central analytical category in the multi-level perspective (MLP), a heuristic designed to provide a tool for understanding socio-technical change over longer periods. Here the niche reflects one of three 'levels': niches, regimes and the landscape (Geels, 2002). The regime is the 'deep structure' which stabilises a particular socio-technical system (Geels, 2011). Socio-technical regimes are given a certain degree of durability by the 'rules' which constitute their existence, as well as the fact that they are embedded in institutions and infrastructure (Geels, 2002(Geels, , 2004)). The 'landscape' refers to the wider societal background within which the regime and niche are situated and which can bring pressure upon regimes (Smith et al., 2010). A niche reflects the space where a new innovation can deviate from the rule of the dominant regime (Geels, 2004). The starting point for niche analyses is often a novel technological artefact (Geels, 2004;Raven et al., 2010). Therefore, a key focus of SNM has been on 'radical' and unproven technologies and the niches that support their development. Such niches provide protection from the 'selection environment', normally understood as a market in which the embryonic innovation is initially uncompetitive (Coenen et al., 2010). Protection for novel innovations can take a number of different forms (Rip, 2012). Smith and Raven (2012) outline a number of different dimensions and processes of protection whilst also arguing that a distinction can be made between active and passive forms of shielding, the former reflecting the existence of intentionality created protection. They outline three possible kinds of passive shielding which can provide unmeditated protection for novel experiments: geographic, institutional and cultural. It is argued herein that an alternative milieu actually reflects a convergence of the geographical and cultural dimensions of protection: a form of passive geographical niche which creates certain kinds of socio-cultural protection that allow experiments to emerge. Smith and Raven (2012) also identify 'socio-cognitive' as one of their six dimensions of protection. They however relate it primarily to the way in which space for creating new knowledge is produced by innovation support and R&D programmes, whereas this paper adopts a broader understanding. Within the sustainability transitions literature there has been only limited research into the nature of sub-national geographical niches. Much of this work has focused on the role that cities play in transition processes, particularly in relation to the governance of transitions (Bulkelely et al., 2011;Hodson andMarvin, 2009, 2010;Rohracher and Sp\u00e4th, 2013). Coenen et al. (2010) explore proximity advantages in relation to Dutch Aquifer Energy Storage. Similarly, Raven et al. (2008) stress the geographical contextualisation of niche experiments. A recent review by Hansen and Coenen (2015) highlights work in the field where certain aspects of geographical proximity are important. One area of literature that they highlight argues that informal local institutions are significant in the shaping of transition processes. Whilst an alternative milieu cannot really be considered a local institution, this paper also illustrates the way in which localised cultural norms, values, worldviews and networks can influence innovation processes by creating socio-cognitive space for experimentation. Of course, there is a rich body of work in economic geography that has contributed theoretical propositions to explain the uneven geography of innovation, including a number of different Territorial Innovation Models (TIM) which describe how local institutional dynamics shape innovation processes (Moulaert and Sekia, 2003). TIMs have been subject to a number of critiques, in particular for overstating the importance of geographical proximity and understating the significance of non-local interactions (Bunnell and Coe, 2001). Thus, it is argued, that multiple forms of proximity can be significant in innovation processes (Boschma, 2005). This paper does take a position which argues for the significance of geographical proximity but, whilst an alternative milieu is a materialised and situated phenomena, it is also, to some degree relationally produced, connected to other places through networks and flows, which partly drive its (re)production. The concept can therefore be understood as a form of 'moderate relationalism' which treats space both as fixed and fluid (Jones, 2009). In this sense it is a particular kind of 'convergence space' (Routledge, 2003) for multiple and overlapping countercultural practice, networks and institutions. Another critique of TIMs is that they are generally narrow in their understanding of innovation, conceptualising it as capitalist-based technological development (Moulaert and Sekia, 2003). In contrast, this paper argues that alternative milieu provide protection for at least three different kinds of sustainability experiment. The first is the conventional 'market based' innovation, goods and services that are provided to customers and which could 'scale up' through the expansion of market share. Secondly, there are grassroots innovations. This paper defines these as non-market in nature, forms of sustainability experimentation which emerge from civil society and that involve volunteerism or new forms of social organising. A growing body of work has begun to highlight and explore the role that social movements and civil society actors can play in the development of innovations relating to sustainability (Smith, 2012;Davies and Mullin, 2010;Toke, 2011;Hess, 2005Hess, , 2007;;Truffer, 2003;Lounsbury et al., 2003;Pickerill and Maxey, 2009b). Seyfang and Smith (2007) propose the concept of 'grassroots innovations' to describe the interface between civil society sustainability innovation and  (Heilscher et al., 2013;Seyfang and Longhurst, 2013;Longhurst, 2012;Seyfang and Haxeltine, 2012). The third type of innovation supported by alternative milieu is conceptual innovation (Vedin, 2007). This reflects experimentation with new kinds of sustainability concepts or ideas that could be 'systemic' in their aspirations or implications (Hegger et al., 2007;Monaghan, 2009). This paper argues that an alternative milieu can provide protection for experiments relating all three of these forms of innovation, as described in the next section.",
            "The alternative milieu around Totnes, Devon": "",
            "Alternative milieu": " The concept of an alternative milieu refers to a localised density of countercultural institutions, sub-cultures, practices and businesses (Longhurst, 2013). Specifically in the context of this paper, the milieu emerged from a set of countercultures which gained widespread popularity during the 1960s and 1970s and to some extent have continued, described here using five dimensions (see Table 1). The lens of an alternative milieu is therefore an approach to understanding the formation of alternative places, and the socio-economic patterns which unfold at such sites. The concept of an alternative milieu has some resonance with one of the TIMs -the notion of an regional innovative milieu (Crevoisier, 2004). The concept of a regional innovative milieu points to the significance of geographical proximity and interconnectedness of institutions in supporting and protecting new forms of innovation (Maillat, 1995). The concepts have some similarity insofar as they are both interested in the effects of a geographically embedded density of actors, networks and institutions. However, the innovative milieu concept is rooted in the new economic geography and reflects a specifically territorial approach to understanding economic development and innovation (Crevoisier, 2004). Applied empirically it can be used to study the milieu that forms around a specific form of innovation, such as lightweight vehicles (Truffer and D\u00fcrrenberger, 1997) or micro technologies (Maillet et al., 1995). In contrast, the notion of an alternative milieu is a heuristic that is intended to unpack some of the complexities of countercultural places and to avoid reducing such places to a single defining characteristic of alterity. The actual nature and extent of different dimensions of a milieu will vary from case to case, but many -including the example detailed in this paper -include a density of 'green' practices, cultures and institutions. The existence of an alternative milieu can have a range of effects on a locality, including stimulating in-migration and the emergence of specific place reputations (e.g. 'hippy', 'new age', 'bohemian', etc.) (Longhurst, 2013). The way in which an alternative milieu supports experimentation is therefore only one aspect of its wider effects on the locality. Totnes is a small market town in the South West of the UK which is the centre of a well established alternative milieu (Longhurst, 2011). It was selected as an exemplar or 'paradigmatic' case study (Flyvberg, 2001) of grassroots experimentation because it has an established reputation as a site of alternative culture and grassroots innovation. For example, Douthwaite (1996, p. 349) describes it as a 'hotbed of economic experimentation' (see also Dauncey, 1986Dauncey, , 1988)). The exact nature of the experimentation and its origin and significance was therefore the focus of an extended case study. This involved a strong ethnographic core (the researcher lived in the field for two and a half years) and a range of data collecting strategies including semi-structured interviews, archival work and participatory research. This was a process focussed research methodology (Geels, 2011 see also Langley et al., 2013) which used a narrative sense making strategy (Langley, 1999). The origins of the alternative milieu in the Totnes locality are rooted in the Dartington experiment, a utopian community established in 1925 by the wealthy American heiress Dorothy Elmhirst and her English husband Leonard (Hardy, 2000). They purchased the Dartington country estate a few miles outside of Totnes and set about establishing it as an experiment in agriculture, progressive education and the arts (Bonham-Carter, 1958;Young, 1996) Over several decades Dartington established a considerable range of activities including a boarding school, a cutting edge art college, and various businesses and projects, the extent of which caused a localised milieu to build up around Dartington. The impact of the Dartington community on the locality was fairly limited until the late 1960s and early 1970s when members began experimenting with countercultural ideas both formally within the structures of Dartington's institutions, and informally in the wider public sphere. The effect of this experimentation was a growing proliferation of alternative practices, institutions and organisations. Fuelled by in-migration and a set of growing reputations, the alternative milieu became a self-sustaining phenomenon with the town of Totnes as its symbolic and economic capital (Longhurst, 2013). The key dimensions of the Totnes milieu are summarised in Table 1. Conceptualising an alternative milieu through multiple strands provides a useful heuristic for revealing the full breadth of countercultural activity within a given locality. However, in practice there is significant overlap and intersection between different activities, groups and practices. The exact patterning of overlap between these different networks cannot not be confirmed without more detailed empirical network analysis. However, some broad intersections can be observed. For example, as noted above, there is a strong localised organic 'countercusine' stretching back to the 1970s and consisting of producers, processors and localised demand (Ilbery et al., 2006;Transition Town Totnes, 2008;CPRE, 2010). This is not created by a single alternative culture but by the overlapping propinquity of a range of different sub-countercultures. As well as the 'green' cultures in the area, the density of Complementary and Alternative Medicine activity in the area (c.f. Andrews, 2003) and some specific spiritual/cultural movements such as anthroposophy also play an important factor in supporting localised organic demand and production. In other words, the organic countercuisine is supported by a number of overlapping localised subcultures. Key social entrepreneurs also play a role in linking groups and networks acting as the catalysts for projects before moving on to establish new ventures (Longhurst, 2011).",
            "Sustainability experimentation": " In recent decades there have been various experiments across the different dimensions of the alternative milieu around Totnes. This section highlights three particular examples of sustainability experiments which can be considered as exemplars in terms of their significance, and which relate to the three categories outlined in Section 2. This claim of significance has three dimensions. Firstly, it is based on the argument that the experiment was in some sense pioneering in the UK context. These were early examples of ideas which have become much more widespread. Secondly, those involved in the local experiments played a critical role in the spread of ideas or practices. Thirdly, in two of the cases the significance comes with the size of the experiment. Like may common categories 'experiment' can be a somewhat slippery term. Here then, it is simply used to denote a process of experimentation with some kind of novelty. Each of these different kinds of innovation is now exemplified with an example from the Totnes milieu.",
            "Grassroots: Totnes 'Acorn' LETS": " In 1986 Totnes became one of the first places in the UK to establish a Local Exchange Trading Schemes (LETS) a form of grassroots currency system. LETS had originally been developed in Commox Valley, Canada in 1983 as a tool to facilitate economic activity within a locally depressed economy. A LETS system functions as a mutual credit system whereby members can exchange services (and sometimes goods) with transactions centrally recorded. The system effectively permits users to create a form of money amongst themselves. Within the UK, LETS became associated with 'DIY culture'1 a kind of 1990s counterculture involving green activism, music and direct action (see McKay, 1998) where it was often associated with attempts to build a parallel anti-capitalist economy (Bowring, 1998). The first official LETS in the UK is normally cited as Norwich, in 1985, but a system -in which the currency was named the Acorn -was also launched in Totnes at around the same time. Although this first system struggled, activists from Totnes played an important role in popularising LETS in the UK, for example, through Dauncey's (1988) book After the Crash (Croall, 1997). Other local activists developed important software that helped with the computerisation of systems. A second system was launched in the 1990s became one of the largest rural schemes in the UK (Williams, 1995). LETS organisers from this phase also played an important role in 'exporting' the idea to France in 1994 when Richard Knight from the Totnes LETS system gave a lecture in the South of France (Sel Terre, 2004). In the 2000s, along with a lot of other UK systems, the Totnes Acorn entered a decline, struggling for resources and members.",
            "Market based: Riverford farm": " A key domain of experimentation has been with alternative food systems. In the 1970s Dartington had established a school for self-sufficiency, and as far back as 1979 the South Devon Organic Growers co-op was established, modelled on Swiss Community Supported Agriculture (CSA) schemes. CSA involves attempts at building alternative food systems and this was a very early example of experimentation with CSA in the UK over 10 years before CSA is generally regarded to have reached the UK. This collective continued into the mid 1980s, and, in part influenced by these pioneering growers, Guy Watson began growing organic vegetables on his father's Riverford farm in 1985. The ethics of his business were also influenced by other local activists, and, in particular, a book called Honest Business (Phillips and Raspberry, 1981) 2 which espoused the ideas of a 'right livelihood'. Other local producers continued to experiment with novel delivery systems and in around 1992, he began a vegetable box delivery scheme. This has incorporated two particular aspects of social innovation which has enabled it to become one of the largest vegetable box schemes in the UK (Clarke et al., 2008). Firstly, a franchised delivery operation has enabled significant geographical expansion. Secondly, in order to provide organic produce it has developed regional farm hubs in partnership with other farms in order to shorten distribution networks outside of the South West of the UK. The Riverford operation in Devon is also supplied by the South Devon Organic Growers co-operative which was established by Watson in order to supply the box scheme. Both Watson and the Riverford business have won several awards for sustainability. ",
            "Conceptual innovation: permaculture": " Permaculture is an ecological design approach to sustainability, often, but not exclusively with a focus on agricultural production (Mollison, 1997). It was first developed in Australia in the late 1970s by Bill Mollison and David Holmgren and has been a growing movement since then. Totnes became a site of permaculture experimentation in 1986 after a group of local people travelled to the South of France for a permaculture design course. Subsequently, the embryonic Permaculture Association of the UK was relocated to South Devon and regular courses were started on a piece of rented land which also functioned as a 'low impact' community. This led to significant new energy being committed to the development of permaculture in the UK and several prominent members of the UK permaculture movement did their training there including Whitfield (2004) and Bell (2004). In 1992 a separate project, the Agroforesty Research Trust, was established on the Dartington estate to experiment with permaculture techniques and continues to be a prominent site of permaculture experimentation, in particular temperate agroforestry. 3 The permaculture philosophy has also been influential within other local experiments including a Green Community Office which supported the 1990s LETS scheme, the Transition Town movement which was launched in Totnes in 2006 by permaculture teacher Rob Hopkins (Hopkins, 2008), and the Landmatters low impact community who are attempting to develop viable self-sufficient lifestyles.4 Indeed, the Transition Town movement has been responsible for considerable amounts of grassroots and conceptual innovation around ideas of community led 'energy descent', both locally and beyond. Table 2 summarises the three exemplars.",
            "Alternative milieu and socio-cognitive space for sustainability innovation": " At one level, it might be taken as self-evident that a locality that contains a density of greenrelated sub-cultures and groups might produce a number of sustainability experiments. However, this paper argues that it is that it is not simply the density of 'green' activities which is significant in creating protective space, but that it is also produced by the cumulative effect the wider alternative milieu. This section outlines three different ways in which the milieu creates socio-cognitive space for experimentation. The first relates to the way in which it produces ontological and epistemological multiplicity, creating space for new ideas to emerge. Secondly, is the way in which it produces spatial imaginaries which support the idea that it is a good place for experimentation with alternatives. Thirdly is the way in which it provides ontological security for those involved in alternative practices -giving them the confidence to experiment.",
            "Ontological and epistemological multiplicity": " The first dimension of socio-cognitive space produced by the alternative milieu reflects the way in which it provides a form of space for radical ideas to be enacted. Goffman and Joy (2005) suggest that the history of countercultures is also the history of 'free thinking'. Several interviewees spoke of the way that their particular area of practice was perceived to be 'cranky' when they first started out but that there was an openness to such ideas within the locality. This openness was regarded as an important factor in explaining why Totnes has become a site of experimentation across a range of different areas. According to one local business owner it is a place that is willing to give slightly alternative, slightly off the wall kind of ideas an opportunity or chance. . .the community has a history of trying new things out Interview with green business owner One explanation for this openness to new or 'cranky' ideas is that many such ideas have circulated locally for some time, a factor that breeds tolerance amongst the wider community. At a most basic level the existence of various green worldviews means that there is space for new ideas that fit within the purview of those particular realities. For example, Rob Hopkins suggested that by picking Totnes to develop his Transition Town community initiative he was delivering a message about peak oil and climate change and a need to respond to people who are already more open to those kind of ideas. Interview with Rob Hopkins, co-founder of Transition Town Totnes Therefore one way of considering the Totnes alternative milieu is as a site of multiple 'bounded rationalities' (Wilk, 1996) as opposed to simply a site of 'irrationality'. An individual's behaviour is 'rational' from the perspective of their own subjective worldview. Thus, those who believe that we are on the brink of global 'resource depletion' are more likely to find ideas of economic localisation posited by the Transition Town movement as a potentially rational response. Here then, the participants in the initiative find the innovation's problem framing credible and convincing (Longhurst, 2012). Therefore, it is not surprising that a density of overlapping green networks and cultures is likely to be supportive of different kinds of sustainability innovation. However, there is another important factor that creates socio-cognitive space which relates to the full diversity and breadth of unconventional thought. Some strands of the milieu actively reject scientific and rationalist modes of thought and are based on alternative epistemologies. This 'anti-scientific' tendency is often the focus of negative depictions of countercultural practices and places: The south-west is the undisputed capital of British credulousness. In Totnes, Glastonbury and numerous other mumbo jumbo-drenched towns throughout the region, pseudo-druids and new agers shamble between homeopathic \"clinics\" and crystal emporia, seeking to cure their manifest problems with treatments so magical that their effects are scientifically undetectable. Totnes, in particular, has a distinguished history of mass charlatanry, largely thanks to its Leechwell springs, which were reputed in the middle ages to banish leprosy. Even in 2003, \"a rare triangular healing pool\" was reportedly discovered behind Leechwell Lane. Benedictus (2007, p. 4) In contrast to this perspective, it is arguable that this culture of 'credulousness' is actually an important factor in creating the socio-cognitive protection for new forms of sustainability experiment. In other words, it creates the socio-cognitive space for experiments to emerge by stretching the socially accepted (and constructed) boundaries of possibility. An alternative milieu therefore consists of a range of different epistemologies and ontologies, from different spiritual practices, to new age beliefs, to radical politics, to -in the case of Totnes -complexity science. 5 The fact that people are willing to believe all sorts of things are possible underpins social experimentation, supporting the argument that alternative epistemologies are a significant aspect of opening up new experimental possibilities (Starr, 2000, p. 154). Furthermore, this epistemological diversity creates ontological diversity, constituting the milieu as a site of multiple, co-existing and neighbouring epistemes (Law and Mol, 2006). This multiplicity stretches the realms of the possible, creating space for new unconventional ideas to emerge. An important local activist certainly felt that this cumulative effect of epistemological and ontological variety was significant in creating the space for new ideas: and so that's sort of opened a space for that sort of thinking in Totnes. So, you know, there was always. . .somebody like me. . .I can be thinking. . .radical things and I wasn't considered too weird because there were a lot more weirder people than me hanging around because of Dartington Hall, you know. Interview with former community activist B In other words, the breadth of radical ideas and unconventional belief systems creates the space for still further new ideas to be articulated.",
            "Spatial imaginaries": " The second important dimension of socio-cognitive space relates to how individuals believe that the area is a good place for experimentation. The argument here, is that the way a place is conceived can effect the actions of the inhabitants (Wolford, 2004). Thus, there are a number of spatial imaginaries which support sustainability innovation, in particular, a utopian reading of the physical landscape appears to stimulate experimentalism. Whilst the visually attractive landscape has acted as a significant migratory driver for the milieu, it has also acted as a source of inspiration. As one local activist put it: It's such a lovely environment. You know, it's like living in a fairytale. Just the landscape, Dartington, the Dart, its just its 'Ow, the world can be better!' The landscape gives you that kind of feeling, a breath of fresh air, it can be contained. . .Totnes is a nice contained little package, but with open views of the Dart and Dartmoor and all these lovely things. Interview with former community activist A The psychologist Csikszentmihalyi (1997) has suggested that beautiful environments can stimulate new connections amongst ideas and new perspectives on issues. As well as the importance of the inspirational 'readings' of the natural landscape, interpretations of the 'beauty' of Totnes were also seen as important by some, the townscape having its own utopian aesthetic. A predominance of smaller retailers gives it a particular sense of place, and one that is in keeping with 'small is beautiful' strands of ecological thought (e.g. Schumacher, 1973Schumacher, [1993]]; Shuman, 2000). Several interviewees mentioned the 'inspirational' aesthetic quality of Totnes and the wider area. Furthermore, the local visibility of 'alternative' practices and cultures also feeds the imaginary that the area is a site of possibility: And then there's everywhere around, there's alternative things actually happening as well. Dartington is there and happens. Sharpham6 is there and happens. The Totnes Natural Health Centre. . .the other one in the High Street, you know?. . .Conker Shoes, all these things. . .There are these businesses. There are alternative projects, 'alternative' in inverted commas, but there are projects happening, so the social infrastructure also gives that message, as something can happen here. You take your kids to the school and people are discussing projects and futures and different social, environmental, economic infrastructure. So one is getting those ideas reinforced which if you are in the middle of a big city, it's much harder to find that, all those elements supporting the internal vision. It's like \"Ah, I can do something\" Interview with former community activist A This visibility of practices and experiments reinforces the imaginary of Totnes as a 'good place' for these sorts of experiment, which in turn attracts new experiments, as explained by Rob Hopkins relating why he chose Totnes as the site to develop his Transition Town model: You know I could have gone to Hull and spent 15 years trying to get it working or actually here in the sense there are certain towns like Stroud, Lewes, Totnes all the places that actually became transition places first that have a long history of being kind of laboratory towns, laboratory places for innovative ideas. . .my wife had lived here some years previously so she knew some people here and yeah so it felt like it was somewhere where the transition idea could embed fasters than it could in other places Interview with Rob Hopkins, co-founder of Transition Town Totnes More radical forms of spatial imaginary are associated with some localised countercultural epistemologies, in particular as those associated with various kinds of 'earth mysteries' such as ley lines (Michell, 1983). Advocates of these perspectives argue that the presence of particular 'earth energies' is the reason that certain practices have flourished in the area. Richard Smith, a key figure in the local anthroposophical community until his recent death was an important figure in articulating such discourses. For example, he suggests that in the Totnes area a wealth of activities; healers and therapists, artists, craftsmen, educators and musicians abound. . .One can begin to see how the Totnes-Dartington area is fed by the pure waters off the hills as well as the mighty surges from the sea. In this area that we call the heart sphere of the landscape much has already arisen and much can still arise. Smith and Cooper (2006, p. 8) Smith builds his case on the legend of Brutus of Troy who, according to Geoffrey of Monmouth's Historia Britonum landed at Totnes to found Great Britain, a popular local myth which is used to reinforce the idea that it is a 'special' place. Such lay narratives therefore shape local spatial imaginaries. The argument being made here is that these lay narratives should be taken seriously because, for some people, they underpin the belief that the Totnes area is a 'special' place where things can happen and which encourages experimentation.",
            "Ontological security": " Due to the geographical propinquity of a number of different spiritual and educational institutions that deal with different approaches to personal transformation, the Totnes area developed a reputation as a liminal site: a 'node' on the global 'spiritual trail'. Liminality is related to processes of individual change, of openness to new ideas and of 'seeing' the world in different ways, and has been associated with some countercultural practices and sites (e.g. Shields, 1991). Many of the countercultural strands discussed featured in Table 1 above involve processes aimed at 'raising' or transforming consciousness (e.g. feminist/ecological/spiritual). This means there is a density of people within the local milieu who are themselves open not only to 'alternative' ideas but also to the processes of personal transformation that enables them to 'see' the world differently. This disposition is sometimes reflected in the term 'seekers', which is often associated with the 'New Age' (Button and Bloom, 1992). A former activist describes how Totnes creates a supportive environment for such transformations: . . .just a supportive symbol in a sense for \"Yes, I'm changing, I can change\". I don't know what it is, but it's to do with all of these things and lots of people come here and their relationships change, their work changes. It's a supportive environment to enable them to look at themselves a bit in whichever area. So those are the kind of belief systems and then there are the resources around to facilitate those kinds of changes. Interview with former community activist A The fact that many of the innovators were also involved in other 'self-transforming' practices, suggests that self-transformation might be a significant part of the innovation process. This resonates with Mihaly Csikszentmihalyi's (1997) argument, that certain 'creative environments' provide a density of interactions and effervescence of ideas that prompts the experimentally inclined to experiment more readily than in more conservative or repressed settings. One way of understanding this is that such environments provide the necessary ontological security for experimentation. For example, the density of the local milieu means that there are people who are interested in new green ideas and projects and are willing to support new initiatives: I mean there's a concentration of people who open at one level again to proposals of this nature where do you find easily bankers, estate agents and accountants who would be interested in these things? People come for the Steiner School or they come to Dartington or they come for whatever and as they sort of sit in Totnes, they become influenced if they are in some of those environments, they become influenced by others and they are open. So at the first level, people will come along to a meeting and they will join in, so its easier in Totnes to launch some of these things. Interview with former community activist A Volunteers and supporters provide not only practical resources, but moral support which appears to give pioneers the courage to face challenges. As one pioneering organic farmer suggested: So I'm sure it helps because if you're struggling and you're in an area that is supportive, that's one thing but if you're struggling in an area where they all think you're wasting you time then it gets to you. Interview with organic smallholder Localised groups and networks appear to reinforce the 'ontological security' of members by providing a shared sense of self-identity and worldview. The existence of shared cognitive frames ('like-mindedness') is essential for determining what makes a given behaviour 'appropriate' or 'acceptable' (Giddens, 1991, p. 36). For example, speaking of their decision to live 'illegally' on their land, one interviewee suggested that: . . .round here people think it is cool so it's easier, it's easier to sort of think 'Yeah we're OK' you know? We're not mad! Back to the land dweller & organic smallholder Thus ontological security also contributes to the normalisation of certain practices and forms of (liminal) experimentation such as living outside the conventional housing system. One way of conceptualising how an alternative milieu supports innovation is therefore as a 'naturally' occurring form of skunkworks. Skunkworks are small and often subversive units within a larger organisation that are created in order to pioneer the development of a technological innovation. Rogers (2003, p. 149) They create space for innovation because the members are able to escape routinised, organisational procedures and social norms. Thus there are obvious parallels with how countercultural sites can create the space for individuals to escape the dominant, 'taken for granted' norms and cognitive frames, particularly as those are within countercultural networks are often also able to occupy 'free space' because they are less structured by work relations and lifestyle constraints, enabling them to dedicate time to grassroots projects and activities (McAdam, 1986).",
            "Conclusions": " A central purpose of this paper has been to draw attention to how 'alternative' places can protect the development of sustainability innovations. Following in the tradition of recent theory relating to sustainability transitions it has used the metaphor of a protective niche to explain how the density of a localised alternative milieu creates a form of passive protection for sustainability innovations and experiments. More specifically, it has described how the milieu creates specific forms of socio-cognitive protection that support the emergence of experiments and get further translated into different forms of support, such as economic and practical. In this way the paper makes a contribution to the geography of sustainability transitions, by drawing attention to the hitherto unrecognised relationship between alternative places and sustainability innovation. It has also further developed the notion of socio-cognitive space, illustrating how multiple dimensions of this can support experimentation with novelties. In terms of the significance of these kinds of geographical niches, the paper has evidenced that certain kinds of innovation can be productively supported in such localities. Whilst it has illustrated that there is some diversity in the form of innovation, it is unlikely that it is going to take the form of highly capital intensive or techno-science driven technology. However, it is arguable that these spaces are still significant, particularly because of the opportunity they offer to experiment with new concepts and ideas, something which it has been argued is a critical part of sustainability transitions (Hegger et al., 2007;Monaghan, 2009). An important question relates to the wider significance and applicability of this particular case. Hansen and Coenen (2015) note that a weakness of geographical analyses is often a focus on highly idiosyncratic case studies of specific regions and localities. This is a valid concern, and it suggests a need for further work on the relationship between countercultural place and innovation, both in terms of other places and other forms of innovation. The exceptionalism of the Totnes milieu will only be established through such work. However, there are some indications that this might be a worthwhile endeavour. Kockel (1991) links countercultural incomers with different forms of entrepreneurship and innovation in Western Ireland. The San Francisco bay area has a complex and long established alternative milieu (c.f. Castells, 1983). There is evidence that the alternative milieu around San Francisco had connections to the emergence of both biotechnology (Vettel, 2006) and home computing (Turner, 2006). In the latter case, the geographical proximity of institutions such as the Whole Earth Catalogue and the Stanford Research Institute appear to have been a significant factor. Florida's (2002) work also makes a link between 'bohemianism' and geographies of innovation, arguing that the presence of a significant bohemian concentration correlates with an underlying openness to innovation and creativity within a locality. Yet, it is important to note that localities with dense alternative milieu are relatively unusual and the result of specific set of processes. Within the UK there are only a handful of towns and (areas of) cities which appear to have a similar densities of countercultural networks and institutions. It is doubtful that an alternative milieu could be created purposively, particularly as many have their roots in the 1960s and 1970s or even earlier. However, those interested in creating experimental spaces of any kind, might want to attend to the socio-cognitive conditions described in this paper, particularly expanding the 'belief space' and supporting the ontological security of experimenters. The co-existence and visibility of the independent and 'alternative' shops, Alternative Food Initiatives, organic growers, community enterprises and NGOs around Totnes is unusual and reinforces the 'place myth' of its role as a vibrant centre where alternative futures can be enacted. As discussed above, these also contribute to countercultural 'sense(s) of place' which encourage further innovation and experimentation. However, to some extent this is an illusion, and whilst the milieu creates the space for experiments, it may not make them any more viable in the longer term (Longhurst, 2011). Thus small scale organic production is not necessarily any more economically viable in the Totnes locality than elsewhere. Caution must therefore be exercised in holding up such places as examples of sustainability futures (e.g. Siegle, 2011;BBC, 2009) or making claims that initiatives can be easily replicated elsewhere. Despite the overlaps that exist between different networks, it should also be noted that there is often socio-cultural conflict both within and towards the alternative milieu (Longhurst, 2011). The in-migration that sustains alternative milieu can be a source of conflict between those who consider themselves to be 'local' and more recent incomers (e.g. Barker, 2012). It can also contribute to the processes of gentrification of alternative places that occurs as their reputation grows (Ley, 1996;Barker, 2012;Smith and Phillips, 2001). Some residents can also object to the various place images that become associated with such places and feel 'invaded' by the alternativeness. There can also be conflict within the milieu, between different strands of countercultural practice. Indeed, it seems that some of the very conditions which create the socio-cognitive space for the emergence of radical or unusual ideas also create the potential for conflict between different perspectives, potentially undermining their potential to grow at a local level (Longhurst, 2011). One feature of the alternative milieu described in this paper is the way in which certain institutions and actors (such as Dartington) connect the Totnes area to a range of other geographically distant places. To some extent the milieu is created by these relational effects, particularly reputations, networks and flows of movement and migration. Such connections create relational 'social movement space' (Nicholls, 2009) through which innovations and ideas have travelled before being recontextualized within the locality. The area can therefore be characterised not simply as a site of experimentation, but also of translation reflecting the way in which concepts evolve they move through space and time (Czarniawska and Sev\u00f3n, 2005). For example, none of the cases detailed in Section 3.2 actually originated in the Totnes area. The idea travelled to the locality and then -as a site of early adoption -it provided a particularly fertile space for examples of that particular innovation to be developed, which then also stimulated further diffusion and experimentation. Perhaps the most striking recent example of this in the Totnes case is the Transition Town movement which has grown extensively since its launch in 2006. Not only has the 'transition town' concept itself travelled significantly (Seyfang and Haxeltine, 2012) but so too have some of the of the experiments that it has supported, such as garden-sharing and Transition currencies (Longhurst, 2011). This paper therefore makes a first tentative step towards exploring the geographies of grassroots innovation, a topic that has received little attention to date. There is also considerable scope for exploring other 'alternative' sites and spaces of innovation. Whilst the notion of an alternative milieu is a useful concept for understanding the countercultural dimensions of a particular locality there are other alternative places which function as loci of innovation. For example, hackerspaces (Moilanen, 2012), community based digital fabrication labs (fab labs) (Heilscher and Smith, 2014), autonomous social centres (Hodkinson and Chatterton, 2006), low impact developments (Pickerill and Maxey, 2009a) and ecovillages (Avelino and Kunze, 2009). Indeed, the example of Dartington itself in this particular case illustrates the role that intentional communities can have in nurturing new innovation. Thus Coates (2001, p. 303) draws attention to a number of social innovations that have originated in UK utopian communities, such as social work and the Town and County Planning System. Further work on the significance and functioning of such sites and spaces would begin to develop an 'alternative' geography of innovation to that represented by the conventional, market focused territorial innovation models."
        }
    },
    "10.1016/j.eist.2014.04.005": {
        "file_name": "108 Assessing and comparing German and UK transition policies for electric mobility",
        "title": "Environmental Innovation and Societal Transitions",
        "abstract": "This paper presents a novel policy assessment approach for sustainable transitions using insights from the multilevel perspective (MLP). An analysis of current German and UK policies for sustainable transport is conducted to illustrate its application. For both cases a potential transition pathway, that can satisfy environmental protection and industrial competitiveness goals, is derived from archetypal transition pathways. These are then put in relation to current policies, discussing whether these measures support these pathways. In the UK case, where emission reduction goals and industrial development are pursued together, current policies of promoting the diffusion of electric vehicles as well as industrial niches are supporting the emergence of a reconfiguration pathway. Replacing foreign suppliers, the local automotive industry shall become a significant part of the future regime. In contrast to that, Germany focuses on a careful transformation and conservation of its automotive industry where none of the current actors is left behind.",
        "label": "Qualitative",
        "text": {
            "Introduction": " The aim of this paper is to present a novel approach that allows policy makers to assess whether their policies are actually supporting transitions that satisfy their policy goals. While the case of electric cars has been chosen as an illustrative example, the approach can be utilized to discuss other cases of sustainable transitions as well. The private car transport sector has been taken as example as it is currently in a transition towards electric cars, mainly driven by significant economic and environmental pressures (IEA, 2010;IPCC, 2007;WEC, 2011). Alike other sustainability transitions this will induce significant changes to the current structure of the (automotive) industry, making it for some national governments a question of industrial policy as well as of energy and environmental policy. These energy and environmental policy goals are largely similar across European countries, however, industrial policy goals can be expected to reflect the particular structure and strategy of national industries and therefore vary more significantly. This hypothesis is supported by the fact that recent policies aimed at promoting electrification of road transport have taken somewhat different forms in different European countries (Elzen and Wieczorek, 2005;Hu\u00e9tink et al., 2010;Santos et al., 2010;Stern, 2007;van den Hoed, 2007). The question policy makers pose themselves is, what policies are most appropriate in order to reach their transition goals? The traditional way of answering the question would be by measuring the results that they have produced so far, in terms of both the uptake of electrified vehicles and of industrial competitiveness. However, given the policies were introduced only recently and vehicle uptake numbers are still low, such an assessment would be characterized by a high degree of uncertainty. Therefore we propose in this paper an alternative approach to assess policies for transitions that are intended to happen, or are at a very early stage. For that we use insights that are based upon recent research on transitions of socio-technical systems. Whilst the role of innovation in driving economic growth and industrial competitiveness has been noted by economists since early in the 20th century, many early works (Schumpeter 1934) focused on technological innovation on its own. However, since then, and over some decades, innovation theory has evolved greatly, leading to the investigation of innovation processes from a system perspective. This has brought more complexity into innovation theory, suggesting that attention needs to be paid also to the societal and institutional system in which an innovation is happening and spreading, leading to research on transitions of socio-technical systems. Looking at those aspects, a number of strands, including transition management (Rotmans et al., 2001), strategic niche management (Kemp et al., 1998), and the multi-level perspective (MLP) on socio-technical transitions (Geels, 2005b;Rip and Kemp, 1998) have been developed (among others) since the 1990s. The MLP is a framework that has significantly contributed towards the understanding of past transitions. Moreover, analysing historical transitions using the MLP, Geels and Schot (2007) have identified a set of stereotypic transition pathways that have been used to describe possible pathways for current sustainability transitions (Foxon et al., 2010;Van Bree et al., 2010;Verbong and Geels, 2010). Strategic niche management focuses on the management of transition experiments (on the niche level) to support niches in breaking existing regimes to initiate transitions. Transition management examines the policy process around the transition itself in a more general manner, including experiments and learning (Lachman, 2013;Markard et al., 2012). Although these strands have provided many new insights into sustainable transitions, they are however not yet providing specific insights into what policies are appropriate to reach specific transition targets for the system. In the literature much focus is on the niche level. In particular, Markard et al. (2012) and Meadowcroft (2009) outline that these approaches do not provide insights on decisive policies such as the target-oriented allocation of scarce resources among various alternatives. To address this, and to show the suitability of research on sustainable transitions for policy making, this paper proposes a novel approach that can be used to assess policy making for transitions, especially in the early stage of transitions. It is based upon the MLP approach, and especially a set of stereotypic transition pathways. The approach is applied to the case study of two European governments that have been introducing policies to support the electrification of vehicles: the UK and Germany. Previous work (Mazur et al., 2012) provided a brief comparison of road transport electrification policy making in the UK and Germany from a transition science and transition management point of view. However, with the help of this newly developed approach the present work goes significantly further. It now uses insights from transition science in a more formalized way in order to develop a methodology to evaluate the current policies in terms of compatibility with their intended goals. In Section 2 key concepts from transition theory and their relevance to this policy analysis are outlined. The notion of socio-technical systems and different types of possible transition paths are also introduced. These concepts are then formalized in Section 3 into an assessment framework. In section 4 this methodology is then systematically applied to the UK and Germany to assess their current policies for transport. This is then followed in Section 5 by a conclusion where we also outline how the approach can be further used.",
            "Theory": "",
            "Socio-technical systems and the MLP": " Innovation literature (Geels, 2005b;Rip and Kemp, 1998) clearly points out that a successful transition involves overcoming barriers that go far beyond pure technical and economic dimensions; and that infrastructural, institutional and societal dimensions are just as important. In the case of electric mobility the transition directly affects a number of actors such as car manufacturers and suppliers, providers of infrastructures (such as oil, gas and utility companies/suppliers) and owners of the vehicles. All of them form a so called a 'socio-technical system' (Geels, 2005b). The MLP describes transitions as an interaction between these different dimensions. For that purpose it classifies the various components of the system into three distinct but closely related levels: regime, niche and landscape. Socio-technical regimes are relatively stable configurations of the system and their rules, practices and networks determine the development and use of technologies (Rip and Kemp, 1998). In the case of transportation, the regime is defined by aspects such as the type of fuel, the type of vehicle power train, corresponding production infrastructures as well as beliefs and habits of the relevant actors. In contrast, niches are seedbeds for change and are normally a relatively protected market or technological domain, where new systems and practices appear. The landscape incorporates the environment in which regime and niches exist. It describes external factors, such as demographic shifts or cultural changes. Niche and regime actors experience changes in the landscape as external pressures and respond to them accordingly. In the case of electric mobility such pressures can be climate change, rising oil prices and related policy measures (Geels, 2002;Kemp and Loorbach, 2003;Schot and Geels, 2007;Smith et al., 2005;Tukker and Butter, 2007).",
            "Stereotypic transition pathways": " Based upon historical observations of transitions, Geels and Schot (2007) have proposed a variety of pathways that are common for transitions. Their typology of transition pathways (cf. Table 1) is based upon the nature and timing of interactions between the landscape, the niches and the regime. The typology differentiates between a landscape that is reinforcing the regime, and a landscape that is disruptive towards the regime. The typology also differentiates between a niche and regime relationship that is either competitive or symbiotic. The timing of the interaction plays also an important role and describes the 'readiness' or 'competitiveness' of the niche based upon its development. With the help of these criteria Geels and Schot (2007) differentiate 4 standard transition pathways that have been observed in the past (see Table 1). A Transformation path is given for a case of a moderate landscape pressure, where no potential niche is strong enough to fill the gap. In such a case the whole regime with all its actors has sufficient time to adapt, for example by an adjustment of its focus or just by slow adaption of knowledge from existing niches. The case where pressures from the landscape have been large enough (e.g. 'avalanche') to lead to a significant erosion (de-alignment) of the regime and to a slow emergence (re-alignment) of an alternative niche among many, is called a De-alignment and re-alignment pathway. In contrast to these two pathways, in the case of a Technological substitution pathway a potential niche (e.g. a radical alternative innovation) already exists. Through a shock, induced for example by the landscape, the niche knocks off the destabilized regime. The fourth type of pathways, the Reconfiguration pathway is at first glance similar to the Transformation pathway, as also here innovations from niches are taken up by the regime. However if these may involve multiple innovations, or rapid and significant changes of the regime structure, affecting many technical elements of the system (e.g. changed behaviour and infrastructures through a change towards electric mobility) then one speaks of a Reconfiguration pathway. In such a case certain regime actors are replaced by new ones while the main regime actors survive the transition. A case where the regime is stable and no transition of the system happens is called Reproduction. Apart from defining four key transition pathways, the typology also outlines the main actors involved and the types of interactions. This typology is the basis for the approach that is presented in Section 3. The transition paths outlined by Geels and Schot (2007) are widely accepted and have already been used as a basis to create possible future scenarios for the transition towards sustainable mobility (Foxon et al., 2010;Van Bree et al., 2010;Verbong and Geels, 2010).",
            "Methodology": " This paper proposes a novel approach to analyze transition policies from the point of view of transition science. Unlike past works (Van Bree et al., 2010) that create transition futures based upon transition theory, in our policy assessment we do not intend to determine what transition outcomes could result from current polices. Instead we propose to carry out an ex-ante, qualitative policy assessment based upon the existing visions of policy makers. In other words, this work presents an approach to assess current governments' policy making with respect to their communicated goals. As transitions, such as the electrification of transport and introduction of electric vehicles, affect many domains (technological, social, economic, etc.), transition theory is the analytical framework of choice for our analysis, due to its improved ability to capture all the key dimensions of a transition process when compared to other approaches. A number of previous studies (Geels, 2005a(Geels, , 2012;;Ieromonachou et al., 2007;Nykvist and Whitmarsh, 2008) have already applied methods from this domain to discuss transitions in road transport from a historical point of view. The methodology applied in this paper is motivated by recent work in the literature (Van Bree et al., 2010). Van Bree et al. (2010) develop possible transition scenarios for the future automotive transport, focusing mainly on the introduction of hydrogen and electric vehicles. For that, their study uses the Multi-level perspective (MLP) (see Section 2) to formalize the characteristics of today's automotive transport system. It then introduces a set of possible triggers (such as policies) that challenge today's system. These triggers lead to different transition pathways that then lead to different future technology scenarios. The pathways are chosen from the typology of standard transition pathways (see Table 1) that have been derived from observations of past transitions (Geels and Schot, 2007). In comparison, this paper also draws upon insights from transition science, but unlike former work (Foxon et al., 2010;Van Bree et al., 2010;Verbong and Geels, 2010), it does not try to provide a set of possible future scenarios or pathways as the result. Instead, the proposed approach aims to provide a means that can assess whether governmental policies do actually support a specific pathway that has been derived from the government's policy goals. The approach involves the following steps, which will be discussed in the next sections in turn: 1 Analysis of the current system and regime. 2 Identification of a future regime based upon policy targets. 3 Identification of a compatible transition pathway. 4 Assessment of whether current policy making supports the proposed transition pathway.",
            "Analysis of the current system and regime": " The first step consists of describing the state of the current socio-technical system with its functions, rules and existing pressures. Furthermore, the system structure is analyzed based on the MLP, and the current regime with its main regime players is described. This is then the basis for the identification of pathways that can link the current and future regime. For instance, the case study in Section 4 explores the automobile system. It focuses on environmental as well as industrial aspects, with an emphasis on the automotive industry, the vehicle type, production system and to a smaller extent, the infrastructure and market (or consumer behaviour), as these are the aspects that describe the current regime. Information such as the type of typical vehicle, national vehicle sales, and the national economic indicators on the automotive sector is taken as a basis for this description.",
            "Identification of a future regime based upon policy targets": " Having identified the attributes that describe the current regime, the second step involves the identification of the policy makers' vision of the future system and hence the future of those attributes. For that the current communicated goals of the respective countries are taken as a basis and the inferred future vision for the regime that is currently favoured by policy makers is formulated. Published government communications or regulations are considered as a good source to get a picture of governments' long-term targets.",
            "Identification of a compatible transition pathway": "",
            "Assessment of whether current policy making supports the proposed transition pathway": " In the final step the current policies are assessed by analysing whether they support the identified transition pathway. For that, the current policies in the observed country need to be reviewed and then compared to the specific conditions and requirements of the transition pathway that has been chosen in the third step.",
            "Case study: assessing policy making for low emission vehicles in the UK and Germany": " In this section the application of the proposed methodology is presented. A case study approach is taken and policies supporting low emission vehicles in Germany and the UK are assessed. We do not take modal changes into account but instead, focus on the change away from internal combustion engine vehicles (ICEVs) towards vehicles with electric power trains, such as hybrid electric (HEVs), plug-in hybrid electric (PHEVs), battery electric (BEVs) and hydrogen fuel cell electric vehicles (FCEVs). Germany and the UK have been chosen for this study due to their characteristics and good availability of data, as well as the fact that they are both bound by the same EU energy and environmental policy targets (landscape), which provides the context for these countries' electric mobility policies. To get a good picture of both countries, information provided by respective national statistics agencies, relevant government departments, and vehicle associations have been analyzed. The two case studies are discussed in the following sections; these are structured according to the four steps outlined in the methodology Section 3.",
            "Analysis of the current regime": "",
            "Today's private car sector in the UK": " There are about 29.5 million cars in the UK. These contribute 12.6% of the country's total energyrelated CO 2 emissions. In 2012, 2.04 million new vehicles were registered in the UK, making it Europe's third biggest automobile market (15% of total European registrations). Of those, only 1262 were BEVs and 25,370 hybrid vehicles, while most cars on the market are conventional combustion vehicles. While there are some battery re-charging stations, most of the energy is still provided through liquid fuel stations (IEA, 2011a(IEA, , 2011b;;SMMT, 2012SMMT, , 2013)). While most of the vehicles sold are supplied by foreign brands, the automotive industry still plays an important role in the UK. The local automotive industry exports 83.7% of the vehicles manufactured in the UK leading to a significant export value of \u00a329 billion -or 11% of UK's total exports (SMMT, 2012(SMMT, , 2013)). Vehicle output has increased over the last decades, from below 1 million in the 1980s to nearly 2 million at the end of the 1990s, followed by a steady growth over the last 10 years until, due to the financial crisis in 2008/09, the output dropped to below 1 million vehicles. Since then output has been rising again (in 2011 more than 1.3 million vehicles were produced), with Nissan, Jaguar Land Rover, MINI, Vauxhall and Toyota being the top five manufacturers among 40 companies that manufacture vehicles in the UK. This is 1.8% of the total passenger car production worldwide. Apart from that, 2400 component manufacturers operate in the UK. Their output also included the manufacturing of 2.5 million engines in 2011 (IEA, 2011a(IEA, , 2011b;;SMMT, 2012SMMT, , 2013)). In total, 868,000 people were employed in UK's automotive sector in 2005 but this number had decreased to 737,000 by 2010. The whole sector generated a turnover of \u00a349 billion in 2010 contributing less than 1% towards UK GDP (SMMT, 2012(SMMT, , 2013)). Many of those manufacturers are directly engaged in automotive R&D activities. Jaguar Land Rover, Ford and Nissan all have major R&D centres alongside SMEs such as Lotus Engineering, MAHLE, MEL, Millbrook, Ricardo and Zytek, to name just a few. R&D within these organizations generally also includes some efforts in the domain of electric mobility (SMMT, 2012(SMMT, , 2013)).",
            "Today's private car sector in Germany": " With a stock of 43 million cars (2012) the passenger car sector in Germany contributed 14% towards total national energy-related CO 2 emissions. 2.9 million new vehicles were sold and registered in Germany in 2012, with German brands having a market share of 70% in Germany. By January 2012 there were 4541 fully electric and 47,642 hybrid vehicles, with an additional 2956 electric and 21,438 hybrid vehicles registered in 2012 (Kraftfahrt-Bundesamt, 2011, 2012a, 2012b). The automotive sector is crucial for Germany's economy as it generated a turnover of D 317 billion in 2010 (20% of German industry). D 200 billion was generated in foreign markets. In 2010, 12.7 million vehicles were manufactured by German companies (52% produced abroad) and more than 75% sold abroad. In total, one in six passenger vehicles worldwide were produced by German car manufacturers. This includes major German brands such as Audi, BMW, Daimler (Mercedes) and Volkswagen that provide, together with suppliers such as Bosch, Continental, Schaeffler, etc. more than 5 million jobs (VDA, 2011). Additionally, the German automotive sector (manufacturers and suppliers) invested D 19.6 billion into R&D in 2010, more than 1/3 of all German R&D investments, and employed 89,000 people (VDA, 2011). As a result, most of the German automotive R&D is also based in Germany. Those major players (especially the suppliers) are also involved in the research & development of alternative power train technologies. They cover the technological niche of electric power train technologies. Additionally the German car manufacturers have entered into collaborations with suppliers of alternative technologies, such as Daimler with BYD and Tesla, and BMW with Toyota (Green Car Congress, 2011;Manager magazin, 2010;Spiegel Online, 2009, 2011, 2012).",
            "Today's private car regime in the UK and Germany": " Both countries' markets, similar in size, are important markets in Europe. Fig. 1 presents some statistics for both countries' automotive industries. Though developments of alternative power train systems are currently being pursued, both regimes are dominated by ICEVs -on the roads as well as in the production plants and sales rooms. The uptake of alternative vehicles has been slow so far in both countries as well as the installation of re-charging stations. In summary, the typical vehicle on the market, the infrastructures, as well as usage patterns, are still supporting a regime that is dominated by the traditional internal combustion engine vehicle. While German vehicle manufacturers are just starting to make their first hybrid and electric vehicles available to the mass market, such as BMW who launched the i-series in July 2013, the current and short-term regime will be still dominated by conventional vehicles with internal combustion engines, and by car manufacturers that offer mainly this type of vehicle, for at least a decade or two. Hence, there are only few electric vehicles on the roads in Germany as well as in the UK (according to sections 4.1.1 and 4.1.2 less than 1% in both cases). In both cases the current conditions are very similar. The regime is dominated by internal combustion vehicles. However the automotive industry that is providing the passenger car in Germany is bigger and more important for its economy. So the industrial dimensions that could be affected by a transition towards sustainable passenger cars are significantly bigger in Germany than in the UK. 4.2. Identification of a future regime based upon policy targets for the UK and German cases 4.2.1. UK government policy goals for the private car regime The UK government has legislated in the DECC Climate Change Act 2008 a binding greenhouse gas emission reduction target of 80% by 2050 (relative to 1990) (UK Government, 2008). Additionally the UK has committed itself to the European Energy and Climate Policy Package in 2008, setting a CO 2 emission reduction target of 20% by 2020. For the road transport sector in particular, the UK government aims to achieve close to zero net greenhouse gas emissions by 2050 (see the report 'The carbon plan: delivering our low carbon future' (DECC, 2011)) which implies that all new cars sold in the UK from 2040 onwards have to be zero-emission vehicles. It is therefore clear that CO 2 emission reduction is a key focus of UK road transport policy. However, the potential that low carbon vehicle technology has for the UK's industrial development is also recognized; as outlined by the briefing paper \"Ultra-Low Carbon Vehicles in the UK\", jointly published in 2009 by the UK Department for Transport (DfT), the Department for Business, Enterprise and Regulatory Reform (BERR) and the Department for Innovation, University and Skills (now BIS) (page 1): \"Our transport system connects people to places and businesses to markets. As such it is fundamental to our economic strength and quality of life. However, the only sustainable future for transport lies in a transformative shift to low carbon. Our ambition must be twofold, to reduce the environmental impact of transport and for UK business to benefit from this transformation.\" and furthermore: \"By acting now there is a real potential for the UK to take a lead in this sector\" (UK Government, 2009) ",
            "German government policy goals for the private car regime": " The German Government initiated a National Electric Mobility Strategy Conference in 2008 that led to the announcement of a strategy paper in 2009: 'Nationaler Entwicklungsplan Elektromobilit\u00e4t' (National Development Plan for Electric Mobility) (German Government, 2009) outlining a set of drivers and targets. While environmental targets also play a role, it is evident that German policy makers are interested in preserving the German automotive sector's role and significance in the world, in order to ensure continued economic activity and employment in Germany. According to that report, the main goal is growing and preserving the automotive industry, as it provides 5 million jobs and generates a D 317 billion (20% of the German industry total) annual turnover. Additionally there is a commitment to a 40% GHG reduction by 2020 and an intention to reduce by 80-95% by 2050 (compared to 1990 levels). Furthermore the German government has set the target of 1 million EVs in 2020 and 6 million in 2030 (German Government, 2009).",
            "Potential visions for the future UK and German regimes": " At first glance the German and the UK governments seem to have announced similar goals concerning the future regime of their private car transport systems (see Table 3). Both emphasize the reduction of carbon emissions as well as the support of the local automotive industry. Both aim to achieve this through the introduction of alternative vehicle such as electric cars and their respective infrastructures making those technologies the new regime. Both also aim to take advantage of the change towards the electric mobility to support their industry, creating jobs and growth. However, there are differences. While the UK has legally binding zero carbon emission targets until 2050, German long-term targets are not as strict. Moreover the health of the existing industry in Germany has a much more important role. German policy makers explicitly aim to sustain the role of German manufacturers and suppliers in a future regime. In comparison, the UK considers such a transition to low emission vehicles to be an opportunity for local SMEs to become a more significant part of a future automotive regime by becoming suppliers of alternative technologies.",
            "Potential transition pathways for the UK": " Comparing the current state (Table 2) and the future vision (Table 3) of the passenger car regime with the future vision, we infer that there will be a need for a change to the regime that will go beyond a simple Reproduction pathway. There will need to be changes in the typical vehicle technology, the recharging (refuelling) infrastructure, as well as the production system. However, as the government favours the development of local suppliers while supporting the existing manufacturers the change will not include an entire replacement of the existing suppliers of passenger cars (manufacturers).  Electrification of passenger car fleet. Existing vehicle stock and vehicles on the market are electric or zero emission cars.",
            "Production system": " There is manufacturing of electric cars and their technologies in the UK. Foreign companies manufacture cars while UK suppliers of electric mobility technologies are important part of the supply chain and also exporting abroad. provide many jobs in manufacturing and engineering. There is manufacturing of electric cars and their technologies in Germany The German automotive industry with the current manufacturers and suppliers still exists and is strong. It still develops and produces cars in Germany providing economic growth and jobs to Germany.",
            "Infrastructure": " There is an infrastructure for EVs and/or FCEVs There is an infrastructure for EVs and/or FCEVs Considering the stability of these multinational car manufacturers implies a Substitution or Deand Re-alignment scenario is also unlikely (Wells and Nieuwenhuis, 2012). Hence the current regime players will still play a crucial role in the future vision. However, the transition pathway will have to go beyond the transformation of the current manufacturing system and its suppliers. And as the government also favours the development and empowerment of local suppliers of alternative vehicle technologies this infers a Reconfiguration pathway. In such a case the suppliers get replaced by new niche players. The UK has already on the niche level a significant number of British SMEs that manufacture various components for the power trains of electric vehicles, such as Ashwoods, Johnson Matthey, GKN or Yasa, as well as engineering firms (e.g. Ricardo, GMD, Lotus) and one major manufacturer, Jaguar Land Rover, whose primary R&D activities are located in the UK, that are already focusing on this market. Hence a Reconfiguration pathway links the current state of the regime with the future vision of the policy makers (see Table 4).",
            "Potential transition pathways and patterns for Germany": " Comparing the current state (Table 2) and the future vision (Table 3) of the passenger car regime with the future vision shows that there will also be a need for a significant change to the German regime in order to reach the future vision. There will be a change in the typical vehicle technology, the recharging (refuelling) infrastructure as well as the production system. However, in contrast to the UK, the German government favours the support of the whole existing automotive industry including its big manufacturers and suppliers. This is supported by the stability of the automotive industry as it has established itself in Germany over many decades. It is dominated by a number of car manufacturers (VW with Audi, BMW, Daimler, etc.) and suppliers (Bosch, Continental, ZF, etc.) leading to significant stability and inertia, especially due to existing networks, technologies and infrastructures. Hence to meet the vision, the change must not include a replacement of the existing production structures. Therefore the regime will have to internalize those technologies to reach both environmental and industrial goals. This can be achieved by a Transformation pathway (Table 1). Table 4 summarizes the characteristics of the transition with regard to the 4 dimensions for the UK and German case.",
            "Assessment of current policy making with regard to its compatibility with a valid transition pathway": " In the previous section it has been outlined that there is a specific pathway that can link the current and future state of the system of both countries. Each pathway occurs under certain conditions or requires certain drivers (see Table 1). In this section the actual policies will be assessed with respect to those pathways and their specific requirements, and whether these policies actually support them and hence the announced policy targets. ",
            "Corresponds with Reconfiguration pathway": " German case There is only moderate pressure from the German government on the automotive industry as its health (growth, jobs) is priority. Symbiotic niche-innovation is taken up by regime, such as power train components, mainly provided by big German suppliers. Innovative solutions can be acquired or developed by car manufacturers While there are no small niche providers who could challenge the system, most of the competition is coming from niche technology providers such as Tesla The current German automotive industry including car manufacturers and suppliers execute the change themselves. -Plug-in vehicle grant: 25% subsidy (up to \u00a35000) for a new Ultra-low Emission Vehicles, with a total budget of \u00a3300 million.",
            "Corresponds with Transformation pathway": " -Favourable tax regimes and exemption from Vehicle Excise Duty and Company Car Tax for Ultra-low Emission Vehicles. -\u00a330 million match funding for Plugged-in Places (recharging stations). Support of new suppliers that replace old ones \u2022 Creation of the Integrated Delivery Programme, an investment programme, jointly financed by Government and business that \"aims to maximize the benefit to UK-based businesses of the rapidly-developing low carbon vehicles market, and to help accelerate the adoption of low carbon vehicles in the UK.\" The Programme co-ordinates the UK's low carbon vehicle activity from initial strategic research through collaborative research and development, leading to the production of demonstration vehicles (\u00a3250m of joint government and industry investment). \u2022 UK government created CENEX (Centre of excellence for low carbon and FC technologies) which is supported by the Department of Business, Innovation and Skills (BIS). Its aim is to catalyze innovation to enhance UK industries' overall capabilities using strategies focused on knowledge transfer and technology demonstration. Founded in 2005. The tasks include, Identifying and communicating emerging technologies, deploying fleet-scale demonstrators, coordinating academia, suppliers, car manufacturers, etc.",
            "Assessment of low carbon vehicle policies in the UK": " In the previous section it has been outlined that a Reconfiguration pathway can link the current state of the system with the policy makers' vision of the regime. This translates into 3 requirements for policies in this case study. It requires some moderate to strong pressure (and possibly also incentives) from policies on the landscape level that makes the regime adopt new symbiotic niche-regime innovations. However, this must be done whilst not destabilizing the main regime players (especially the car manufacturers that produce in the UK). It also requires policy makers to support niche suppliers in order to replace the current suppliers. Table 5 presents different policies that do support these three drivers and hence a Reconfiguration pathway. The main pressure on the existing regime is being already created by EU emission limits for vehicles. Therefore, the UK's efforts to create additional strong pressure in this way are unnecessary. The UK has a procurement programme for low emission vehicles and there are low emission zones within cities where low emission vehicles do not have to pay certain charges. In terms of supporting the regime in achieving the change, the UK government has introduced more extensive measures. Through the creation of the Office for Low Emission Vehicles (OLEV) it has provided more than \u00a3400 m funding for the development and deployment of ultra-low emission vehi- cles, providing consumer incentives, supporting recharging infrastructure and research, development and demonstration programmes. Although these measures also put pressure on the regime, they do not endanger the current regime players but instead provide incentives to adapt. A possible result of such an incentive may be the decision of Nissan to build the BEV Leaf at their existing location in Sunderland UK (The Guardian, 2010;The Telegraph, 2010). Measures that support the uptake of new local or national niche suppliers have also been employed by the UK government. For instance, the variety of RD&D programmes directed towards UK-based businesses that offer low carbon technologies, the investments into infrastructures and especially investments into recharging stations and the choice of niche actors for demonstrator projects, all have the potential to nurture the local niche industries that then can grow and become a part of a bigger solution. In summary, the application of the proposed approach shows that the UK government has introduced policies that support a transition pathway (Reconfiguration) that is compatible with environmental and industrial goals.",
            "Assessment of low carbon vehicle policies in Germany": " In the previous step it has been outlined that a Transformation pathway links the current state of the system with the policy makers' vision of the regime. This translates into 3 targets for policy makers. Pressures on the regime should be low so that it can adopt new innovations and does not get replaced by another regime. This also means that in a future regime the current regime players, and especially the German manufacturers and suppliers, should still exist. Hence it will require policy makers to create only enough pressure to help and incentivise German industry to achieve a change towards electrification of transport without destabilizing it. This might require policy actions that decrease pressures if they might challenge Germany industry too much. Furthermore the support of a general transition in infrastructure is necessary. Table 6 presents different policies that do support these three drivers and hence a Transformation pathway. mentioned before, the main pressure on the existing regime is driven by EU emission limits for vehicles. However, this could threaten the health of the German automotive industry, which produces vehicle fleets with average carbon emissions that are well above the limits that are being discussed at the EU level. As a result the German government has tried to weaken those targets. Germany's role during the EU negotiation on vehicle emission targets reflects this protective behaviour (Spiegel Online, 2008). \"Merkel has fought energetically for months to get the proposed regime weakened\", (The Guardian, 2008). This does not mean that Germany is opposing the transition. It invests in infrastructure, provides limited incentives for electric cars and funds demonstrator programmes -purchase grants have not been considered though (Handelsblatt, 2012). The main goals of German policies appear therefore to be the preservation of its automotive sector by supporting the German automotive industry's transition towards the electrification of their products. Germany provides extensive R&D programmes supporting major German-based car manufacturers and suppliers to conduct research in the area of electric mobility, production technologies and demonstration projects supporting already existing regime actors and hence their transformation. There are significant investments into the technological competitiveness of its own automotive industry and the cost efficient manufacturing of power train components. Both measures imply a strategy that leaves enough time for the German car manufacturers to adapt and start selling EVs in Germany as well as elsewhere. The absence of a purchase grant is probably to limit the ability of foreign car manufacturers to increase their market share in Germany through subsidized PHEV or EV sales before German car manufacturers are ready.",
            "Drivers": " German measures that support drivers for a Transformation pathway Only low pressure on the regime \u2022 Loosen emission limit targets during negotiations on EU level as well as slowing down introduction of limits \u2022 Adaptation of vehicle taxation system in 2009, so that the tax is now based upon both the engine size and CO2-emissions. \u2022 Electric vehicle owners do not pay any vehicle tax for the first 10 years. General support of transition In summary, German policies are consistent with its policy targets as the policies support a Transformation pathway that satisfies these targets.",
            "Conclusions": " This paper has presented a novel approach to assess policy making for transitions of socio-technical systems with respect to policy goals. To show the application of this method, two case studies (electric mobility in the UK and Germany) are discussed. The methodology draws insights from transition science, using the multi-level perspective (Geels, 2005b;Rip and Kemp, 1998) and common pathways of transitions (Geels and Schot, 2007) that have been observed in history. First it involves the translation of policy makers' targets into a vision for the future regime. Then a pathway is identified that can reach such a future. In the last step the actual policy making is assessed by its compatibility with the proposed transition pathway. A review of the current state as well as of the respective policy goals has been conducted. It shows that in the UK and Germany, policy makers have targets that are motivated by environmental and industrial goals: a decrease in GHG emissions (hence a fast introduction and diffusion of low emission vehicles) and simultaneously the development or preservation of their automotive industry and its competitiveness. In the case of the UK, the main drivers are the government's announcement of the 2050 emission reduction goals, the conservation of the current foreign owned manufacturing, as well as an establishment of a local automotive industry (mainly from the niche level) that can take advantage of the change towards electric vehicles. In the German case, although environmental targets exist too, industrial goals play a more important role, driven by the fact that Germany is economically highly dependent on its automotive industry (current regime actors) and this is threatened by a global transition from a fossil fuel based transport towards electric mobility, if it does nothing. The differences in these two cases are illustrated by the proposed pathways that have been identified for both cases. The UK transition problem could be satisfied by a Reconfiguration pathway while in the German case a Transformation is more suitable. While there are many similarities in both cases, there are differences in terms of the role of the automotive industry. While the UK wants to develop a new local industry in the domain of mobility (suppliers), German policy makers favour the preservation of the existing German automotive manufacturers and suppliers making the extent of the transition less disruptive. In order to achieve their specific goals, the governments of both countries have introduced a variety of measures. In contrast to the UK, where a significant amount of the budget is allocated to a low emission vehicle purchase grant as well as to the support of niches, the German government did not introduce a purchase grant. Instead, Germany directs funding mainly towards R&D, especially focusing on technology development within the current industry regime. The UK has introduced measures that support a pathway that can lead to a move away from CO 2 emitting vehicles towards a future where cars are electrified. Furthermore it can allow the UK industrial environment to take advantage of such a change, providing jobs and prosperity. In Germany the government has announced emission reduction targets as well as the industrial health of its automotive industry as main drivers for its policy making. Their actual policies actually imply that a bigger focus is put on the latter one supporting a Transformation pathway and therefore a controlled transformation of the German automotive industry. Hence in both cases our methodology shows that policy makers are applying policies that support pathways that lead to transition outcomes that satisfy policy targets. However, there are limitations in the approach proposed here. While the approach allows us to assess whether policies support the proposed pathways, it does not provide insights as to whether the policies are sufficient to achieve the targets on time. In the case of Germany for example, while a Transformation pathway would correspond with the attempt to give the industry enough time to adapt, it might not meet national and international road transport emission targets, especially as a significant amount of vehicles that are sold in Germany are of German make. Such a pathway might not be even sufficient in the current world wide race towards electric cars, assuming that other countries (China or Japan) might execute their transition in a faster way, and Germany might jeopardize its automobile industry's role (ifo Schnelldienst, 2008). To summarize, we have presented here a method that can provide insights on policies for transitions. While we have chosen the case of electric cars as an example, the approach can be as well utilized to discuss other cases of sustainable transitions where policies are implemented to reach certain goals. Examples can be the decarbonisation of energy production, the change of manufacturing towards 3D printing or the introduction of autonomous transport means. The approach just requires that there are policies targeting the transition that is to be assessed. additional research on more precise pathways as well as the quantification of further aspects could lead to more a more extensive analysis. However, that would decrease the easy applicability of the proposed approach which provides a simple way to assess whether transition policies are consistent with policy targets."
        }
    },
    "10.1016/j.eist.2015.06.002": {
        "file_name": "109 Understanding the drivers of fleet emission reduction activities of the German car manufacturers",
        "title": "Environmental Innovation and Societal Transitions",
        "abstract": "The current mobility system, dominated by fossil fuel powered automobiles, is under increasing pressure due to its environmental impact. To address this issue there is a need for a transition of the system towards one that is more sustainable, including the introduction of car technologies that allow a decrease in fuel consumption and the substitution of fossil fuels as primary energy source. Due to the stability of the current automotive industry and the dominance of the internal combustion engine technology, it is expected that the incumbent firms and their activities will play a crucial role in the transition. Policy makers have therefore introduced a variety of policies to encourage the industry to provide suitable solutions. We have conducted a micro-level analysis of how the three main German car manufacturers have changed their activities in the field of low emission vehicle technologies in response to national/international events and policy making. Our analysis suggests that policy makers only have limited influence on the type of disruptive solution that is chosen by these individual companies and that activities related to solutions that were not familiar to the individual car manufacturer were mainly induced by internal or external champions. Still, while the existence of regulatory policies allowed such activities to succeed, on its own it only encouraged the industry to work on incremental solutions based upon the knowledge already possessed.",
        "label": "Qualitative",
        "text": {
            "a b s t r a c t": " The current mobility system, dominated by fossil fuel powered automobiles, is under increasing pressure due to its environmental impact. To address this issue there is a need for a transition of the system towards one that is more sustainable, including the introduction of car technologies that allow a decrease in fuel consumption and the substitution of fossil fuels as primary energy source. Due to the stability of the current automotive industry and the dominance of the internal combustion engine technology, it is expected that the incumbent firms and their activities will play a crucial role in the transition. Policy makers have therefore introduced a variety of policies to encourage the industry to provide suitable solutions. We have conducted a micro-level analysis of how the three main German car manufacturers have changed their activities in the field of low emission vehicle technologies in response to national/international events and policy making. Our analysis suggests that policy makers only have limited influence on the type of disruptive solution that is chosen by these individual companies and that activities related to solutions that were not familiar to the individual car manufacturer were mainly induced by internal or",
            "Introduction": " Over the last few decades the automotive regime has been experiencing a number of challenges, both changing customer expectations and needs, particularly their perception of oil supply uncertainty and price volatility, and also governmental and regional policies driven by climate change and local air quality issues. As automobiles are responsible for a large fraction of total energy-related GHG emissions (IEA, 2010;WEC, 2011) the on-going discussions on fuel efficiency and emission reduction goals has led, and will lead, to changes in behaviour, strategies and products in the automotive industry. One way of addressing these pressures is the introduction of technologies such as hybrid, battery and fuel cell electric vehicles (Howey and Martinez-Botas, 2010;IEA, 2010;Offer et al., 2010). It is argued that the whole spectrum of electric vehicle technologies is likely to be needed in a future decarbonised road transport system, each playing a different role (Contestabile et al., 2011;IEA, 2010;McKinsey & Company, 2010). As a result scenarios, such as those analysed by the IEA and World Energy Council, are used to highlight futures with a diffusion of those different vehicle propulsion technologies that may lead to the change of whole socio-technical systems (IEA, 2010;Vallejo et al., 2013;WEC, 2011). Hence the diffusion of a new vehicle propulsion technology is potentially a complex systemic problem, subject to issues such as technology lock-ins (Unruh, 2000(Unruh, , 2002)). While policy makers have tried to create policies leading to futures that are favourable for their countries, economies and citizens, the response of the system is not always as expected. And even now in the current transition towards electric cars the diffusion of low emission vehicles is not happening as fast as it was aimed for by policy makers. This can be explained by the stability of the system and especially the role of the automotive industry that is strongly embedded in the current private car transport regime (Wells and Nieuwenhuis, 2012). Because of that stability we assume that the change towards electric cars will happen at least with the participation of the current incumbent automotive manufacturers, if not even be executed entirely by them. Even in the case of the electric vehicle manufacturer Tesla we would argue that it is actually an 'offspring' of the existing automotive regime, as it strongly relies on an employee base that has been hired from the automotive industry regime except for the engine engineers. Additionally they take advantage of the existing automotive supply chains. Using the typology of stereotypic historical transition pathways (Geels and Schot, 2007), this would imply a transformation or a reconfiguration pathway where the current regime playersnamely the automotive industry -still play an important role in a future regime where electric vehicles dominate (Wells and Nieuwenhuis, 2012). Hence as a result this paper focuses on a transition towards electric vehicles that is executed by the existing automotive industry. This is confirmed by the fact that this industry has presented different types of low emission vehicles in the past. Not only have there been a vast number of low emission vehicles in the past, such as the electric EV-1 by GM in 1996 and the fuel cell vehicle Necar by Daimler in 1994 to name two early ones. But recently we are observing the introduction of various low emission vehicles into the mass market, such as the Tesla S by Tesla Motors, the i3 by BMW, the Leaf by Nissan or, before that, the Prius hybrid vehicle by Toyota. A number of studies (Bakker and Farla, 2015;Bakker et al., 2012a,b, Geels, 2012;K\u00f6hler et al., 2013;Mazur et al., 2015;Wiesenthal et al., 2010) have emphasised the strong role of policy in leading to this development. Other studies (Farla et al., 2012;Mazur et al., 2015;Penna and Geels, 2012;Wells and Nieuwenhuis, 2012;Wesseling et al., 2013) have also emphasised the importance of the existing automotive industry in delivering this transition, implying that the understanding of the micro-level activities of this industry is crucial if policy makers are intending to design policies that are able to deliver the desired environmental objectives. To understand what events have particularly influenced the automotive industry's activities regarding vehicle fleet emission reduction technology, we have conducted a study of the micro-level activities of the German car manufacturers, linking these with historical events at the regime and landscape level. The goal is to identify patterns in the companies' behaviour.",
            "Methodology": "",
            "Analytical framework": " In order to analyse the behaviour of the automotive industry in response to various types of events and pressures, we have developed the framework illustrated in Fig. 1. We have built upon methodologies from a number of studies (Budde et al., 2012;Konrad et al., 2012) addressing the effects of expectations on strategy and micro-level activities within the industry. Moreover, the framework's structure is based upon the multi-level perspective on socio-technical transitions (Geels, 2005;Rip and Kemp, 1998) that differentiates between landscape, regime and niche levels, and describes transitions as the result of interactions between these levels. In our framework the activities of the automotive industry are put in relation to events on the regime and landscape level -this can also include expectations. The framework is then used as a basis to create narratives on the industry as commonly done in previous research (Augenstein, 2015;Budde et al., 2012;Konrad et al., 2012;Nykvist and Nilsson, 2015) addressing the role of the automotive industry in sustainability transitions. We focus our analysis on the three main car manufacturers in Germany (Daimler, BMW, Volkswagen). They are part of the current regime and conduct different activities in order to respond to company external pressures. These activities are differentiated in the framework between (1) strategy decisions and announcements, (2) research and development activities as well as introduction of efficiency improvement technologies, and the (3) collaboration with other companies in these domains. What events made the car manufacturers work on niches? technology R&D, concepts and car introduc\u019fons  Budde et al., 2012 andKonrad et al., 2012). (For interpretation of the references to colour in this sentence, the reader is referred to the web version of the article.) Strategy decisions and announcements include new, revised or abandoned technology targets for the achievement of efficiency improvements and related sales targets. Technology related activities can include launches, changes or discontinuation of certain technologies, establishing a new research group, presenting a prototype and launching a vehicle on the market. Finally, collaboration activities include instances where new collaborations are set up or cancelled, companies acquired or external actors approached the company. These activities are then put into relation with events on the regime and landscape level. For this to be possible, the framework needs to also cover the regime and landscape around the incumbent players and their evolution over time. In particular, the landscape level focuses on aspects such as economic development, fuel prices and climate change pressures, while the regime level illustrates international and national policies, and consumer's and competitors' behaviour, similar to past studies (Budde et al., 2012) conducted in this field. In addition to the above, the niche level offers a possible pool of alternative and disruptive solutions to the organisations. In certain cases the car manufacturers can interact with these technology niches, meaning that they can conduct activities that have the aim to internalise these disruptive solutions. Alternatively they can respond to pressure by just introducing incremental improvements. This study aims to identify what events on the landscape and regime level, and on the micro-level, encouraged the car manufacturers to internalise these niches (see red arrows in Fig. 1).",
            "Design of the study": " In order to conduct the study, first an extensive review of the literature on the micro-level activities as well as on events that occurred on the landscape and regime level since 1990 was conducted. The type of information collected was defined by the analytical framework and focused on activities relevant to the reduction of fleet emissions. The information gathered was then used to build a set of historical timelines that are presented in Section 2.3; the set consists of one timeline showing major events on landscape and regime levels in which the car manufacturers are embedded, and three micro-level timelines, one for each German car manufacturer studied. The content of the timelines are motivated by the analytical framework and so constructed allow the comparative study of three companies that are all in the same environment and are all affected by the same company external events. To this end, we then conducted an analysis where the timeline for each car manufacturer was examined for significant changes in the firm's activities, with a focus on those activities involving major interactions with niche solutions. Once this was done the landscape/regime timeline was examined for events that had occurred during or before this activity, in order to find potential causal links between the landscape/regime timeline and the car manufacturer's. The focus was put on activities such as research, development and commercialisation of technologies and solutions that contributed to lower emissions. Based upon this approach a narrative for each car manufacturer is created and presented in Section 3.",
            "Data": " Alike similar studies (Budde et al., 2012;Konrad et al., 2012;Wesseling et al., 2013) that looked at the behaviour of the automotive industry, the data needed for our study are obtained using a mixture of methods, including an extensive review and analysis of scientific literature and discourses, and then validated through interactions with industry experts. As already outlined by other studies (Budde et al., 2012) such a meticulous approach is necessary, as the automotive industry normally does not disclose the reasons for their activities. Initially we reviewed the literature (Bakker and Budde, 2012;Bakker et al., 2012a,b;Budde et al., 2012;Collantes and Sperling, 2008;Dijk and Yarime, 2010;Hacker et al., 2009;IEA, 2012;K\u00f6hler et al., 2013;Konrad et al., 2012;Mazur et al., 2015;Wesseling et al., 2013Wesseling et al., , 2014) that provides insights into strategies and activities, technology trends and hypes, national and international policies, competitors' behaviours, economic pressures, fuel prices and infrastructures, and future expectations. Subsequently we executed a discourse analysis of coverage in the mass media,1 screening our selected sources for information on vehicle releases, strategic decisions and collaborations. For our analysis we selected those articles containing keywords such as \"electric vehicle\", \"hybrid\", \"concept vehicle\", \"fuel cell\", \"battery\", etc. and those that dealt with major vehicle exhibitions such as the events held in Detroit, Geneva, Paris or Frankfurt. Finally, annual reports of the three German car manufacturers were screened for information on vehicles releases, strategy decisions and low emission technologies. Here the environmental sections often offered insights into what technology solutions were preferred at given times. The data above has been gathered for each year of the observed period of 1990-2014 and put into the timelines (see Figs. 3-8). The timelines were presented at conferences attended by representatives of the automotive industry and were also -in private -discussed with experts.2 This provided a form of validation of the data gathered and of the main causal relationships that we had derived from it; the latter is particularly important as the review of the literature and discourses we carried out does not in itself guarantee the validity of the causal relationships inferred. In the following section, we provide simplified versions of the timelines above where we summarise the main disruptive events that led the car manufacturers to work on niche solutions.",
            "Analysis": " In the following a number of cases are outlined where various car manufacturers interact with niche technologies and solutions; these are put in relation with pressures the companies experienced at the time. In the analysis of the timelines, particular attention is paid to cases where companies have decided to do something new -something that went beyond their past technology path. This means that while continuous improvements in domains where the companies had already extensive knowledge, including efficiency improvements in combustion engines, are also discussed, the focus is put on events that led to the work on technologies that were step changes for the company. Following the analytical approach described, disruptive events were identified and then put in relation with changes at the regime and landscape level, in order to identify possible causal relationships. In the following sections we provide narratives of the temporal evolution of the automotive regime and landscape in which the car manufacturers are embedded (see Fig. 2) and of the micro-level activities of the three main German car manufacturers.",
            "The automotive regime and the landscape": " The Zero Emissions Vehicle (ZEV) initiative in California in 1990 was one of the first policy measures pushing towards electric vehicles (Budde et al., 2012;Collantes and Sperling, 2008). It encompassed a number of targets with regard to vehicle emissions as well as the market penetration of zero emission vehicles. Though it was only limited to California it had a significant impact on the US and the world. More than 10% of the US vehicle market was in California (National Automobile Dealers Association, 2014), and policy developments in California often moved to other States. Although it triggered a number of EV and FCEV prototypes being presented by the industry, it was then relaxed in 1996 as by then the original goals were no longer expected to be met (Budde et al., 2012). Despite this, the ZEV initiative influenced policy makers worldwide, also in terms of technology choices (Budde et al., 2012(Budde et al., , 2015)). In the case of Germany, until the 1990s hydrogen fuel cell vehicles had been favoured by the government resulting in substantial finding for hydrogen and fuel cell research (Budde et al., 2012). As a result of the ZEV initiative, this changed and the interest diversified to include other technologies such as batteries (Budde et al., 2012). Then around 1996/97, at a time",
            "National and international events": " Activities in the automotive events 1990 1991 1992 1993 1994 1995 1996 1997 1998 1999 2000 2001 2002 2003 2004 2005 2006 2007 2008       when hydrogen was not seen as a winner anymore (Der Spiegel, 1996), major OEMs in Germany and Japan presented their respective solutions to deal with the CO 2 emission challenge. Surprisingly Daimler launched the Necar II hydrogen prototype, which triggered a new hydrogen/fuel cell hype, which however was mainly limited to Germany. However, this was reflected by a hype in media coverage that peaked in 2000/2001 (Konrad et al., 2012). At around the same time, hybrid vehicles such as the Toyota Prius and the Honda Insight were launched on the Japanese and US markets (H\u00f8yer, 2008). The early 2000s were dominated by global economic crisis that had some influence on the production capacities and outputs of the automotive industry. So with regard to technology choices it was not until 2004/05 that major changes occurred. Toyota's success with the Prius hybrid vehicle and the launch of its second generation started to put significant pressure on the other automotive players. This was magnified by rising fuel prices. As a result, the changing perception of the hybrid  technology led to a 'hybrid race'; this is testified by the significant increase in patents of hybrid technologies, HEV/PHEV prototypes being presented at various automobile exhibitions, and numerous announcements of HEV release dates (Budde et al., 2015). A wave of collaborations on these technologies among manufacturers and with suppliers could also be observed at the time (see timeline for the three manufacturers). During all that time, even with ups and downs, hydrogen fuel cell technology continued to enjoy support from various government initiatives worldwide, such as the US Department of Energy's Hydrogen Program. However, the inauguration of Steven Chu as the new US Secretary under President Obama in 2009 together with a reassessment of all technology options triggered a major change in perception of this technology. The US Hydrogen Program underwent major cuts and it was only the intervention of the Congress that prevented it from being cancelled altogether (Bakker et al., 2012a,b). During that time (2009)(2010)(2011)(2012) the global financial crisis hit, and governments in Germany, the UK, the US and elsewhere launched a swathe of different national support programmes for the automotive industry as part of broader economic stimulus packages, most of which had a technology focus. The \"Nationale Plattform Elektromobilit\u00e4t\" in Germany (Bundesregierung und deutsche Industrie, 2010) and the \"Ultra Low Emission Vehicles initiative\" in the UK (Department for Transport, 2012) had the aim to support the uptake of electric mobility in order to reach both environmental and industrial targets. Since then, HEV/PHEVs and BEVs have dominated the debate while the hydrogen fuel cell technology has seen less hype, such as in the US White House Blueprint for a Secure Energy Future. In contrast, the introduction of the TESLA Model S, Chevrolet Volt, Nissan Leaf, Mitsubishi iMiEV and many more have kept battery technology firmly in the spotlight. It is also worth noting that, despite the fact that post 2012/13 the focus is slowly shifting away again from small, fuel efficient vehicles towards bigger cars such as SUVs, PHEVs and BEVs still remain in the car manufacturers' technology portfolios as short-or medium-term solutions and are steadily gaining momentum (see technologies in timelines), which suggests that a change in the current regime may be occurring. This is also reflected by a continuous reduction of fleet emissions of the three manufacturers studied here (based upon fleet emissions reported in the annual reports of those companies).",
            "The German car manufacturers": " In this section the activities of the German car manufacturers BMW, Daimler and VW in response to various events are analysed. Following the analytical framework in Section 2, a set of micro-level key activities related to low fleet emission technologies and solutions has been outlined and then put into relation with events that had happened at the automotive landscape and regime level. The analysis resulted in the identification of cases where activities on the micro-level were started, changed or discontinued as a consequence of regime and landscape pressures (Table 1). These activities and the corresponding events are summarised in Figs. 6-8. For each of the activities outlined in Table 1 the following sections provide insights, in a narrative manner, into what triggered them and the extent to which policy played a role by discussing what happened at that time or earlier on the niche, regime and landscape levels. For a very long time Daimler was at the forefront of fuel cell research for automotive application. It was the move of the company's internal FC group from Dornier to the car section in the early 1990s that allowed Daimler to develop a number of FC prototypes and demonstrator vehicles. A few years later, in 1994 Daimler presented its first FC prototype Necar I (New Electric Car I), but it was the Necar II that would raise the profile of FC vehicles at that time (Budde et al., 2012). Since that time Daimler has presented a variety of FC vehicles, including hybrids and versions with gas reformers. A collaboration with Ballard in Canada led to the purchase of a stake in Ballard by Daimler (together with Ford) in 1997, andin 2007 to the total acquisition of the Ballard's automotive FC division. This meant that since the early 1990s Daimler had been accumulating substantial know-how and R&D infrastructure in hydrogen fuel cells (Budde et al., 2012). Around the millennium this had led to high expectations with regard to the commercial launch of FCEVs. However, although Daimler announced in 1999 that there would be 100,000 FCEVs in 2004, the application of the fuel cell technology never went beyond demonstrator programmes or small series production (Budde et al., 2012). Even though at the end of the 1990s fleet emission targets started being discussed at the EU level, they only led to improvements of internal combustion engine efficiencies. In the early 1990s Daimler introduced the Smart brand, providing small and efficient cars for the urban environment. But this development was not an indirect effect of the California ZEV programme. Instead the development and introduction of the Smart had been proposed and initiated by Swatch, reflecting their vision of future mobility. In 1994 Daimler took over Volkswagen's engagement in Nicolas G. Hayek's micro compact vehicle project, aiming to provide a small city vehicle (Die Zeit, 1994). The Smart fortwo, a small two seat vehicle was brought to market in 1998, but as Hayek's vision of a small and energy efficient vehicle that could be used for car sharing had not been satisfied nor shared by Daimler, Hayek decided to leave the joint venture and Daimler became sole owner of Smart. Although Daimler launched a number of vehicles under the Smart brand, the only generated losses (Lewin, 2004;Steger et al., 2007;The New York Times, 1999). However, the Smart brand contributed to decreasing Daimler's average fleet emissions, down to around 180 g CO 2 /km in 2005 from 230 g CO 2 /km in 1995. At this point in time the disruptive change (the Smart vehicle meant for Daimler the introduction of completely new distribution and supply chains and the engagement with a new customer segment) from the view point of Daimler had been induced by an external actor. But the company was not entirely backing this vision and pressures on the landscape level were not strong enough. The impact of this project on Daimler's direction was negligible. The same can be said about the Smart EV trials that were induced by actors external to the company (Zytek Automotive, 2013). Being interested in gaining experience in the application of electric vehicle technologies, the British company Zytek that was recently acquired by Continental had approached Daimler (Zytek Automotive, 2014) and proposed and delivered the first generations of the Smart EVs, covering all expenses. This development fell into a time (2004/05) when there was already significant pressure on the existing regime from the landscape level. There were consumer concerns about fuel costs, the effects of carbon emissions as well as the discussion about legally binding fleet emission targets. Also the introduction of the second generation of the Toyota Prius Hybrid that was well received in the US market put pressure on the entire automotive industry, including Daimler. Daimler however, only responded with the market introduction of incremental technologies such as start-stop, efficient diesel engines and mild hybrids. It also introduced, together with Volkswagen and GM, its Bluetec Diesel branding (see timelines). Although Daimler had already experienced pressures on the landscape level, it was the externally induced Smart EV trials that provided a push towards the mass introduction of battery electric vehicle technologies, a novelty for the company. This fell also in a time when a new CEO (2005) had been appointed who launched significant restructuring programmes. As a result, while past developments had often ended in the presentation of concept vehicles only, these new developments (see Fig. 6) finally led to a continuous journey towards different types of electric vehicle technologies. While the first Smart electric vehicle components were still provided by Zytek Automotive (2013), the newest generations were using batteries, battery systems and motors from subsidiaries that Daimler created in the late 2000s. Together with Evonik, a specialist in chemicals, it formed a joint venture for batteries, called 'Li-tec' and one for battery management systems (Handelsblatt, 2008), called 'ACCUmotive' (Handelsblatt, 2009), and with Bosch it formed a JV on electric motors, called 'hubject GmbH' (Daimler, 2012). Before that, in 2009 Daimler bought stakes in TESLA, which supplied the batteries for the 2nd generation of electric Smart vehicles (Spiegel Online, 2009a). To ensure economies of scale for the JVs with Evonik, the batteries were also offered to other OEMs such as Renault/Nissan. Furthermore, in the early 2010s Daimler announced a collaboration with Toyota in the domain of fuel cells (Green Car Congress, 2010) and more collaborations with carbon and composite manufacturers. At the time Daimler's competitors were receiving significant media coverage in relation to their battery EVs, especially BMW with the i3 and i8 models and Tesla with the model S. Daimler had to respond accordingly, relying again on external help. In parallel to the launch of the BMW i3 it surprisingly launched an all-electric B-Class that slightly outperforms the i3 in range, price and sizethough it features an electric vehicle technology developed by Tesla (Green Car Congress, 2012). To summarise the Daimler case, while pressures on the landscape level were always driving some developments of battery, hybrid or fuel cell technology, in general there was no actual move to bring them to the mass market. If work on technologies or solutions that were novel for the company were started, then it mostly focused on incremental improvements based upon past work, such as that done on engine efficiency improvements. Disruptive change was brought about only by the appearance of external actors, as in the case of Smart and Smart EV. These actors led to the introduction of novel technologies and vehicle segments. But they could only succeed because there was already sufficient pressure on the landscape level backing these developments.",
            "BMW's journey from burning hydrogen in engines through project i to lightweight electric vehicles": " During the early 1990s BMW's ZEV regulation-driven experiences with alternative vehicle propulsion technologies were unsatisfactory, but in 1996 the company established serious hydrogen research activities. This happened at a time of hydrogen disappointment in the automotive sector (Der Spiegel, 1996). Daimler, BMW's main competitor, had presented its Necar hydrogen fuel cell prototypes and hence, instead of regulatory pressure it was the action of its main competitor which had led to the establishing of a fuel cell research group (Budde et al., 2012). Furthermore, though research work also focused on PEM fuel cells and later SOFC fuel cells, in 1998 BMW presented the 750hL, a large executive sedan that was not powered by fuel cells but instead burned the hydrogen in a conventional combustion engine. The vehicle only featured a 5 kW fuel cell that was used as auxiliary power unit for various electronic systems in the vehicle (VDI Nachrichten, 2010). Since then, BMW built a small series of more than 100 of these hydrogen combustion engine vehicles. These were used at various events (Spiegel Online, 2001), such as the World in 2000 in Germany and a number of demonstrator programmes where the vehicles proved themselves running for a total of over 4,000,000 km. A petrol fuelled car that a solid oxide fuel cell auxiliary power unit was also presented. The fuel for the fuel cell was obtained by reformation of the petrol. But these vehicles were not a move towards new technologies as they still relied on combustion engines -these solutions were still part of the existing regime. On the other hand, using fuel cells to deliver power to the electronics of the car was a way for BMW to gain knowledge in the application of this technology. However, the above-mentioned vehicles never reached the market. Although there were discussions about fleet emission targets at the EU level and BMW announced in 2002 that it would bring its hydrogen combustion vehicle to market (Auto Bild, 2002), this never went beyond the status of demonstrator. There was no attempt yet by BMW to bring novel vehicle electrification technologies to production. Moreover, since the beginning of the 2000s, BMW focused its efforts on the introduction of a variety of engine efficiency improvements and on the wider use of diesel in the fleet, both of which led to a slow but steady decrease in average fleet emissions -an incremental solution. Furthermore, hybrid and electric vehicle development at BMW did not intensify over this period of time. BMW did not attempt a disruptive change of their vehicle propulsion technology, nor was this even mentioned in the company's annual reports. This changed in 2005/06, coinciding with the success of Toyota's Prius and rising fuel prices, causing customers to demand similar solutions (Der Spiegel, 2005). Until then, only hydrogen combustion technology featured in the annual reports as future solution for low emission vehicles. In contrast to that, from 2005/06 onwards, hybrid vehicle technology started to feature in the annual reports as well. Around that time, collaboration with GM and Daimler-Chrysler was announced in order to develop a hybrid system to compete with the Japanese manufacturers. Additionally, in 2006/2007 BMW intensified its hydrogen combustion vehicle activities by leasing out 100 vehicles to the public and with incremental improvements such as the recuperation of energy to its lead acid battery (Spiegel Online, 2006b). Still, BMW did not provide any real hybrid vehicle solution. It continued to concentrate on the technologies it was familiar with -the internal combustion engine and its efficiency -and this, in spite of the increasing pressure on the landscape level created by discussions on mandatory CO 2 fleet emissions standards in the European Union to replace the existing voluntary agreements. However, after the selection of a new CEO in 2006, in 2007 (a very successful year for BMW, with no signs of the financial crisis yet to come) BMW initiated 'project i' under its so-called 'number ONE strategy'. This project was launched to review the future technology options. It was this project that triggered a significant change in the long-term technology strategy of BMW with disruptive consequences on its technology choices (BMW Group, 2009;Spiegel Online, 2013a). Shortly after the review had finished, BMW stopped the hydrogen combustion vehicle programme that it had been promoting for so many years and instead announced a series of changes (FOCUS, 2009), including the launch of a Mini EV trial fleet, collaboration with SB LiMotive on batteries and the creation of a Joint Venture with PSA (Peugeot/Citroen). The results from these trials led in 2010 to the announcement that BMW was planning to develop and produce a BEV for the mass market. BMW's announcement meant that the company was now embarking on a journey towards electric vehicles (Der Spiegel, 2010). In the early 2010s, after a number of competitors brought their PHEVs and BEVs to market, BMW presented its Megacity Vehicle (BMW i3), a lightweight BEV vehicle built in Leipzig that was commercialised at the end of 2013 (Der Spiegel, 2010). With an entirely new production plant built to produce the i3, has clearly committed to this technology. During 2011 the acquisition of SGL Carbon, the supplier of lightweight materials for the i3 and i8 was also announced (Spiegel Online, 2011, 2013a). In 2012/2013, a time when the number of HEVs/PHEVs in BMW's portfolio was limited, BMW also agreed to collaborate with Toyota on fuel cell systems, lithiumair batteries, lightweight technologies and the electrification of vehicles (Spiegel Online, 2012). To summarise the BMW case (see Fig. 7), while pressures on the landscape level were always driving some developments of vehicle electrification technologies; there was no actual move to bring them to the mass market until the introduction of a new CEO in 2006. Most of the work focused on the known internal combustion engine technology -only the fuel being replaced with hydrogen. It can therefore be stated that the concept and trial vehicles were still largely based upon 'past' knowledge. Despite the significant pressure at regime level brought by the success of the Prius hybrid vehicle and the serious discussions of mandatory fleet emission standards, it was not until the 'project i' was initiated and a review of BMW's long-term technology strategy conducted, triggered by the appointment of the new CEO, that BMW decided to focus on lightweight and battery vehicle technologies (BMW Group, 2009). The company has since embarked on a path towards a disruptive change of their technology and product portfolio.",
            "VW's steady path meeting emission limits": " Even though VW executed some trials on EVs, PHEVs and FC vehicles in the 1990s, its vehicle propulsion technology research was mainly focussed on highly efficient combustion engines and especially diesel engines, as well as the use of bio fuels. While BMW and Daimler had presented their solutions for low emission transport, VW presented its Lupo 3L with a fuel consumption of 3l/100 km in 1998 (Der Spiegel, 1998), followed in 2002 by the announcement of a 1 L vehicle (Spiegel Online, 2002), that was not introduced to market at that time. This work was strongly supported by the CEO who had a background in combustion technology and especially diesel engine engineering. However, development of the vehicles was soon scrapped due to low demand (similar to what had happened to the Audi A2) before 2005 (Spiegel Online, 2005b). In comparison to BMW and Daimler, VW made fewer public announcements with regards to alternative vehicle concepts. During 2005 the success of the Prius and rising fuel prices coincided with the creation of the collaborative brand Bluetec for Diesel combustion engine vehicles -together with Daimler and GM (Spiegel Online, 2006a). It can be seen that during these times VW was still sticking to its traditional, internal combustion engine based products. Similar to its German competitors, VW reacted to the success of the Prius in the late 2000s with the development of low emission engines. This led very early on to the development of downsized engines such as the 1.4 litre TSI turbocharged that won Engine Awards for 7 consecutive years since 2006 (Green Car Congress, 2013;Spiegel Online, 2005a). The micro vehicle up!, which is similar to the Smart fortwo but a four-seater, was introduced in 2009 (Spiegel Online, 2009b). Furthermore, the 1 L vehicle project was re-launched again in 2007 (Green Car Congress, 2007), leading to a number of prototypes, with the last one in 2013 called XL1 Super Efficient (Spiegel Online, 2013b). In addition to that VW pursued the development of biofuels and launched its own production facilities in the early 2010s. Until recently, no significant changes in technology could be observed, despite the mandatory emission regulations introduced in the EU. This is explained by the fact that, unlike the rest of the German manufacturers, these policies were less of a threat to VW as it had historically served the market with smaller vehicles. As a result VW has always been on track towards meeting average fleet emissions targets (120 g CO 2 /km by 2015 and 95 g CO 2 /km by 2020). As a result, regulation did not create sufficiently strong pressure to introduce disruptive vehicle electrification technologies such as EVs at VW. However, VW has recently started to develop EV concepts such as the EV 'VW which was introduced in 2014, probably responding to the electric vehicle activities of its competitors. It is worth noting that within the VW family it is Porsche that first started work on electric propulsion in 2007 (Spiegel Online, 2007), developing hybrid vehicles in response to the request for 'green' SUVs from its customers, collaborating with Sanyo in Li-ion batteries and Continental for the delivery of the necessary components (Green Car Congress, 2009). To summarise (see Fig. 8), VW's technology choice of highly efficient diesel technology had been able to satisfy landscape pressures such as emission regulations and high fuel costs. Therefore in contrast with the other manufacturers it is difficult to identify a significant move towards electric vehicle technology yet. However, there are recent signs that VW has finally taken this step, although the exact reasons are hard to infer yet.",
            "Conclusion": " This study has examined on a micro-level what has influenced the low emission vehicle technology related activities of the three main German car manufacturers. Based upon the analytical framework chosen (see Fig. 1), major changes in the activities of these firms that went far beyond business-asusual were identified and then put in relation to what had been happening at the regime and landscape level at that time. The goal was to identify triggers for these activities. To summarise, the analysis has led to the following insights. For all three manufacturers, activities related to niche technologies that were new to them only occurred when actively introduced by external actors such as collaborators or induced by internally disruptive events such as new CEOs. This is in line with the finding by studies (Benn et al., 2006;Howell and Higgins, 1990;Howell et al., 2005) that 'innovation champions' or 'change agents' play an important role with regard to disruptive changes. in order for change agents to initiate niche related activities, the presence of sufficient pressure at the regime and landscape level is a necessary condition. One example of such pressure is already the discussion of mandatory fleet CO 2 emission targets to replace the automotive industry's voluntary agreements. As already found by earlier studies (Budde et al., 2012;Konrad et al., 2012;Wesseling et al., 2013), in the absence of significant external pressures the German car manufacturers did not seek niche technologies. Such pressure, where present, can also be created by consumers' demands and the success of competitors. Moreover we find that the influence of regulatory policy on the selection of particular disruptive technologies by the automotive industry is limited. Policy programmes that were supporting one specific niche technology did not make all three car manufacturers work on this one technology but instead they continued to work on the technologies that were familiar to them. The industry by itself determines the path or technology they choose and this can differ across companies even though they are part of the same socio-technical system. All three German players studied were affected by the same trends and policies -still, they came up with different technology solutions. And on the world scale, Toyota had chosen hybrids; Nissan, Tesla and BMW went for battery electric vehicles; and now, Toyota is back towards fuel cells -a solution which Daimler is moving away from, in favour of battery electric vehicles. Clearly there is no obvious winner yet. Finally, it appears that, in the absence of external or internal change agents, car manufacturers typically respond to regime and landscape pressures such as fleet emission regulations with incremental technologies created through the combination of internally available solutions. Although the observations we have made in our study are general in nature and the sample on which they are based is relatively limited, the results still provide valuable insight into the effect that government policy has on the automotive industry -what limitations exist. Our observations make it clear that in the case where a transition that requires a significant alignment of the regime is favoured by policy makers, the creation of policy incentives or pressures on the landscape level might not be enough to induce such an alignment due to the existing circumstances of the individual actors and organisations. The internal conditions at these companies might not be supporting such a change, either due to lack of internally available knowledge or the lack of support within the organisation. This does not mean that policy making is obsolete. It might not influence what particular technologies (combustion engine efficiency, lightweight materials, BEV, PHEV or FCEV) a will choose in the end, but it can create landscape conditions -or pressures -that support the work of internal change agents whose disruptive propositions are more likely to be accepted. Hence under the right conditions niche related activities become less of a disturbance to the company's status quo and more of a welcomed solution. To conclude, we propose that policy makers should ensure that the industry (that often has already chosen and often is already developing a certain technology) is supported in its efforts to gain a competitive advantage with their chosen solution. Therefore, financial support should not have the purpose to push the industry towards a certain technology over others, but instead, for example for being technology neutral, it should support the R&D of the disruptive technologies that the industry itself selects. At the same time it is essential that policy makers should maintain the non-financial policies such as regulations and standards that create the landscape conditions that destabilise the regime if it does not support the ultimate policy goals in terms of fuel efficiency and emission reduction. With regards to the presented framework, it has to be mentioned that different interpretations are possible due to the nature of the MLP and especially the soft boundaries between its different levels. Still, although the MLP is perceived to have a number of limitations (Geels, 2011), it provides a useful framework for a structured discussion of the way, in which micro-level activities contribute to transitions."
        }
    },
    "10.1016/j.enpol.2009.11.001": {
        "file_name": "11 Are tradable green certificates a cost-efficient policy driving technical change or a rent-generating machine",
        "title": "Are tradable green certificates a cost-efficient policy driving technical change or a rent-generating machine? Lessons from Sweden 2003-2008",
        "abstract": "In the European policy debate, tradable green certificates (TGC) have been suggested to be a superior regulatory framework for promoting the diffusion of renewable electricity technologies. The purpose of this paper is to assess the performance of the Swedish TGC system, contributing to the European debate on the suitability of different types of frameworks. The expectations of the TGC system were that it would: (a) be effective in terms of increasing the supply of \u201cgreen\u201d electricity; (b) do this in a cost effective manner (from both a social and a consumer perspective); (c) generate an equitable distribution of costs and benefits and (d) drive technical change. So far, it has performed adequately in terms of effectiveness and social cost effectiveness. However, consumer costs have been substantially higher than expected, very large rents are generated and, at best, it contributes marginally to technical change. Thus, a TGC framework should be selected if the overriding concern is to minimize short term social costs of reaching a certain goal with a high degree of predictability. However, it cannot be expected to also drive technical change, keep consumer costs down and be equitable. Such trade-offs need to be revealed and not obscured by analysts.",
        "label": "Qualitative",
        "text": {
            "Introduction": " For more than a decade, the European Union has recognised the need to tackle the challenges of climate change. Initially, EU outlined a 15% reduction target for greenhouse gas emissions by the year 2010, as from the 1990 level (European Commission, 1997). Since energy generation is a prominent source of CO 2 emissions, an increased use of renewable energy, in particular electricity produced from renewable energy sources, was considered as an important condition for reaching this target (European Commission, 1997;European Parliament and Council, 2001). For this reason, but also to ensure security of supply as well as social and economic cohesion, a 21% target for renewable electricity penetration by 2010 was adopted by the European Parliament and Council (2001). Whereas EU member states seem to be making good progress in meeting this target, much stronger efforts will be needed to reach the reduction targets for greenhouse gas emission set in 2007, which calls for a 30% reduction by 2020 and a 60-80% reduction by 2050 compared to 1990 (European Parliament, 2007Parliament, , 2008)). This accentuates the question of which government policy instruments are likely to be effective in stimulating the required investments in renewable electricity generation equipment, such as wind turbines, photovoltaic cells and biomass combined heat and power plants. For a couple of decades, various regulatory frameworks have been experimented with to stimulate investments in such renewable energy technologies. Two main types of policy instruments have been deployed: feed-in tariffs and tradable green certificates-based quotas (TGCs). In countries with feed-in tariffs, owners of distribution networks are required to accept renewable electricity fed into the network and pay a fixed, regulated price (or price premium) for that electricity. This type of system was adopted by Denmark in the 1980s and by Germany and Spain in the 1990s, and is now the dominant system in the EU15 (cf. e.g. Rowlands, 2005;Rickerson et al., 2007;Fouquet and Johansson, 2008). The price premium is covered through crosssubsidies among electricity consumers, by the taxpayers via the government budget or through a combination of these systems (Menanteau et al., 2003). Based on the experiences of these and other countries, several assessments of the efficiency and effectiveness of feed-in tariffs have been published (e.g. Morthorst, 2000;Menanteau et al., 2003;Meyer, 2003;\u00dcrge-Vorsatz et al., 2004;Madlener and Stagl, 2005;Ragwitz and Huber, 2005;Rowlands, 2005;Contaldi et al., 2007;Ringel, 2006;Finon and Perez, 2007;del R\u0131 \u00b4o and Gual, 2007;Diekman, 2008;Verhaegen et al., 2009). The main advantage of this system, as described in these assessments, is its effectiveness in promoting technology development and diffusion (especially with regards to wind power in e.g. Germany and Spain). 1In tradable green certificate-based quota systems (TGCs), renewable electricity is sold in the usual electricity market at market prices, but these sales are complemented by certificate trading in a separate market for green certificates. The certificates are demanded by obligated buyers (e.g. electricity suppliers or consumers) who must buy certificates corresponding to a certain quota of their total electricity sales or consumption. Here, countries such as Belgium (Flanders), Sweden and the UK have been early adopters. According to the existing academic literature (most of which is based on either theoretical analyses or simulation approaches), the expected main advantages of TGCs are that they (1) are cost-efficient, (2) ensure a stable development towards set deployment goals and (3) drive innovation and cost-reduction through ''double'' competition in both electricity and certificate markets (cf. Morthorst, 2000;Menanteau et al., 2003;\u00dcrge-Vorsatz et al., 2004;Madlener and Stagl, 2005;Contaldi et al., 2007;Ringel, 2006;del R\u0131 \u00b4o and Gual, 2007;Verhaegen et al., 2009). However, it is still very much unclear whether certificate systems can meet these expectations; in previous assessments it has been concluded that the experiences of these systems are too limited to allow for a thorough analysis of their performance (cf. Menanteau et al., 2003).2 However, after six years of operation, there is now enough data to make an assessment of the performance of the Swedish ''electricity certificate system'' so far. The purpose of this paper is, therefore, to assess the performance of the Swedish TGC system and, thereby, contribute to the Europeanlevel debate on the suitability of different types of systems for the support of renewable electricity. 3The paper is structured as follows. In Section 2, we summarise the expectations on TGC systems. We begin by outlining the expectations formed by the European Commission and the European Parliament in the second half of the 1990s, simply since these were very influential for the later Swedish choice of regulatory framework ( \u00c5strand, 2005). We proceed by specifying the expectations of the Swedish government, as expressed in a number of government bills and in a central government committee of inquiry. On the basis of these expectations, we identify four criteria for assessing the performance of the Swedish TGC system. In Section 3, the design of the Swedish TGC system is described and the performance of the system is analysed in relation to the identified criteria. In Section 4, we end the paper with a concluding discussion of the lessons learnt. 2. TGCs in the European and Swedish policy debate: Expectations and assessment criteria",
            "Policy expectations on TGCs at the EU level": " Against the background of a belief in a growing importance of renewable electricity in the European power balance, a report from the European Commission (1998) pointed to advantages of a harmonisation in terms of support schemes for renewables in Europe. As a consequence, it identified a need to determine the relative merits and disadvantages of the different approaches in the Member States. The results of a largely theoretical assessment of various support schemes were reported in 1999 in a Commission working paper (cf. European Commission, 1999), in which the Commission made it very clear that it advocated a quota, or ''competition-based'', system. A number of expected advantages of such systems were identified. They would (i) be compatible with the EU treaty rules, (ii) provide a ''considerable'' level of security (depending on design) and (iii) ensure static efficiency, i.e., ''y that electricity is generated and sold at minimum cost'' (European Commission, 1999, p. 15, our italics). The expectations referred, thus, to cost efficiency not only in terms of social costs4 but also in terms of consumer costs, which is not surprising considering that low electricity prices for consumers is one of the main goals of EU environmental-energy policy (Sa \u00b4enz de Miera et al., 2008). This goal is also reflected in the Renewables Directive, where one of the main arguments in favour of a future pan-European support scheme is to keep consumer costs down: Such a framework would ''enable electricity from renewable energy sources to compete with electricity produced from non-renewable energy sources and limit the cost to the consumer, while, in the medium-term, reduce the need for public support'' (European Parliament and Council, 2001, p. 34, our emphasis). In part, the focus on consumer costs stem from a worry that too high prices for consumers would erode public support for increasing generation of renewable electricity: ''Once a significant level of renewables generated electricity develops, and the consequent price uplift to overall electricity tariffs becomes appreciable, the need to demonstrate 'value for money' /y/ becomes increasingly vital if continued public support for large levels of Res-electricity is to be maintained'' (European Commission, 1999, p. 16). Finally, in contrast to a feed-in solution, a quota based scheme was expected to (iv) stimulate innovation: ''As the system [feed-in tariff schemes] is not one based on direct competition ... the incentive for innovation must, by definition, be less pronounced than under a scheme that is based on competition'' (European Commission, 1999, p. 16). ''[Q]uota/competition-based schemes have been the most effective in the EU in driving down prices for renewable generated electricity and, according to economic theory, as a result of the competition, stimulating innovation'' (European Commission, 1999, p. 18). In spite of these powerful expectations, the Commission was not ready to suggest a harmonised quota-based system, probably due at least in part to the opposition from member states having adopted feed-in tariffs (Lauber, 2007). In the proposal for a directive on the promotion of electricity from renewable energy sources, it was argued that although a harmonised European-level support scheme would be beneficial, the experiences of different support schemes were too limited to conclude which model should form the basis of an internal market for renewable electricity, ''in particular with regard to the innovative 'green certificate' system y'' (European Commission, 2000, p. 6).",
            "Policy expectations of TGC in Sweden 5": " The policy expectations in Sweden overlap to a very large degree with those of the EU. In particular, European Commission (1999) appears to have had a major influence on Swedish policy documents. The core arguments in favour of TGC were drawn from that paper and reproduced in both SOU, 2001:77 (a key Government committee of inquiry) and in a prior Government bill introducing the certificate system (Swedish Government, 2000). A first expectation of the Swedish TGC system was to substantially increase the share of electricity generated from renewable energy sources: ''The certificates are, thus, a means which primarily relate to the goal of increasing the share of electricity from renewable energy sources. The objective of this goal is, in the long run, to obtain a sustainable energy system built on renewable energy sources. In Sweden, such a development is necessary in order to manage the transition of the energy system in connection with the phasing out of nuclear power'' (SOU, 2001:77, p. 108-109). An initial goal of adding 10 TWh 'green' power to the power balance by 2010 was a response to the European Parliament and Council (2001) directive on the promotion of electricity produced from renewable energy sources. This goal was subsequently raised to 17 TWh by 2016 and a new target of 25 TWh by 2020 was recently suggested by the Swedish Government (2009). A second expectation was that the expansion in the supply of 'green' power was to be done in a cost-efficient manner. As in the Commission working paper referred to above, the concept of 'cost' included both social cost and consumer cost. With respect to social cost, we can refer to an influential government committee of inquiry and a later Government bill: ''An efficient promotion of electricity from renewable energy sources implies ... that the total cost ... shall be as low as possible. An efficient solution that is adjusted to the conditions of the market is to let the quota rise gradually. Investments with low marginal cost will be included first and only thereafter will investments with a higher marginal cost be included'' (SOU, 2001:77, p. 125). ''A basic idea in the system is that the price of the certificates shall mirror marginal costs for a new investment ... for the production of renewable power. This means that investments which are most cost efficient and most simple shall be implemented first'' (Swedish Government, 2006a, p. 29). The emphasis on cost efficiency reflected, however, also a strong perceived need of keeping the costs for the electricity consumers down (Thornstr \u00f6m, 2005). Thus, as a Government bill put it: The costs of the support system must be kept down in order for it to achieve acceptance among the public, to maintain the competitive strength of industry and an improved competitiveness of the renewable energy sources'' (Swedish Government, 2002a, p. 88). The concern for electricity consumers is also demonstrated by the implementation of a limited quota obligation fee (a penalty fee for obligated buyers who fail to meet their obligation) that prevented the certificate price from shooting up (cf. SOU, 2001:77, p. 173;Swedish Government, 2002b, p. 117). This focus on consumer costs, in addition to social cost, mirrors that in the European Commission (1999) and European Parliament and Council (2001) and is related to the issue of equity, i.e., the fairness in the distribution of costs and benefits between different actor groups. A main concern was, therefore, to avoid overcompensation of the power industry (Swedish Government, 2000, p. 14). It was, hence, clearly specified that the TGC scheme should only support renewable power production that was not commercially competitive (Swedish Government, 2000Government, , p. 20-21, 2002b, p. 40), p. 40). A third expectation of the Swedish TGC scheme was that it would increase the competitiveness of electricity from renewable energy sources through technical change (Swedish Government, 2002a). The expectations were that a TGC scheme would be an elegant solution to obtaining the twin benefits of cost efficiency and technological development: ''The transition to market based solutions to promote power from renewable energy sources means that conditions are created for an effective competition between different forms of power from renewable energy sources. An effective competition leads to cost efficiency and to the development of new technical solutions'' (SOU, 2001:77, p. 104, our italics).",
            "Criteria for assessing the performance of the Swedish TGC system": " Comparing the expectations of a TGC system, in Sweden and on the EU-level, 6 there is a substantial agreement in terms of what the most important criteria to consider are: (1) effectiveness (ability to increase renewable electricity generation/meet targets), (2) costs efficiency, in terms of both social cost and consumer cost, (3) equity (avoiding overcompensation) 7 and (4) the ability to stimulate technical change and drive costs down in the longer term. We will now define these criteria more precisely. Effectiveness is measured as the amount of new renewable electricity production generated in the TGC system relative to the expectations, using official data from the Swedish Energy Agency and Svenska Kraftn \u00e4t. 8 We also use qualitative sources to discuss the extent to which this new production can be seen as an outcome of the TGC system rather than of other incentives. The results of this analysis are given in Section 3.2. Cost-efficiency is assessed by the achievement of a prior determined target at a minimum cost and we label this the cost-effectiveness of the system (cf. del R\u0131 \u00b4o and Gual, 2007). 9 The cost-effectiveness in terms of social cost is discussed in Section 3.2 (although this is played down in relation to the following criteria). In line with the concern for consumer costs revealed in Swedish and EU policy documents, we also include measurements related to the total cost for the consumers, including transaction costs (cf. del R\u0131 \u00b4o and Gual, 2007). In Section 3.2, we use official data supplied by the Swedish Energy Agency as the basis of an analysis of the total gross cost for the consumers in relation 5 All quotes in this section are our translations. 6 These expectations overlap partly with those in the academic literature (see Section 1). The exception lies in policy makers' expectations that both social costs and consumer costs may be minimised with a TGC system. 7 The issue of equity is not explicitly dealt with in the EU document referred to above but follows from the focus on keeping consumer costs down. 8 Svenska Kraftn \u00e4t is a state utility, which administers and runs the national electrical grid. It is also in charge of the electricity certificate register. 9 An alternative approach is to compare the environmental benefits and other socioeconomic benefits with the (societal) costs of the scheme (static efficiency) (del R\u0131 \u00b4o and Gual, 2007). This is, however, outside the scope of this paper. to the expectations, including the transaction costs paid by electricity suppliers. Equity, i.e., how the costs and benefits of promotion are shared between actors, is assessed in terms of who receives support and for what type of investments. In Section 3.3, we analyse the rents/ producer surplus generated in the system, i.e., various types of ''abnormal'' profits that benefit electricity producers at the expense of electricity consumers (cf. Verbruggen, 2004Verbruggen, , 2008;;Finon and Perez, 2007). We define and discuss the concept of 'rents' and our estimation method in further detail in Section 3.3. The system's ability to foster technological development is assessed in Section 3.4 on the basis of an analysis where insights from modern innovation research are applied to the field of renewable electricity. 3. The Swedish TGC system: characteristics and outcomes",
            "Essentials of the Swedish TGC system": " The Swedish TGC system came into force on 1 May 2003. After a first assessment by the Swedish Energy Agency in November 2004 (Swedish Energy Agency, 2005a, b), the scheme was revised in 2006 with regard to both goals and design. In the following, we will describe the system (originally and after the 2006 revision) to provide a background for the subsequent performance assessment. The system has two main components: (1) a right for producers of renewable electricity to receive certificates and (2) a quota obligation for electricity consumers/suppliers (excluding the energy-intensive industry), creating a demand for the certificates.",
            "Certificates for producers of renewable electricity": " Producers of electricity from selected renewable sources receive one ''electricity certificate'' for each MWh of renewable electricity they produce. The system includes existing and new wind power plants, biomass-based power/combined-heat and power plants, geothermal power plants, solar power plants, hydropower plants ( o1.5 MW) and wave power plants. 10 A particularity of the Swedish system is that existing power plants were included in the system from the start. Since the 2006 revision, however, the support period for these plants is limited to 2012 or 2014 (depending on whether the plant in question has received any previous government support or not). New power plants (built 2003-2016) are guaranteed certificates for 15 consecutive years. The certificates can be traded in a special ''certificate market''. This generates an income stream in addition to that stemming from sales of the electricity (on the conventional electricity market). Holders of certificates can also choose to ''bank'' the certificates and sell them later on. Since all eligible electricity production receive the same amount of certificates per MWh, all types of electricity sources receive the same amount of support. This implies that a common, ''technology-neutral'' market is created, in which the eligible renewable electricity sources compete with each other directly and investments occur in stages depending on the cost level of different sources. The basic idea is that the certificate price at a certain point in time will correspond to the additional cost (in comparison to conventional power production) of the marginal renewable power plant in the system.",
            "Quota obligation and quota levels": " Each year by April 1st, all obligated buyers have to hold, and hand over to the state, certificates corresponding to a certain share (quota) of their total electricity consumption/sales the previous year. Originally, this obligation referred to the electricity consumers, but in the 2006 revision it was moved to the electricity suppliers (with some exceptions). Electricity consumed in the manufacturing process in electricity-intensive industries or produced in small (o50 kW) plants is wholly or partly exempted.11 In total, approximately two thirds (100 TWh) of the total electricity use in Sweden is included in the certificate system. The quota is decided by the Swedish Parliament. Originally, it was set to increase from 7.4% of consumed/invoiced electricity in 2003 to 16.9% in 2010 (see Table 1). This was estimated to correspond to 10 TWh increase in renewable electricity production in comparison to the 2002 level. In 2006, the quota was adjusted to correspond to a new target of 17 TWh by 2016. 12The development of the quota takes into consideration the phaseout of plants that are no longer eligible for support (as described above). Obligated buyers that do not meet their obligation are required to pay a penalty to the state. This ''quota obligation fee'' currently ",
            "System outcomes I: effectiveness and costs": " In this section, we begin our assessment of the Swedish TGC system. Section 3.2.1 contains a description of the effectiveness of the system in terms of added supply of renewable electricity in comparison to the expectations and discusses to what extent the social cost of achieving the set target has been reasonable. Section 3.2.2 briefly describes the system's performance in terms of consumer costs, including transaction costs.",
            "New renewable electricity production 2003-2008 and social costs of the system": " Table 2 shows the production of renewable electricity in the Swedish TGC system in the period 2003-2008, with the existing production in year 2002 included as a reference. In 2008, the total production was 15 TWh. As the TGC system provides a uniform premium, this secures that the currently most cost-efficient technologies are invested in. Thus, the vast majority of the production (10.4 TWh) consisted of biomass-based (incl. peat) electricity production in industrial back-pressure plants and combined heat and power (CHP) plants. Small-scale hydro power and wind power contributed 2.6 and 2.0 TWh, respectively. In comparison with the 2002 level (6.5 TWh), this implies an increase in renewable electricity production of roughly 8.5 TWh, i.e., 82% of the forecast of 10.3 TWh (see Table 1). Thus, the Swedish TGC system has not quite met the expectations, but seems to have been reasonably effective. Of the renewable electricity produced in 2008, only 2.5 TWh were produced in plants taken in operation after 1 May 2003 (Swedish Energy Agency, 2009). This implies that most of the production increase has, so far, been achieved in plants that were already in operation in May 2003, in main part through low-cost measures such as increase in power outputs in biomass-based CHP plants or conversion from fossil fuels to biomass in existing CHP plants. 13 As mentioned previously, these plants may receive certificates until year 2012 or 2014 depending on whether they have received government investment subsidies or not. The system, thus, seems to have performed well so far in terms of social costeffectiveness, in particular as most increase in output has been achieved at a very low social cost in already existing plants. The low share of output from new plants is, of course, not surprising since it takes a number of years for the power industry to react to new incentives, to get permits for new power plants and for the capital goods industry to deliver these. Thus, to get a more complete picture of the outcomes of the TGC system, we also need to look at planned investments. Here, it is clear that the TGC system has stimulated a great interest in the paper and pulp industry and among utilities to make further investments in biomass CHP plants. This has been particularly evident after the extension of the system to 2030 (Hirsmark and Larsson, 2005;Jacobsson, 2008). The interest in investments in wind power has also increased, although there are still substantial obstacles for wind power deployment in terms of e.g. a slow permit process (Michanek and S \u00f6derholm, 2006) and the limited capacity of the global wind turbine industry to supply wind turbines (Swedish Energy Agency, 2007a). This increased interest to invest in renewable electricity production is, however, also due to other factors. Investment decisions are made in a very complex reality, and may be influenced by a large number of different factors. These include increase in electricity prices in recent years (partly driven by the Emission Trading System in the EU), various investment support measures, demand for 'green' electricity and industry's willingness to invest in power production in order to secure access to electricity at reasonably stable prices. This implies that some investments would surely have been made even if the TGC system had not been introduced. However, Hirsmark and Larsson (2005) report that 63% of the CHP producers claim that the TGC system has had a decisive influence on their investment decisions and that 23% agree that the system has had some influence. Similarly, Michanek and S \u00f6derholm (2006) show that the TGC system has been of crucial importance to investments in new wind power plants. To conclude, there has been a quite rapid increase in renewable electricity production in Sweden since the introduction of the TGC system, from 6.5 TWh in 2002 to 15 TWh in 2008. Whilst only about 2.5 TWh of the increase was produced in new power plants, the TGC system has spurred the interest of potential investors in renewable electricity production and we may, thus, come to experience a continued increase in the future. 14 Taken jointly, it would be reasonable to say that the Swedish TGC has, so far, been effective in that it has almost met expectations with regard to increase in renewable electricity production. It has also, so far, met the expectations of cost-effectiveness in social terms, in particular as most of the increase in output has been achieved at low cost in already existing plants.",
            "Consumer costs, including transaction costs 2003-2008": " In the first six (almost) years, the Swedish TGC system has resulted in (gross) consumer costs15 of 19.5 billion SEK (approx. The consumer cost can be divided into the following main components: value-added tax (VAT) paid to the state; quota obligation fees (penalty fee for obligated buyers who fail to meet their obligation) paid to the state; administrative and transaction costs; support to producers of renewable electricity (payment received for certificates). The distribution between the different components is shown in Fig. 1. A first item is VAT and quota obligation fees paid to the state, which amounted to 4.1 billion SEK (21% of the total consumer costs [2003][2004][2005][2006][2007][2008]. Approximately 1.9 billion SEK (10%) are estimated to have been transferred to electricity suppliers in order to cover their transaction costs and administrative cost. Although these costs have decreased over time, they were still substantial in 2008: 185 million SEK. It should also be noted that the official data only include transaction costs of electricity suppliers. To these should be added the transaction costs of electricity producers and consumers, which are probably higher than those of the electricity suppliers (cf. Van der Linden et al., 2005;K \u00e5berger et al., 2004). Hence, a worry of the EU Commission (1999) of possible high transaction costs of quota based systems has proved to be of substance. Yet, the largest cost item is, of course, payments to the producers for traded certificates that have been cancelled, which amounted to 13.5 billion SEK (69%). We will now turn to analyse the extent to which these are constituted by various types of rents rather than ''well-earned'' compensation for higher production costs of renewable electricity in comparison to conventional electricity.",
            "System outcomes II: equity and rent generation": " The principal idea of a TGC system is that the payment producers of renewable electricity receive from selling the certificates they are awarded should cover the extra costs involved in producing renewable electricity in comparison with conventional electricity. The certificate price should, thus, correspond to the difference between the marginal cost of renewables -i.e., the cost of the marginal renewable power plant in the system -at the determined quantity Q (mcn) and the market price for electricity (PE) (see Fig. 2). However, for some plants payments are expected to exceed the extra cost. The producer surplus generated by such plants constitutes a ''rent''. 18 In previous literature, these rents are often referred to as ''windfall profits'' (e.g. Verbruggen, 2004;Finon and Perez, 2007), since they do not correspond to any extra achievement by the profiting parties and are largely uncontrolled by them. We may distinguish between two types of rents. The first type is generated in plants which were already profitable without the extra payments provided via the certificate market (i.e., the renewable electricity up to quantity A in Fig. 2). For these producers, the system creates an extra profit which does not correspond to any extra achievement on their part (the difference between mc n and PE in Fig. 2). The second type occurs due to the fact that the overall marginal cost curve for renewables consists of several different curves, one for each technology (see Fig. 3). At each point in time, the certificate price will correspond to the most expensive technology included in the system (the ''marginal'' technology), (footnote continued) production may be out-competed and the producer surplus decreases. According to a recently published study, this effect has been clearly evident in Germany (BMU, 2007). Similarly, Sa \u00b4enz de Miera et al. (2008) have recently shown that the increase in the costs of renewable electricity support may be offset by the short/ medium-term reduction in the wholesale electricity price, leading to a reduction of retail electricity prices. However, it has not been possible for us in this paper to take this type of interaction effects into consideration. 16 All conversions between Swedish Krona (SEK) and Euro are based on official exchange rate statistics from the European Central Bank (www.ecb.int). 17 According to Swedish official statistics, the higher than expected certificate price has not been compensated for by lower electricity prices. 18 Verbruggen (2009) makes a distinction between ''real rents'' and ''excess (swindle) profits''. The former are differential (Ricardian) rents produced within a technology group that are the result of natural endowments and/or higher proficiency of some producers leading to cost differences between plants of the same type. The latter are created by differences in costs between technologies included in the same support scheme. Verbruggen (2008) argues that the rents created in TGC systems are better described as ''swindle profits''. and all technologies with lower costs will, thus, receive an extra profit. As more and more expensive technologies are required to fill the quota obligation, an increasing share of the funds transferred from consumers to producers will be rents to submarginal producers (cf. Verbruggen, 2004). Fig. 3 illustrates how the marginal cost mc n , corresponding to the cost of technology C at target quantity Q, produces rents for technology A (light grey area), technology B (medium grey area) and some plants within technology C (dark grey area). In the following, we will estimate the size of these two types of rents in the Swedish TGC system.",
            "Type I rents: Payments to already profitable electricity production plants": " Due to some particularities of the Swedish TGC system, Type I rents currently constitute a major part of the total rents generated. First, as mentioned previously a number of already existing production plants were included in the system from the start, with the right to receive certificates for 10-12 years (to 2012 or 2014). One reason for their inclusion was to ensure enough liquidity in the certificate market (cf. SOU, 2001:77). Another reason was to prevent existing biomass plants to switch back to fossil fuels (SOU, 2001:77). 19 Some of the existing plants that were included in the system had previously received investment subsidies and/or production support, whereas others (especially some industrial plants) had been built without any government support. Most of this production was already competitive or at least needed far less support than entirely new production plants. Second, there was a relatively large potential for ''easily accessible'' production increases in existing CHP plants, for example through fuel conversion and increase in the number of full-load hours. Although some of these increases required investments, these were much lower than the investments in new wind turbines or new CHP plants that would come to determine the certificate price level. In order to capture these two sources of Type I rents, we make two estimations. In the first, we only include the rents to existing renewable electricity production in 2002 (6.5 TWh according to the Swedish Energy Agency (2007b)). For this production, we  assume an extra cost of 0 SEK/kWh, since most of the plants were already profitable. In our second estimation, we also include the ''easily accessible'' production increases in existing plants. Here, we use data on the actual electricity production in these plants in 2006 (10.8 TWh according to the Swedish Energy Agency (2007b)). We use this number since it corresponds well to the sum of total production in 2002 and the short-term bio power potential identified by the Government committee of inquiry responsible for suggesting a design for a future certificate system (SOU, 2001:77). 21 We assume that these plants will be phased out according to the prognosis presented Swedish Government (2006a). The extra cost (in relation to the electricity price) of increasing the production of renewable electricity in existing CHP plants ranged from 0 SEK/kWH (increases in the number of fullload hours) to 80 SEK/MWh (for conversion from fossil fuels to biomass) (SOU, 2001:77). Since we lack data on the exact distribution between different types of investments, we use an average cost of 40 SEK/MWh. We use actual yearly certificate prices for the period 2003-2008(cf. Swedish Energy Agency, 2009). The first two estimates are, therefore, quite likely on the low side, whereas the third seems more realistic. The results of the analysis are presented in Table 3. According to our calculations (see Appendix B), the Swedish TGC system has already (2003)(2004)(2005)(2006)(2007)(2008) produced Type I rents in the order of 8-11 billion SEK (830-1160 Mh), where the higher figure is more reasonable considering the easily accessible production increases discussed previously. These rents constitute up to as much as 79% of the total payments to electricity producers (approx. 14 billion SEK). For the period of 2009-2014, our calculations indicate that Type I rents may amount to 5-7 billion SEK (if we only include the existing production) or 8-13 billion SEK (if we also include the ''easily accessible'' production) (see Appendix B). In total, the Type I rents may amount to 12-23 billion SEK (1.3-2.4 billion h) in the period of 2003-2014. Again, considering that the average price was SEK 289 in the last year and the quite low estimate of the ''easily accessible'' production, the highest figure (assuming a certificate price of 300 SEK/certificate and 10.8 TWh of existing and ''easily accessible'' production) is not at all unrealistic. In such a case, Type I rents would amount to about 59% of the total payments to producers in the period of 2003-2014 (see Appendix C).",
            "Type II rents: Overcompensation to sub-marginal producers as more expensive renewable electricity technologies are introduced in the system": " As technologies with higher costs have to be introduced to meet the quota obligation, the certificate price will increase above the cost of the previously marginal renewable power plant in the system. The size of the rents generated is obviously dependent on the size of the quota, the potential of the ''cheaper'' production technologies and the cost difference between different technologies in the specific country. In the Swedish case, the cheapest new renewable electricity production is bio power and land-based wind power. As the combined potential of these technologies in Sweden is estimated to be about 22 TWh in 2015 (Swedish Energy Agency, 2005b), the current quota obligation of an additional 17 TWh by 2016 of new renewable electricity to the 2002 level of 6.5 TWh, can most likely be met by these technologies alone (together with an already achieved growth in small scale hydro). Since these are quite close in terms of production costs, Type II rents will probably not become a main issue within this time frame. However, if there is a need to introduce off-shore wind power (or other more expensive production technologies) in the Swedish TGC system to meet the quota obligation, substantial Type II rents may be generated for producers of bio power and land-based wind power. This may be the case if the quota obligation is increased or if land-based wind power diffusion is blocked by remaining difficulties in obtaining building permits. Both these events are highly probable. Indeed, the Swedish government recently announced its intentions to raise the quota to 25 TWh by 2020 in order to increase the share of renewable power substantially: To reduce vulnerability and increase the security of supply, a third leg needs to be developed for electricity supply, thereby reducing the dependence on nuclear and hydro power. To achieve this, combined heat and power, wind power and other renewable power production must account for a substantial share of the power production. (Swedish Government, 2009, p. 3, our translation). Although it is not clear what ''substantial'' is, it would not be unreasonable to interpret this as ''one third'' considering that renewable sources are described as ''a third leg'' of the future certificates corresponding to the two estimates. For reasons of simplicity, we assume that the number of annulled certificates each year includes all certificates for existing production, except when the number of annulled certificates corresponds to a lower production than the existing production. Saved certificates in this period are included in the period 2009-2014.  21 This committee of inquiry estimated the short-term potential to 3.7-4.7 TWh in total, including a 2 TWh increase in biomass CHP in district heating plants and a 1.7-2.7 TWh increase in industrial back-pressure processes. This implies that the ''easily accessible'' production in 2002 was 10.2-11.2 TWh (including 6.5 TWh of existing production in 2002), i.e., a mean value of 10.7 TWh. An alternative way to calculate the ''easily accessible'' production would be to take the actual production in 2008 (15.0 TWh) and reduce that figure with production in that year in plants that have been built after 2002 (2.5 TWh). This would amount to 12.5 TWh. Yet, we choose to be cautious and use, therefore, the lower figure of 10.8 TWh. Swedish electricity supply. This would require a contribution of renewable electricity sources within the TGC system of about 50 TWh. Thus, although we cannot say with any certainty when Type II rents may appear in the Swedish TGC system, it is clear that they will appear sooner or later. To give an indication of the size of the potential Type II rents, we assume that off-shore wind power (or another technology with a corresponding cost level) will be introduced in the system starting in 2015. According to an early estimate by the Swedish Energy Agency (2005b), the introduction of off-shore wind power could result in certificate prices of up to 370 SEK/certificate. In a more recent report by the same Agency, it is suggested that the certificate price would have to be doubled (from approx. 250 SEK/ MWh) in order for off-shore wind power to be profitable (Swedish Energy Agency, 2007c). In our estimate, we assume, therefore, a certificate price of 500 SEK/MWh. This price results in an over-compensation to plants built between 2003 and 2014. We assume that these will be profitable at certificate price levels of 206 SEK/certificate for plants built in 2003-2007 (the average certificate price in this period) and 300 SEK/certificate for plants built in 2008-2014. The latter figure corresponds to the highest certificate price level used in the calculation of the Type I rents and is, as previously mentioned, only slightly higher than last year's average price. For reasons of simplicity we, thus, assume that all plants in each group will receive the same over-compensation per certificate from 2015 to the year they are phased out after 15 years of operation, in accordance with current legislation (see Appendix B). The estimated amount of renewable electricity produced in plants taken into operation in 2003-2007 is based on data on the production in these plants in 2007. For 2008-2014, the estimated amounts are derived from a prognosis of new production based on an exponential increase in investments (see Appendix B). Under these assumptions, Type II rents generated in 2015-2030 for new plants taken into operation in 2003-2014 would total in the order of 19 billion SEK (i.e., about 2 billion Euro) at a certificate price of 500 SEK (see Appendix B).",
            "Conclusions: Total rents and their share of payments to producers": " To sum up, the Swedish TGC system has already produced Type I rents (i.e., overcompensation to already existing production) in the order of 8-11 billion SEK, equalling 57-79% of the payments to producers depending on whether we include only the 6.5 TWh of existing production in 2002 or all the 10.8 TWh of ''easily accessible'' production in existing plants. In the most realistic of our estimates for the entire period 2003-2014 (based on a certificate price of 300 SEK in 2009-2014), Type I rents will amount to up to 23 billion SEK, which would constitute as much as 58% of producer payments. The estimation of Type II rents (i.e., overcompensation to cheaper technologies as more expensive technologies are introduced in the system) generated in the period 2015-2030 are, of course, much more uncertain but an indication could be about 19 billion SEK. 22Taken jointly, Type I and Type II rents for the existing plants at the start of the scheme and for those constructed up to 2014, are estimated to amount to about 33-42 billion SEK in the period 2003-2030 (see Table 4). With an average certificate price of SEK 300 in 2009-2014and SEK 500 in 2015-2030, this , this  These figures are, arguably, not in line with the expectations from the EU Commission and the Swedish government that the TGC system would be cost-efficient in terms of low consumer costs, nor that it should avoid overcompensation to power producers, as emphasised by the Swedish Government. On the contrary, the TGC system has turned into a ''rent-generating machine''. The Swedish TGC scheme performs, therefore, badly not only in terms of consumer costs but also with respect to equity.23 ",
            "System outcomes III: TGC as a driver for technology development": " As shown in Section 2, a TGC scheme was expected to stimulate technical change and drive down costs. This theme is a recurring one in the Swedish policy literature (e.g. in various Government bills). For instance, a TGC will ''y give rise to a market dynamic that create the conditions for cost efficiency and technical change'' (Swedish Government, 2000, p. 1). In what follows, we will argue that this expectation is unreasonable. We will do so by relating the TGC scheme to the literature in innovation studies. That market dynamic influence technical change is wellknown in the field of innovation studies, where the close relationship between technical change (and cost reduction) and diffusion has been emphasised for a very long time, indeed already by Adam Smith in 1776 (Smith, 1776(Smith, /2003)). This is, for example, reflected in the literature on so-called ''learning curves'' (e.g. Neij et al., 2003) that describe how an increase in performance, or reduction in costs, stimulates diffusion which, in turn, generates opportunities for more learning. In part, these opportunities stem from the larger funds available for R&D among capital goods suppliers as their sales increase (Klepper, but they are more general than so (Kemp et al., 1998;Jacobsson and Bergek, 2004). This means that it is not enough for a government to fund R&D, pilot plants and the occasional demonstration plant for a learning process to unfold. Learning and technical change is dependent on market formation. This market formation needs to be started very early on and in parallel to R&D support -the process is not linear (Kline and Rosenberg, 1986). In an early phase, diffusion rests on the formation of nursing markets, where the new technology is protected from competition for quite a long time, often decades. These nursing markets may be conventional niche markets, where the new technology is superior in some dimension, but in the energy field they are often created through some kind of state support, e.g. in the form of demonstration programmes. 24 Although very small, these markets are strategic in terms of technical change since they create a base for learning and self-reinforcing processes which enable the new technology to begin to improve its price/performance ratio and to adjust to the demand from specific segments (Kemp et al., 1998;Jacobsson and Bergek, 2004;Suurs, 2009), There is, though, a large discrepancy between the demand from these early niche markets and the fully commercial mass market. Bridging markets may, therefore, need to form to allow for different types of selfreinforcing process to gain strength (Andersson and Jacobsson, 2000). Without nursing and bridging markets, there is little incentive for capital goods suppliers to enter into the industry and provide resources for product, process and market development. Without a capital goods industry being formed, learning is limited to that taking place in academic R&D organisations. The link between policy, market formation and technical change goes, therefore, via the capital goods industry. This link is particularly strong in early phases where an initially immature, expensive and poorly performing technology is embarking on a long learning process. By forming initial markets, policy may induce firms to enter into the capital goods industry and take the new technology through this process. Initial markets are, therefore, necessary for the new technology to be put ''on the shelf'' (Sande \u00b4n and Azar, 2005). As an example of successful market formation and capital goods industry development, we may take the German wind turbine case. German support to wind turbines from the mid-1970s and forward induced the entry of about 14 firms in the period 1977-91 (Jacobsson and Bergek, 2004). The initial nursing market was very small: in 1989, about 15 years after the start of the wind turbine programme, the total installed effect of wind turbines was only 20 MW (221 turbines) (Bergek and Jacobsson, 2003). This was followed by the formation of a bridging market in the form of a 250 MW demonstration programme with invest-ment subsidies. This market was 12 times larger than the initial nursing market and strongly supported the development of the domestic wind turbine industry. 25 Yet, it was still a very small market compared to what was to come. In the first half of the 1990s, the first version of the feed-in law, with fixed tariffs for e.g. wind power, was implemented. Together with the 250 MW programme, this induced a growth of annual installations from 10 MW in 1989, via 500 MW in 1995 to a peak of over 3200 MW in 2002 (see Fig. 4). This growth created a large space for the German wind turbine industry. More firms entered and a division of labour emerged in a growing industrial system (Bergek and Jacobsson, 2003). A substantial learning process followed, which most notably involved a rapid up-scaling of the turbines. The capital goods suppliers' contribution to technical change was reflected in a learning effect which was in parity with the Danish (Neij et al., 2003). Today Germany accounts for about 30% of EU's supply of wind turbines (compared to Denmark's 40%) (EWEA, 2009a) and 35% of the direct employment in the European wind industry (EWEA, 2009b). Both nursing and bridging markets can, thus, be rather small; contrast the figures above for wind power (20 and 250 MW, respectively) with the situation in 2008, when the German installed effect of wind turbines was almost 24,000 MW (see Fig. 4)! However, these markets were still instrumental in setting in motion learning processes that eventually led to the development of a range of domestic turbine alternatives to the more established Danish wind turbine industry. How, then, does the TGC scheme compare with this? As noted above, uniform TGC systems, such as the Swedish TGC system, create a ''technology-neutral'' market where all eligible technologies compete. This leads, of course, to a step-wise investment pattern where the lowest cost technologies are included first: ''A basic principle of the system was that the different renewable energy sources should compete with each other so that the most cost-efficient electricity production is built first. Only thereafter may the more expensive production be gradually built as the level of ambition (the quota) is raised'' (Swedish Government, 2006b, p. 106). 24 See Jacobsson and Bergek (2004) and Stern (2006) with respect to some of the reasons for the need for intervention to form initial markets. 25 The capital goods suppliers benefitted from this generous support both by the creation of a domestic market and by the transfer of some of the support to the capital goods suppliers through high equipment prices, which to a large part were used for technology development (Bergek and Jacobsson, 2003). In addition, German turbine manufacturers were partly protected from competition from the Danish firms through the design of federal and local support systems, which ensured them a 50% share of the German market. A uniform TGC scheme, thus, creates a market for relatively mature technologies (Midtun and Gautesen, 2007), whereas immature technologies are locked out, perhaps for an extended period of time (unless the quota is raised to a very high level). 26  This means that it applies to early mass markets, for which more mature technologies are available (see Fig. 5). It needs to be emphasised that this is not an unintended consequence of this regulatory framework. It is rather a basic principle that investment should be made ''y at a rate that is economically justified and not prematurely'' (Swedish Ministry of Industry, 2002, s. 38). It is, thus, deliberately designed to avoid forming nursing and bridging markets. This implies, on the one hand, that TGC schemes like the Swedish one may improve the conditions for a further development of relatively mature technologies as these begin to exploit mass markets. One example could be conventional technology for biomass based combined heat and power plants. This is a mature technology dominated by a handful of suppliers of boilers (e.g. AE&E, Metso Power and Foster Wheeler). In such a field, a market expansion driven by the Swedish TGC scheme may induce further technical change. Thus, some learning of this kind may have been generated by the Swedish TGC scheme. 27 Given that the Swedish market is only a fraction of the global, the impact cannot, however, be expected to be more than marginal. Moreover, this learning is largely external to Sweden as we do not have any larger wind turbine manufacturers and only one strong supplier of CHP equipment (Metso Power, which originates from two Swedish firms: G \u00f6taverken and Generator). On the other hand, the focus on relatively mature technologies implies that uniform TGC systems cannot be expected to drive technical change in the first vital few decades in a new technology's life. Nor can it be expected to contribute to generating an early and supportive home base for Swedish capital goods firms in new technology fields. A ''gap'' has, therefore, been created in the Swedish policy package between R&D, pilot projects/occasional demonstration plants and the more mass market flavoured TGC scheme (see Fig. 5). This gap means that Swedish policy does not provide a space for learning, where firms establish themselves early in the capital goods industry and invest resources into technology and market development. A case at hand is the Swedish development of thin-film solar cells, in which the academic spin-off Solibro AB was forced to leave Sweden for Germany in order to get the investments needed to build up a production plant (see Box 1). To conclude, without an early home market, Swedish capital goods firms are placed in a disadvantageous position vis-a-vis firms operating in countries with an early home market. This hampers the ability of Swedish firms to exploit the fruits of academic research, lead the process of technical change and take part in the rapidly expanding global market for renewable energy technologies. The Government has, therefore, perhaps unconsciously, played down the importance of fostering a Swedish capital goods industry and, consequently, made sure that the Swedish contribution to technical change and cost reduction will be small. The Swedish TGC scheme cannot, therefore, be expected to fulfill the goal of contributing to technical change and cost reduction more than in a marginal way.",
            "Concluding discussion and some lessons learnt": " The purpose of this paper was to assess the performance of the Swedish TGC system in relation to expectations at the EU and Swedish policy levels, contributing to the European-level debate on the suitability of different types of schemes for the support of renewable electricity production. On the positive side, we concluded that the Swedish TGC system passed on the criteria of effectiveness and short term social cost efficiency. The TGC scheme has strongly contributed to a considerable change in the interest among firms to invest in biomass CHP and wind turbines as compared with the 1990s and the expansion of 'green' power to reach the first set target has been achieved at a low social cost. On the negative side, we first noted that the cost for the consumers have so far greatly exceeded expectations; certificate prices and payments by electricity consumers have been far higher than expected, including substantial transaction costs. The main problems of the Swedish TGC system, in relation to expectations, are, however, related to the equity and technology development assessment criteria. We will elaborate on these and conclude with some lessons for policy. 4.1. Equity: the Swedish TGC system as a rent-generating 'machine' Our estimates show that the Swedish TGC system has so far (2003)(2004)(2005)(2006)(2007)(2008) generated rents to already profitable production units that amount to up to 11 billion SEK (79% of the payments to the producers). These rents may increase to in the order of 23 billion SEK (59% of the payments to producers) in the period 2003-2014, if the certificate price reaches 300 SEK. These very substantial rents, thus, follow from the decision to include already existing plants in the scheme. However, Verbruggen (2009) similarly suggests that 64% of the turnover of the equivalent Flanders system was constituted by excess profits, which indicates that rent-generation is not only a peculiarity of the Swedish TGC system. As and when more expensive technologies have to be introduced in the system to meet the quota, further rents will be generated. Whilst the size of these are very uncertain, a certificate price of SEK 500 by 2015 (reflecting the higher cost of e.g. off-shore wind power) could generate rents to previous investments in lower-cost production (on-shore wind and biomass CHP) in the period 2003-2014 of in the order of 19 billion SEK. Hence, for the existing plants at the start of the scheme and for those constructed up to 2014, the combined rents may amount to up to 42 billion SEK in the period 2003-2030. Assuming that no further sources of rents emerge, this would constitute a share of rents of up to 28% of the payments to producers. The TGC scheme is, indeed, a rent-generating machine! These rents mean that the TGC scheme does not pass on the Swedish Government criteria of equity, avoiding overcompensation (to the power industry) and securing the legitimacy of the system, a point also emphasised by the European Commission (1999). 28 The big risk of these rents is, however, not that they threaten the legitimacy of the TGC scheme but that of renewable energy technology (obstructing the Government's ambition of securing a ''third leg'' in the Swedish power balance in addition to nuclear and hydro power). This feature ought not to come as a surprise. Type II rents are inherent in economic activities with marginal cost pricing and an upward sloping cost curve. Theoretically, it is straightforward to show that social cost-effectiveness will not imply minimum impacts on the electricity consumer collective. The empirical analysis in Section 3 demonstrated the orders of magnitude involved. It is, therefore, surprising that makers were expecting to minimize both social costs and consumer costs. In addition, the ease of expanding output in already existing plants and the difficulties involved in designing the system to avoid overcompensation to power producers (Type I rents) was well described by the government committee of inquiry investigating the future TGC system in Sweden: According to our opinion, the expansion in existing plants can occur soon after the introduction of the certificate system. It can come about with moderate or zero investments and small changeover efforts, e.g. through fuel conversion and increased amount of full-load hours'' (SOU, 2001:77, p. 74). One of the difficulties is to construct the model so that existing plants will not be strongly overcompensated, with consequent excess costs for the consumers, as new investments will be given adequate cost coverage'' (SOU, 2001:77, p. 158). Interestingly, however, we have in no official Swedish documents before or after the system was launched come across any calculations of neither potential nor actual rents. This is, indeed, remarkable as it is obviously so that a very large share of the turnover of the scheme is wasted in the sense that it could have been used to fund a much higher level of investments in renewable energy technology.",
            "Technology development: the gap in Swedish energy policy": " The expectations on the TGC system to drive technical change neglects two fundamental features of the development of new technologies: (a) longer term learning processes as a source of innovations and cost reductions and (b) the role of the capital goods industry in these learning processes. The Swedish TGC system was, thus, deliberately designed so as not to stimulate early nursing and bridging markets, where those that invest in new energy technologies, as well as those capital goods firms who develop such technologies, are rewarded. On the contrary, our analysis shows that the substantial rents in the TGC system are reaped by investors in relatively mature technologies. These rents are, therefore, not -as appropriate in a market economy -the reward to successful entrepreneurs developing and applying relatively immature technologies. Box 1-The case of Solibro AB. Sources: Alpman (2008), Bengtsson (2007) and Malmqvist (2000). Research on thin film solar cells started at The Royal Institute of Technology (KTH) in Stockholm in the 1980s. Key researchers moved to Uppsala University in the 1990s and participated in forming \u00c5ngstr \u00f6m Solar Centre in 1996. A plan for commercialisation of the world class R&D results involved spinning off a firm and seeking a Swedish industrial consortium that could add competence and capital to it. Yet, interest among Swedish actors was very low. After an intervention from the highest political level, a new discussion took place with leading Swedish industrialists (Malmqvist, 2000). A spin-off company, Solibro AB, was founded in 2000 by four researchers and a small amount of capital was supplied by a group of firms and a pension fund. Although development money was supplied by the Swedish Energy Agency, there was little interest by these firms to become suppliers of solar cells (Bengtsson, 2007). When funding was subsequently sought for up-scaling of the production technology and to build a manufacturing plant, Solibro AB eventually had to enter into a joint venture with the German firm Q-cells, forming Solibro GmbH. Solibro GmbH invested 500 million SEK in a plant and started production of cells in May 2008 (Alpman, 2008). As expected, the TGC system did not provide this firm with a home market, nor was there a home market that could induce the small group of firms that had already put a little bit of money into Solibro to invest in up-scaling the technology. A ''gap'' has, therefore, been created in the Swedish policy package between R&D, pilot projects/occasional demonstration plant and the TGC scheme. This gap points to a very large opportunity cost of the massive rents generated within the Swedish TGC scheme. These rents are the result of legislation and can, therefore, be regarded as a tax that is collected by industryi.e., a hidden industrial subsidy. Of course, these rents may be used in a socially desirable way, but this is beyond the control of the Parliament that voted for the TGC scheme. If we compare the rents with the size of measures put into more direct use for the purpose of furthering technology development in the energy field, a simple example is the annual Swedish public expenditure on energy R&D, which was SEK 875 million in 2008. Of greater importance is the lack of funds for larger demonstration programmes to fill the gap referred to above, for instance for off shore wind, wave, tidal and solar power as well as alternative fuels, such as gasified biomass. Recently, the Government decided to scale up the funding to such plants and allocated SEK 875 million to a demonstration programme for renewable fuel and power. This is, so far at least, seen as a one-off programme where the funding will be dispersed over 3-4 years. With access to the rents generated within the TGC system (perhaps SEK 23 billion in the period 2003-2014 only, see Table 3), RD&D funding could thus have been greatly increased, improving the opportunities for Swedish capital goods firms to contribute to the process of technical change.",
            "Lessons learnt for policy": " Given this outcome of the Swedish TGC system, it is fair to say that such a scheme should be selected if the overriding concern is to minimize short term social costs of reaching a certain goal (e.g. fulfill an EU Directive) with a high degree of predictability. However, it is clearly uninformed to have an ambition that a TGC system of this kind should also drive technical change, keep consumer costs down and be equitable. There are, thus, trade-offs involved in selecting a support system. Choosing a TGC scheme implies that the significance of rents and the importance of driving technical change/creating opportunities for industrial development would need to be played down dramatically. Of course, as the TGC scheme fares poorly with respect to driving technical change, this option is only available if the capital goods can be imported from countries with regulatory frameworks that drive technical change and the formation of capital goods industries. For an analysis of the implications of having a pan-EU TGC system and the necessity to foster a European capital goods sector in this field, please see Jacobsson et al. (2009). Other alternatives should be sought if (a) society recognises the value, and even the necessity, of industrial development and technical change and (b) it is deemed important to keep rents down and by implication, maximise the production of renewable power in relation to the support given to industry. These trade-offs were, however, not identified neither by the European Commission (1999) nor in various policy documents in Sweden prior to the selection of a TGC scheme. Indeed, they were obscured by arguments claiming that TGC would lead to both static efficiency (in terms of both social and consumer cost) and technical change. In this expectation, there is a striking similarity between the European Commission (1999) and various Swedish government propositions and reports. This suggests that there were shared beliefs between EU and Swedish policy makers, as argued by \u00c5strand (2005). a We assume that existing/ ''easily accessible'' production will be phased out according to Column E.  B1 and B2.  B1 and B2. b See Appendix Table B3. Indeed, Sweden had in the 1990s, encouraged by the European Commission, gone through a massive deregulation of e.g. the power and telecommunication sectors and it is not far-fetched to believe that the same thinking was now applied to renewable power (cf. European Commission, 1999). However, it is a vast difference between deregulating mature industries (where it is likely that the twin benefits of cost reduction and innovation will be achieved) and building up new industries. It is also a huge difference between the initial ambition of the Swedish TGC scheme to add only 10 TWh by 2010 and the long-term goal to build a 'third leg' in the Swedish power balance, which would imply a capacity to supply about 50 TWh. Assessing the Swedish TGC scheme in that light would unavoidably have led to an identification of the issue of rents early on. Policy makers must thus appreciate these kinds of differences and design policies accordingly. 'One size fits all' policies must be avoided! "
        }
    },
    "10.1016/j.eist.2013.12.003": {
        "file_name": "110 Zero emission housing",
        "title": "Environmental Innovation and Societal Transitions",
        "abstract": "A change to a zero emission housing future requires significant innovation in both policy and practice, as described by socio-technical transitions theory. This paper examines emerging policies towards zero emission housing standards from the EU, UK, USA, California and Australia to determine alignment with socio-technical transitions criteria. This analysis is then positioned within the Australian context, which is characterised by a lack of policy innovation. The limitations of existing regulatory approaches are identified. The analysis finds that a number of key socio-technical transitions elements are addressed in the case studies, but there are also elements that are absent or inadequately dealt with. Five key transitions elements are identified as being developed only to a limited extent in the Australian context, namely long-term goals, pathways, links to wider policies, financial innovation, and the inclusion of wider social elements. Consideration of these elements in future minimum energy performance standards could facilitate a transition to zero emission housing.",
        "label": "Qualitative",
        "text": {
            "Introduction": " This paper takes as a starting point the proposition that zero emission housing (ZEH) is a necessary requirement to achieve a low carbon future and that policy will be required to achieve this outcome. ZEH is defined for this paper as housing which has the capacity to generate all energy consumed in the dwelling across a calendar year through renewable energy technologies (Marszal et al., 2011). This definition includes all emissions producing energy consumed by the household within the property boundary, including energy used for heating, cooling, hot water, lighting, cooking and appliances. In 2009-2010 there were 8.4 million households living in private accommodation in Australia (ABS, 2012). Of these, 79% live in detached dwellings, followed by 11% in flats/units/apartments and 10% in semi-detached dwellings. The most common residential construction type in Australia is a brick veneer outer wall construction, built on a concrete slab on ground floor assembly (ABS, 2008). The existing detached housing regime in Australia, and other developed countries, is producing relatively large new dwellings which exhibit relatively poor thermal performance (Clune et al., 2012;Horne and Hayles, 2008). A focus on tried and tested technologies, materials, designs and building practices (Smith, 2006) continues to produce a residential sector which has been identified as a significant contributor to greenhouse gas emissions in Australia and internationally (Schultz & Petchey, 2011;Wang et al., 2010). Policy responses to date (such as minimum energy performance standards) have had some success but exhibit significant limitations (Pickvance, 2009;Wilkenfeld and Associates, 2007). The focus on technical solutions entails a myriad of assumptions about households, and furthermore the focus on heating and cooling energy efficiency typically addresses less than 50% of total energy consumption within dwellings in warm temperate climates like much of Australia (DEWHA, 2008). Such policy measures reflect other attempts since the 1980s to link technology innovation to environmental issues within policy framed by an ecological modernisation approach (Mol et al., 2009). Along the way, ecological modernisation has received significant criticisms regarding its ability to effect long-term environmental protection. The focus on technology providing the solution, a limited supply-side focus, continued market failures and the lack of social and demand-side considerations are among a number of concerns with ecological modernisation (Fisher and Freudenburg, 2001;York and Rosa, 2003). Recent shifts in the literature have meant that wider innovation approaches are being argued for in order to improve environmental outcomes (Newton, 2008;Smith et al., 2010). In this regard, socio-technical transitions (STT) theory is an emerging paradigm which builds upon a requirement for technology innovation from an ecological modernisation framing, but which also advocates moving beyond just a technology focus. This approach also draws upon social, environmental and governance considerations, and aims to generate deep structural change in order to achieve a transition to a low carbon future (Geels, 2002). Within STT literature, there are both descriptive and prescriptive applications and conceptualisations, the latter being typified in the idea of transition management. The transitions management approach hopes to identify those characteristics which might best allow for a transition to develop (Alkemade et al., 2011;Grin et al., 2010). Key elements include (Kemp and Rotmans, 2009;Rotmans and Loorbach, 2008): \u2022 Long-term thinking, including the setting of visions and goals, which informs short-term policy development. \u2022 Multiple domains, actors and levels, including links to wider national and international policy development such as Kyoto protocol. \u2022 The establishment of a transitions arena for technology and social innovation, programme development and ongoing learning. \u2022 Policy oriented towards system innovation besides system improvement (deep structural changes). \u2022 Reflexive governance (periodic reviews and assessment) throughout the process to ensure that the transition is 'on track' and to avoid a lock-in of technologies and practices; and \u2022 Identification and engagement of societal actors. The aim of this paper is to interrogate policies towards zero emission housing standards from selected jurisdictions to determine if there is alignment with socio-technical transitions criteria. For this analysis, STT criteria for a ZEH regime are developed using the descriptive transitions concept of the MLP. A review of international literature on the topic ensures that developed STT criteria are based on foremost expert opinion and on recognised theoretical perspectives. This analysis is then located within the Australian context in order to identify limitations of existing policy based upon a socio-technical transitions approach. The remainder of the paper is organised as follows: firstly, the application of STT theory to sustainable housing in the wider literature is discussed (Section 1.1), highlighting the emerging area of research. The research approach and methods are then presented (Sections 2 and 3), followed by the results (Section 4). Section 5 discusses the implications of the results around the five key elements identified as absent or only partly addressed in the Australian context (long-term goals; pathways; links to wider policies; financial innovation; and the inclusion of wider social elements) before concluding remarks are made (Section 6).",
            "STT and housing": " An STT approach to sustainable housing, including energy performance, has begun to emerge in the literature and in recent policy development, exemplified in the research by Smith (2006Smith ( , 2007)). Smith explores the development of green housing niches and defined the current housing regime through an STT framework, identifying in the process a number of critical societal issues, including the need for engagement with householders to promote involvement within the new paradigm. Bergman et al., 2008Bergman et al., ,2007 adds to the work of Smith (2007) having assessed a transition to sustainable housing in the UK through the development of a number of potential policy development pathways to 2050. They propose that significant pressure must be placed on the existing regime not only by niche actors but also by landscape elements (climate change for example), if deep structural changes are to be achieved. Bergman et al. (2008Bergman et al. ( , 2007) ) state that in order for this to occur in the residential sector, radical changes to current housing and energy performance regulations are required. Bergman and Eyre (2011) explore small-scale renewable energy generation in the context of a transition to a low carbon housing regime in the UK. A scenario is proposed where households shift from energy users to 'energy citizens', who both consume and produce energy, giving them new responsibilities, levels of awareness and practice. A different approach is taken by Tambach et al. ( 2010), whose research in the Netherlands assesses existing housing and energy policies focused on the current housing stock against an STT framework. They conclude that a number of critical elements are missing from the current range of policies if a transition to a more sustainable, low-carbon, lowenergy housing regime is to occur. These include a lack of a long-term policy agenda (and short and medium-term goals and visions), a lack of capacity building of required new skills within the industry in preparation for changes and a requirement for financial reconfiguration (for example, banks and governments offering low-interest loans and lower stamp duty (or other taxes) for low-carbon housing) (Tambach et al., 2010). The lack of wider social support, training, development and financial constraints have been identified in other housing energy transition research as key factors limiting the capacity for a paradigm shift in the housing sector (Williams, 2008). In jurisdictions as diverse as the UK and California, there is evidence of a commitment to zero emission housing (ZEH) (CPUC, 2011;DCLG, 2008). With the development of STT and growing interest in ZEH, it is timely to assess developments across jurisdictions and consider the prospects for ZEH transitions.",
            "Approach": " There has been limited focus within the STT field on assessing existing policy against an STT theoretical framework (Beerepoot and Beerepoot, 2007;Kern, 2012;Tambach et al., 2010). This paper addresses this gap in the literature by applying a transitions management approach to the development of a ZEH regime in Australia. The benefit of this approach is that it identifies policy characteristics, particularly gaps, which may be important for a transition to ZEH in Australia. In so doing, it does not propose that the transition lens allows researchers to address all relevant dimensions of steering a transition. This paper intentionally commences with an objective, structural approach to assessing the housing regime, utilising a notion of governance which seeks to manage an STT towards a pre-defined goal or vision. The management aspects of this approach are strongly contested in the literature with opponents arguing that due to overriding issues of power and complexity involved, it is not possible to manage the dynamics of a transition (Shove and Walker, 2007). However proponents argue that 'transition management' is not management in the traditional sense, but is in effect more a process of 'steering' or facilitating transitionary activities (Loorbach and Rotmans, 2006). Furthermore, a limitation of transitions management broadly is that it reflects notions of objective, observable paths in a highly structured regime, whereas the housing regime is in fact disaggregated and dispersed, both geographically and in terms of industry segmentation and structure. The focus on one identifiable segment-that of the supply of 'volume' build new housing -ameliorates this limitation. In this regard, this paper contributes to the wider transitions literature through the development and application of a policy assessment framework, applied to existing housing performance policies, based upon STT principles. The method used in this paper is rather scarce in applying the STT concept of transitions management to existing and proposed policy (Beerepoot and Beerepoot, 2007;Kern, 2012), and especially the application to the housing sector in general, and ZEH in particular.",
            "Method": " A comparative criteria-based policy document analysis was carried out involving a systematic review of relevant housing energy performance policies across five case study jurisdictions. Criteria were developed and applied to analysed policies, based upon a socio-technical ZEH framework. A comparative matrix was developed to facilitate clear comparisons of trends and gaps between policy approaches across jurisdictions. A comparative matrix consists of the same criteria (or questions) applied systematically to each case study, in order to ensure consistency in the analysis. Criteria for the matrix draws upon the STT and sustainable housing research of Tambach et al. (2010), Smith (2006) and Bergman et al. (2007) who have identified a number of key elements which make up ZEH regimes, in addition to the work of Geels (2002) who has identified a number of wider key elements in STT. The matrix was then populated with data through a comparative document analysis of the selected case policies. The case of housing policy in Australia has been carefully chosen to illustrate the benefits of a STT approach to policy analysis. Current housing policy in Australia is characterised by a lack of innovation, a lack of information and communication across stakeholder groups and an incremental approach to addressing sustainability issues in the built environment (Moore, 2012). There is a particular problem in Australia in recent times of relatively low environmental performance and low stringency of minimum energy performance standards (Horne and Hayles, 2008). If the end goal of a low carbon transition in housing is of a housing regime characterised by ZEH, the appropriate policy mix and a facilitating regulatory environment represents a critical early step in such a transition. While the housing sector represents a narrow cross-section of a multitude of other regimes, including the national economic regime and local and regional urban systems regimes, such a focus is appropriate to analyse sectoral policy against STT principles. It is likely that if a transition to a housing regime characterised by ZEH were to occur, it would almost certainly be part of a wider transition to a low carbon economy. For the purposes of this paper, the housing sector is sufficiently complex to warrant the application of STT concepts such as the MLP and transitions management, yet is confined enough to allow a manageable boundary to be drawn on the scope of the research. The research approach reported in this paper may however be replicated at macro scales, and for regimes of greater complexity.",
            "Criteria development": " The framework for analysis was developed based upon both social and technical elements widely acknowledged as necessary requirements for regime transition. Table 1 identifies elements which make up the ZEH STT regime which have primarily been taken from the work of Geels (2002) and emerging housing transitions research by Smith (2006), Bergman et al. (2007) andTambach et al. (2010). From these, 17 primary criteria were developed across two key elements: technical requirements for ZEH, identified from empirical analysis and wider socio-technical transitions theory principles, identified from the literature. The selection of these criteria was taken directly from Yes: Recommended requirement in policy, generally one of a number of options which needs to be addressed -not a mandatory requirement P Yes: Partially addressed, but does not completely address the criteria question N Acknowledged within the policy but not included as a requirement f Discussed in the policy for future inclusion (mandatory) -Aspect is not mentioned in any way elements identified by the aforementioned research. There is insufficient room to discuss each in turn in this paper but they are all discussed in detail in Moore (2012). As a result of this process, a number of key elements were identified for facilitating socio-technical transitions. These key elements inform the criteria developed for the analysis and include: \u2022 long-term policy and vision setting, \u2022 scenarios (pathways), \u2022 international best practice, \u2022 link to wider policy goals, \u2022 reflexive governance, \u2022 social aspects, \u2022 overall/targeted emissions reduction, \u2022 research and development, \u2022 financial sector, \u2022 institutional structure reform, and \u2022 behaviour (user practices). Further, a number of performance requirements identified by ZEH standards fit within the wider requirements of STT theory. These performance requirements were also applied as criteria and included: \u2022 energy efficiency of building envelope, \u2022 energy generation/infrastructure, \u2022 house as part of larger system, \u2022 smart technology integration, \u2022 through-life costs and benefits, and \u2022 appliances. Within the 17 criteria categories, 66 specific questions were developed to interrogate compliance with the criteria. The full list of the questions is provided in Moore (2012).",
            "Assessment": " A matrix for analysis was developed and populated with data obtained by coding selected policy documents against the framework criteria. Inspected document analysis was conducted for each criterion. This ensured that a systematic approach was applied to evaluate all studied policy documents in each case study area. Responses to the criteria questions were coded into one of 6 categorical answers, as presented in Table 2.",
            "Case study selection": " Five case study jurisdictions were selected; four international cases and the Australian context. These included both state and federal level governments. This enabled appropriate comparison across different levels of government. A number of selection criteria were applied to assist with case study selection. Firstly, selected international case studies were required to have either implemented or be in the process of developing ZEH policy. Case studies jurisdictions were also selected on the basis of broadly similar problems faced in relation to fossil fuel energy consumption and greenhouse gas emission concerns to those in the Australian context (Garnaut, 2008;Stern, 2007). Historically, the response to these issues from the built environment sector in the selected case study jurisdictions has been similar to those of Australia; that is, the setting of minimum energy efficiency standards for new dwellings. Furthermore, as climate zones can impact on energy and building requirements for addressing heating and cooling energy, it was important to draw upon policies that were developed in jurisdictions with broadly comparable climate zones (Horne and Hayles, 2008) and commitments to improve housing performance and reduce greenhouse gas emissions. In doing so the following federal and state level jurisdictions were selected for analysis: \u2022 United States of America (USA), \u2022 California, \u2022 European Union (EU), and \u2022 United Kingdom (UK). The Australian context is also included and is the main focus of the analysis.",
            "Policy instruments selection": " Current housing performance policy documents (instruments) as of 1st January 2012 were selected from each case study area (Table 3). Policies were selected based upon their relevance to housing energy performance. A detailed discussion of these is presented in Moore (2012).",
            "Results": " Table 4 presents a summary of the coded results from the policy document analysis for each of the 17 broad criteria categories for each jurisdiction. Detailed results can be found in the appendix to this paper. The analysis of housing energy performance policy documents from the case study jurisdictions using a socio-technical ZEH framework found that there are a number of gaps and trends across analysed policy documents for the case study jurisdictions. Overall the analysis found that each jurisdiction addressed different elements from the criteria. Each jurisdiction was found to have strengths and weaknesses, but these varied in each case. These are presented below in Tables 5-9.",
            "Discussion": " New or altered policy and regulation has been described as a potential driver to generate deep structural changes in socio-technical regimes which are required for a transition to a low-carbon, lowenergy housing regime (Smith et al., 2005). To this end, the international case studies demonstrated a number of key STT elements are included in current policy development. The evidence suggests that there is some alignment with STT elements although based upon the analysis a number of substantial  gaps exist in each case study. Only in time will we be able to assess if these gaps will prevent or hinder a STT to a low carbon housing future. For the time being, the policies represent a significant departure from previous ones which had a clear focus on primarily addressing heating and cooling energy requirements. With this in mind, the evidence finds that the international case study jurisdictions addressed a greater number of the STT criteria compared to the Australian policy context. In particular five key STT elements are identified as being absent or only partially addressed in the Australian policy context at the time of the study (2012). These will be discussed with reference back to the international case studies as follows.",
            "Element 1: long-term goals -ZEH": " The setting of long-term goals is critical for a transitions management approach to STT as transitions can take a generation or more to eventuate (Kemp and Rotmans, 2009). We found that the implementation of ZEH standards is stated as a medium-term (5-15 years) policy goal of the international case study jurisdictions, and longer term policies beyond 15 years are generally absent. The lack of a longer-term policy agenda has been identified within the housing STT literature as a barrier to a low-carbon, low-energy housing regime (Tambach et al., 2010). Considering that houses can last for 100 years or more, the dearth of term policies regarding their fate is notable. The need for a long-term goal has been recognised by the Australian Government as an important factor in moving towards a low-carbon, low-energy housing regime (Australian Government, 2010). However, to date, there is little evidence in the policy documents analysed for this paper of any advancement of this recognition to more affirmative policy development activities. There is no ZEH goal in Australia at present, and current policy is largely limited to annual revision of the Building Code of Australia, the document which sets minimum standards and requirements for new dwellings. A longer-term goal of ZEH would be expected to evolve in line with principles of reflexive governance as the transition progresses (Grin et al., 2010). Without a longer-term goal, there is no structure, direction or end point for the transition (Eames et al., 2006). While ZEH in itself might not be such an endpoint, it would provide a notice of intent for the future direction of housing energy performance requirements and allow space for the development of structures and agencies with similar goals. The goal of ZEH also implies the inclusion of renewable energy technologies as well as drawing upon wider social elements to achieve the paradigm shift required (Smith, 2006). Of the housing policies analysed, California, the UK and EU have medium term policy plans for future mandatory requirements for renewable energy technologies. In the EU for example, Member States must include mandatory requirements for renewable energy technologies for all new dwellings from 2015. The USA federally lacks such policy approaches, however the inclusion of renewable energy requirements in future policy development is predicted (DOE, 2010). Mandating the inclusion of renewable energy technology into minimum new housing energy performance standards in Australia would signal a radical policy shift away from addressing heating and cooling energy only. Increasingly, the literature in Australia has begun to highlight the need for renewable energy technologies to be included in improved housing energy performance standards (Newton and Tucker, 2011). This is in line with international research which is increasingly focused upon the integration of wider energy elements such as renewable energy technologies in achieving low carbon housing (Zhu et al., 2009). However, such an approach needs to be balanced against the wider technical, environmental, social and economical benefits of addressing energy generation at a national level, as highlighted by research by Beyond Zero Emissions (BZE, 2010).",
            "Element 2: develop a pathway": " The process of goal setting is removed from and distinct from the process of goal realisation (Eames et al., 2006;Grin et al., 2010). Without the use of pathways (or scenarios), goals remain distant with little grounding in practicality. The development of pathways (or scenarios) has been identified in the ZEH STT literature as critical to the process of facilitated socio-technical regime change (Bergman et al., 2007;Smith, 2006). In the EU, UK and California, attempts have been made to put pathways in place. For example, the UK government set a 10 year step-change policy pathway based upon feasibility studies which analysed associated costs and benefits. This included improvements to minimum standards in 2010 with further improvements in 2013, before the introduction of ZEH standards in 2016. It has been argued that basing pathway and goal development on a strong evidence base strengthens policy outcomes and has allowed for a more open discussion regarding the pathway forward, helping to legitimise the process (Hudson and Lowe, 2004;Osmani and O'Reilly, 2009). In California, a step change pathway began with the introduction of a voluntary green housing standard in 2008, and became mandatory in 2011. Further performance changes are planned in 2015 before the full introduction of ZEH standards in 2020 (CPUC, 2011). Such pathways are deemed important for encouraging innovation and reducing costs and disruptions from planned changes (Park, 2011). They provide a structure and focus for all actors involved and provide improved certainty for all stakeholders regarding future policy (Eames et al., 2006). It is argued that in the absence of pathways and goals, particularly from government, innovation and community uptake is likely to rapidly decline (DCLG, 2007). If we accept this argument, the lack of pathways (or goals) in Australia means that there is significant uncertainty surrounding future energy performance requirements. This affects all stakeholders in the housing system, building industry and consumers. The lack of pathways (or goals) in the Australian context is not surprising as there is no longer-term goal/s to require a pathway to achieve. Transition management advocates also argue that as a transition progresses, changes to technologies, costs and actor responses mean that there is a requirement for regular reassessment of pathways, goals and wider approaches (Foxon et al., 2009). In the EU, UK and Californian contexts there has been review of both the end goal and the pathway, leading to policy support changes. However, it must be noted that such measures also provide opportunities for abrupt changes in course, which run counter to the need for stable support for the growth of technologies and practices of ZEH. Recent changes to the definition of ZEH in the UK context (relaxed from covering all household energy consumption to now cover energy from heating, fixed lighting, hot water and building services (HM Treasury, 2011)) could be regarded as either reflexive governance, as updated costs data and predicted impacts to the building industry and consumers were considered in policy evaluations (McLeod et al., 2012) or as a politically motivated change in direction of the ZEH transition.",
            "Element 3: links to wider policy": " Links can be logically expected between ZEH policy and wider government policy approaches, in particular those relating to climate change and renewable energy generation policies. Policy makers might be expected to link ambitions for greenhouse gas emissions reduction and renewable energy generation targets in combination with feasibility analysis, to inform and provide justification for mandating zero emissions for new housing stock. In the UK, for example, it is predicted that the Code for Sustainable Homes will be responsible for generating (through mandated renewables) 1.4% of the UKs total energy consumption by 2020 (DCLG, 2008). This will contribute to the UK Government's goal of achieving 15% of energy from renewable energy technologies by 2020 and 80% of greenhouse gas emission reduction by 2050 (DECC, 2011). For Australia, the analysis reveals little evidence of a link between minimum housing energy performance policy and federal government objectives such as greenhouse gas emissions reduction targets. This lack of policy integration has been identified by other researchers in Australia (Newton and Tucker, 2011). The lack of a link between future housing energy performance policy development in Australia and wider government policies may be a significant constraint for policy progress towards ZEH. According to transition management advocates Bergman et al. (2007), apart from strengthening housing energy performance policy, strong links to other policies can put pressure on the existing regime via landscape pressures such as climate change and can help to legitimise the niche alternative.",
            "Element 4: financial instruments": " Innovative financial instruments -including to temporally smooth out capital costs and 'payback' -is apparently seen by the house building industry as an important factor in improving energy performance requirements in dwellings (HIA, 2009;MBAV, 2008). by Moore (2012) finds that taking a through-life perspective of costs and benefits identifies significant economic, social and environmentally beneficial outcomes. In addition to developing innovative ways to address capital costs, a shift in policy thinking from a focus on capital to life-cycle costs and benefits is indicative of the type of deep structural change which is required for a transition to ZEH (Smith, 2006). The EU, UK and Californian policy agendas include requirements to address the additional capital costs of ZEH construction. Examples from these three case study jurisdictions include measures to reduce capital costs through economic efficiencies in the material and building process and through the introduction of financial mechanisms such as low interest loans or tax breaks (reduced stamp duty for example). It is explicitly recognised here that the government must work with the financial sector to develop innovative economic levers to achieve such changes (CPUC, 2011;Tambach et al., 2010). Through such policy innovation, governments in the EU, UK and California are beginning to change current perspectives on housing costs from a focus on the capital costs of construction to a more comprehensive understanding of the through-life costs and benefits of alternative housing models. This process involves changes within the financial sector. Recognition of the benefits of reduced living costs and improved resale values of low emission housing by the financial sector could precipitate new financial business models to account for the changed risk and benefit profile of such housing. New financial instruments may be required to accurately reflect the lifetime consideration of costs and benefits in this way. Innovation of this kind is consistent with wider societal shifts necessary for transition to low-carbon, low-energy housing. The importance of such measures is highlighted by Tambach et al. (2010, p. 994) who state that 'new national, as well as local forms of financing energy efficient renovation projects in housing also deserve special attention in further research'. In Australia there is a history of policy innovation in housing finance, but the scale of initiatives regarding ZEH lags behind the EU, UK and California. A range of rebates have been provided by the Australian government across the past decade for renewable energy technology as well as for some energy efficient materials (e.g. insulation). However, these rebates have an inconsistent history. Despite this, they have helped to deliver a market for renewable energy technologies which was virtually nonexistent prior to the rebates schemes and, in turn, have improved overall cost efficiencies (Macintosh and Wilkinson, 2011). In addition, the Australian Government has attempted, albeit only temporarily, to work with the banking sector to offer low/no interest loans to households who make sustainability improvements to their homes (e.g. Green Loans program). Innovative financial instruments are arguably important in enabling niche uptake of ZEH, and through this, in applying significant pressure on the existing housing provision regimes (Smith, 2006). The lack of wider structural change relating to financial instruments has been recognised as a barrier to achieving improved energy performance from key actors within the Australian building industry. For example, the Housing Industry Association (HIA, 2009, p. 25) states: 'Home lenders do not take into account operating housing costs, such as energy efficiency savings, when assessing the capacity of borrowers to make repayments on home loans. The preference of home lenders to assess repayment capacity on the basis of current and not future income is suggestive of a market failure in the mortgage market. That home lenders are unwilling or reluctant to approve larger loans to cover the additional entry cost of energy efficient new dwellings is not addressed by mandating more stringent building regulations'. It is reasonable to assume that a significant increase in innovative and attractive financial products to address capital cost issues for owner-occupiers would, over time, result in expanded lifecycle perspectives. This may have flow on effects regarding practical knowledge of relating operating costs, overall housing energy performance and the impact to mortgage costs. This, in turn, could shift the way in which decisions are made. The Australian Government recognise that consumers rarely consider improving energy efficiency options if the payback period is seen to be more than a few years (Australian Government, 2010). Furthermore, the requirement to move to lifetime thinking with regards to both costs and outcomes has been identified in the wider housing STT literature (Smith, 2006).",
            "Element 5: wider social elements": " Articulated measures to facilitate a transition to ZEH within the STT literature all include acknowledgement of wider social elements, such as improving occupant health and social well-being, reducing fuel poverty and understanding and responding to building industry dynamics (Bergman et al., 2007;Smith, 2006). The UK case study provides the most integrated example of social and technical requirements within the policy documents analysed. These include links to, and performance indicators for, wider social elements such as improving occupant health, improving affordability, reducing fuel poverty and developing the active participant household. Institutionally, there is a focus on developing an understanding of existing and future actors and networks in the building industry in order to identify the risks and benefits presented by a transition to a low carbon housing regime. In Australia, concern with land costs and lack of housing supply have fuelled house price inflation and a concern with \"affordability\", which has in turn dominated debate regarding broader housing provisions and ZEH. However, this debate is still focused on upfront capital costs rather than on through-life costs and benefits (Morrissey and Horne, 2011). Beyond this, there is recognition from the Australian Government that any further improvement to energy performance standards requires supplementary measures to be introduced to policy including programmes of training and education for the building industry (Australian Government, 2010). Limited consideration of 'non-technical' factors in the Australian context has also been recognised by Newton and Tucker (2011, p. 46) who state 'policy analysts need to engage with both technology and behaviour-based approaches to energy conservation'. The authors also discuss how addressing deeper social constructs of housing could lead to a reconfiguration of physical house design outcomes (demand for smaller, more appropriate size housing), as personal concern and responsibility for environmental impacts and outcomes improves. The idea that raising awareness of householder practice and their role in shaping energy demand is another related issue explored in the transitions literature (Vergragt, 2006). Across all jurisdictions considered here, there remains limited evidence of the need to incorporate a systematic understanding of building industry networks and actors; the meaning of and connection to home; and culture and institutional socio-technical dynamics of housing systems into policy initiatives in the context of ZEH policy ambitions, despite research which finds significant social benefits for elements such as improvements to health, well-being and comfort (Clinch and Healy, 2000). While this research has attempted to produce robust and transparent analysis, there are still a number of limitations of the research which could be addressed in future studies. For example, the implications and role of non-policy related reforms aimed at achieving ZEH should be included in future analysis. In addition, reflexive governance is required to assess the impact on ZEH outcomes in Australia if a more comprehensive inclusion of STT elements is undertaken.",
            "Conclusion": " In this paper we have sought to interrogate policies towards zero emission housing (ZEH) standards (housing which has the capacity to generate all energy consumed in the dwelling across a calendar year through renewable energy technologies) from selected jurisdictions to determine if there is alignment with socio-technical transitions criteria. This analysis is then located within the Australian context in order to identify limitations of existing policy based upon a socio-technical transitions approach. Through this analysis we have sought to show how socio-technical transitions theory can provide a useful way of identifying and arranging priorities and gaps in policy. In so doing, we do not propose that the transition lens allows researchers to address all relevant dimensions of steering a transition. Transition management has been criticised on the basis that a focus on observable paths tends to neglect the social (e.g. households), and the political, and thus that regime framing is an objectification process (Moore et al., 2014). The 'who' and 'how', while present in the rhetoric of transition management, is demoted in favour of the policy maker as arbiter of the regime. To address this weakness, we propose that transition analysis research such as that presented here should be juxtaposed with research from sociological and political traditions specifically addressing; (a) cultural (e.g. different meanings of home), consumption (e.g. different ways occupants use their housing) and social dimensions (e.g. security) of home and (b) political and power relations in the regime over time (during the 'transition'). While such juxtaposition offers further strengthening of the prospects for steering transitions, we also conclude with clear implications of our analysis for contemporary housing policy in Australia. Australian housing and building code energy efficiency stringency lags behind comparable countries, and there is a lack of evidence for socio-technical transitions precursors that would be required before any prospect of a regime change towards ZEH. Drawing upon the implications of our analysis, as discussed in this paper, we present the following propositions for ZEH policy in Australia: \u2022 Set a longer-term housing energy performance agenda. \u2022 Develop a pathway to achieve specified goals. \u2022 Link housing energy performance standards to wider government policies such as greenhouse gas emission reduction and renewable energy targets. \u2022 Address financial innovation to improve cost efficiencies to achieve ZEH standards. \u2022 Integrate wider social considerations into minimum housing energy performance standards to ensure a more comprehensive policy approach is developed.  Many of these elements are evident in comparative international case study jurisdictions. The analysis presented here suggests that progress and prospects for ZEH in Australia are slim without these specific and significant shifts in policy and supporting mechanisms."
        }
    },
    "10.1016/j.eist.2012.07.001": {
        "file_name": "111 Sustainable urban development and the multi-level transition perspective",
        "title": "Environmental Innovation and Societal Transitions",
        "abstract": "This article discusses some challenges and possible adaptations of transition theory as a framework for analyzing the prospects for environmentally more sustainable development of urban land use and transport infrastructure. Rather than depending first and foremost on niche innovations, a transition toward sustainable urban development is a matter of changing the composition of existing multi-segmented land use and transportation regimes. Those well-experienced forms of built environment and transport infrastructure that are in line with sustainability objectives should be strengthened while those that are not should be actively constrained and reduced. Urban development in a Danish provincial city is used as a case to illustrate some of the points made in the theoretical part of the article. Due to the wide gap between present conditions and those required to realize a sustainable urban development, more attention should be directed toward landscape level conditions and possibilities for changing them.",
        "label": "Qualitative",
        "text": {
            "Introduction": " The topic of the present paper is to discuss a number of challenges arising when trying to apply the multi-level perspective of transition theory to sustainability-oriented studies of urban development and mobility, and to suggest some possible adaptations of the perspective in order to cope with these challenges. By urban development we here refer to the development of building stock, land use and transport infrastructure within functional urban regions. Our focus is thus not limited to particular districts within a city; what we are interested in is whether and how the functional city as a whole can develop in a way compatible with a low-carbon and environmentally more sustainable society. Few previous studies have investigated transition toward sustainable urban development from the perspective of transition theory. During the latest decades, several studies have investigated the performance of different urban spatial structures against sustainability criteria (e.g. Naess, 1993;Tjallingii, 1995;Newman and Kenworthy, 1999;Williams et al., 2000;Naess, 2001;Schremmer et al., 2011), and some studies have also addressed conditions for implementing more sustainable patterns of urban development (e.g. Naess, ibid.;Banister, 1998;Naess et al., 2011;Schremmer et al., ibid.). The former group of studies draws on a broad range of theories illuminating how urban development impacts on the natural environment during construction and from subsequent human activities facilitated or necessitated by the resulting urban structures (e.g. space heating and travel). The studies of conditions for implementation draw on theories from fields such as planning, political science, political economy, and discourse theory, but have so far not made use of transition theory to any great extent. A few examples incorporating transition-theoretical concepts into urban studies exist, including Bulkeley et al. (2011) and Hodson and Marvin (2010). A few authors have also addressed urban mobility and transport within the framework of transition theory (K\u00f6hler et al., 2009;Zijlstra and Avelino, 2011;Sheller, 2011;Bertolini, 2011). None of the above-mentioned contributions inspired by transition theory have, however, dealt extensively with the development of urban land use and transport infrastructure nor have the various sustainability and climate-related impacts of this development been addressed in a comprehensive way. Coenen et al. (2012) criticize the ignorance in most transition theory literature of how transitions take place in spatial contexts/scales (local vs. international). While sharing this critique, our focus here is not so much on spatial conditions as contexts for transition, but rather on spatiality itself (i.e. the spatial extension and the internal spatial structure of cities/metropolitan areas) as the object of transition. More precisely, the topic of this paper is the development of the building stock, land use and transport infrastructure in cities and the prospects of changing this development in a way compatible with a low-carbon and environmentally less unsustainable society. Section 2 will reiterate key sustainability challenges of urban development, which is followed by a brief account of the state of knowledge on sustainability-relevant impacts of urban spatial structures. Cities as objects of transition will then be discussed in the light of the multi-level perspective in Section 3. Next, Section 4 will consider some challenges of applying the multi-level perspective to sustainable urban transition, which will include proposals for possible adaptations of the theory to this field of transition. In Section 5, the use of some of the above-mentioned framework adaptations is illustrated in an empirical case study of the provincial city of Fredericia in Denmark. Finally, Section 6 will end this paper with some concluding reflections on limitations and prospects.",
            "Sustainability and urban development": " 25 years have passed since the UN World Commission on Environment and Development put the issue of sustainable development on the international agenda as a common challenge for all nations. According to the Commission, the key tenet of a sustainable development is to meet basic human needs -especially the needs among the world's poor -in a way that sustains the possibilities for future generations to meet their own needs (WCED, 1987:43). Whereas raising housing standards and improving hygienic conditions may be important to meet basic needs among urban dwellers in poor countries, the most serious sustainability problems of cities in the affluent North are rooted in their high resource consumption and unsustainable ecological footprints. Based on this understanding of the concept, important challenges of a sustainable urban development in wealthy nations are to mitigate climate change, limit energy consumption, reduce pollution, protect natural areas and arable land, and provide a safe and healthy environment for its citizens, in particular the most vulnerable groups (UN/ ECE, 1998). A large proportion of CO 2 emissions worldwide stem from buildings and transportation in cities, and the magnitude of these emissions can be considerably influenced by the solutions chosen for the development of the urban built environment. Achieving sustainable mobility (Holden, 2007) is an important part of the sustainability agenda of urban planners. Improved vehicle technology and provision of environmentally less damaging renewable energy may reduce the emissions per kilometer driven by cars and other motor vehicles. However, growth in urban traffic ties up (possibly renewable) energy resources that could have been used with higher benefits in other sectors of society. Moreover, many of the vehicle technology solutions proposed (e.g. hydrogen fuel cells) are not necessarily climate-and environmentally friendly when all chains in the production and consumption cycle are taken into consideration (Holden, ibid.). Anyway, urban car traffic causes a number of social and environmental problems in addition to energy use and emissions, such as traffic accidents, barrier effects, congestion, noise, and the encroachments of transport infrastructure on green areas and existing built environments. These problems will not be solved through the introduction of 'clean cars'. In many European countries, much discussion has evolved around the negative environmental consequences of a land-consuming and sprawling urban development in terms of, among others, loss of natural and agricultural areas and a high energy use for transport and in buildings. To a large extent, the predominant ideas of a sustainable (or rather: a less unsustainable) urban development in these countries appear to converge on the ideal of the \"compact city\" (cf. among others, Commission of the European Communities, 1990;Breheny, 1992;Jenks et al., 1996;Naess et al., 2011). The basic mechanisms through which urban structure influences travel are theoretically well understood and have been identified in numerous empirical studies (see Naess, 2011a for an overview of such studies within a Nordic context). Compact cities tend to be less car-dependent, provide for shorter trips and have lower per capita consumption of energy for transportation than do sprawling, low-density cities (see, e.g. Newman and Kenworthy, 1999;Naess et al., 1996;Lef\u00e8vre, 2010). It is difficult and expensive to provide high-class public transport services in low density urban districts. In contrast, dense urban development can provide accessibility to facilities through proximity instead of by means of a high mobility, thus combining important environmental and social aspects of sustainability. With short distances to potential destinations, a higher proportion of trips can be made by bike or by foot, and the remaining, shorter motorized trips will cause smaller emissions than if long distances have to be covered. In particular, locating a high proportion of new buildings close to the city center normally contributes to reduce energy use and greenhouse gas emissions from transport. This applies to residential development (see, e.g. Naess and Jensen, 2004;Naess, 2006Naess, , 2011)), office workplaces (see, e.g. Naess and Sandberg, 1996;Hartoft-Nielsen, 2001) as well as specialized service facilities. Local service facilities like primary schools, kindergartens and grocery shops should of course not be centralized to the downtown area but be interspersed with residential areas all over the city. Other exceptions from the general favorability of inner-city densification are freight-generating and area-demanding manufacturing industries and warehouses, which should rather be located close to suburban transport arteries than occupying inner-city sites more favorably utilized for higher-density land uses (Verroen et al., 1990). If one assumes that people will aim at reducing travel time, improve travel comfort or reduce direct expenses related to traveling, improvements in transport infrastructure could be expected to induce more traffic in terms of trip frequencies, trip lengths and travel modes. International research during several decades has demonstrated theoretically and empirically that whereas improved public transport, better cycling facilities and improved conditions for pedestrians contribute to reduce the number of car travelers, road capacity increase to make car traffic flow more easily contributes to a growing traffic volume (Mogridge, 1997;SACTRA, 1994;Litman, 2011). Building types associated with high density are, other things being equal, more in line with lowcarbon objectives than low-density building types. Multifamily houses require less energy for space heating and cooling per square meter than detached single-family houses (H\u00f8yer and Holden, 2001;Brown and Wolfe, 2007), and less material for the construction of the buildings themselves, sewers, cables and access roads (Burchell et al., 1998). By reducing the encroachments on surrounding natural areas, densification is also more favorable than sprawl in terms of maintaining the carbon sequestering capacity of forests (Lourenco et al., 2009). Admittedly, there are also negative environmental impacts of making cities denser. For example, densification tends to reduce the available intra-urban green areas (at least per capita) and may hence make it more difficult to set aside sufficient intra-urban pervious surfaces to adapt cities to a changing climate with more heavy precipitation. Inner-city densification also tends to increase the number of people living or working in the parts of the city most exposed to local pollution, noise and risk of traffic accidents. Unless particular measures (such as restrictions on auto use) are taken to counteract these conditions, densification may lead to unfavorable public health impacts (Naess, 2011b). Urban densification can hardly be characterized as environmentally friendly in an absolute sense. Compared to urban sprawl it is still less environmentally harmful (Newman and Kenworthy, 1999;Naess, 2001). Buildings are seldom, if ever, constructed with environmental protection as a main purpose. Instead, construction takes place to accommodate growth in the number of households, jobs, etc. and in the floor space per resident or employee. As the saying goes, you cannot make omelet without cracking eggs. In most situations fewer 'environmental eggs' will be cracked by densification than by urban sprawl. The negative impacts of densification tend, however, to be more pronounced the greater is the growth in the size of the building stock (Naess, 2011b). Several of the above-mentioned influences of urban structural characteristics on sustainability parameters have been subject to controversies in public debates. Defending their position against criticism of unsustainable traveling patterns, advocates of low-density and decentralized urban developmental patterns (including supporters of alternative urban sustainability ideals such as 'the green city' or 'the polycentric city') have often raised doubt about the relationships between urban form and travel emphasized by compact city proponents (see, e.g. Breheny, 1992;Williams et al., 2000;Bruegmann, 2005). It is also not uncommon to encounter debaters denying that road capacity increase in urban areas induces more car traffic. Such counter-claims must, however, be evaluated on their own scientific credibility. Often, they are based on transport modeling simulations where the results merely reflect the assumptions fed into the models. In other cases, skeptics have drawn general conclusions about non-influence of urban structure on travel, based on investigations of relationships between other urban structural characteristics (such as neighborhood-scale density) or other aspects of travel behavior (e.g. travel time instead of traveling distances or modal split) than those which, from theoretical considerations, could be expected to be the most important ones. Quite often, the counter-claims are raised by representatives of conservative think-tanks fearing that the research showing adverse environmental effects of sprawl and urban highway development could be used to change the status quo in urban development (Owens and Cowell, 2002; see also Jacques et al., 2008 for a wider account). Within academic scholarly work, there is rather overwhelming agreement that urban land use and infrastructural characteristics do influence greenhouse gas emissions from transportation as well as the other sustainability parameters discussed above (although the magnitude of the effects will necessarily vary, depending on the city context).",
            "Cities as objects of transition": " The so-called transition theory, dealing with transitions and system change and focusing particularly on technological transitions, has been developed mainly by Dutch authors since the beginning of the present century. Transition theory can be subdivided into three main directions: (1) a sociotechnical approach represented by scholars like Frank Geels and Johan Schot, where the focus is on ex-post studies of historical transitions, generally spanning several decades; (2) a complex system view represented by, among others, Jan Rotmans and Derk Loorbach; and (3) a governance perspective advocated by e.g. John Grin and Adrian Smith, focusing on transition management. The so-called multi-level perspective (MLP) is one of the most discussed transition concepts associated mainly with the socio-technical approach within transition studies. Within this strand, Geels and Schot (2007) have coined a typology of sociotechnical pathways. A key feature of this typology is a multi-level perspective (MLP), which understands transitions as the results of alignments between developments at multiple levels, reflecting variations of timing and nature of multi-level interactions. The multi-level perspective differentiates between three levels of analytical concepts: niche-innovations at a micro level, sociotechnical regimes at a meso level and sociotechnical landscapes at a macro level. According to Geels and Schot (ibid.,, the notion of sociotechnical regime refers to a broad community of involved groups including an engineering community, scientists, policy-makers, users and interest groups, their cognitive routines and their alignment of activities, resulting in development along 'technological trajectories'. Technological niches are the loci of emergence of radical novelties, brought forth by small networks of dedicated actors, often outsiders to or at the fringe of the existing regime. The sociotechnical landscape makes up a slowly changing exogenous environment that cannot be directly influenced by niche or regime actors. Key elements at this level are macro-economics, deep cultural patterns, and macro-political development (Geels and Schot,ibid.,p. 400). According to Geels and Schot, transitions happen as a result of interactions between the three levels. Niche-innovations can build up momentum through learning processes, improvements in price or performance, and support from powerful groups. In addition to being challenged by niche processes, changes at the landscape level can create pressure on the regime from above. Moreover, the regime itself can become destabilized due to inner tensions or pressure from outside, resulting in the emergence of windows of opportunity for niche-innovations (ibid., p. 400). In their development of the multi-level perspective, Geels and Schot (2007) use historical examples as illustrations. A common feature of these examples is that they involved a change from one type of artifacts (cesspools, horse-carriages, sailing ships, traditional factories) to a different kind of artifacts (sewers, automobiles, steamships and factories built for mass production), usually also involving a change in related infrastructures. For our study topic, defining the subject of transition is less straightforward. At the outset, cities include a multitude of categories of urban neighborhoods (high-density, low density, central, peripheral, etc.), building types (high-rise and low-rise, apartments and singlefamily homes, etc.) and transport infrastructures (motorways, metro lines, mixed-use streets, bus lanes, bike paths, parking areas, etc.). It is therefore problematic to define regimes if these are to be understood as single, dominating technological solutions. Moreover, it is difficult to envisage that a transition process toward sustainable cities would result in such monolithic solutions. As a technical artifact, a city is so to speak by its nature unstable. Transitions in urban built environment and transport infrastructure take place continually, since new buildings are each year added to the existing urban fabric, new roads and parking spaces are established, expanded or changed in other ways, metro and streetcar lines are sometimes opened or closed down, and road space is sometimes reallocated between different forms of transport, made unidirectional or opened for two-way traffic. Of course, the stock of steamships within a steamship regime for sea transport also undergoes change as new ships are built and old ones are taken out of use or wrecked. The changes regularly taking place in the urban built environment and transport infrastructure are, however, of a qualitatively much more extensive nature. This raises the question of what 'urban transition' is to mean in terms of transition theory. Arguably, 'business as usual' changes in the urban structure are not the kinds of transitions that transition theory is dealing with. Instead, what should be considered as urban transition within the perspective of transition theory are changes in the ways in which urban structures change. Such changes can be for the better or for the worse, seen from a sustainability perspective (cf. the discussion in the previous section). Often, the change will consist of a combination of positive and negative traits, i.e. change-elements contributing to bring the cities closer to the sustainability goals as well as traits of development pulling in the opposite direction. For the change to contribute to more sustainability, the sustainability-positive changes must dominate over the traits of development that are not in line with sustainability criteria. As criticized by Coenen et al. (2012), the historical narratives often used in transition theory analyses may create the impression of causalities merely based on sequences of events, where a deeper analysis uncovering the generative mechanisms and causal influences of structures as well as agency would be more appropriate. Giddens' (1984) structuration theory, which is referred to in much of the literature on MLP as far as structure-agency relationships are discussed (e.g. Geels and Schot, 2007) claims that structure and agency are mutually constitutive and cannot be analytically untied. In our view, this ontology directs the attention away from the specific properties and powers of structures and agents, respectively, and how they influence each other. Instead, an ontology should be applied which recognizes the relative permanence of social structures and the time-lag between structures' influences on agents' actions and the agents' actions serving to reproduce or transform the structures, such as the Transformational Model of Social Activity proposed by Bhaskar (1993) or Archer's (2000) morphogenesis model. As a particular kind of socially constructed structures, the built environment exerts its own causal influences. The permanence of the material urban fabric calls for a structure-agency ontology acknowledging the long-dur\u00e9e and path-dependency effects of the existing built environment on cityscape as well as its influences on daily-life mobility (Bhaskar, 1993).",
            "Challenges of applying the MLP perspective to a sustainable urban transition": " In line with Geels and Schot (2007) we consider it crucial to combine theories from various substantive fields in order to explain why certain niche innovations and regimes turn out to be successful while others never win through or are destabilized. Theories within the relevant substantive fields are in our view the basic ones when studying, for example, urban developmental processes, and many interesting studies of such processes have been carried out without the guidance of transition theory. Yet, we see the multi-level perspective as a fruitful descriptive framework and a device for structuring narratives about transition processes. However, when the subjects of change are high-complexity and context-dependent entities such as cities' built environment and concern the prospects for transition toward an environmentally more sustainable, low-carbon society, the multi-level perspective needs to be translated and adapted to cater for the differences such a transition process would represent, compared to the processes studied so far within this perspective. Below, some challenges of applying the multi-level perspective to processes of transition toward urban sustainability will be discussed. The discussion is based on a reinterpretation and inductive aggregation of experiences from previous case studies of urban development and does not purport to be exhaustive.",
            "The complexity, scale and context-dependency of cities": " Compared to the historical examples of multi-level interaction given by Geels and Schot ( 2007), the socio-spatial structures and mobility patterns of cities are arguably more complex systems. Unlike a technical invention, such as an automobile, cities are shaped in very different ways dependent on the natural, social, cultural, economic and political conditions. Cities vary very much in population size, composition of trades, affluence level, positions in hierarchies of central places, access to national or international transport infrastructure, etc., as well as in climate, land use in the hinterland, etc. Although, for example, automobiles are supplied in different sizes and brands, the content of the concept of 'car' is arguably less variegated and context-dependent than the concept of 'city'. The large scale of cities and the interrelatedness of new, environmentally sound elements of the urban fabric with existing, less environmentally favorable structures mean that positive synergies between different sustainability-oriented 'niche solutions' may not manifest themselves in current practice. For example, even if you build a new high-density residential district close to the city center, with a high number of workplaces and service facilities within short reach, the gains in terms of less car commuting can be reduced if, for example, some of the central workplaces are at the same time moving to a new office park at a car-based location on the urban fringe. In order to illuminate whole-scale transitions toward sustainable urban spatial structures, thought experiments in the form of scenarios for cities developed consistently according to sustainability principles over a long period will probably have to be constructed (see below). In this sense the city scale represents some particular challenges compared to analyses of transitions where the solution to be promoted already exists in fully developed form as a niche product (e.g. a heat pump system for utilizing the temperature of the underground for space heating or cooling). The complexity of cities implies that an assessment of whether or not a transition toward sustainability is taking place must be based on a range of indicators rather than just recording whether one kind of technological system is being replaced with a new system. The differences between 'technologies' (for example low-density versus high-density urban form) are often gradual, not categorical. It is therefore not straightforward to tell what should be considered -in a particular context -as a car-dependent versus a transit-oriented city, a high-density versus a low-density city or urban district, or a high or low provision of bike paths. The same applies to the changes in the spatial urban structure taking place over a period: how dense and centralized must, for example, new housing and workplaces be built, compared to what was built in previous periods, in order to justify a statement that a transition in urban development has taken place from sprawl to compact city development? For example, the population density within the continuous urban area of Greater Oslo increased by 27% over the period 1985-2011, with an increase of more than 40% within Oslo's Inner Zone. Does this represent a transition toward a sustainable urban form? Maybe in some respects, whereas other aspects (e.g. road development) have followed less sustainable trajectories, and the steady growth in building stock has contributed to increase the overall environmental load (Naess, 2011b). The relativeness of transition necessitates qualitative judgment in order to state whether a change in the trajectory of urban development is sufficiently significant to be called a transition (see also Hodson and Marvin, 2010).",
            "Multi-segmented regimes": " In most of the transition theory literature, transition is illustrated as processes within different arenas of society where one regime is by and large replaced with a new one (possibly after an interim period after the de-alignment of the old regime where several niche actors compete for the new regime position). When it comes to urban spatial structures and mobility patterns, the situation is less clearcut. Several different 'technologies' for, e.g. housing, neighborhood design and urban transportation often exist alongside each other with relatively stable market shares and without clear signs of some solutions replacing their competitors. Although some of the transition theory researchers who have addressed urban mobility talk about a 'car regime' (Zijlstra and Avelino, 2011), the car is hardly so dominant in urban transportation in European cities that it can be attributed a regime status on its own. According to Pucher (1990), West European cities were during most of the 20th century characterized by much higher degree of automobile-oriented policies and travel behavior than the Soviet Union and the East European countries, but at the same time by much lower automobile-orientation than the United States and Canada. A similar situation applies to housing, where single-family homes played a much stronger role in USA and Canada than in the Soviet Union and Eastern Europe, where apartment buildings were dominating. Again, West European cities were in a middle position. Pucher attributed the large differences between USA/Canada and Soviet/East Europe to a high extent to ideological differences (individual versus collective solutions), with the more mixed situation in West Europe reflecting more pragmatic, less ideologically fixed land use and transport policies (Pucher, ibid.). Our point here is that West European cities have inherited a building stock and transport infrastructure featuring different housing types and transport modes. Current land use and transport policies seem to a high extent to reproduce these multi-modal structures (see, e.g. Naess et al., 2011). The different components of this multi-modal mix (such as apartments, row houses and single-family homes within the housing sector, or infrastructure for cars, public transport and non-motorized modes within the transportation sector) could be viewed as solutions targeted at different market segments reflecting differences in income, household structure, lifestyles and attitudes. In a market-liberal society, offering products satisfying the preferences of different market segments is arguably one of the main tenets. Arguably, therefore, in contemporary (neo-)liberal European societies, sociotechnical regimes are increasingly becoming multi-modal rather than single-modal: there should be 'something for every taste'. Combined with the inherited material structures facilitating different modes of housing and other urban functions as well as transport, this speaks in favor of characterizing multi-segmented regimes as typical for urban land use and transportation in many European cities. In other words, the very nature of a regime can be its multi-modality (= offer something for all consumer segments). For example, according to the Danish National Infrastructure Commission (2008: p. 69), \"it is not about giving priority to one mode of transport rather than another one, but to ensure the correct combination of efforts\". Such multi-segmented regimes could be viewed as compromises (or agreed mix) between different 'technologies' reflecting a situation where no political ideology (individualistic or collectivistic) is completely dominant. Such a multi-segmented conception of regimes squares well with what we can observe in the urban land use and transport policies of many European countries, where investments in public transport like metros or light rail take place alongside with road capacity increases, and where new housing development has for many decades taken place as a combination of apartment buildings, row houses/terraced housing and single-family homes.",
            "Changing the composition of well-experienced old solutions": " Distinct from sociotechnical change where a dominant technological system is replaced with a new technology promoted by niche actors, the 'technologies' that could contribute to more sustainable urban development are not necessarily 'new'. They are often old and well-established (e.g. high-density urban districts, apartment buildings, bikes, streetcars, buses), but exist along with less sustainable 'technologies' and have too low 'market shares' compared to their competitors. Their market shares are still in most European countries not so low that they can be considered as being relegated to marginalized niche products. A transition toward a low-carbon and environmentally more sustainable society requires a departure from the combined (and ambivalent) development of environmentally less damaging and environmentally harmful housing types, transport modes, etc. characterizing current multisegmented regimes. At least, the market shares of the environmentally favorable solutions must be increased significantly at the cost of the more polluting and resource-consuming ones. Instead of stepping on the accelerator (building more roads) and the brake (improving public transport) at the same time, the foot must be moved away from the speeder in order to halt the racing toward higher greenhouse gas emissions and environmental encroachments.",
            "'Sustainable' and 'unsustainable' niche technologies": " In addition to increasing the shares of the environmentally less damaging housing types, modes of transport, etc., these modes should themselves be subject to 'green' innovations, e.g. in terms of improved energy and land efficiency, better adaption to climate change, etc. New urban development contributing to a particularly high degree to low carbon dioxide emissions from transport as well as from the buildings and with a high performance measured against other relevant sustainability criteria could be considered as 'niche products' in a sustainability transition perspective. So-called 'sustainable', 'car-free' (Scheurer, 2001) or 'smart' city districts are examples of this. However, it is important also to be aware that environmentally sound 'niche technologies' in urban development are not the only 'niche technologies'. The liberal principle of offering 'something for every taste' also applies to niche developments. Environmentally less favorable or outright unfavorable 'niche technologies' (e.g. information technology geared at diverting traffic away from peak periods in order to increase the total number of cars that can be accommodated on the urban road and parking network over the day) complement and counteract the new 'green' technologies. Such niche solutions, the actors promoting them and the vested interests they represent seem to be somewhat overlooked in the transition theory literature (yet there are exceptions, such as Cohen's (2009) analysis of the emergence of a highly unsustainable niche of personal aeromobility in the USA, and the call by Coenen et al. (2012) for a stronger focus on struggles between different interest groups each seeking to realize their desired version of the sustainable society). Sustainable urban development and mobility development is not only about promoting the environmentally less damaging niche technologies and products, it is also about actively constraining and shrinking the existence of the unsustainable 'products' -novel as well as old ones that are part of the multi-segmented regimes.",
            "The inertia of the existing built environment": " The overall built environment of a city normally changes very slowly. There is considerable inertia in the existing building stock and transport infrastructure, making radical changes in the environmental performance of the urban built environment a long-term affair. The existing infrastructure and buildings represent 'sunk investments' and create path dependencies that may only be overcome through strong and deliberate policies. A new 'technology' will have to co-exist with artifacts of the 'old regime' for a very long time before it eventually becomes dominating. Again, the situation is different from those mentioned by Geels and Schot (2007) in some of their historical illustrations of transition, where, for example, the horse-carriages, as well as their supporting infrastructures (stables, etc.) disappeared when electricity-based trams entered the scene -and the electric tram and trolley line cables in their turn were dismantled when the car became the dominant mode of transportation in the USA. Different niche solution for low-carbon and environmentally more sustainable built environments and mobility schemes will usually only change the overall urban structure marginally unless they are implemented consistently (ousting other, less favorable solutions) over a long period. We are not knowledgeable of any historical examples of cities where such a consistent process of sustainable urban development can be studied. It may be possible to learn from more or less favorable 'best practice' examples, but since these examples usually include a combination of more and less sustainable elements, the performance of a consistently implemented low-carbon urban strategy has yet to be seen. Needless to say, this represents a methodological problem in transition studies. Our suggestion is to combine case studies of actual urban development with backcasting involving normative sustainability scenarios and pathways towards their realization (see below).",
            "A transition towards non-growth of building stock and mobility?": " There is an element of technology optimism inherent in the traditional MLP conception of innovative, 'green' technological solutions developing in niches from where they can by and large challenge and replace the existing sociotechnical regime. Much of the literature on MLP and sustainability transitions seems to be permeated by a tacit assumption of continual economic growth. Although this assumption is often not made explicit, the focus on niche innovations has clear connections to the discourse of ecological modernization, according to which innovation can stretch and redefine ecological limits and the production can be redirected towards environmental goals in order to decouple economic growth from environmental degradation (Smith et al., 2010). But what if the problem is not primarily to add something new, but to change the composition as well as to shrink the overall volume of the urban built environment? As indicated in Section 2, 'smart' spatial/physical solutions for urban development are environmentally friendly only in a relative sense, not in absolute terms. Policies for sustainable urban development should therefore also problematize growth in building stock and in urban mobility. Today, changes in the urban fabric are usually the result of growth in the building stock and in the provision of infrastructure. Old material structures are rarely being removed to the same extent as new ones are added. Since growth in mobility and in the building stock, other things equal, contribute to increase the environmental load, a sustainable urban transition is usually framed as a matter of obtaining as high degree of decoupling (OECD, 2002) as possible between negative environmental and climate consequences and growth in floor area and mobility. This requires more environmentally sound ways of adding new elements of the built environment as well as environmentally sound refurbishing of the existing urban fabric. However, full decoupling over a long period of time is probably not possible (Naess and H\u00f8yer, 2009;Xue, 2012), and in a longer term stabilization or even decline in the building stock and mobility, at least per capita, will probably be necessary in order to obtain environmental sustainability. This might involve removal of the environmentally most damaging buildings, urban districts and infrastructures to compensate for new construction, and maybe even resulting in overcompensation (leading to shrinkage of the material urban fabric) if the built environment has reached a per capita volume beyond a sustainable threshold level. Such a non-growth agenda for building stock and mobility would, in our view, necessitate a shift in emphasis from niche innovations to current growth dynamics operating on the landscape level, which has in transition theory traditionally been treated as merely exogenous.",
            "Landscape-level conditions hampering environmental sustainability": " The task of envisaging transition from unsustainable to sustainable ways of developing urban built environment and mobility patterns is very different from that of describing, e.g. the transition from sailing ships to steamships. The latter could take place with less profound changes at the landscape level than those probably required for a transition away from the current practice of 'offering something for every taste', which appears to be closely tied to the prevailing neoliberal economic paradigm. Even more dramatic changes at landscape level would probably be required if we are to depart from the consumerism represented by ever-increasing mobility and consumption of floor area. As discussed by Geels et al. (2011) in a recent book on the prospects for transitions toward sustainable mobility, current traits of development at landscape level tend to stabilize rather than disrupt the existing regime within the domain of transport. The implication of this is that more attention than usual among transition theory researchers should be directed toward the landscape level and the need for changes at this level in order to enable sustainable urban transitions. Partly, this applies to the need for national-scale regulations preventing municipalities from adopting lax environmental regulations in order to obtain competitive advantages. Landscape-level analyses should, however, also include critical analyses of overall political-economic structures and mechanisms acting as driving forces towards generally increased consumption levels, single-family and car-based housing and mobility schemes, and weak urban land use regulations (Harvey, 2010). Notably, barriers to sustainability constituted by the capitalist economic system through its growth imperative, competition, uneven spatial development and aversion against regulations hampering environmentally harmful entrepreneurialism need to be addressed, as well as strategies by which these barriers could be overcome. Especially, this seems necessary if adherence to ecological limits (which may require zero-growth or shrinkage of the urban building stock and road infrastructure in wealthy countries) is to be combined with ensuring a decent standard of living for the least affluent inhabitants. In a shrinking total economy, there is a risk that low-income people will be locked in continual or even worsened poverty, unless this is counteracted by active redistributive policies. The above circumstances call for a focus on political niche actors and their strategies for transition, rather than technological niche actors and technologies. Some inspiration could perhaps be gained from Geels' (2011) discussion about the lessons learned from the history of political revolutions, as well as a host of other literature in the same vein.",
            "Backcasting the utopian sustainability": " Whereas most transition theory literature has arguably depicted sustainability transitions as something that is possible within the existing overall social structure, we think a transition involving departure from the prevailing growth paradigm is utopian in the sense that it cannot be realized under the present politico-economic conditions. Envisaging a development based on normative values differing markedly from those promoted by the presently most powerful actors therefore calls for a counterfactual approach. Backcasting in the form of the construction of normative, sustainabilityoriented future scenarios and analyzing the conditions and processes necessary for their realization seems to be a fruitful approach for concretizing the currently utopian (Dreborg, 1996;Vergragt and Quist, 2011). Examples of backcasting studies addressing urban sustainability include Naess (1993), Gullberg et al. (2007) and Gunnarsson-\u00d6stling and H\u00f8jer (2011), although none of these studies have applied conceptual frameworks of transition theory. The specification of the underlying assumptions of each scenario should be based on retroductive thinking, i.e. thought operations aiming to reconstruct the basic conditions for something (here: a possible future situation) to be what it is (Bhaskar, 2008). In scenario construction, this will require the use of qualitative knowledge about natural mechanisms, social contexts, causal complexes, and links between the different processes that together account for the trajectory of each scenario (Patom\u00e4ki, 2006). In line with Vergragt and Quist (2011), who call for a coupling of backcasting studies with sociotechnical transition studies, we recommend to envisage scenarios and pathways showing how environmentally sound 'niche solutions' (or maybe rather 'best-practice neighborhood-scale solutions', cf. above) for urban development could become dominating, what kind of resulting urban structure this would entail. A backcasting approach allows a view on short-term steps necessary to realize long-term scenarios and the contexts enabling or preventing such steps from being made. The magnitude of achievement compared to 'business as usual' as well as to the requirements of a truly climate-friendly and sustainable urban development should be crudely assessed. Such an assessment would also be necessary in order to judge whether the environmentally more sustainable 'best practices' and 'niche technologies' are sufficient -given that they become widespread -to enable continual growth in the built environment and in mobility or some limits to this growth have to be imposed in order to meet goals of environmental sustainability.",
            "The case of Fredericia, Denmark": " Below, some of the above-mentioned adaptations of the multi-level perspective will be illustrated with the provincial city of Fredericia in Denmark as an empirical case. The case, which is rather typical for urban development of smaller and medium-sized cities in Denmark, exemplifies the multi-segmented regimes within transportation and land use policy as well as the prevailing growth imperative as a landscape condition hampering more consistent advances toward sustainability. The case inquiry so far builds on the analysis of municipal as well as regional planning documents, strategic and visionary papers and meetings with local actors as well as an interview with the director of the Triangle Region in 2011. The municipality of Fredericia has a population of approximately 50,000 (of which 40,000 in the continuous urbanized area) and is a part of the polycentric Triangle Region including six municipalities with a total of around 350,000 residents. The Triangle Region is part of the so-called East Jutland Growth-Corridor, encompassing 17 municipalities from Randers in the north over Arhus to the Triangle Region in the south. Since 2006, this corridor has been given attention in national planning documents as a growth center along with Copenhagen Metropolitan Area (Ministry of Environment, 2006). Reflecting a general increase in the awareness about climate change and its consequences, many cities are aiming to take responsibility to tackle causes and adapt to conditions and so is Fredericia. The municipality plans to reduce its CO 2 emission by 25% in 2015 (with reference to 2006) and participates in a few climate initiatives launched within the Triangle Region's network (Triangle Region Denmark, 2009). However, the land use and infrastructure plans of Fredericia reflect no clear development strategy, continuing a trend of sprawling development with expansion of the urban area demarcation, while simultaneously planning for inner-city densification, notably the new city district 'Fredericia C'.",
            "Fuzzy transitions": " In order to analyze the spatial urban development in Fredericia we have adopted the general frame of the MLP with its three analytical levels. These would translate as described in the following: The Triangle Region as a municipal network has no authority power on municipal planning practice, however, relevant though are the mediations of planning approaches for the overall region and what is understood as valuable and necessary development. Here, landscape pressure is exercised by the general trends of coupling between economic growth and growth in transport, a culture where high mobility is seen as an important aspect of freedom, and the notion of competition between urban areas internationally, nation-wide (the East Jutland Growth Corridor versus Copenhagen Metropolitan Area) as well as between municipalities in the Triangle Region (especially Fredericia, Kolding and Vejle). Consequently, Fredericia values spatial expansion of housing and commercial development as competitive advantage and this is for example reflected in the municipal planning practice in the western part of Fredericia with a spacious zoning plan for urban expansion (residential and commercial) as well as a reluctance toward limiting the size of the vast areas already set aside for commercial and industrial development in the industrial park Danmark C. Both of these examples have concerns too. The highway infrastructure is understood as a logistic necessity for the industrial park and more generally as a major growth-generating asset of the region. The geographical context of the case municipality is as such interesting, because the region is promoting its location as logistic advantage and furthermore as argument for the expansion and construction of transport infrastructure being an important Danish transport hub (Fredericia Kommune, 2011). Generally speaking, the Triangle Region is one of the Danish regions with an outstanding high automobility and highly car-depended land use structures (Krawack, 2011). Fredericia though is under normative pressure from the environmental discourse. The municipality has formulated an ambition for transition towards more sustainable urban development and does take effort in implementing measures and stimulate processes. Currently Fredericia's focus is directed toward the urban transformation project Fredericia C, where a former industrial area at the harbor is redeveloped into a dense and multi-functional city district. This appears to be a positive transition towards more sustainable structures in urban spatial planning, and it is branded as a sustainable flagship project. Additionally, local mobility management projects concerned with travel to work, parking policies, buses running on alternative fuel or pilot projects introducing electric vehicles try to address a change in travel patterns and lower-emission transport towards more sustainable conditions. Certainly, the aspiration is there to develop towards more sustainable regime patterns in Fredericia, but this appears as slender chance under current conditions of a general lack of an integrated approach of land use and transport planning towards more sustainable mobility. Thus Fredericia C meets demands among people preferring multistory inner city living, but at the same time plans are made for low-density development geared toward another part of the multi-segmented regime. In Fredericia there are hardly any niche developments evolving within land use and transport infrastructure development. The only niche we can identify concerns the mobility management field. However, such niche development does neither affect the spatial urban development nor address transport demand reduction or modal shift; instead the efficiency and capacity problems of car travel are in focus. Unless these approaches are being backed up sufficiently, they risk to be inefficient or outweighed by more dominant practices of daily mobility patterns, car-lobbies or businesses in general that would lose profit through major changes. Thus sustainability initiatives run the risk of being subordinated to or coopted by a dominating strategy of increasing the city's economic competitiveness (Fredericia C, 2011). The transitions taking place in Fredericia and the Triangle Region may slightly adapt the regime structure to an increasing pressure to act more sustainably, but in the main the regime remains. This means that policies for more sustainable mobility are pursued under a general acceptance of the region's car-dependent structure, focusing on car-pooling, mobility management and zero-emission vehicles rather than aiming to make people shift from cars to other modes. To influence the 'mobility culture' of the Triangle Region would definitely call for greater transitions of the regimes for land use and transport infrastructure development, which would in their turn depend on significant changes on the landscape level. This will be illustrated in the scenario introduced below.",
            "Alternative prospects for Fredericia": " Below, an image of Fredericia's possible 'sustainable urban land use and transportation future' will be presented, building on principles introduced earlier in this paper and advancing these to meet the sustainability vision. The backcasting approach in this research will be development in steps: (1) creation of a rough normative scenario of the case development (as introduced forthcoming), which will be used as input in interviews, (2) further development with estimation by stakeholders and theoretical knowledge, and (3) final discussion and development of a sustainability scenario for the case. Steps 2 and 3 are still pending and the interviews will be carried out in the near future. Fredericia in 2050 reflects a clear separation between urbanized and non-urban land surrounding Fredericia and the encroachments on natural areas and farmlands is down to zero since the municipality focuses on available brownfields for development proportional to actual development needs estimated from a comparison of the available building stock and the expected future numbers of households and jobs. The new buildings are thus constructed to match demographic changes and changes in employment but not to accommodate increase in per capita consumption of floor area. Personal car traffic is banned from the inner city. Car-parking facilities are located on the fringe, outside Fredericia's historical town wall. Permission is given to businesses for unload goods only or other temporary traffic. There exists personal motorized transport in the rest of the city but with strict parking regulations. No further increase in road and parking capacity has taken place; instead some road lanes for car traffic and parking spaces have been reallocated to other purposes such as bike paths, lines of trees or building sites. Sydtrafik, the public transport network of southern Denmark, has extended its cooperation with the different transport suppliers in the region, such as services by Movia, Arriva and DSB. Mobility Management concentrates at first on transport demand reduction measures in their service and counseling, which is taking place in close cooperation to decisions in the housing and commercial sector, before improving capacity and efficiency. Accordingly planning approaches (a) reduce land consumption by re-using already developed areas as well as increasing the efficiency of plots due to higher density, (b) impose physical and fiscal restrictions on car traffic, (c) improve public transport services in the whole region and (d) with an on-going education of planning and political authorities as well as civil society they offer a different approach to growth with clear separation between needs and desires. Consequently the political climate and planning authorities go beyond technological solutions within the transport sector and towards a deviant mobility culture and norms.",
            "Key conditions and obstacles for realizing a sustainability scenario": " In this paper we have focused on the building stock and transport infrastructure and could identify major challenges in the existing multi-segmented regimes. Ensuring a consistent sustainability policy requires that multiple measures in many sectors (and regimes) have to play in concert to promote a more sustainable development. Efforts have to be taken to support evolving developments towards more sustainable urban form and transport while simultaneously regulating and preventing unsustainable practices and structures presently bolstered by powerful landscape conditions. The case reflects the need to critically approach the landscape level conditions for sustainable transition as well as the requirement for much higher degree of political steering. More radical niche development was faint, reflecting the strong position of the 'broadly customized' multi-segmented regime and dominant landscape influences. Pressure from political niche actors would probably be necessary to provoke and counter present unsustainable conditions and to gain momentum in the current regime structures, but such political niches are hardly yet to be found in Fredericia. Developing Fredericia towards the sustainability scenario requires an integrative and more regulatory planning of land use and transport, as well as measures to prevent competition from leading to 'a blind race for growth' without any holistic evaluation of its local and global environmental and social impacts. Hence a governance structure has to be prevalent that sets a clear regulative frame with strong national guidelines and regional embeddedness, e.g. a Triangle Region Plan as binding policy paper, with the ability to efficiently influence land use and infrastructure systems. State interventions, regional regulations, changed political agendas as well as changed responsibilities for planners would be crucial conditions for realizing less unsustainable futures, as well as more profound transitions of social structures necessary to enable these changes. The outlining of such a multi-governance structure was, however, not the focus of the present paper.",
            "Concluding remarks": " Transition theory offers, as we see it, a useful framework for describing processes of major sociotechnical change. However, the complexity, scale and context-dependency of cities, the relative permanence of the urban built environment and the strong vested interests, cultural norms and lifestyles associated with present modes of urban development present huge challenges to a transition toward sustainability, politically as well as analytically. The multi-level perspective needs to be translated and adapted to cater for the differences such a transition process would represent, compared to the processes studied so far within this perspective. Rather than depending on niche innovations, a transition toward a more sustainable urban development is a matter of changing the composition of existing multi-segmented land use and transportation regimes. Those well-experienced forms of built environment and transport infrastructure that are in line with sustainability objectives should be strengthened while those that are not should be constrained and reduced. The inertia of the existing built environment makes radical changes in the environmental performance of urban land use and infrastructure a long-term affair. Moreover, resource-saving technological solutions will hardly be sufficient to compensate for the environmental impacts of continual growth in the building stock and in mobility in a long-term perspective. This raises new challenges to the MLP. Notably, the current strong landscape pressure for increased consumption and individualized, resource demanding solutions, e.g. in terms of housing types and transport modes calls for a greater attention directed toward the landscape level and its interplay with regimes than what has hitherto been common in research inspired by transition theory. In particular, basic economic, social and discursive landscape-level structures should be addressed, drawing on relevant theories from each of these fields. Our case example (Fredericia and the Danish Triangle Region) also illustrates the need for curbing unsustainable parts of existing multi-segmented regime solutions as well as for integration of regimes within different domains, such as transport planning, housing policies, business development and land use planning. Due to the wide gap between present landscape conditions for urban development and those required to realize an environmentally sustainable urban development, the scenario method of backcasting could preferably be integrated into the analytical framework of sustainability-oriented transition studies."
        }
    },
    "10.1016/j.eist.2012.05.001": {
        "file_name": "112 Transition in South African water governance",
        "title": "Environmental Innovation and Societal Transitions",
        "abstract": "After apartheid, South Africa has stepped up to the challenge of reforming an inequitable water service delivery system to meet the needs of all citizens. We frame this systematic societal change as a transition in water governance. We argue that when evaluating this pathway of transition, we should not only look at the changes in water legislation and number with improved access, but also analyze the quality of the water service delivery in terms of different payment schemes, participation by local citizens and conflicts around equality of water provision. By analyzing power in transition studies, we explore the power dynamics at play in two regions of Johannesburg, namely Alexandra and Soweto. The paper highlights the need to explicate the politics of water service delivery and suggests opportunities to break the negative patterns in order to achieve equitable and sustainable water service delivery in South Africa.",
        "label": "Qualitative",
        "text": {
            "Introduction": " Following apartheid, South Africa was faced with the challenge of redressing the social and environmental imbalances of the past. As a water-stressed country, allocation of water has been tied to development and the changing political landscape of the country. The evolution of water service delivery and the political history of South Africa are inalienably related (Tewari, 2005). In the democratic dispensation starting in 1994, particular attention was paid to sectors such as water service delivery where services were previously distributed in a systematically inequitable manner across racial groups, with a specific focus on meeting the needs of whites and excluding Africans (Tewari, 2005). The new water laws sought to address the social inequities and environmental concerns of the earlier political periods. The National Water Act of 1998 repealed over 100 water acts and related amendments and extinguished all previous public and private rights to water (s. 4 and Schedule 7, RSA, 1998). The significant change brought about by the new legislation was the recognition that water is a scarce and unevenly distributed resource, belonging to all people and no discriminatory law should be established to prevent water access and that sustainability should be the aim in distribution through which all users could derive benefits (RSA, 1997). In 1994, the new government thus had the responsibility to sustainably manage the water resources for the benefit of all people according to the constitutional mandate (s. 3, RSA, 1998). We conceptualize the overall dynamic patterns of change in water governance in South Africa since 1994 as a transition toward sustainable and equitable water service delivery. Transitions are systematic, complex and long-term societal changes comprising multiple actors at different scales and levels (Geels, 2011;Loorbach et al., 2011). We approach the distributional effects of the water service delivery reform by analyzing the payments for water services and the mechanisms of service delivery provided in two former townships2 in the City of Johannesburg, namely Alexandra and Soweto. In these two cases, we particularly examine the exercise of power in the processes of social and legal mobilizations with the aim of providing a contribution to the analysis of power in transition processes. The paper is organized to provide a brief introduction to the methodology of the research in Section 2. This is followed in Section 3 by a discussion of transition heuristic including different conceptualizations and criticisms of the transition framework. The latter part of the section focuses on the role of power analysis in transition heuristic. Section 4 first traces the transition in water service delivery in South Africa and then addresses whether the transition is in lock-in or acceleration phase by examining the power of agents in shaping water service delivery. Section 5 provides reflections from the case studied and discusses opportunities to strengthen the power dimension in transition studies.",
            "Methodology": " The analytical framework to study power relations in connection with the water service delivery reform in South Africa was drawn from a literature review of transition studies, and academic writing on the transition framework. This analytical framework is tested through a study of water service delivery reform in the city of Johannesburg. This process offers useful material to study a social change as there has been an explicit transition from the pre-to post-apartheid system of water service delivery. The examination on water service delivery within two former townships of Alexandra and Soweto in the City of Johannesburg represent cases of previously disadvantaged areas, characterized by the inequalities that are the focus of reform process. The main data sources for this study consisted of water policy documents for the Republic of South Africa and reports and papers on the payments for water services in the city of Johannesburg. The mechanisms of water service delivery (i.e., the way water is accessed by households either through standpipes, shared taps or taps in houses) were investigated via interviews and field observations. Since Alexandra, in comparison to Soweto, is less studied, and limited data is available, we carried out more primary data collection in this case. We had five in-depth interviews in three different parts of Alexandra (namely Tsutsumani, East Bank and Old Alex) over two weeks of fieldwork. The respondents were identified through a stratified sampling approach where we first identified the different water service areas in Alexandra. A random sample was selected within these stratified areas based on people's availability and willingness to talk to the researchers. Some of these interviews were conducted through a translator who was fluent in Zulu and English. In addition, we carried out five indepth interviews with experts in the field including a manager from the city of Johannesburg, a water engineer from the Department of Water Affairs and Environment, director of the Water Research Commission, manager of the Alexandra Renewal Project and a development facilitator in Alexandra. These individuals were identified by the authors for their expertise and direct knowledge of water service delivery in the area. Given the rich literature available in the case of water service delivery in Soweto, we only conducted a few narrative walks with the residents of Phiri to gain a better understating of the implication of using pre-paid water meters",
            "Theoretical framework": "",
            "Transition heuristic": " The patterns of change in water governance in South Africa are characterized by a complex and longterm process comprising multiple actors at different scales and levels. This process entails changes in technology, culture, policies, politics, power and economics where a wide range of vested interests are involved to promote particular solutions, policy instruments or packages. The complexity and multifaceted characteristics of this process, so called transition, requires interdisciplinary frameworks that can explore processes of change from different disciplines and societal perspectives (Geels, 2011;Loorbach et al., 2011). In analyzing the change in the South African water governance system, from an old and inequitable to an (envisioned) modern and equitable water access in the city of Johannesburg, we employ transition heuristic (framework). This is useful in three ways. First, it provides a frame to discuss differences in perception, ambition and understanding of objectives of transition as normative goals, and to orient these aspirations into efforts in a systematic way (Meadowcroft, 2011). Second, transition heuristic is a flexible framework meaning that different theories and concepts can be combined to explore the intricacy of interactions among critical components of a water governance system, i.e. water legislation, policies, and reforms, civil society, policy makers and water organizations (Geels, 2010). By incorporating different social theories on transitions, a comprehensive picture of change processes can be generated and used to assess the water governance practices. Third, transition heuristic compiles a practical toolbox of participatory techniques to choose from and scale up successful experiments to achieve the governance objectives (Rotmans and Loorbach, 2009).",
            "Conceptualization of transition": " From a multi-level perspective, transitions can take place when developments at landscape (macro), regime (meso) and niche (micro) levels move in the same direction (Geels, 2002). Landscape acts as a peripheral structure in which regimes and niches interact with each other. Developments at this level are relatively slow and correspond to the broad societal trends (Geels, 2002;van der Brugge et al., 2005). Landscape pressures can be identified at different scales. Climate change, population, international agreements, and MDGs are some of the driving forces from the landscape level on the current water institutions as regime actors in South Africa. The global and national approaches to these issues form dominant discourses that bound the policies and programmes of water institutions in South Africa. The regime may be defined as any form of rules enabling or constraining human activities within communities such as economic rules, legislation or social conventions (Foxon, 2002;van der Brugge et al., 2005). The regime actors may include different entities of the state, such as the Department of Water Affairs (DWA) at national level, City of Johannesburg and Johannesburg Water at local level and so on that are explained later in the 4th and 5th sections of the paper. Niches include organizations, individual persons or innovations instrumental in the take-off of the new regime (Foxon, 2002;van der Brugge et al., 2005). The niche pressures can be described as the experiments and projects formed by a small group of agents that deviate from the regime. These experiments can be scaled up by different means such as technological innovations or through different types of social mobilizations. Until recently, there has been limited discussion of the role of power, incorporation of theories of power in transition studies or application of techniques that uncover power dynamics in transition frameworks (Lawhon and Murphy, 2012;Meadowcroft, 2011). Although power and politics are key aspects of any change process, most research has focused on socio-technological transitions with less emphasis on socio-political transitions. Neglecting power in transition analysis brings the risk of ignoring important determinants of social change, and the distribution of costs and benefits within society. Hence, in this paper, we focus on the niche experiments in a more socio-political context than a socio-technological one by exploring the political dimension of transition and the interplay of power between and within different levels. From a multi-phase perspective, the transition trend is the consequence of shifting from one dynamic state of equilibrium to another. This conceptualization of transition as an S-shaped curve is built on diffusion of innovations theory wherein the process of system transformation or regime-shift unfolds over time (de Haan and Rotmans, 2011). Comprising four main phases, pre-development phase is the first stage of transition where the marginal changes happen in the system's background and do not have any impact on the status quo. Second is a take-off phase in which the structure of the system starts to slowly change. Third is an acceleration phase where the new pattern of the system becomes visible because of accumulation of the changes in the previous stages. Finally, there is a stabilization phase where the rate of fluctuation is marginal, and the net effect of any changes is neutral (van der Brugge et al., 2005). We look at the indications of temporal phases not only in terms of progressive changes in water legislation but also their actual and practical implementations in our cases as illustrated in the fourth section of the paper. Although the multi-phase perspective is often portrayed as a linear, progressive trend, the conceptualization does acknowledge that trends can stall or be reversed. Within the transition heuristic, it is assumed that transitions (toward acceleration) are driven by two mutually reinforcing mechanisms. First is the destabilization of the dominant regime due to landscape pressures, and second is the emergence and up-scaling of niche experiments, e.g., in terms of policy, behavior, technology, etc. (van der Brugge and Rotmans, 2007). In the absence of one of these mechanisms, transition pathways may turn into a lock-in situation. In transition studies, lock-in is considered as one of the transition pathways in which the regime is able to maintain and reproduce its internal dynamics (Geels, 2002;Rotmans and Loorbach, 2009). This can be seen as an exertion of power by the current regime to prevent a change in the status quo. As a result of this process, a set of actions and strategies that could be taken in the future will be limited or constrained by the current regime practices (i.e. actions taken by the regime actors, including institutions). In addition to this \"non-ideal\" transition pattern, there is a risk of \"reverse\" transition wherein niche experiments fail to become the new mainstream, and the system will return to its earlier state. This \"backlash\", is identified as a possible transition pattern and a special case of lock-in (Geels, 2002;Rotmans and Loorbach, 2009). It is suggested that it is at these points that overt conflict occurs and the influence of different actors diverges. Using a multi-phase perspective can offer an opportunity to identify moments of contestation and changing power relations during a transition.",
            "Criticisms": " Avelino and Rotmans have offered one of the first explicit attempts to conceptualize an analysis of power in transition research. The attempt with this conceptual framework is to move away from the abstract and introduce useable definitions of concepts of power. The intention is to offer a framework that explicitly encapsulates the range of resources and power exercises so that it can be applied across different types of transitions. Their attempt runs the risk of over-simplification, and it can be criticized for its limitations and biases. Firstly, the labeling of types of power is done in relation to types of actors. Power is thus seen to exist only in relation to how actors mobilize resources. This is a limited view of power and the typology may be restrictive in application. The definition differs from that of Parsons where resources are mobilized by the system (Parsons, 1967). There is thus greater emphasis in the new framework on the role of agency which downplays inherent power of resources. Secondly, there is a lack of recognition of heterogeneity within levels. There is a risk of creating bundled actor categories when in fact there can be a great diversity of actors at different levels. This may result in ignoring potential conflicts within levels as well as the cooperation between some niche and regime actors. A further limitation of the framework is that resources are viewed as power neutral. This may be simplistic if one considers that resources themselves may have a materiality that affects relations (Bakker and Bridge, 2006). Given the wide-ranging perspectives on power, there are many additional criticisms that can be raised against the framework. Nevertheless, we believe in the merits of this first attempt, and apply the Avelino and Rotmans framework to test its usefulness in the analysis of the transition of water service delivery in South Africa. Looking at the different strategies for water service provision in the city, and especially within former townships of Alexandra and Soweto, it is possible to identify different resources and tactics mobilized by niche and regime actors to exert power. This influences the nature of the transition in water service delivery in South Africa and influences the equity of the system.",
            "A perspective on power dynamics and transitions": " In the first editorial of the Journal of Power, Haugaard and Malesevic (2008) discuss the ubiquity of power and raise a fundamental challenge to the study of power, namely, that it is \"all around us, part of the everyday, and hence invisible to the taken-for-granted natural attitude of social practice\" (Haugaard and Malesevic, 2008). This has resulted in conceptual and theoretical diversity in the examination of power. Power can therefore be viewed as an example of Wittgenstein's term 'family resemblance concept' so that when we use the concept in different contexts, its meaning changes sufficiently so that there is no single definition of power which is covered by all usage (Haugaard, 2002). Haugaard (2002) identifies a broad classification of power theory which includes normative political theory of the analytical conceptual variety (Barry, Dahl and Morriss); political theory building of a non-conceptual variety (Aristotle and Arendt); and social theory of modern (Marx, Weber and Bourdieu) and postmodern orientations (Nietzsche and Foucault). This classification offers different language games which theorists employ. The challenge in entering the power debate lies in moving between the different theoretical approaches to power whilst being cognizant of the subtle variation between them. For a summary of the different theoretical works, see (Avelino and Rotmans, 2009;Haugaard, 2002;Murphy, 2011). This challenge of terminological subtlety as well as the fact that a great deal of power theory has a high level of abstraction seems to have deterred researchers from engaging with the complexity of analyzing power in transitions (Inglis and Bone, 2006). The research study \"Power in Transition\" is an attempt to elaborate power dynamics in relation to the transition framework (Avelino andRotmans, 2009, 2011). Avelino and Rotmans' approach to power can be characterized as lying within the realm of social theory of modern and postmodern orientation. The framework attempts to explicitly conceptualize the role of power in transition studies and connect the study of power to material realities (Avelino and Rotmans, 2009). The framework draws on the work of power theorists, most notably, Luhmann (1995) who views power as a social medium (Luhmann, 1995). Drawing on Parson's (1967) definition, Avelino and Rotmans (2009) define power as \"the ability of actors to mobilize resources to achieve a certain goal\". A departure from Parson's definition lies in the idea that resources are mobilized by actors rather than by the system and that the goal could be either collective or in one's self-interest (Luhmann, 1995;Parsons, 1967). Resources are defined broadly by Avelino and Rotmans (2009) and can include persons, assets, materials or capital including human, mental, monetary, artifactual and natural resources. Each type of resource can be the object of power to more or less extent. The resources are themselves considered 'power neutral' but become 'power-ladened' when they are mobilized by actors to reach certain goals (Avelino and Rotmans, 2009). How resources are mobilized is explained in the framework by looking at a typology of power exercise. Here, different ways in which one can mobilize resources and the different levels these are enacted are used to distinguish five types of power (Avelino and Rotmans, 2009). \u2022 Innovative power: the capacity of actors to create or discover new resources. An example includes the development of new institutions for water management such as the river basin commission or catchment management agency. \u2022 Destructive power: the ability to destroy or annihilate existing resources. An example includes ability of upstream users to restrict water access for downstream users thereby destroying their water supply from rivers. \u2022 Constitutive power: the ability to constitute (establish, institute or enact) a distribution of resources. An example includes transboundary river agreements which create new ways of managing water that extend beyond national institutions. \u2022 Transformative power: the ability to transform the distribution of resources, either by redistributing resources and/or by replacing old resources with new resources. An example includes the constitution of river basin organizations which re-organized the distribution of water resources and institutions around the physical river resource. This changed the way water management is viewed. \u2022 Systemic power: the 'combined' capacity of actors to mobilize resources, for the survival of a societal system. An example includes the system of water rights and permits that may exist in a country to allocate water for different uses. The system only works because of the mobilization of resources by actors within the system to support its functioning, even if the goals of individual actors may not represent a collective goal. Both regime and niche level actors can exercise power. In this exercise, it is possible to identify two dimensions, namely, the nature of mobilization: constructive versus deconstructive and the level of mobilization: resources versus the distribution of resources (Avelino and Rotmans, 2011). Constructive mobilization brings in resources through innovative power and the distribution of resources is through constitutive power whereas deconstructive mobilization brings in resources through destructive power and distribution of resources is influenced by transformative power. The former is a process of creation and building up new systems whilst the latter is a process of destruction and breaking down of old systems. In the process of applying different forms of power, regime and niche actors are able to influence a transition process. For example, niche actors may apply innovative power to produce alternatives to the status quo whilst regime actors may apply constitutive power to work to maintain the status quo. In mobilizing resources to exercise power, actors must have access to resources; strategies to mobilize resources; skills to apply those methods; and a willingness to do so (Avelino and Rotmans, 2009). According to Avelino and Rotmans (2011), their most important lesson for transition studies, and 'sustainability governance' more generally, is that antagonistic power dynamics and relations (i.e. overt critical debates, resistance, disobedience and political conflict) are essential elements for bringing about change and making 'transitions' occur.",
            "Transition in water service provision": "",
            "A historical overview": " Southern Africa is overall a water scarce region and projected to become more so over time (Hallowes et al., 2008). During the period of apartheid, water service delivery as well as other services were managed through a system of separate governance (Swatuk, 2010), which led to very unequal levels of service in 1994. The new ANC-led Government faced significant challenges for water services, with approximately 15 million people without access to safe water and 20 million without access to adequate sanitation (DWAF, 2006). In this section, the history of reconstructing the water services sector in South Africa, and thereby in the city of Johannesburg, is traced using a transition framework.",
            "Pre-development phase": " The first stage in the transition is the pre-development phase where changing socio-environmental conditions impinge on the regime structure. It is not possible to observe any important change of the regime but its resilience decreases. The political struggle from the 1950s and the shift to a democratic state in 1994 in South Africa, was one of the pivotal elements that imposed stress on the centralized and authoritarian water management system. The management of water in South Africa was in keeping with the apartheid policies of the time and there was thus differentiated access across the city of Johannesburg based on racially created spaces for White, Black, Indian and Colored residential areas (Hemson, 2002). Throughout the struggle period against apartheid, civil liberty struggles were coupled with the demand for legitimate housing areas for Black South Africans, especially in urban centers in South Africa (Desai, 2002). Townships such as Alexandra faced the risk of demolition and the removal of residents to homeland areas or designated townships. In turn, townships formed centers of political activity for the liberation movement. Post-apartheid, the newly formed Government of National Unity faced the challenge of addressing the inequality in the provision of basic services. Guiding the process was a set of policies that laid out a vision and mission for South Africa's future. The key documents included the Reconstruction and Development Programme (RDP), and the Constitution of the Republic of South Africa (RSA, 1994(RSA, , 1996)). These policies established the sustainability vision (including equitable access to water) in the transition from the apartheid to post-apartheid state. The Constitution states that, every South African has the right to basic access to safe drinking water (RSA, 1996).",
            "Take-off phase": " The second stage (take-off phase), in which the structure of the system starts to change, included the creation of new institutions and a new policy environment for water service delivery. The action that led the take-off phase was the introduction of the new National Water Act in 1998 and the policy of free basic water in 2001 (DWAF, 2002). The Constitution provided the basis for these policies. Through the co-operative government model laid out in the Constitution, the duty of water service provision was delegated down to district and local municipalities. This shift required that the City of Johannesburg, as a representative of the state, became responsible for ensuring that all its residents had access to safe drinking water within 200 m from their home (DWAF, 2002). The administration introduced new ways of mapping the city, different from the racial divides of the past. The city has been divided into seven service delivery regions (Fig. 1) including Region E of Sandton/Alexandra and Region D of Greater Soweto which form the focus of this study. The City of Johannesburg, as the municipal authority is responsible for water service delivery has established Johannesburg Water as its utility responsible for water and sanitation services (City of Johannesburg, 2010b). Johannesburg Water was established in January 2001 as an independent company, the city of Johannesburg being the sole shareholder. In keeping with global Integrated Water Resources Management principles of managing water as an economic good (Dublin Principles), Johannesburg Water operates under a neoliberal corporate model and provides services along business principles, with the aim of ensuring customer satisfaction and cost recovery (Johannesburg Water, 2011). Annual turnover exceeds ZAR1.6 billion (City of Johannesburg, 2009). The full cost-recovery mechanisms are also endorsed by municipalities as they have been under tight fiscal pressure imposed by national government to be self-sufficient. This pressure is the result of withdrawing central financial support based on landscape level actors such as the World Bank and IMF's advice on decreasing grants and subsidies to local governments (Dugard, 2010). The impact of following the advice has been directly on municipalities' basic services including water and electricity (Dugard, 2010). As mentioned earlier, water service delivery and infrastructure for different population groups varies across the city of Johannesburg (Fig. 2). Although Johannesburg Water operates as an independent company, the plan for payments for water services is varied according to the needs of residents (City of Johannesburg, 2010a;Gauteng Provincial Government, 2008). Most households in Johannesburg are charged for water on a progressive scale with the cost per kiloliter of water increasing with increasing volumes consumed per month. In all cases, the first 0-6 kL per connection per month are free (City of Johannesburg, 2011). Other households across the city qualify for Expanded Social Package benefits of water and depending on the indigent category they fall into, are able to get an additional allocation of free water per person per day (City of Johannesburg, 2008a). In certain areas, previously deemed consumption areas under the Gcin'amanzi Project, domestic charges are based on a slightly lower sliding scale but water is pre-paid using a metered system (Johannesburg Water, 2006). Although many new institutions have been introduced, the process of reform there is still a significant challenge to redress apartheid era access which perpetuates according to race as reflected in Fig. 2.",
            "Acceleration or lock-in phase?": " The third phase in a transition process is the acceleration phase where the new pattern of structural change becomes visible due to accumulation of socio-cultural, economic and institutional changes in the previous phases. This includes the transformation of power from the traditional regime toward the new regime. At present, it is difficult to say whether acceleration has been achieved or a lock-in situation has occurred. If we consider progressive water legislation as the only indication of the new regime pattern, one could argue that South Africa might be at acceleration stage toward an equitable water service delivery. Nevertheless, the effectiveness of this human rights approach on paper to result in an equitable water provision has been questioned. For example, Bakker (2007), points out the barriers to implementing a \"right to water\", such as lack of clear responsibility and capacity for implementation as well as potential abuse of the concept by governments to over-allocate water to privileged groups at the expenses of other people and also the environment (Bakker, 2007). It is also argued that human right approaches have had little practical impact on tackling the inequality of water distribution in South Africa (Bakker, 2007;Bond and Dugard, 2008). In this sense, one can argue that the regime is in a lock-in situation if institutional changes in water governance have not changed water distribution effectively in term of equality of water access. As might be seen from the account above, the distinction between different pathways of transition is linked with a set of indicators used to assess the process. We assess the direction of transition not only based on progressive water legislation, but also testing whether there is equitable water service delivery across the city of Johannesburg. Focusing on two areas in the city, namely Alexandra and Phiri in Soweto, we discuss whether the acceleration phase is reached or the transition pathway is in a lock-in situation given the power relations at play between actors at different levels 4.2. Transition dynamics and power in the city of Johannesburg",
            "Water services in Alexandra": " Alexandra is characterized by high population density, fast population growth, a young population, elevated levels of unemployment, relatively low levels of education, and low incomes (De Wet et al., 2001). The physical area of Alexandra is divided into 10 unofficial areas for purposes of development initiatives. These areas represent different forms of housing in Alexandra and include formal houses, yards with numerous houses, apartment blocks and informal shacks (De Wet et al., 2001). A representative of the Alexandra Renewal Project said that all of Alexandra has access to water and the entire area has water infrastructure connections (Fenn, 2010). However there are major differences in water infrastructure amongst different areas. During site visits, we found that households in flats, East Bank and River Park have piped internal water. Those in Setswetla, hostels and Transit Camp share communal taps. In Tsutsumani, households have internal and yard taps. On paper it seems as if the requirements of water service delivery are being met however the disparity between service levels is significant (Fig. 3). One-fifth of people still rely on free communal taps which require walking from houses to collect water in buckets. A significant improvement was made post-1994 in providing water services by including a tap and toilet on each stand in Alexandra. However, the Alexandra Benchmark Survey in 2006 as well as our own numeration during fieldwork in 2010 showed that on average there are 19 households per stand in Old Alex. This translates to approximately 133 people sharing the same tap and toilet as compared to 7 people per house in the East Bank or less than 5 in houses in Sandton (where additionally, each house is likely to have more than two taps and toilets). In Alexandra, we found the full range of payment schemes used by Johannesburg Water with the exception of the pre-paid meters. Some interview respondents paid according to the progressive scale, others benefited from the free water allocation under the Expanded Social Package whilst still others used communal taps. People in the informal settlement of Setswetla were also observed to be using the Jukskei River for washing needs. This is in keeping with the Alexandra Benchmarking Survey which found that household expenditure on water and electricity varied significantly across the different housing areas with only 4% of people living in Marlboro warehouses spending money on water and electricity (average expenditure of ZAR 6) while over 99% of households in East Bank included expenditure on water and electricity (average expenditure of ZAR 251) despite over 90% of households in Alexandra being connected (ARP, 2005). Interestingly, only 14% of households had ever had their water or electricity disconnected for non-payment. Overall, our findings suggest that water service delivery has improved in Alexandra but the improvement is unevenly distributed across the former township and more so when one considers Region E as a whole. Payment for services is not consistent in Alexandra. Although there was variability in the distribution of water service infrastructure within Alexandra, it was interesting to note that all interview respondents expressed satisfaction with the level and mechanisms of water service delivery (note, the interviews did not include residents from Setswetla but did cover the other main housing forms in Alexandra). Considering how varied access was, we as outsiders anticipated that people would express a wish to have the higher level of service delivery represented by the tapped water in formal housing structures found in East Bank. As this was not the case, one can ask why this situation is perceived as acceptable. The target of access within 200 m of a household makes perhaps sense in South Africa because of the limited water service during apartheid. However, the innovation of 200 m access enabled the further entrenchment of inequality of access and potentially obstructed the replacement of the older disparities by a new system of equal access. Many residents of Alexandra may feel that some tapped water is better than nothing but the level of service is not comparable to former white, colored and Indian areas. This would be an example of innovative power that 'enables' and 'enforces' constitutive power, meanwhile preventing transformative power (Avelino and Rotmans, 2011). The City of Johannesburg and Johannesburg Water have unintentionally reproduced traditional paradigms and structures that are used to reinforce the inequality in the water services system in South Africa. This has counter-productive results in terms of meeting the sustainability aspirations of creating intra-generational equity. The subject of cost-recovery and payment for water services has been much debated in connection with poor communities across the world (Desai, 2002). We suggest that payments for water services is an important element in the transition in the South African water sector as it determines water access and raises questions of equity. We found that in Alexandra, many households did not pay for water, with some such as those people living in warehouses accessing water illegally according to one of our interview respondents. In an area with very high unemployment rates, inexpensive or free access to water is a significant benefit to households. However, this situation represents a great dependency of citizens on the state for basic needs. Most of the decision making authority to determine financial support and allocate water dispensations is held by the regime actors, City of Johannesburg and Johannesburg Water. According to the model of co-operative government in South Africa the local tier of government can decide how best to allocate resources internally (RSA, 1996). The establishment of the Alexandra Renewal Project also introduces a top-down influence and an additional regime actor into the agenda setting and decision making processes surrounding water service delivery in Alexandra. Both the identification of Alexandra for the renewal project and the decision to subsidize water in the area were made by regime actors and not through any direct intervention from the local residents. One of the interview respondents suggested that she was not aware why residents paid different fees for water. At present, the government seems prepared to subsidize the cost of water to Alexandra but if financial resources are reduced or diverted elsewhere, many households in Alexandra will be unable to pay for water and therefore lose access. The power of the regime actors to determine resource allocations may prove unsustainable if the financing for water services change in the city. The regime actors in the transition in water service delivery in Alexandra have mobilized natural and economic resources in a constructive manner to constitute a sanctioned discourse and approach to payments for water services and economic cost recovery that is in line with international norms of Integrated Water Resources Management. The state has by far the greater access to resources, strategies to mobilize financial, technical and human resources, skills to apply these resources to water service delivery as compared to citizens and the willingness to do thus creating the conditions for the exercise of power (Avelino and Rotmans, 2011). By framing the transition in terms of power, it uncovers an imbalance in the relationship between the state and local citizens (regime-niche interactions) in relation to the development processes of Alexandra. Under the banner of the Alexandra Renewal Project, the re-development of the area has been placed into the hands of outside experts, albeit with some engagement with local residents. Citizens' power and ability to mobilize economic and human resources has been reduced whilst the state's systemic power in managing development in Alexandra has expanded. \"For destruction to be an act of power, it must be visible\" (Avelino and Rotmans, 2009), but this does not necessarily involve violence or physical force. The destruction of resources, in this case, can be exemplified by destroying mental resources (e.g. an idea, a belief or knowledge) that may not be visible from an insider perspective. Residents seem to accept the disparate service levels across Alexandra and did not express a desire for more standardized service delivery. This is in line with the exercise of ideological power which prevents people, to whatever degree, from having grievances by shaping their perceptions, cognitions and preferences in such a way that they accept their role in the existing order of things, either because they can see or imagine no alternative to it, or because they see it as natural and unchangeable (Lukes, 2005). During the apartheid struggle, residents of Alexandra were actively engaged in the development of their community including providing services not provided by the state. In the current situation, regime actors in the form of the Alexandra Renewal Project and City of Johannesburg drive community development and local residents are less cohesive as a community. As outsiders we find that power exercised by regime actors has been destructive in a sense that has ignored the role of niche actors and their capacities have ultimately become neglected. Power has been exercised in creating a sanctioned discourse but also through organizing participation of local citizens through regime-led participatory initiatives. External actors have been brought into the area to lead the development process and decisions regarding resources are made at national and local government levels by regime actors. This finding is in line with the research pointing out that development agendas in disadvantage areas, as in Alexandra, pay little attention to local experience and knowledge (Mayekiso and Bond, 1996). The nature of mobilization of niche actors is thus limited and becomes deconstructive or disempowering.",
            "Water services in Soweto": " Soweto, the second case is also a township that was once established on the borders of the city of Johannesburg and has now been incorporated into the City of Johannesburg. Situated in Region D, Soweto has 15% of the city's informal settlements with an approximate total of 12 809 shacks and 1 300 000 people (City of Johannesburg, 2009). Johannesburg Water is responsible for the provision of water and sanitation to Soweto, ranked as one of the highest water consumption areas in Greater Johannesburg (City of Johannesburg, 2009). The situation in Soweto and particularly within the neighborhood of Phiri is used here as a comparison to Alexandra. The management of water service delivery in Soweto is contrasting sharply to Alexandra especially in terms of payment for water services and social mobilization of local citizens. Although the situations vary greatly between the two areas, a comparison is appropriate given that both lie within the city of Johannesburg and share similar socio-economic characteristics. In theory, they should therefore be managed according to the same strategy and policies of water service delivery by the City of Johannesburg and Johannesburg Water. In Soweto, similar to Alexandra, water services have historically been of a low standard and efforts were made from the mid-1990s to upgrade and improve water infrastructure. Problems with economic cost recovery rose for Johannesburg Water due to the inability of residents to pay for their water use. Cost recovery was exacerbated by water losses due to old infrastructure in the area. The over-riding market logic to ensure cost recovery led Johannesburg Water to introduce a different approach to managing water service delivery. The Operation Gcin' Amanzi pilot project was introduced in mid-2001, to physically restrict water consumption in Phiri, one of the poorest suburbs in Soweto (City of Johannesburg, 2008b;Dugard, 2010). Based on the project objectives, a household could purchase additional water credit by means of pre-paid meters if the water consumption exceeded the obligatory free basic water allocation (6000 L of water per household per month or 25 L per person per day of free water) (Johannesburg Water, 2006). The Phiri water right case in Soweto can provide us with insights on the power relations between the local citizens and the government in the city of Johannesburg. Johannesburg Water successfully promoted the pre-paid meters in all the communities in Soweto through a participatory process that was perceived as flawed (Barnes, 2009). Council employees were the main participants in stakeholder meetings and a majority of households were not consulted at all about the pre-paid meters (Barnes, 2009). The residents in Soweto were informed that the only way of receiving their free basic water allowance and having their debt written off, is through pre-paid meters while the normal credit meters (promoted in rest of Johannesburg) or the diverse subsidized options available in Alexandra weren't offered as viable alternatives (Ruiters, 2007). Following this process, pre-paid meters were installed across Phiri. As with Alexandra, Soweto residents were active and vocal during the apartheid era as well as during the formation of the new government in demanding their rights to services and infrastructure. Where the inability to pay for water in Alexandra resulted in various packages which allow people to access water for free, in Soweto, the inability to pay became a threat to accessing water at all (Dugard, 2010). Residents that lagged behind with their payments had a weak bargaining position to resist the installation of the meters (Desai and Pithouse, 2004). The introduction of pre-paid water meters could be viewed as a form of destructive power that made the earlier/traditional system of water governance disappear in Phiri. Citizens living in Phiri were no longer treated the same as residents in other former township areas who had a similar system in terms of water provision (unlimited access) and water charges (pay post-use). Instead Phiri residents now had controlled access and a pre-paid system. In the process, Johannesburg Water also applied innovative power by establishing a new system. The new system included the pre-paid meters and can be seen as disempowering to the residents. The residents in this system were perceived as irresponsible and not able to manage their water use themselves (Ruiters, 2007). The neoliberal corporate model of water service delivery in effect worked to marginalize Phiri residents by treating them differently from other residents of the city of Johannesburg (Bond and Dugard, 2008). Local citizens mobilized to resist the new system of water service delivery. Members of the Phiri community took the City of Johannesburg to court in December 2007 to challenge its installation of prepaid water meters, and in April 2008, the South African High Court found this practice unconstitutional and wrote that denying the poor access to adequate water \"is to deny them the rights to health and to lead a dignified lifestyle\" (City of Johannesburg, 2008b;Dugard, 2010). Further, limiting free basic water to 25 L per person was reviewed and changed to 50 L of free water per person per day provided by the option of an ordinary credit-metered water supply (instead of pre-paid) for more use (City of Johannesburg, 2008b;Dugard, 2010). The City of Johannesburg appealed the decision in the Supreme Court of Appeal, and in October 2009 the court overturned the ruling of the High Court and declared pre-paid meters lawful (Dlamini, 2009). It also ordered that account holders in Phiri, registered as indigent, should receive 42 L of water per day per resident (Dlamini, 2009). The social mobilization in the case of Phiri initiated local residents and supported by the Anti Privatisation Forum (APF) and other activists, can be viewed as one of the niche experiments and application of innovative power which were later absorbed by the regime. The residents constructed a legitimate case for the reconsideration of pre-paid meters as a device of restricting human rights. However, through the course of engagement with the City of Johannesburg, this power exercise was weakened through delays, conflict and a legal process. Through this slow process, City of Johannesburg and Johannesburg Water became quite successful in weakening the Phiri social movement through the judiciary's support for Operation Gcin' Amanzi. In August 2003 any obstruction of the project was banned and many activists and 14 residents of Phiri were charged in a court of law with malicious damage to property. Consequently, the campaign by the Anti Privatisation Forum and its affiliate organizations was weakened since they had to divert their energy to defeat those charges (Dugard, 2010). One can argue that a relation of power existed where the City of Johannesburg could mobilize more resources that the residents of Phiri. The citizen resistance before 2005 only delayed the process of pre-paid meter installations but it was not able to affect the water management strategies at the regime level. From a power relations perspective, this is an example where innovative power at niche level was not sufficient to be constitutive, Or in other words, the destructive power at regime level was able to deconstruct the mobilization at the niche level and create a lock-in situation. The final decision of the South African Constitutional Court, which was in favor of City of Johannesburg in 2009, can be seen as a path dependent pattern toward a lock-in situation wherein the state dictates its rules of the game. The case can thus show how bottom-up approaches cannot be effective in moving toward a desired transition pathway in the presence of obstructive power relations and the absence of protected space for niche experiments. There is however reason for optimism regarding the process of niche empowerment through legal mobilization. The voices of Phiri citizens were heard across the country and have already had an impact on the broader struggle in South Africa (Dugard, 2010). The presence of conflict may bring a potential change to institutions at regime level (Mahoney, 2000). This can be contrasted with Alexandra where there does not appear to be any overt conflict between citizens and the state with regards to water service delivery.",
            "Discussion": "",
            "Different exercises of power": " By comparing the different exercises of power in the cases, we draw some initial conclusions on the nature of the transition in water service delivery in the city. Water service delivery varies greatly across the city and the inequities of the past are still apparent. Poor (and largely black) urban communities living in informal settlements and former township areas have a much lower quality of water supply than wealthier areas. The different water supply options in Alexandra and the different payment schemes across the city, show that the new system maintains inequities. Part of the reasoning given for the differential supply systems includes the ability to pay for services under a liberal model of water governance (Swatuk, 2010). Inability to pay has led to limited water supply options including shared standpipes. This distinction between wealthy and poor is not however uniform and between the two cases of Alexandra and Soweto, we see differences in the municipal water payment schemes. The neoliberal model of supply management has thus created new mechanisms of instituting inequalities within society (Ahlers, 2010;Narsiah, 2002;Shiva, 2002). In both Alexandra and Soweto, citizens as community actors have been disempowered by the governance approach adopted for water service delivery. In Alexandra, this seems to have made local actors dependent on the authorities with little exercise of power themselves. In Soweto, the resistance to the pre-paid meters did not influence the outcome but community actors mobilized their resources to engage in governance. These examples indicate that even where conflict is not visible, the exercise of power is at play. Ultimately, the transition in water service delivery can be questioned based on the power imbalances between citizen and state actors suggesting that local residents of former townships are compelled to accept a standard of water services prescribed by the local government even if they are not satisfied with it.",
            "Power between and within the levels": " The conceptual framework offered by Avelino and Rotmans (2009) presented a useful starting point for applying a power analysis in our case studies. There are several limitations to their conceptual framework and different approaches to power analysis would introduce different nuances to the investigation. The conceptualization of power in Avelino and Rotmans' framework revolves around the notion of a capacity that can be mainly exercised between regime and niche actors. Although it is useful for developing an understanding of the power dynamics between the state and the citizens in Alexandra and Soweto, it provides less support to explore the interaction between and among these communities, and hence, it does not provide us with an insight on how these heterogeneous niche actors interact with each other. The framework could therefore benefit from incorporating a multi-relational analysis within levels as discussed in the theoretical framework (Shove and Walker, 2010). This is particularly crucial in studying water service delivery across the city of Johannesburg wherein the power dynamics between the state and the local citizens differ between various areas. Including an analysis of horizontal relations between the communities in Alexandra and Soweto can be valuable for improving the understanding of power dynamics as well as for finding potential entry points for structural change.",
            "Agents of change in socio-political transition arenas": " An important outcome of the power analysis, is bringing to the fore the role that actors play in determining change through the exercise of power. In the examination of water service delivery in Johannesburg, our research shows that actors at the niche and regime levels in transition arenas are pivotal to maintaining or changing a system. In breaking a lock-in situation, frontrunners are essential (Rotmans and Loorbach, 2009). Frontrunners are one of the key change agents of transition processes. They are \"niche players\" and \"change-inclined regime players\" with the \"capacity to generate emergent structures within the deviant structures\" in a virtual network called the transition arena (Rotmans and Loorbach, 2009). The arena can be considered as an experimental space in which the actors use social learning processes to acquire knowledge leading to a new perspective on a transition issue and to be better equipped to exercise power against the lock-in regime. As in the case of Soweto, the transition arena does not need to be the exclusive domain of the experts but can be a space where social and legal mobilization can be initiated. Niche empowerment has a crucial role in the transition management process. It is suggested that actively communicating the shared vision and transition pathways into other networks will encourage people to join the innovation network to build joint strategic agendas (Rotmans and Loorbach, 2009). Focusing on actors with particular competencies, creative minds, strategists and visionaries, this arena is meant to empower niche actors to become a threat to the current distribution of resources, or in other words, a threat to constitutive power at the regime level (Avelino and Rotmans, 2009;Rotmans and Loorbach, 2009). In a sense, the outcome of the transition arena can stimulate the formation of new coalitions and networks to exercise innovative power and to shape transformative power. Frontrunners and their exercise of innovative power can be observed in the case of Phiri. In building a strategic agenda to move social mobilization forward, a number of actors operating as frontrunners were involved in the court case in Soweto. The Socio-Economic Rights Institute of South Africa, Anti Privatisation Forum, Soweto Electricity Crisis Committee and other groups of political activists can be viewed as frontrunners that created a momentum together with Phiri residents to struggle against prepaid meters. It took active communication of these networks through mass meetings, over a couple of years, to stimulate new ways of resource mobilization. This case has relevance for conflicts over service delivery in many other places in South Africa. Whether a transformative power will emerge as a result of these conflicts and will succeed to break-down the existing regime's constitutive power or not, depend on future acts of frontrunners. According to Dugard, the result of proactive litigation by the Anti Privatisation Forum is too soon to be judged, but initial feedback suggests that social mobilization has not been deterred or discouraged (Dugard, 2010). The experience of exploring the power dynamics in the transition process in the Soweto case, could be applied in relation to Alexandra. An important aspect of the Soweto case is the role of social mobilization in increasing the systemic power of citizens. There are frontrunners in Alexandra such as non-governmental organizations, community based-organizations, e.g., Wynberg Concerned Residents as niche actors and Alexandra Renewal Project as one of the main regime actors that potentially could initiate social mobilization in relation to the water service delivery transition. In the history of Alexandra, such frontrunner organizations have effected change during the apartheid struggle. These organizations played a central role for safeguarding the continued existence of the township during a period of destruction of many townships and forced removals under the National Party apartheid government. A frontrunner organization at the time was the Alexandra Liaison Committee headed by Dr. Sam Buti who led a protest against forced removals and was able to \"save Alexandra from extinction\" (Mafenya, 2002). Such locally based community organizations have been powerful frontrunners in the past and could be so in the future. There is thus a role for social mobilization to be a potential cause of change in water governance in South Africa (Kolb, 2007). This is in line with work by Pithouse (2008) which shows that shack dwellers are constituting a major challenge to technocratic conceptions of democracy (Pithouse, 2008). In safeguarding the long-term orientation and goals of a transition process, building up continuous pressure on lock-in regimes is a central theme and challenge in transition and power studies. Understanding social change processes as transitions can thus allow one to find trigger points for change in stalled processes. Litigation processes may give frontrunners the protected space that they need to create new coalitions and to experience human capacity to mobilize resources to reach certain goals. The continuous process of engaging niche and change-inclined regime actors can create a portfolio of transition experiments that move the struggle against unsustainable water access forward. In doing so, exploring power relations can prevent the constitutive power of the current regime from derailing the struggle.",
            "Concluding remarks": " Given the process of water service delivery in Alexandra and Soweto in the city of Johannesburg, we argue that the transition pathway is in the take-off phase but not near acceleration phase. Considering the ongoing struggle between niche-regime actors in Soweto and lack of any dynamic or struggle in the case of Alexandra, one could argue that the transition pathway may be closer to lock-in situation where regime actors have been able to absorb certain socio-political niche experiments. In our assessment we focused more on socio-political arenas than socio-technological ones. We argue that in evaluating the pathway of transition in water governance we should not only look at the water legislation and the numbers in relation to accessibility to potable water, we must also focus on the conflicts and contestations concerning the justice of the system. Hence, the power dynamics associated with the post-apartheid development process were focused on here with particular attention to payment for water services as one of the main mechanisms for changing distribution of water across the city of Johannesburg. Understanding the power dynamics at play in water governance is crucial for interventions for strengthening the objectives of equitable and sustainable water access in the city. In relation to the role of citizens and social/legal movements, we point toward how niche-experiments can potentially be scaled up to challenge the regime practices. Delineating the concept of frontrunners and identifying key niche-actors is an attempt to communicate the future transition pathway of water provision into the social networks and build strategic agendas by encouraging people to join these networks. Incorporation of an analysis on power was not only useful for developing a comprehensive understanding of the ongoing transition, but also beneficial to address one point of critique of the transition heuristic, namely the absence of a discussion of power in analyzing the interplay of actors at different levels. We have offered a contribution to the ongoing debates on framing power by looking at existing work in transition studies. Our research suggests that initial attempts are in the right direction but there is a great deal more room for the political dimension of transitions to be developed to fully capture the dynamics of societal change."
        }
    },
    "10.1016/j.eist.2014.11.002": {
        "file_name": "113 The role of politics in sustainable transitions",
        "title": "Environmental Innovation and Societal Transitions",
        "abstract": "This paper studies how political conditions and external events influenced the rise and fall of offshore wind on the political agenda in Norway between 2005 and 2012. In this sense, the paper contributes to recent debates about the role of politics in sustainable transitions. Key findings are that changes in government posts combined with a need for the offshore petroleum industry to diversify created favourable conditions for offshore wind. However, offshore wind as a solution to articulated problems was insufficiently developed when the window of opportunity opened up. The analysis then shows how a recovery in the offshore petroleum industry and new changes inside government closed the window of opportunity. The paper concludes that we should attend more to the interests of government actors, and conflicts inside government, in the analysis of energy transitions.",
        "label": "Qualitative",
        "text": {
            "Introduction": " Studies of sustainable transitions seek to understand how the introduction and development of more renewable energy technologies can be promoted. Since many of these technologies are immature, the introduction of technology-specific policies that protect these technologies from competition is often necessary (Sanden and Azar, 2005). Because different technologies require different types of policy intervention, a growing body of literature has employed a technological innovation system (TIS) framework to help identify barriers for technology development, which then can be used to design technology-specific policies (Hekkert et al., 2007;Jacobsson and Bergek, 2011). A related approach focuses on the need to nurture immature innovations through strategic niche management (Kemp et al., 1998). Both approaches recognise the importance of technology-specific policies for technology development. However, overly attention to the effects of policy on technology development can lead to a neglect of the political processes that bring about policy change. In recent years there has therefore been an increased attention in the transitions literature to the formation of policy (Weber andRohracher, 2012, p. 1040). An emphasis on niche empowerment (Smith andRaven, 2012, p. 1030), or the strengthening of the process of legitimation in the innovation system (Jacobsson and Lauber, 2006), does provide opportunities to study influences on the policy-making process. However, much analysis has still tended to neglect the political circumstances that make the adoption of certain policies likely (Meadowcroft, 2011, p. 73). Because a successful transformation of e.g. the electricity system is not only about a technological but also a political challenge (Kern, 2010, p. 20), studies of transition processes therefore need to put more emphasis on the role of politics and the complexity of the policy formation process (Flanagan et al., 2011, p. 704;Jacobsson and Bergek, 2011, p. 55). This paper seeks to explore the role of politics in transition processes by analysing attempts to secure public support for the introduction of policies for offshore wind in Norway. On the one hand, Norway has the potential to contribute significantly through its impressive offshore wind resources (Energir\u00e5det, 2008) and technological competencies related to the offshore oil and gas (O&G) industry (Steen and Hansen, 2014). On the other hand, an electricity sector dominated by hydropower and a reliance on cost-efficient policy measures has provided few opportunities for immature energy technologies over the past two decades. Nonetheless, between 2007 and 2009, the government signalled that it had big ambitions for offshore wind in Norway, hence leading to large public and industrial R&D initiatives. Despite the political ambitions for the development of offshore wind, coupled with substantial private and public investments, only 2.3 MW of capacity has so far been constructed off the Norwegian coast. The empirical objective is to study how offshore wind could rise so prominently on the agenda in Norway and why the big ambitions for the development of offshore wind have not been realised. In this way, the main justification for the study is to shed more light on the political processes exerting an influence on the development of renewable energy technologies. In the following section, I provide a brief review of how the development of niche technologies can be studied with a theoretical point of departure in the sustainable transitions literature. Here, I propose an agenda-setting model as a useful framework for providing a better understanding of the role of politics and agency in the development of renewable energy technologies. Section 3 presents the agenda-setting model in more detail. In Section 4, I trace the development of offshore wind in Norway, with an emphasis on political and industrial events. Using the framework presented in Section 3, I distinguish between different periods in the agenda-setting process, and outline how this may explain what can broadly be called \"the rise and fall\" of offshore wind development in Norway. Section 5 sums up the findings and proposes some implications for further research.",
            "Theoretical background: understanding the development of niche technologies": " From ideas of path-dependency and carbon lock-in (Unruh, 2000), we know that established technologies often hold many advantages over new technologies. An important contribution in the literature on sustainable transitions has therefore been made by exploring how the creation of protective markets and technology-specific policies for new renewable energy technologies such as offshore wind (e.g. Kern et al., 2014) can counteract the effects of path-dependency and lock-in. With the attention to policies comes the need to understand how policies are shaped. Simply put, policies are shaped through negotiations between both interested state and non-state actors (Smith et al., 2005). Actors have different opportunities to negotiate the policy process (Smith andRaven, 2012, p. 1031), and these opportunities are influenced by the institutional environment (Jacobsson and Lauber, 2006). This asymmetrical distribution of opportunities is often self-reinforcing through positive feedback processes. The concept of regimes can be useful for understanding the role of path-dependency and how new paths can be created (Hanson, 2013). Although there is little coherence in the literature on the regime concept (Markard and Truffer, 2008, p. 605), one common interpretation is that regimes provide stability, consequently acting as a barrier for the development of new technologies. A main purpose of the multilevel perspective (MLP) on transition processes has been to show how regimes can be unlocked through pressure on the regime from the development of alternative niche technologies and exogenous developments occurring at the 'landscape' level. A destabilisation of the regime can then open a window of opportunity for advocates of niche technologies to help influence the policy process (Geels and Schot, 2007, p. 400). Geels and Schot (2007) stress that the timing of exogenous events and the development of niche technologies are of great importance. For instance, the maturity of niche technologies when external pressure is applied to the regime will greatly impact on the ability of advocates of these technologies to exploit opportunity windows. The MLP provides a heuristic device to understand how regimes may change through the articulation of windows of opportunity (Geels, 2011). However, this perspective rarely explains why such opportunities are created, how interested actors negotiate these opportunities and why opportunity windows close (Smith et al., 2010, pp. 445-446). In particular, the perspective has been criticised for not providing a sufficient understanding of the political circumstances for policy formation (Meadowcroft, 2011) and for not incorporating a conceptualisation of power (Avelino and Rotmans, 2009;Smith et al., 2005). However, an excessive emphasis on power may put us in danger of downplaying the role of institutions and structures in facilitating and constraining the negotiations between different interests (Hill, 2013). In recognition of this, approaches focusing on policy networks (Marsh and Rhodes, 1992) or advocacy coalitions (Sabatier and Jenkins-Smith, 1993) have been developed as a way of conceptualising the role of power and institutions in the analysis of the policy process. Attending to the role of advocacy coalitions, Kern et al. (2013) find that studying how actor networks create narratives to draw attention to particular solutions can explain why some sustainable energy advocates are more successful than others in influencing policy. However, they also conclude that their proposed framework pays insufficient attention to how competing issues on the agenda as well as competing solutions to policy problems affect the opportunities for actors or groups of actors to influence policy. I would add that the framework pays too little attention to how solutions become attached to different problems, and how this affects the position of certain solutions on the political agenda. Borr\u00e1s and Edler (2013) suggest opportunities for policy change occur through a co-evolution of technological and institutional change. However, as mentioned above, opportunities themselves do not generate change. Thus, it becomes important to study the capabilities of agents to exploit opportunities. Kingdon (1984Kingdon ( , 2011) ) argues that such capabilities depend on the availability of appropriate problems and the agents' ability to attach policy solutions to these problems. This ability is also influenced by the prevailing political environment at the time. To comprehend how political actors operate within an institutional context, Kingdon (2011) conceives of \"three policy streams flowing through the system -streams of problems, policies, and politics. They are largely independent of one another, and each develops according to its own dynamics and rules. But at some critical junctures the streams are joined, and the greatest policy changes grow out of that coupling of problems, policy proposals, and politics (p. 19).\" To this, Sabatier (1991, p. 151) points out that even though Kingdon developed his model primarily for studying agenda-setting and policy formulation, the model can easily be expanded to the entire policy process.",
            "Agenda-setting": " Kingdon's agenda-setting model provides a number of complementary tools to the study of politics and sustainable transitions. Hannigan (1995), who argues that struggles over policies can be particularly complicated when it comes to energy and climate issues, displays how Kingdon's model has been applied as a framework for explaining environmental policy outcomes. Moreover, Kingdon's focus on how the coupling of societal problems, available solutions and political conditions can lead to policy change, is reminiscent of the importance Geels and Schot (2007) place on the timing of events. This is demonstrated by Elzen et al. (2011) who show how Kingdon's model of agenda-setting can enrich the MLP by attending more explicitly to the role of agency, politics and the timing of events. In this paper, I demonstrate that concepts from Kingdon's model can enhance our understanding of the political dynamics affecting sustainable transitions. First, the inclusion of political dimensions opens up for a greater understanding of the complexities of the policy making process. Second, Kingdon's explicit attention to the coupling of solutions to problems provides a tool for understanding how certain issues have come to dominate the political agenda. The theoretical purpose of this paper is to enrich the ideas of windows of opportunity in the transitions literature by applying Kingdon's model of agenda-setting to a renewable energy case. I do this to better understand the processes that can lead to windows of opportunity, under what circumstances such opportunity windows can be exploited, and finally, why such windows are closed.",
            "The policy stream": " The principal concept in the agenda-setting model is the concept of ideas. Kingdon is not interested in where these ideas come from, but rather under what circumstances they blossom (2011, p. 77). Ideas circulate in the policy stream, and can be interpreted as policy solutions or alternatives that have not necessarily been coupled with a particular problem. Thus, Kingdon uses the concepts of ideas, solutions and alternatives interchangeably, with the point of interest here being the idea of offshore wind and the actors involved in developing this idea. For this reason, the critical thing to explore in the policy stream is how offshore wind surfaced above all of the other ideas in the policy stream. The concept of a policy stream can be related to the concept of technological niches. Niches are sources of transformative ideas and capabilities, and provide 'spaces' for alternatives or solutions that are not yet competitive against the selection environment in the prevailing regime (Smith et al., 2010, pp. 440-441). By using the concept of solutions in the policy stream, we may then also understand more about why some niches are favoured over others. Kingdon (2011) proposes several characteristics of the policy stream that may affect the selection of ideas. First, a policy alternative needs a policy entrepreneur that is persistent over time and willing to invest resources in promoting the idea (pp. 122-124). Additionally, policy alternatives are constantly evaluated against criteria such as technical feasibility, projected costs and anticipated reception among key decision makers (pp. 131-139). For a successful exploitation of an opportunity window, a policy alternative must therefore be properly developed and compatible with budgetary considerations. Nevertheless, it is through changes in the problem or political stream that certain ideas rise above the rest. If the conditions are not right in the political stream, or if the policy alternative is not attached to an appropriate problem, the window may only be open for a short time.",
            "The problem stream": " The problem stream contains all types of conditions that people in and around government could attend to at some point in time. Kingdon (2011) hence makes an important distinction between a condition and a problem. A condition can be recognised through a variety of indicators, exogenous shocks and feedback processes related to existing policy processes. However, a condition only becomes a problem when we come to believe that something can and should be done about this condition. This understanding of problems resonates with what Smith et al. (2005) term the articulation of selection pressures, which relates to whether a particular problem has been defined, as regimes are constantly exposed to different kinds of pressure. However, it is when different pressures act in concert and are explicitly translated into problems that substantive regime change can occur (Smith et al., 2005(Smith et al., , p. 1495)). In this process of problem definition, the context for a transition plays a pivotal role (Hanson, 2013, p. 168). Thus, when looking at the agenda-setting process we must also explore how particular problems are defined, and under what conditions offshore wind has been attached to articulated problems. Kingdon also proposes several explanations as to why problems drop off the agenda. First, government officials may feel that they have addressed the problem by introducing new legislations. Second, a failure to solve or address a problem can lead to it dropping off the agenda due to lack of stamina from those actors that have invested in keeping the issue on the agenda.",
            "The political stream": " The political stream consists of both public opinion and the actions of the political elite, and has powerful effects on the articulation of conditions as problems. Kingdon (2011, pp. 153-164) argues that the type of change that has the most impact is shifts in the national mood, combined with government changes through elections and changes in government posts. While consensus in the policy stream is reached through persuasion, consensus in the political stream is reached through bargaining. This has the implication that we must explore the negotiations that occur inside government to better understand why certain issues rise on the agenda, which can be done through the analysis of public debates. However, the particular nature of the policy process offers a methodological challenge since many of the real negotiations over policy take place outside of the public eye (Hill, 2013). To a certain extent, this problem can be mediated by conducting elite interviews.",
            "Coupling of the streams": " Windows of opportunity primarily occur through changes in the political or problem stream. Sometimes the window is opened up by a problem that presses in on the government. This is also recognised by Geels and Schot (2007), who emphasise that external shocks and events can open opportunities for particular niches or alternatives. To this, Kingdon (2011) adds that alternatives fare much better if there are also favourable conditions in the political stream. His main point is that windows of opportunity do not in themselves lead to change. Instead, change occurs through the coupling of a solution to a particular problem, which then makes developments in the political stream critical for the likelihood of such a coupling. An analysis that includes events in all three streams, including attention to the timing of events, will help us understand more about the role of politics in the development of new RETs. Solutions are sometimes rather arbitrarily attached to problems, and then often inappropriately (Hovi et al., 2011). An understanding of the different problems that offshore wind has been attached to, as well as the relevance of this coupling in the broader political context, can also provide insights into the rise and fall on the agenda. Kingdon sees the development in each stream as largely independent of changes in the others. The implication of this understanding is that what gets on the agenda depends upon fortuitous timing (Mucciaroni, 1992, p. 460). This is problematic, as it neglects any element of strategic action and choice, which does not make for a particularly useful perspective for anyone interested in contributing to the development of new RETs. Mucciaroni (1992) therefore suggests an alternative that stresses the importance of linkages between the three streams, and the advocacy coalition framework (Sabatier and Jenkins-Smith, 1993) can be understood partly as an attempt to see the policy and political stream as more closely related (Kingdon, 2011, p. 218). This is a sensible approach, insofar as it will tell us more about the attempted strategies (or lack of) involved in placing certain issues on the agenda. Advocates of a certain solution will make conscious efforts to attach this solution to a problem recognised in the problem stream, while political changes can simultaneously influence the articulation of different problems. By tracing the mutual interdependence between the streams, agenda-setting seems less random and more purposeful. Kingdon's model serves a purpose by accounting for why some ideas rise on the agenda. Even so, the complexity of translating policy objectives into instructions for action poses a challenge, as ideas may nevertheless fail to influence actual policy outcomes (Hill, 2013, pp. 180-204). The reason for this failure can be that the 'sellability' of an idea depends on the wider political framework (Smith, 2007(Smith, , p. 1444). In the analysis, I will therefore also explore some of the preferences of the different political parties in government, and how these may have affected the reception of certain ideas and solutions. The model of agenda-setting requires a detailed tracing of events in the areas of problems, solutions and politics. Hence, I employ the method of process tracing. Process tracing is well suited for explaining particular policy outcomes (George and Bennett, 2005, pp. 205-232), in addition to being helpful for studying how the relationship between agency and structure influences such outcomes (Pettigrew, 1997, p. 341). The main part of my empirical data consists of 27 semi-structured interviews conducted in 2013 and 2014 with politicians (7), civil servants (2), industry representatives (11), research centres (2) and interest organisations (5). On average, the interviews lasted one hour, and were recorded, transcribed and coded according to the concepts presented in the analytical framework in order to trace developments in the three streams. Newspaper archives, public documents and minutes from parliamentary debates have also been used to construct the narrative and as a way of reducing primary source bias by triangulating data (Thies, 2002, p. 359).",
            "The rise and decline of offshore wind in Norway (2005-2012)": " In this section, I describe the development of offshore wind in Norway. However, it is first necessary to point out a few key structural conditions that have influenced the development of renewable energy in Norway. Following the deregulation of the Norwegian electricity market in 1991, Norwegian energy policies have rested on a short term cost-efficiency principle that has guided resources towards less expensive technologies for electricity production (Hanson et al., 2011, pp. 236-239). Moreover, nearly all domestic electricity consumption is covered by emission-free hydropower. Consequently, it has been difficult to see any substantial motivation for a rapid expansion of new renewable energy in Norway (Hanson et al., 2011). It is also important to understand that the vast majority of Norwegian offshore wind firms have grown out of, and are still linked to, the petroleum industry (Steen and Hansen, 2014). This linkage has resulted in a competitive advantage related to marine operations and offshore technology. Nevertheless, this relationship also makes the offshore wind industry sensitive to developments in the offshore petroleum industry.",
            "A window of opportunity opens up (2005-2009)": " Whereas the first offshore wind farm was installed off the coast of Denmark in 1991 (EWEA, 2013), concrete plans for a domestic market for offshore wind in Norway emerged in 2005 when the project development company Havgul announced plans for a large bottom fixed offshore wind park called Havsul. Motivated by energy deficits in the M\u00f8re region, caused by the development of new energy intensive industry in the region without additional investments in grid and new production capacity, the need for new electricity production was from 2005 an increasingly debated issue in Parliament (e.g. Stortinget, 2006). An important driver behind Havsul was therefore to develop the project as a solution to this problem. Although the project lacked licences and funding at the time, the early plans for Havsul played an important role in planting the idea of a domestic market for offshore wind in the policy stream. At the same time as a licence application for Havsul was submitted, several of the biggest energy companies made R&D investments in offshore wind as Statkraft, Shell and Lyse Energi, together with the Research Council of Norway, invested 1.4 million EUR in a three-year research project, using a floating concept for offshore wind developed by the company Sway. A further investment of 19 million EUR was then made in 2007 by Statoil, Lyse Energi, Scatec and Rosenberg Verft. In contrast to, e.g. Danish offshore wind turbines installed in shallow waters, the Sway concept used an anchor line based on existing offshore technology, and could therefore be installed in deeper waters with rougher seas. The national oil company Statoil also had its own floating turbine concept called Hywind, which had originally been developed by two engineers at the energy company Hydro. 1 In 2007, Statoil received 7.5 million Euros from Enova, 2 a public enterprise, in support for what would be the world's first full-scale floating turbine demonstration off the Norwegian coast. Statoil initially had an agreement with the partners at the Troll natural gas and oil field to connect Hywind to petroleum installations (Str\u00f8mmen Lycke, 2013). However, because there was no law governing this part of the North Sea, it was not possible for the authorities to grant a licence. As a result, the project had to be moved to within 10 km of the shoreline, and an opportunity for niche protection through electrification of petroleum installations was missed. Lyse Energi also announced plans for a separate offshore wind project in the North Sea, and were in talks for a period with ConocoPhillips about supplying the Ekofisk oil field with electrical power from offshore wind turbines (Aamodt, 2014).  Towards the end of 2007, developments in the political and problem streams opened up an opportunity for the idea of offshore wind to rise to the surface of the policy stream. First, the consequences of climate change as a condition was more explicitly articulated as a serious problem. As shown in Fig. 1, public attention to climate change in 2007 was more than double that of previous and subsequent years, which was largely fuelled by the publication of the fourth assessment report by the IPCC. The increased public and media attention was amplified by pressure from the political opposition towards the government to introduce plans for new renewable energy production. With reference to Hywind, as well as the possible electrification of offshore O&G installations, this included a proposal by the opposition to invest in offshore wind in Norway (Stortinget, 2007). An important change in the political stream came when \u00c5slaug Haga was appointed as a new Minister of Petroleum and Energy in 2007: I'm not sure where it started, but I remember that \u00c5slaug Haga established the Energy Council [which focused on offshore wind] (. . .) and I would say that the fact that \u00c5slaug Haga entered the Ministry of Petroleum and Energy made a difference (Flataker, 2013). Haga was a renewable energy enthusiast, and she immediately commissioned a special report on the offshore wind potential in Norway. The report, which was delivered to the minister in May 2008, highlighted both industrial opportunities and the potential for clean electricity exports (Energir\u00e5det, 2008). It was in particular the contribution of offshore wind as a solution to the problem of climate change and the idea of Norway as \"Europe's green battery\" that was emphasised by Haga and other members of government. These attempts to couple offshore wind as a solution to the problem of climate change seems to have been primarily driven by political rather than industrial actors. The increased attention to climate change in both the general public and Parliament led to the negotiation of the so-called Climate Agreement towards the end of 2007. The purpose of this agreement was to ensure a long-term strategy for Norwegian climate policy that all political parties could agree upon. 3 The agreement was initiated by the Liberal Party from the opposition and the Socialist Left Party from the coalition government, and was an opportunity for the opposition to raise the issue in Parliament for a need to complement policies based on a cost-efficiency principle with technologyspecific policies (e.g. Stortinget, 2008). An important outcome of the agreement was the establishment of eight Centres for Environment-friendly Energy Research (FME) in 2009 (Fr\u00f8ysa, 2013). Two of these, NORCOWE and NOWITECH, targeted offshore wind. The FMEs received extensive support from the 3 The Progress Party was excluded from the negotiations. industry, though firms such as Statkraft and Vestavind Offshore argued for concentrating offshore wind research efforts in one centre. Several industry representatives pointed out in interviews that the establishment of two centres led to an unhealthy competition over researchers, funding and industrial partners. In June 2008, Terje Riis-Johansen replaced Haga in the Ministry of Petroleum and Energy (MPE), and later in 2008 he initiated work on a new law for the production of offshore renewable energy. The adoption of the law in Parliament in 2009 improved the idea of offshore wind as a realistic alternative by removing practical barriers (Str\u00f8mmen Lycke, 2013). A second initiative in 2009 by Riis-Johansen was to provide a licence for the Havsul project. The project, which had been purchased by the energy consortium Vestavind Offshore, would consist of 70 turbines with an installed capacity of 350 MW. The total cost of the project was estimated to approx. 900 million Euros, with about 200 million Euros needed in investment support from Enova or directly from the state (Bergens Tidende, 2011). The government was still under pressure to resolve the problem of regional electricity demand. The licence was therefore presented by the government as a solution to this problem (Hj\u00f8rneg\u00e5rd, 2014), whilst Vestavind Offshore also highlighted the benefits to industry development and job creation. We can see that in the period between 2007 and 2009, a range of developments in the political stream appeared to signal government investments in offshore wind. Both Ministers Haga and Riis-Johansen argued for public support of offshore wind, while the political opposition repeatedly attempted to put pressure on the government to invest in offshore wind. The attention to offshore wind in the Climate Agreement was influenced by these developments. Nonetheless, despite the stated political ambitions, there was an increasing unrest in the industry about the lack of financial instruments needed to realise these ambitions. The developers of Havsul responded to this by arguing publicly for improved framework conditions (e.g. Sunnm\u00f8rsposten, 2009). Even though these complaints were echoed by other influential energy companies such as Statoil, Statkraft, Fred. Olsen and REC, these firms reacted by investing in offshore wind projects in the UK market, where the incentives were more favourable. A consequence of this was that Statoil and Statkraft from an early stage showed little interest in collaborating with other Norwegian firms (Tande, 2013) nor in the development of a domestic market (Dirdal, 2013). Despite promising industry developments and favourable conditions in the political stream, coupling offshore wind with the problems of both an energy deficit and climate change proved difficult. The regional energy shortage in M\u00f8re had been a critical problem for the government during the winter of 2006/2007 due to cold and dry weather. However, due in part to more rain leading to an improved hydropower production, this problem diminished in the subsequent years. Moreover, Prime Minister Stoltenberg from the Labour Party was famously known for his support of cost-efficient climate measures and technology-neutral policies (Alstadheim and Stoltenberg, 2010). With an increased appreciation of the costs of offshore wind compared to other solutions available in the policy stream such as onshore wind, small-scale hydropower and even natural gas, a coupling of offshore wind with climate change or energy deficit was not seen as a politically realistic option. As a result, there was a growing understanding that the government was unlikely to finance the development of a large domestic market for offshore wind in Norway. However, reduced activity in the offshore petroleum industry created a new problem and a new opportunity. Because the petroleum industry is cyclical, many firms operating in the offshore petroleum industry need a strategy for diversification to meet situations of waning demand. Unsurprisingly, the industry is more attentive to this during periods of downturn: In 2009, there was a major drop in oil prices with a decline in oil investments. There were layoffs in the oil service sector where the majority of employees in the oil industry work. This led to a discussion about how Norway could transfer the competence it had to new sectors and also a willingness to look at R&D for the sector (Ellingsen, 2013). Firms in the offshore petroleum industry were increasingly looking for alternative projects. In 2009, the lack of orders in the offshore supply industry was a much debated topic in Parliament, and became a recognised problem by both the government and the political opposition. This problem was most prominent in the Verdal region of Norway where the cornerstone company Aker Verdal had to lay off workers. The solution of offshore wind that had emerged in the policy stream thus became an attractive opportunity for the industrial cluster in Verdal. The government therefore supported a diversification into offshore wind by providing funding for the development of a harbour that could accommodate offshore wind turbines, by financing the establishment of a wind energy cluster in the region, and by attracting GE Energy to invest in local turbine production company ScanWind. The more explicit articulation of industry decline as a problem by both political and industry actors can also be observed in the way Vestavind Offshore developed its strategy for the Havsul offshore wind farm. To help attract attention from influential policy makers and the political elite, the offshore wind alternative was attached explicitly to the industrial problem as a solution to job losses and industrial decline: The purpose of the Havsul project was to produce energy. The other stuff was about communication and how to argue that this should be given money. Energy shortage is not a hot enough topic in Norway to mobilize great political interest, but if you can say that this also contributes to tremendous industrial development on the west coast, because it would certainly have created many jobs, then it would be more interesting for a wider political audience (Lie Larsen, 2013). Summing up the period from 2005 to 2009, offshore wind as a solution developed at first rather independently through entrepreneurial activity and exogenous developments such as a growing international market. The idea of offshore wind was initially only to a very limited extent coupled as a policy solution to a particular problem. With changes in the political stream favouring offshore wind and problems related to climate change, energy deficiency and industrial decline all articulated at various points in this period, the potential for joining the streams of politics, policy and problems opened up. In the end, it was with the problem of industrial decline towards the end of this period that the most potent coupling occurred. The description so far lends strength to the perspective provided by Mucciaroni (1992) in that the streams do not develop entirely independently. The initial attention in the political stream to offshore wind came as a result of the promising technology developments in the policy stream, as well as the early willingness of energy companies such as Statoil, Lyse Energi and Vestavind Offshore to invest in offshore wind. Further, the articulation of problems related to both climate change, industrial decline and energy deficit were all in various ways influenced by the developments in the political stream. Thus, we can see the opening of a window of opportunity as a result of both fortuitous timing and strategically based actions.",
            "The window closes (2010-2012)": " The success of offshore wind depends on bringing costs down through innovation and learning, which primarily takes place in firms. These firms need learning arenas not only to demonstrate technology, but to also foster further learning processes and build support for a technology (Kemp et al., 1998, p. 184). Still, the Norwegian industry lacked a domestic market that could provide such a learning arena (Hansen and Steen, 2011). The general innovation policy approach in Norway was based on R&D incentives for technology development and a cost-efficiency principle guiding investment support for the more mature technologies (Bysveen, 2013). This left a policy gap for bridging the \"valley of death\" facing offshore wind projects (Flataker, 2013). In an attempt to better attach offshore wind to the problem of industrial decline, the offshore wind actors focused more on the need for government to assist the development of an industry through the establishment of demonstration projects, rather than subsidising production of electricity. The most noteworthy proposals for such demonstration projects were Demo Rogaland (Statoil, GE Energy and Lyse Energi) and Demo2020 (NOWITECH, NOR-COWE, Arena NOW and Arena Mid-Norway). In particular, Demo2020 received support from both The Federation of Norwegian Industries and the Norwegian Confederation of Trade Unions (LO). Simultaneously, on a more general level, the need for government funding of offshore wind demonstration projects was repeatedly put forward by representatives from both government and opposition parties in Parliament in 2010. However, even though there was no real resistance against offshore wind within the government (Halvorsen, 2014), the supporters of Demo2020 were unable to convert the apparent support into a favourable policy outcome in terms of funding for the project. It is not possible to point to one single explanation to this outcome. Several respondents involved in the demonstration proposals pointed out that the proposals suffered from competition between different regions and industrial actors (Aamodt, 2014;Str\u00f8mmen Lycke, 2013), and that competition between the two proposals damaged the entire process: Instead of cooperating and being satisfied with that, people would say that it had to be Havsul or a different project. That is a little destructive for achieving political consensus. (. . .) To get the whole industry, the developer and the government to agree on a good model, that is difficult (Tande, 2013). This lack of collective action and a single proposal to the authorities shows that the offshore wind industry suffered from \"weak networks\" (Carlsson and Jacobsson, 1997). Poor interaction between organisations can lead to a lack of shared visions for future technology developments, which might hinder both research efforts and, perhaps more relevant in this context, investments in a technology (Woolthuis et al., 2005). Moreover, having already dealt with major internal conflicts over other climate and energy issues related to CCS investments at Mongstad, and lengthy negotiations over the introduction of a tradable green certificate scheme, there was little room left for the supporters of offshore wind inside the government to fight for government funding of Demo2020: We had a major effort to solve the issue over natural gas with CCS at Mongstad, and we had to deal with the issue of tradable green certificates for years. It was not easy to ask for another couple of billion NOK when we had spent so much money on these other issues that the Prime Minister was opposed to (S\u00f8rensen, 2014). It should here be noted that because the CCS process was concluded in 2005 (S\u00f8rensen, 2014), policies for the demonstration of offshore wind was in no direct competition with CCS (Halvorsen, 2014). By contrast, the negotiations over the certificates took place in 2008 and 2009, during a period when there was considerable interest for offshore wind, and was the result of a long-standing pressure to introduce a policy instrument that promoted new clean energy production in Norway. However, because this scheme is a technology-neutral policy instrument that favours mature industries at the expense of the more expensive technologies (Bergek and Jacobsson, 2011), the scheme can be seen as a continuation of the dominant energy regime with little to be gained for the offshore wind industry. One respondent pointed out that no one positioned the certificate debate towards how the scheme could deliver to offshore wind (Holm\u00e5s, 2014). This can in some way be explained by poorly organised interests advocating technology specific policies at the time, and strong coalitions supporting cost-efficient energy policies (Gotaas, 2014). Finally, political actors are not unaffected by external pressure. It is therefore interesting to observe that none of the environmental organisations had offshore wind as a priority. Offshore wind also lacked an enduring policy entrepreneur that could sustain momentum over time. With only nine months at the MPE, \u00c5slaug Haga was not given time to show the tenacity that was needed. Similarly, the Demo2020 initiative lacked a responsible person who could sustain a consistent effort over time (Fr\u00f8ysa, 2013). With a recognition that offshore wind could not be realised through the certificate scheme (Dale, 2013;Lygre, 2013), and the unsuccessful proposals for demonstration projects in 2010, much relied on whether Enova would be handed the opportunity to support large scale demonstration projects. In March 2011 two influential changes in the political and the problem streams occurred within the space of two weeks. First, the government announced a new Minister of Petroleum and Energy, who supported considerably different policies than his predecessors (Ellingsen, 2013). Shortly thereafter, Statoil announced a major oil discovery in the Barents Sea. The former event made the political stream less favourable to the solution of offshore wind. The latter event led to increased optimism in the O&G supply industry, diminishing the problem of industry decline. A few months later, GE Energy announced the discontinuation of the production facility in Verdal, which sent a negative signal to the entire offshore wind industry in Norway. Even so, Vestavind Offshore remained optimistic, and made a range of attempts in 2011 and 2012 at establishing a dialogue with both the MPE and the Ministry of Trade and Industry. However, there was little political interest to meet with representatives from Vestavind Offshore (Ellingsen, 2013). One of the respondents argued that Vestavind Offshore did not pay enough attention at an early stage to the issue of securing political backing for the financing of the project, and that once they did start to focus on this area it was too late and the opportunity was missed (Dirdal, 2013). Another respondent pointed to insufficient knowledge and experience with working with policies for offshore wind within both the MPE and Enova (Lie Larsen, 2013). Former minister Haga expressed similar views, stating that the MPE completely lacked competence in new renewable energy (Haga, 2012, pp. 294-296). The Havsul project was also hampered by challenging seabed conditions (Str\u00f8mmen Lycke, 2013) and the overall complexity and costs of offshore wind turned out to be higher than what had been anticipated a few years earlier (Engevik, 2014;Gotaas, 2014). Thus, the respondents point to what Kingdon would identify as a failure to meet the necessary criteria for the solution to be considered as a viable proposal (2011, p. 131). After much uncertainty, it became clear in the summer of 2012 that Enova had not been granted the mandate to support Havsul or similar large-scale offshore wind projects (MPE, 2012, pp. 168-171). For this reason, the board of Vestavind Offshore declared in December 2012 that they had given up on the Havsul project due to unfavourable framework conditions (Bergens Tidende, 2012). The period from 2010 to 2012 shows how advocates of offshore wind attempted to the window of opportunity by lobbying for the public funding of large demonstration projects. Yet, the advocates were unable to exploit the opportunity due to unfavourable conditions in the political stream, the lack of a persistent policy entrepreneur and because offshore wind was not sufficiently developed as a solution. Policy windows rarely remain open for long (Kingdon, 2011, p. 166), and in 2011 exogenous events and a ministerial change ultimately closed the policy window for offshore wind in Norway.",
            "Conclusions": " The point of departure for this paper has been an acknowledgement of the dependence of new renewable energy technologies on technology-specific policies. I have pointed out that while policy has been a central topic in many studies of renewable energy technologies and transition processes, the complexities of the policy process have often been underplayed. I have shown that an analysis of the development of streams of politics, solutions and problems can complement what we know about transition dynamics from the innovation literature. First, the agenda-setting model provides a precise framework to study the importance of the timing of events and developments at different levels. From a multilevel perspective, we can see that a window of opportunity opened up as exogenous events put pressure on the regime, whereas developments in the offshore wind industry placed it in a position to exploit these opportunities. Be that as it may, the findings in this paper show that the first problems of climate change and energy security did not provide sufficient conditions for the exploitation of this window of opportunity as offshore wind represented a climate and energy measure that fit poorly with the principles of cost-efficiency. Thus, we can say that offshore wind was attached to inappropriate problems (Kingdon, 2011, p. 178). However, exogenous events affecting the offshore petroleum industry gave rise to a new problem of industrial decline. To this problem, offshore wind was articulated as a more credible solution than to the problems of climate and energy. Nevertheless, this new coupling of problem and solution, which provided favourable conditions for change, did not materialise into ambitious policies for offshore wind. In this paper, I suggest that developments in the political stream have had a significant influence on this outcome. Furthermore, offshore wind as a policy alternative failed to meet Kingdon's criteria related technical feasibility and anticipated costs (2011, pp. 131-139). To this, we can add that a lack of cooperation also undermined the potential for offshore wind as a solution. Through the lens of a technological innovation systems framework, this can be conceptualised as a system weakness in the form of weak networks that led to a weak legitimation function (Jacobsson and Bergek, 2011, p. 51). A scrutiny of developments in the problem stream also shows how new petroleum discoveries resulted in increased activity levels in the offshore petroleum industry, which led firms to redeploy resources back to petroleum activities. Exogenous events that prompt windows to open may quickly go away (Kingdon, 2011, p. 169). The timing of the petroleum discoveries influenced the direction of search by altering the expectations for offshore wind and the legitimacy for public policy. The significance of these events, which was beyond the influence of the actors related to offshore wind, thus exhibits some of the difficulties in managing niche protection (Shove and Walker, 2007). Most significantly though, the case of offshore wind in Norway demonstrates how political conditions influence the development of new renewable energy technologies. I have therefore put forth that the main contribution of applying an agenda-setting model to the study of renewable energy technologies is that it allows for a detailed analysis of actors in the political stream. First, we have observed the way in which a ministerial change contributed towards placing offshore wind on the political agenda in a period when the coupling of streams was possible. Similarly, a new ministerial change four years later diminished the chances of the coupling of offshore wind with any articulated problem. Hence, even though we recognise the importance of developments at both the landscape-and niche levels, this study also points to the role of strategic political actors that operate at the regime level. In this way, whereas the multilevel perspective lets us observe that windows of opportunity occur, concepts from an agenda-setting model allows us to explore in more detail how and why windows open and close. Second, the findings in this paper remind us that governments consist of a heterogeneous mix of actors with often competing interests (Smith, 1993). Conflicts within the government over issues related to natural gas fired power plants, and the introduction of a tradable certificate system, led to the prioritisation of these issues. In contrast, offshore wind did not have the capacity to solve conflicts inside the government. Consequently, building alliances with actors inside the government and with environmental organisations became difficult for offshore wind advocates. An implication of these observations is that we need to reflect more on how we can include the different interests of government actors, as well as their influences on policy, in the study of sustainable transitions. On a related note, the green certificates process uncovers a weakness in the agenda-setting model in that is less suitable for analysing how groups of interests compete over policy outcomes. The TIS does recognise the role of networks in the policy process. However, the emphasis tends to be placed on the effects of networks on system performance or how policy might strengthen certain networks, rather than on how the balance of power in networks evolves and how the structure of the networks changes. A network approach such as the advocacy coalition framework could be a useful alternative for studying this particular aspect of the development of offshore wind in Norway. Lastly, and in an attempt to end on a positive note, Hay (2002, p. 133) remarks that although strategic action can help yield a minimal transformation of the context, it can yield strategic learning on the part of the actors involved, thereby enhancing an awareness of structures and providing the basis for a subsequent strategy that can be formulated for further contextual change. Provided that there is a degree of continuity among the actors involved in offshore wind, lessons from the experiences described in this paper could provide these actors with improved capabilities to influence the regime in the future. With increasing uncertainties related to the issues of \"unburnable carbon\" and activity levels in the offshore petroleum supply industry, this could become relevant sooner rather than later."
        }
    },
    "10.1016/j.eist.2014.06.003": {
        "file_name": "114 The EV paradox \u2013 A multilevel study of why Stockholm is not a leader in electric vehicles",
        "title": "Environmental Innovation and Societal Transitions",
        "abstract": "Despite seemingly favourable conditions for alternative road-based transport technologies, progress on battery electric vehicles (BEVs) have been slow in Stockholm. We investigate why, applying the multilevel perspective for socio-technical transitions to a local case study of Stockholm. Using in-depth interviews with key actors we trace processes and discuss possible explanations at niche, regime and landscape levels. The results show that niche developments are clearly lacking, resulting in limited experience and knowledge of BEVs, and enduring conceptions among both policymakers and consumers. Regime actors are also ambivalent towards BEVs, leading to limited regime action with for example car companies moving more to Plugin Hybrid Electric Vehicles instead of BEVs. Finally, there is uncertainty as a result of a lack of strong policy signals for BEVs, in turn driven by policy makers\u2019 aversion against technology-specific support. We outline what governance gaps need to be addressed to induce faster progress on BEV uptake.",
        "label": "Qualitative",
        "text": {
            "Introduction": " Today, the transport sector stands out as one of the key sectors that has not been able to \"bend the curves\" on greenhouse gas (GHG) emissions (Chapman, 2007) and with the highest projected emission growth rates (UNEP, 2012). While energy production, buildings, and industrial emissions have generally been able to achieve at least relative decoupling of emissions, transport-related GHG emissions keep increasing also in many high-income countries. Furthermore, air pollution and noise impacts often create severe public health problems in urban areas (EEA, 2012a). As a result of these unresolved challenges, sustainable transportation has for some years been a policy priority around the world including in the EU (European Commission, 2001) and Sweden (Regeringskansliet, 2008). A transition towards more sustainable transportation involves a range of new innovations, solutions and policy measures including: reduction in transport demand, increased efficiency, modal shifts such as shifting from private to public transport, and new technologies such as biofuels, electrification, and hydrogen fuel cell (Nykvist and Whitmarsh, 2008). This paper focuses on one part of this transition, namely the deployment and up-scaling of battery electric vehicles (BEVs).",
            "The promise of the BEV": " A key reason for looking closer on the dynamics of BEV innovation is the significant drawbacks associated with other alternative technologies. Biofuels is questioned due to limited primary energy as well as negative environmental effects such as land use change and competition with food production (EEA, 2006;WBGU, 2008). Hydrogen Fuel Cell vehicles (HFC) vehicles have long been researched (Solomon and Banerjee, 2006) but the technology is far (likely decades) from a scale-up due to high costs and major infrastructure challenges (Grahn et al., 2009;Pollet et al., 2012;Romm, 2006). More imminently on the agenda are therefore plugin hybrid electric vehicles (PHEV) and pure BEV. BEV enables the reduction of local air pollution and the potential climate benefits are very large (Jacobson, 2009;Tran et al., 2012). Because of this potential, and the availability of the technology, there is today broad political agreement for the need to deploy BEVs. At the global level, the International Energy Agency has launched a multi-government policy forum dedicated to accelerating the introduction and adoption of electric vehicles worldwide and according to their most recent outlook they put the global cumulative target for the BEV stock at 20 million in 2020 (IEA, 2013). Groups from Sweden industry has put forward a vision of 600,000 BEV and PHEVs on the road by 2020, but with no specific target on BEV. We show in this paper that the favouring of PHEV in Sweden as a country influences local developments in Stockholm. However, there are other environmental impacts to be accounted for and there are so far few complete life-cycle assessments on BEV (Hawkins et al., 2012). Ultimately the environmental performance and CO 2 mitigation potential of BEV depend on the both the production, use, and recycling of the specific technologies applied (e.g., the batteries, inverters, motor), as well as the electricity generation mix (Hawkins et al., 2013(Hawkins et al., , 2012)). There is considerable disagreement on how to calculate CO 2 intensity in future projections. But in the Nordic context, where the power system is dominated by low carbon energy sources, significant emissions reductions are possible when scaling out BEVs (Albrecht et al., 2013;Vattenfall, 2010). BEV has seen a rapid development over the past years with the introduction of growing numbers of commercially available electric vehicles (Fig. 1). Cumulative sales worldwide have increased tenfold in two years from 20,000 in 2010 to almost 200,000 in 2012 (IEA, 2013). Some of the recently introduced cars are only for sale in specific states in the US (e.g., the Toyota RAV4 EV) where legislation force car manufacturers to develop and sell Zero Emission Vehicles. But a growing number of cars are introduced globally with a performance comparable to Internal Combustion Engine cars (ICE) in terms of characteristics such as top speed and number of seats. Cost for a given range is a major constraint before BEV can become on par with ICEs (MacLean and Lave, 2003;Tran et al., 2012) but as we show in this paper (Section 3.3.1), battery prices are actually declining rapidly. Hence, while reports and the academic literature still tend to put forward the same challenges as a decade ago, the landscape is now rapidly changing. As recently as 2007 the California Air Resources Board expert panel on Zero Emission Vehicle technologies projects that BEV would not sell in numbers above 100,000 per year until 2030 (Kalhammer et al., 2007). This level was actually reached by 2012 (IEA, 2013). Scholars are also arguing that batteries are closer to commercial viability than often recognized, highlighting that there is as much an information and perceptual challenges related to a mismatch between consumer demand and technology development, as actual technology Fig. 1. Year of introduction of BEV models for commercial sales in EU and/or US. The recent development since 2008 is sometimes referred to as the second wave of BEV, with the first taking place in the mid 1990s. Data sources: Based on list of vehicles in de Santiago et al. (2012) company press releases, and news items, but does not induce concept cars, test-fleets and cars not capable of typical highway speed (top speed less than 110 km/h). development per se (Axsen et al., 2010). The case for high technological and cost barriers to BEV might hold a similarly false notion. It has long been known that BEV hold other unique advantages valuable to consumers in their own right (Kurani et al., 1996), and while it is true that consumers are not willing to pay much extra up front for BEV (Tran et al., 2012) the recent success of high-end vehicle manufacturer Tesla Motors (Hirsch, 2013) illustrates that for certain vehicle categories the additional cost of batteries is now low enough to sell compelling and competitive BEVs. In summary, technological developments and recent trends in sales indicates a shifting landscape indicating a potential acceleration in BEV uptake.",
            "Personal road transport and environmental innovation in Stockholm": " Our study of how the uptake of EVs is taking place examines the case of Stockholm, Sweden. The empirical case focuses purely on Stockholm, but when the national context matters we discuss Sweden as a whole. Thus, we start our analysis by observing that Sweden is often viewed as both an environmental pioneer (Lundqvist, 2004;Sarasini, 2009) and a top innovation country. In the European Commission's Innovation Scoreboard, Sweden came out as No. 1 of EU's member states in 2013 (European Commission, 2013). In the global innovation index 2013, Sweden came out as No. 2 worldwide.2 Sweden has also been a leading nation in advanced engineering industry in general and in automotive industry in particular with both personal cars (Volvo Cars and Saab) and world leading truck manufacturers (Volvo AB and Scania). National environmental legislation has been pioneering in many respects, for instance with the world's first carbon tax (1991), which all but removed all fossil sources from Sweden's power and heating systems (Prop, 1990/91:95) and the development of a range of environmental policy integration measures in the late 1990s (Nilsson, 2005). The frontrunner status of Sweden may, however, have become depleted somewhat in later years. Yale University's environmental performance index for 2012, Sweden slipped to No. 9 globally but still rank among the \"strongest performers\". Combining these three leadership traits Sweden also pioneered the first wave of alternative vehicle fuels both through R&D and development of a range of alternative vehicle technology niches (Hillman et al., 2011(Hillman et al., , 2008;;Magnusson and Rickne, 2012) but also in particular through regulation, e.g., the requirement for filling stations to supply biofuels (lag 2005:1248) pushing out ethanol nationwide in the early 2000s. Moving on to our local case in focus here Stockholm as a city has also enjoyed a strong environmental reputation. It was the first city to receive the award European Green Capital by the EU Commission in 2010 (European Commission, 2010). The motivation for this award states that \"the City has an integrated administrative system that guarantees that environmental aspects are considered in budgets, operational planning, reporting and monitoring, the City has cut carbon dioxide emissions by 25 per cent per inhabitant since 1990, and the City has adopted the objective of being fossil fuel free by 2050\".3 Following the lead of London's and Singapore, Stockholm was among the first cities in the world to introduce congestion charges (Stockholms Stad, 2007), and the recent report \"Stockholm -Green Economy Leader Report\" (LCE, 2013) reinforces this image of Stockholm and Sweden being in the forefront on environmental innovation and political steering towards a low carbon future.",
            "Aim of study -examining the EV paradox": " In other words, there is every reason to expect that Stockholm, a \"European Green Capital\" of Sweden, an environmental, automotive and innovation leader, would be an international frontrunner when it comes to the introduction of EVs -the central solution on the horizon today to make advancements on sustainable road-based mobility. However, a quick look at the latest statistics of registered BEV in Stockholm speak for itself (Fig. 2). Sweden lags behind both neighbouring Norway and Denmark and while Oslo municipality recently initiated a large procurement round of 1000 BEV (Andrine Gran, 2012) similar initiatives in the city of Stockholm (more than twice the size of Oslo) contain fewer than 100 vehicles. This is what we consider the \"EV paradox\". The aim of this paper is first and foremost to explain this paradox and to identify key barriers and developments that are lacking. The overarching question for the paper follows from this: Why is the allegedly greenest capital in Europe, placed in one of the true environmental frontrunner countries, with traditionally progressive environmental policy, in addition an innovation leader, having a vibrant automotive and power engineering industry -not rapidly scaling up one of the major solutions to one of the major environmental challenges of our time? And if policy makers want to close this gap, what general areas of intervention need their attention? We examine this overarching question using a socio-technical approach (Geels, 2004;Smith et al., 2005). The approach is used to study interactions between society, markets, industries, culture and technology, and sheds light on how technological systems, institutional rules and the actors that benefit from them in different ways form stable regimes that lock societies into certain paths of technology and practice. The paper studies the links between these systems components. In this paper we use a specific incarnation of socio-technical analysis; the multi-level perspective (MLP) which focuses on the dynamics between incumbent regimes that dominate the socio-technical system and niches where novelty emerges and experimentation take place driving innovation at a faster pace than in the established regime (Geels, 2012(Geels, , 2004)). This interaction in turn takes place in a larger landscape for socio-technical change, i.e. the context of macro-level drivers such as policy directions, market prices of commodities and societal culture and beliefs. The socio-technical perspective helps us establish empirical categories of data that shed light on different types of barriers and drivers. What are actually the main hurdles? Is there regime resistance that impede innovation and niche development? Is there a lack of correct/effective policy instruments? Or is it simply too slow technological development and cost reductions for things like batteries? Furthermore, are the key factors and barriers internal to a country or city, or is the transition constrained at the EU or global level? We deduce three hypotheses (one for each level in the MLP framework) drawing on previous analysis in Sweden (Albrecht et al., 2013;Magnusson and Rickne, 2012) to explore these questions. The final aim of the paper is to use this empirical research to contribute to recent developments in this literature critiquing the MLP framework for not taking more explicit account of the spatial aspects of socio-technical transitions (Coenen and Truffer, 2012;Coenen et al., 2012). This debate calls for more spatially explicit frameworks and empirical research and we thus use the following three hypothesis to explore the Stockholm case study both empirically and to inform our theoretical discussion.",
            "Hypothesis explored": " Hypothesis 1. The niche hypothesis. The relatively slow development of EV in Stockholm is the result of a lack of niches or poorly functioning niches. There are few spaces for niche development and niche actors and activities such as demonstration fleets and new market are few. This leads to few opportunities to experiment, engage with EV technology, learning and scale out. Examining this hypothesis, our research design examines, first, what actors exist at the niche level and to what extent they are connecting, and second what are the levels and types of activity that can be found at the niche level, and how do they perform in terms of learning and growing (Raven, 2008). Hypothesis 2. The regime hypothesis. The relatively slow development of EV in Stockholm is the result of a strong ICE car regime in Sweden. Anchored in the Swedish automotive industry and coupled institutional, cognitive and normative structures, the system tends to induce incremental developments of the transport systems, favouring, e.g., hybrids and efficiency improvements of the ICE, as opposed to more transformative changes such as BEV. Examining the second hypothesis, we examine how regime players (car manufacturers, transport planners) respond to the EV opportunities, whether they are driving the development in tandem with niches, and what cognitive and normative structures that shape the regime response (Geels, 2002). Hypothesis 3. The landscape hypothesis. The relatively slow development of EV in Stockholm is the result of a lack of economic incentives, policy directions, and visions at different scales. This results in a weak overall signal, that a transition to EVs in Stockholm is far off and/or highly uncertain, offering few incentives and prospects for regime or niche development in favour of EVs. Examining the third hypothesis, we consider the overall system of national incentives that are at play, as well as market aspects such as technology costs (Hillman et al., 2011).",
            "Theory and method": " The MLP offers analytical tools to make explicit the interplay between developments at niche, regime and landscape level, where many different types of interactions and resulting alternative transitions are possible (Geels and Schot, 2007;Markard and Truffer, 2008). The literature is primarily based on historical case studies with theoretical analysis of past technological transitions (e.g., Geels, 2012) and significant developments have been made in literature the past decade (Geels, 2011). However, the theory is generic and does not assume a certain spatial or jurisdictional scale to delineate cases (Coenen et al., 2012;Hodson and Marvin, 2010;Lawhon and Murphy, 2012). In practice, both theoretical and empirical studies often refer to national boundaries to illustrate the usefulness of MLP (Lawhon and Murphy, 2012), which is indeed the primary focus in recent efforts to apply MLP for transportation research (Geels, 2012;Nykvist and Whitmarsh, 2008). However, there is now an emerging research agenda recognizing the need for a geography perspective on sustainability transitions (Coenen and Truffer, 2012) with examples of locally explicit case studies that apply MLP and transitions theory, e.g., to the city level (Hodson and Marvin, 2010;Maassen, 2012). Key is that even if the generic MLP framework is applicable to any given scale, the niche and regime actors involved in a transition and the patterns of structuration are rarely possible to fully contain to a single geographical scale (Lawhon and Murphy, 2012). Car manufacturers are global actors, but with presence and influence across scales. Hence, in practice also local studies need to relate to the global innovation system and such cross scale analysis has not been developed much in previous MLP work (Bulkeley et al., 2011;Hodson and Marvin, 2010;Lawhon and Murphy, 2012). This is an important gap if the MLP framework is applied in research on automobility transitions since many variables related to regime concepts such as norms, prevailing policy, incumbent regime actors, and niche activities, are locally or nationally determined, but the transition is at the same time highly influenced and dependant on patterns of niche and regime interactions in a highly connected global socio-technical system. Hodson and Marvin (2010, p. 484) concluded that \"when utilizing these concepts in relation to particular problems, contexts or scales these terms need to be clarified.\" and this paper helps address this gap. We do so by both addressing the need for deeper empirical cases and place based analysis. Following Bulkeley et al. (2011) and Maassen (2012) we examine a specific city with its specific system characteristics. We also develop an adapted MLP framework that explicitly clarifies what spatial scales are considered.",
            "MLP framework for local socio-technical studies": " We consider the local MLP case as a sub-part to the higher MLP (Fig. 3). Some niche actors are local only, some are active locally, nationally, and globally, and some are national and global only, and so on. The corresponding logic applies also to the regime level. For example, in one sense, the personal mobility regime, with the car industry as a central player, is a global regime, where technology developments (part suppliers and coalitions of manufacturers collaborating on R&D), rule systems (e.g., harmonized safety and emission standards) and actor constellations all operate at the global level (global production and distribution systems). In another cut, the transport and infrastructure system of the Stockholm region can be understood as a regime where the city government and its administration are central actors. With such a lens, the global car industry (which has no real presence in Stockholm beyond retail sales) becomes part of the landscape. Third, when it comes to electrification of transport, new industrial actors become relevant, such as battery and electronic component manufacturers (e.g., Panasonic and Samsung) that despite their size and global presence can be argued to operate in new niches that present themselves not in a specific local context but actually emerge and grow in the global market system. At the national scale, the actors of the road-based personal mobility regime in Sweden include car manufacturers, parts and sub-contractors to the car industry, university researchers, sales and services networks, refuelling infrastructure, public procurers and leasing businesses etc. Moving to the local scale, several of these are represented in Stockholm, but some are not. The \"Swedish\" regime is in turn present in Stockholm to some degree. We make these different spatial patterns explicit in the MLP framework in the following way. For each level of structuration (niche, regimes, landscape), often illustrated as horizontal planes in the MLP framework, we indicate the spatial dimension along the xaxis. The generic character of the framework with structuration not necessarily linked to spatial scale (Hodson and Marvin, 2010) is kept, but at the same time the approach makes explicit the hierarchical patterns that exist through geographical scales.",
            "Methods": " In order to investigate the three hypotheses of the locally specific niche developments, regime dynamics, and landscape conditions, the case study method of process tracing was chosen, focusing on the recent historical development of EVs, written documentation in the form of reports and local policy, and transcripts of in-depth interviews (George and Bennett, 2005). The method is suitable for \"intensive study of one deviant case, a case that fails to fit existing theories, may provide significant theoretical insights\" (George and Bennett, 2005, p. 7). Hence, it is appropriate both as a tool to understand the details of niche and regime dynamics of Stockholm as a deviant case that in theory should be well progressed and supportive of BEV, and as a method to contribute to theoretical debates around the MLP framework. As the case is local in character, and there is only a limited amount of documentation available, the case study relies heavily on in-depth interviews and their transcriptions as the primary data source. The first set of interviews was identified through documents and news items, and the following remaining interviews identified by asking each new informant for new relevant actors to include (Kvale, 1996;Noy, 2008). The aim was to cover all key actors important too, or actively working with, the developments of BEV in Stockholm and interviews were conducted until no more key actors were identified through each interview. In total 11 actors were identified, but with some redundancy where actors have very similar roles and agendas (2 power companies) and 10 interviews were carried out. In addition, approaching the final count we experienced rapidly \"diminishing returns\" in terms of new information emerging in the interviews (as these were informant interviews not respondent interviews) (Kvale, 1996, p. 101). The majority of the actors are supportive of BEV, but few except Nissan are biased in having direct economic stakes of favouring BEV developments. Each actor was interview with a semi-structured interview guide with sections of open questions related to; (1) Drivers, barriers, and BEV technological progress; (2) New experiments, and activities (niche development); (3) Questions specific on regime resistance and engagement with BEV (regime dynamics), and finally; (4) the governance and policy measures supporting BEV development (landscape and policy developments) Respondents were promised anonymity, while stating the organizational affiliation, and interviews recorded for cross checking of notes and quotes if the respondents were comfortable with this (7 out of 10). Notes were transcribed immediately after each interview resulting in fully transcribed data in case of recorded interview and partly transcribed based on written notes in unrecorded cases. Coding of transcribed data was done both with initial codes based on the four sections of the guide (Bowen, 2008), and then with open coding, aggregating themes from common categories of statements on each of the three hypotheses as well as emerging themes in the data (Coffey and Atkinson, 1996;Patton, 2002). The aggregated patterns from themes in coded data provided the results on key aspects of each level in the MLP framework, and one emerging pattern on the importance of learning, knowledge of, and use of BEV, a causal factor that was not expected beforehand and therefore had no proposed hypothesis. Results generally consist of our descriptions of these aggregated patterns, but we also use some illustrative quotes on important cognitive and normative patterns where the actual wordings of informants are particularly telling of the process or barrier highlighted.",
            "Results": "",
            "Niche developments": " Among the earliest experiment with BEV in Stockholm were some 10-15 converted Mercedes 307 transport vehicles used by Televerket (the Swedish formerly state-owned telecommunications company and agency) in the early 1980s and some of these were used in Stockholm (Styrelsen f\u00f6r tekniks utveckling, 1981, p. 167). Before 1980 only a handful of converted BEV vehicles were produced annually (Styrelsen f\u00f6r tekniks utveckling, 1981, pp. 143-144). The City of Stockholm has experimented actively with BEV since the 1990s, and today operates ca 50 BEV, some of which belong to this first wave of BEV (Interview City of Stockholm). The initiative started in the early 1990s and was initiated by the former Swedish Development Agency (NUTEK) enabling a collaboration on BEV (project STEG) between the largest cities in Sweden (Stockholm City, 2010) and latter procurement of BEV. The first question in each interview was an open-ended one, asking: \"What drives the development of electric vehicles in Stockholm?\" and the answer given was typically \"Nothing\", or \"Very little\". When informants were asked about new initiatives, test fleets, and experiments, the actors working with these, and if there were any periods in time where the number of BEV cars in Stockholm had increased, very little emerged. Of the resourceful actors that could act decisively, only the City of Stockholm is working in an active niche, by running the procurement programme \"Elbilsupphandlingen\" together with Vattenfall, the largest power utility in Sweden, with the aim to help procurement of BEV and PHEV both locally in Stockholm and throughout Sweden. This is the major actor developing charging infrastructure in conjunction with public parking (Interviews with City of Stockholm and Stockholm Parking). In total 25% of the new BEV bought in Sweden in 2012 were procured through this initiative making this niche experiment not only important for the Stockholm, but for the whole of Sweden. Apart from this initiative there are few niches for BEV in Stockholm. In the interviews the second most often mentioned important niche actor is a courier service that operates only a total of 6 Nissan Leaf (interview Ryska Posten and Nissan dealership). The major taxi companies of Stockholm and rental agencies have one or a few cars each. A small number of actors are also experimenting with fast chargers and other charging solutions. Finally, there is one civil society initiative, \"Elbil 2020\", organized by a community of collaborating housing cooperatives. Elbil2020 organizes circa ten different projects on both BEV and PHEV, including demonstration fleets, organizing panels of consumer testing (today 300 people operating BEV and PHEV), organizing public and private charging infrastructure, and organizes seminars that bring together citizens, local politicians and commercial actors (Interview Elbil2020). The organization is, however, small and so far primarily influences development in the comparatively affluent city district of Hammarby Sj\u00f6stad.",
            "National and global actors supporting local niche activities": " Throughout our interviews the actors mentioned pushing for introduction of BEV are the power companies, with an obvious interest in supporting charging solutions if sound business models emerge, the municipalities of the Stockholm region, and the automaker Nissan. Nissan is important both due to the local Nissan car dealership that actively work for sales of BEV (Interview Nissan), and due to the marketing of the Nissan Leaf car and the support given for infrastructure developments by Nissan Europe in collaboration with some other local actors (A few municipalities, McDonald's, and the courier service mentioned above). Nissan Europe is one of very few actors behind the limited fast-charging infrastructure in Stockholm, another being one fuel supplier (OKQ8). In other words, actors that are to be considered national Swedish actors, e.g., the national procurement programme, other power companies, fuel providers, and even global actors such as Nissan, are more important for the current niche development than local niche actors. Momentum is gained as these actors from the national or global level show interest in the local EV development, and begin organizing or contributing to local initiatives.",
            "Lack of niches explain lack of experience of BEV and cognitive barriers": " The relatively few and highly limited niche activities result in few opportunities to engage with and learn more about BEV. Throughout the interviews it is clear that a very strong barrier for a more rapid development of BEV in Stockholm is the lack of personal experiences with BEV. This leads to misconceptions of what a BEV is, what it is capable of, and how a BEV can be used. Since the vast majority of BEV have limited range (all but Tesla Motors Roadster and Model S with close to 500 km range) current BEV are necessarily different to ICEs in terms ownership and user patterns. This constitutes an important cognitive barrier since most BEV requires a change in perception of what a car is and changed behavioural patterns where BEV car ownership need to be complemented with, e.g., renting of an ICE for longer trips. Interviewees highlight that most people that try a BEV through the test fleets are very sceptical before their first experience, reluctant in view of the inability to drive long distance on one charge, and uncomfortable with the limited charging options. Before drivers have had the personal experience, fast charging is perceived as very important, but after a while, this need declines, and in the end play a very minor role in people's minds. Using the BEV, drivers adapt, and start valuing other benefits such charging while parking, range anxiety declines, new user patterns emerge, and they leave the test phase with a positive impression. Due to the lack of niches, where consumers, policy actors, and private companies procuring vehicles could come in contact with BEV, this cognitive and normative change in perception of BEV is very slow. This pattern is neatly summarized by one of our interviewees, who conclude: \"A common claim one gets is that there are no fast chargers. But you do not have to refuel! Just get used to the idea to do something different. When do you need fast chargers? You don't use them -you drive with the range that you have.\" Meeting people again after having the vehicle for a while they conclude: \"I had such strange questions before [I tested it]\".",
            "Support for the niche hypothesis": " We identify strong support for our first hypothesis. There are very few local initiatives, test fleets are small, and there is limited experience on BEV use to generate knowledge and spread awareness. BEVs are not visible locally. There is clearly a lack of initiatives and support for local experiments and alternatives to the national level support systems that could encourage more niche developments.",
            "Regime resistance and adaptations": " The Stockholm region has no car manufacturers, and the local transport regime actors are primarily the policy actors including local and regional politicians and planners. The regime includes the transport infrastructure, where Stockholm has a strong record in public transport. This would potentially help explain the lack of interest in BEV and other sustainable person road transport technologies. In other words, the \"the landscape pressure\" for sustainable transport would be absorbed by public transport and would not create societal demand for BEV. However, despite a high share of public transportation, local infrastructure planning still indicates a strong dominance of the car regime, and car use levels are high in Stockholm -similar to those of for example Oslo -and the trend is towards greater share of car use (SL, 2010). Following the adapted MLP framework we consider the national regime actors that are locally represented in the analysis. This includes foreign and global car companies, such as Nissan, present through vendors of cars on the Swedish market. It also includes the Swedish car manufacturers Volvo and Saab (in the late 90s acquired by Ford and General Motors respectively, and in recent years sold to Chinese companies), who dominated sales until late 1990s. (Volvo continues to be the bestselling brand in Sweden.)",
            "Reluctant adaptation and compliance": " The car industry, clearly at the centre of the personal mobility regime, constitutes a barrier also locally in Stockholm, but shows signs of adaptation. On the one hand they adapt when policy frameworks set the direction. From our interviews we conclude that they are all perceived to be generally in favour of the currently unfolding electrification of the power train in ICE cars. Due to more strict emissions regulation globally and in particular the requirements of average CO 2 emissions in EU and Zero Emission Vehicles requirements in (parts of) the US, all major car manufacturers have developed electric vehicles for specific markets (e.g., compliance cars in California) and put significant resources into improved fuel efficiency and hybridization. On the other hand, they are careful not to carry the costs of spearheading the technology and market development, and the result is a reluctance to engage with development and promotion of pure electric vehicles. Nissan was the only manufacturer with a reasonable consumer BEV car on the market in Sweden in 2013 and the only car company mentioned as a driving force in our case study. Other major brands on the Swedish market like Toyota, Opel, and Audi, are primarily pushing for PHEV cars. Volvo, being the only major remaining Swedish car manufacturer in Sweden, belongs to the category of car manufacturers that now push for PHEV. They recently began manufacturing engines developed for seamless integration hybrid solutions representing an investment of 2 billion SEK (St\u00e4pel, 2013) part of a 73 Billion SEK investment programme geared at new vehicle platform supporting PHEV (Volvo, 2013). Volvo did engage early on in the R&D of HEV. However, these initiatives never lead to HEV being released to the market as Ford purchased Volvo and centralized HEV R&D (Magnusson and Rickne, 2012). Interest remerged in 2005-2010 due to debates on climate change, increasing fuel prices and the EU standards for average CO 2 emissions from manufacturers. A limited test fleet of adapted battery electric versions of Volvo C30 available for lease since 2010 have not been followed through with BEV being developed for sales and the C30 model programme as such is being discontinued (Vijayenthiran, 2012). The recent efforts of other brands such as BMW, currently introducing the all-electric i3, and the future models by highly popular WV (all-electric Golf and Up models) were rarely mentioned in interviews. In summary, there is little support at the regime level in Stockholm for pure BEV, and the car industry and their sales of vehicles in Sweden is geared towards hybridization and PHEV instead of pure BEV.",
            "Cognitive and normative barriers in the regime": " Regime dynamics is also about the interplay between hard technological systems factors and soft institutional factors such as societal norms, values and attitudes (normative structures) and knowledge and perspectives (cognitive structures). Herein lays a particular stickiness in the regime. Our interviews suggest that there are specific interpretations and cognitive frames for what a car is and should be. One reason for the reluctance towards BEV in the car industry can be the human capital devoted to the internal combustion engine (ICE). Indeed, the engine development is often considered the \"heart of the car industry\" and the main performance attribute for cars. Removing the ICE and instead simply purchase electrical engines from electronic engineering firms, means removing a core part of the auto manufacturers' identity. It would also signify a dramatic change of the industrial logic and require a shift in skills and capacities in the car manufacturing industry itself. Also, some interviewees mention the problem of significantly reduced after sales service revenue for car companies of the pure BEV compared to the much more complex ICE vehicle. The normative structure, as an integral part of the regime, also links to a specific consumer attitudes-where the popular preference in Sweden is for large cars as a prioritized family equipment, and a symbol of welfare and status (Henriksson, 2008). As a result, for a long time, Sweden has had, together with Germany, the heaviest and most energy intensive car fleet in the EU (ICCT, 2012). BEV vehicles, on the contrary, are with few exemptions (e.g., Tesla Model S) typically small and nimble and signal entirely different values. From consumers, respondents frequently hear that the EV is not \"a real car\". As one of our interviewees express this barrier: \"A lot of BEVs cannot have a towing hook. A barrier in Sweden! If you have a company car, you have it as first choice for everything. Pulling a trailer, for instance. Drive to the summer cottage. If you cannot do that you have to rethink.\" The question is how stable and resistant to change these normative and cognitive structures are. Statistics over driver's licenses in Stockholm now show a rapid decline among young drivers: the young generation places much less priority and value on personal mobility than previous generations. For those that are still enthusiastic about private cars, testing periods suggest that with even initial experience, people are prepared to rather quickly rethink the personal mobility paradigm. One interviewee recollected a statement by a Stockholm city focus-group respondent, who said: \"First I did not want it-now I don't want to be without it\".",
            "Regime dynamics on charging infrastructure": " Lack of charging infrastructure, and fast charging in particular, is a complex barrier to disentangle. Many interviewed actors argue that the lack of charging infrastructure is of limited importance since most cars will be charged over night at parking places at homes (and work). Range anxiety is also seen as a limited problem, if consumers are only able to try out BEV and develop new user patterns (as discussed in Section 3.1.3). However, fast chargers are important as a signal that the BEV is here to stay and as a remedy for range anxiety. Although for people that start using EVs they find that one uses fast charging much less than anticipated-they find that they can \"trust\" the battery much like you trust the gas tank indicator on a conventional car. As one of our informants expressed it: \"Of course [the charger] has a symbolic value, as we have seen in Japan -there they started by setting up one fast charger, then another, and then they measured the driving patterns, and then people dared to go much farther. But they had not charged more, but instead they dare return home with a more depleted battery. So, certainly [chargers] contribute to reducing range anxiety. Here, regime actors are to some degree active. The City of Stockholm has given the publicly owned parking company the task and mandate to encourage and build out public charging and citizens can request that chargers are built in garages with parking for rent. However, politicians are also clearly reluctant to act proactively in advance of demand for charging infrastructure. They (with few exceptions) do not contribute to the development fast-charging infrastructure and are against charging along public roads (Interview Stockholm Parking, Fortum). This latter fact is clearly a regime barrier in that the majority of citizens in Stockholm lives in apartment blocks and park their cars on the road, and not in a private or public garage.",
            "Support for the regime hypothesis": " To conclude, we find some support for the ICE regime being particularly strong in Sweden. Volvo, with strong market shares, has favoured a slow progression of hybrids over pure BEV. These car manufacturers are strongly associated with the prevalent norms in society of what a car is and how it is used, and this cross-fertilization of regime actors and norms in both industry and among consumers currently constitute a strong barrier for BEV. However, it is also the case that the regime shows quite some ability to adapt. When stricter polices have been introduced in EU on average emissions of CO 2 , auto manufacturers do adapt, and build more efficient cars. When consumers get hands-on experience their attitudes change. The regime level barriers must therefore be understood in the light of the regime responding to policy change at the landscape level.",
            "Policy landscape drivers and barriers": "",
            "Prices of fuels and technologies": " A key factor is relative prices of different technologies. One driver in this regard is the increasing fuel cost, both due to increasing oil prices and higher taxes on energy and CO 2 (raising inflation adjusted prices about 50% from 1980 to 2013, and the changing policy landscape in Sweden and EU have led to more efficient passenger cars in Sweden (Fig. 4). The single most important landscape factor for the BEV technology is, however, the reduction of battery costs (Cairns and Albertus, 2010). While the specific battery technology in BEV varies, the vast majority uses some form of Li-ion batteries (de Santiago et al., 2012). There are no academic publications that coherently report the declining battery cost at pack level for BEV. Therefore this study has made a short review of reports and individual studies from the scientific literature, grey literature, and white papers. The results are shown in Fig. 5, and highlight an impressive cost reduction of 18% annually and a cost in 2012 of about 500 USD/kWh at pack level. This should be compared with, e.g., the target price by the U.S. Advanced Battery Consortium (USABC) initiated by the Obama Administration for mass adoption of BEV placed at 150 USD/kWh. This goal might be reached substantially faster than many actors predict. In fact, recent outlooks (Tran et al., 2012) only assessed data from 2007 to 2008 giving the impression that Li-ion battery prices at pack level are still at 1000 kWh USD. Similarly, the assessment in a recent Swedish public inquiry put current prices at 600-800 USD and prices in 2020 at 400-450 USD/kWh (Regeringskansliet, 2013a). These often cited battery costs in the range of There are few academics sources and prices are here estimate from a range of sources (Deutche Bank, 2009;Element Energy Limited, 2012;Gaines and Cuenca, 2000;IEA, 2013;Kassatly, 2010). 600-1000 USD/kWh should now be reconsidered as cost estimates are declining rapidly. The declining cost of batteries is a landscape factor that currently is a strong and rapidly changing driver for BEV development globally.",
            "Environmental and climate change drivers": " Over the last five years, EU air quality norms have been exceeded for certain parts of the Stockholm city. This has triggered a significant political debate and formal responses from the city of Stockholm to the European Commission (Stockholm Region EU Office, 2013) and could be expected to be a driver, but surprisingly few actors mention it. Climate change is more often mentioned as a driver for introduction of BEV, and specifically, that policy makers put pressure on the car industry to produce cleaner and more efficient vehicles. The availability of BEV, the market promotion of these vehicles, and procurement by Stockholm City and the major niche actors, is all to be understood against this backdrop of increasing recognition of climate change and the policy goal of a fossil fuel independent transport sector in 2030, both nationally (Regeringskansliet, 2013b) and locally in Stockholm (Stockholm Stad, 2012). However, these landscape changes seem to have rather enabled incrementally more efficient ICE vehicles (Fig. 4).",
            "National policy uncertainty and ambivalence": " The most often mentioned barrier to BEV uptake in our case is the unpredictability and perceived ambivalence in political support of new technologies in general, and the weak signal on BEV in particular. In order to understand why this is the case it is important to know that Sweden has since the 1970s been in the forefront of developing alternative fuel technology for personal vehicles (Hillman, 2008;Ulmanen, 2013). This development culminated in the mid 2000s due to a strong policy framework that required fuel providers to make renewable alternatives available at gas stations. At the time, this favoured the adoption of biogas and ethanol flexi-fuel vehicles in particular (Nykvist and Whitmarsh, 2008), and lead to a major expansion of ethanol vehicles nation-wide. In early 2010s, the debate on the negative environmental and social impacts of first-generation biofuels received significant attention and the political support faded. Today, sales are back at 2004 levels (Fig. 6). This hype and decline (Geels, 2012, p. 477) of biofuels in Sweden now surfaces in our local case study as a barrier. All interviewees describe the lack of lasting polices for alternative technologies with resulting uncertainty in the political support for BEV and charging infrastructure. At both the Stockholm and national level there are overarching visions about a fossil free transport fleet by 2030, but the government parties are afraid to abandon the \"technology neutrality\" axiom and do not want to be accused of \"picking winners\" in particular ones that have limited support from the car manufacturers. In the 1990 and 2000s both Volvo and Saab developed flexi-fuel cars (constituting regime adaptation) much more progressively than is now the case with BEV and PHEV, where industry and policy makers are both waiting for the other to lead the way.",
            "Support for the policy landscape hypothesis": " As expected, there is lack of policies driving the introduction of BEV in Stockholm. However, it was not clear beforehand why polices are lacking. Our case study identifies a couple of landscape factors that explain why Stockholm is lagging behind. Since fuel prices, climate change concerns and battery prices are national and international landscape factors, they give limited value for explaining this. Instead, the most important ones are the ambivalence of national policy makers resulting in a weak signal and uncertainty for both industry and consumers whether choosing to purchase or market a BEV makes sense in the long term. This ambivalence is rooted in both policy paradigms (market liberalism) and poor political experiences (ethanol) of the state \"picking winners\".",
            "Conclusion and implications": " Stockholm is in many respects an environmental front-runner and received the award European Green Capital by the EU Commission in 2010, with clear visions of becoming independent of fossil fuels and attaining net zero CO 2 emissions. Sweden, in turn, is routinely listed as one of the most innovative countries in the world, with a proud automotive manufacturing legacy, a history of support for alternative vehicles and fuels, and a national policy framework with high CO 2 taxes to support the adoption of low carbon technologies. However, despite these seemingly good conditions, progress on Battery Electric Vehicles (BEV), the currently most researched and argued for low carbon option for personal road-based transport, has been very slow. How should we understand this paradox? This paper, using a locally adapted version of the multilevel perspective (MLP) to understand socio-technical change, gives support to explanatory factors at niche, regime and landscape levels. The MLP framework has provided relevant and useful perspectives for generating hypotheses and empirical focal areas at different levels. The hypotheses are not competing but complementary: explanations for the situation are nested in each of them. The niche hypothesis receives the strongest support. Very few local niche initiatives exist in Stockholm, resulting in very limited awareness, experience of, and therefore knowledge of BEV. This results in many misconceptions of the progress of the technology, among planners, policy makers and consumers. In fact, one of the strongest supporting actors locally is not a niche actor per se, but Nissan through its Swedish presence (Nissan Nordic) and the local Nissan dealership. It should be noted that we have not explicitly measured the scale of the niches or the degree of coordination between niches-factors that can be at least as important as the amount of niches. Arguably, a few strong and highly coordinated niche developments can be more impactful for a transition than a multitude of small and fragmented ones. However, our interviews have not suggested that the niches that do exist are either strong or strongly coordinated. The support for the regime hypothesis is not as strong, but can still be clearly discerned. There appears to be \"regime ambivalence\" towards EVs, leading to disparate and limited regime change, and adaptations primarily in support of PHEVs as opposed to BEVs. BEVs are to some degree threatening key structures built up around ICE innovation and development, which lies at the heart of the car industry and its service revenue streams. That incumbent actors -and in particular industrycan act as barriers to transitions due to commercial interest is a common notion in regime studies and our interviews do give partial support to this explanation. However, as the current development within the commercially available BEVs is now quickly changing, this explanation is rapidly losing ground. At least as important barriers that come out in our data are the prevailing norms and perceptions among consumers as well as producers of what a \"real\" car is, how it should be used, coupled with a lack of knowledge and experience of how to use EVs. The cognitive dimension is probably very important to explain the differences between Stockholm and Oslo. In Oslo and Norway where there appears to be greater alignment between both perception of cars and the capability of BEV, and higher observability as BEV have easily recognizable license plates and access to bus lines in Oslo, this is effectively raising the awareness of BEV (Figenbaum and Kolbenstvedt, 2013, p. 20). Viewed in the larger context of marked differences also between Denmark and Norway, despite strong incentives in the latter (Albrecht et al., 2013), this calls for more comparative research between all the Nordic countries. Finally, there is considerable support for the landscape hypothesis, and in particular policy uncertainty and lack of sufficient political support for subsidies lowering the costs of BEVs. The uncertainty concerns both the goal itself (will BEV be a preferred option in 10 years or not?) and the instruments to achieve it (will there be a subsidy or some other measure?). This lack of policy signal is set against a background of strong aversion against technology-specific support and reluctance to repeat what is now commonly perceived as a mistake: the support for ethanol as a transport fuel, a policy decision that backfired on politicians when public and expert opinion on biofuels changed. The national policy and car actors in Sweden are therefore now significantly more reluctant and ambivalent towards the technology uncertainties with BEV, resulting in a lack of signal. Also at the Stockholm city level, even in the \"green sector\", there is ambivalence in relation to BEVs. Do we really want to promote an expansion of BEVs through, for instance, building up charging infrastructure, or should local transport policy be more geared towards shifting from private to public transport? The regime response to this weak signal is to focus on developing PHEV rather than BEV. PHEV are seen as the natural development of earlier hybridizations, as easier to implement, circumventing the (real and perceived) lack of charging infrastructure, and less challenging from a consumer acceptance perspective.",
            "The usefulness of a spatially explicit MPL framework": " This paper has responded to calls for case studies of transitions at geographical scales other than the nation state (Lawhon and Murphy, 2012;Hodson and Marvin, 2010). The framework that we introduce modifies the existing MLP framework (Geels, 2002) and combines the spatial scale with analysis of structuration. This makes it possible to describe a rich empirical picture where the interactions between local niche developments (such as spaces for early adoption of BEV in test-fleets), need to be analyzed in parallel with niche developments that have a global character. The promise of lower batteries costs and the entering of new actors such as Tesla are phenomena that can be described as niche developments in relation to the existing regime, yet unfold on the global arena and market. In Stockholm, important niche activities are triggered by innovations and collaborations fostered by global actors such as Nissan. Coenen et al. (2012) used the example of wind turbine innovation, and we show in this paper that also the niche development in the electro mobility domain have both local, national, and global dimensions \"from the start\" (Coenen et al., 2012, p. 973). While much of the theoretical groundwork and arguments for this type of analysis have been put forward by the above scholars, our paper contributes with a novel empirical example, and a suggested concrete modification of the MLP framework and its graphical representation of structuration.",
            "Policy implications": " Debates about supporting policies for BEVs tend to revolve around economic incentives and charging infrastructure. This study suggests that this focus must be complemented with other measures. As regards economic incentives, it is true that the current incentives to select BEVs are not sufficient for a mass-market acceleration, but judging by cost developments (see Section 3.3) they can become close to \"grid parity\" very soon. Volumes are needed to press costs downward, but since the market is global, Stockholm actions will not affect cost reductions. Over the scale up phase, it should be possible to reduce incentive schemes gradually. As regards the charging infrastructure, although charging is needed, the actual need for the individual drivers have been proven to be exaggerated, but is important as a signal to consumers. One advantage with looking at in-depth empirical case studies is that we can get a firmer grip on real barriers. Critical barriers are visible at all three levels: at the landscape level there is significant ambivalence and lack of political signals. At the regime level most actors in the car industry are not pushing for BEV, and at the niche level there are consumers not getting experience and knowledge about BEVs. We submit that policy and governance measures are needed to address all these issues. The conclusions drawn from this study does not allow us to go into detail on policy prescriptions but can only make general observations. In general terms, there is a need for efforts for changing of norms and knowledge by exposing different actors to demonstration, testing and piloting. There is a large opportunity for spurring BEV developments through enabling funding for local projects and initiatives, as a complement to national-level economic incentives. In addition, a much stronger policy signal is needed on where the societal priorities are for the transport system. In summary, if more BEV is viewed as a desired way to faster progress towards set policy objectives of a fossil-fuel free vehicle fleet by 2030, both locally in Stockholm and nationally in Sweden, an acceleration of the penetration of BEVs needs to be induced through appropriate policy measures. Several measures are linked and build upon each other. First, there is reason to investigate a further enhancement of economic incentives -with a long time horizon but also with a clear plan for phase out as technology costs come down. Second, local and national government can give a more coherent signal that they see this as an important infrastructure development priority. Such a signal probably requires overcoming the current aversion against technology-specific support measures. Third, promotion of demonstrations and pilots, using both fleets of professional vehicles and public procurement could help familiarizing drivers with the experience of BEVs.",
            "Appendix A.": " The following actors were interviewed in the study."
        }
    },
    "10.1016/j.eist.2013.12.001": {
        "file_name": "115 Analysis of institutional work on innovation trajectories in water infrastructure systems of Melbourne, Australia",
        "title": "Environmental Innovation and Societal Transitions",
        "abstract": "Infrastructure systems are facing sustainability challenges but are locked into their current practices. Transitions studies aims to understand trajectories towards new socio-technical regimes and argue for agency-centric perspectives to explain processes of change. This paper adopts an institutional lens, examining the institutional creation processes needed for maturing innovations within established systems. Three innovations in Melbourne's water system were selected as empirical cases: desalination, wastewater recycling and stormwater harvesting. Each had a different institutional alignment with the established regime and different trajectories between key stages of maturity, from pre-niche to niche, niche-regime and regime. The paper examines the purposes and types of institutional work undertaken to support each stage: cultural-cognitive, normative and regulative. Their trajectories were influenced by the regime alignment and characterised by maturation speed, institutional work undertaken and limiting conditions for further maturation. Cross-case comparison enabled derivation of hypotheses on the linkage between institutional work and innovation maturity.",
        "label": "Qualitative",
        "text": {
            "Infrastructure systems are facing sustainability challenges but are locked into their current practices. Transitions studies aims to understand trajectories towards new socio-technical regimes and argue for agency-centric perspectives to explain processes of change. This paper adopts an institutional lens, examining the institutional creation processes needed for maturing innovations within established systems. Three innovations in Melbourne's water system were selected as empirical cases: desalination, wastewater recycling and stormwater harvesting. Each had a different institutional alignment with the established regime and different trajectories between key stages of maturity, from pre-niche to niche, niche-regime and regime. The paper examines the purposes and types of institutional work undertaken to support each stage: cultural-cognitive, normative and regulative. Their trajectories were influenced by the regime alignment and characterised by maturation speed, institutional work undertaken and limiting conditions for further maturation. Cross-case comparison enabled derivation of hypotheses on the linkage between institutional work and innovation maturity.": " Infrastructure systems are facing sustainability challenges but are locked into their current practices. Transitions studies aims to understand trajectories towards new socio-technical regimes and argue for agency-centric perspectives to explain processes of change. This paper adopts an institutional lens, examining the institutional creation processes needed for maturing innovations within established systems. Three innovations in Melbourne's water system were selected as empirical cases: desalination, wastewater recycling and stormwater harvesting. Each had a different institutional alignment with the established regime and different trajectories between key stages of maturity, from pre-niche to niche, niche-regime and regime. The paper examines the purposes and types of institutional work undertaken to support each stage: cultural-cognitive, normative and regulative. Their trajectories were influenced by the regime alignment and characterised by maturation speed, institutional work undertaken and limiting conditions for further maturation. Cross-case comparison enabled derivation of hypotheses on the linkage between institutional work and innovation maturity. \u00a9 2013 Elsevier B.V. All rights reserved.",
            "Introduction": " Complex infrastructure systems such as water, energy and transportation are facing immense sustainability challenges globally. Impacts of climate change, population growth, ecosystem degradation and resource limitations are having significant consequences for how well these systems can deliver services that adequately meet societies' needs (e.g. Bates et al., 2008;Frantzeskaki and Loorbach, 2010;Westley et al., 2011). Despite a growing scholarly and practical awareness that fundamental changes in urban infrastructure systems are required (e.g. Chapin III et al., 2010;de Graaf and van der Brugge, 2010;Pahl-Wostl, 2009;Truffer et al., 2010), sectors are locked into their current approaches due to barriers such as path-dependencies, institutional inertia and inadequate actor capacity to engage in new practices (Berkhout, 2002;Farrelly and Brown, 2011;Frantzeskaki and Loorbach, 2010;Pahl-Wostl, 2009;Westley et al., 2011). To overcome these challenges, scholars argue it is critical to support the emergence, up-scaling and stabilisation of innovative technologies and practices that increase the sustainability of urban infrastructure systems (Frantzeskaki and Loorbach, 2010;Pahl-Wostl, 2009;Truffer et al., 2010). Transitions studies focuses on addressing path-dependencies, with particular attention on trajectories towards new socio-technical regimes that are likely to encompass a range of innovations. In recent years, this scholarship has advocated that further explanatory detail on the role of agency in stimulating and steering the maturation of innovations is needed (e.g. Brown et al., 2013;Farla et al., 2012;Grin et al., 2011;Markard et al., 2012). An institutional lens that focuses on the institutional structuring processes that actors put in place may contribute to developing this more agency-centric perspective for understanding processes of transitional change (e.g. Brown et al., 2013;Geels, 2004;Geels and Schot, 2007;Truffer et al., 2009). In this study, we define an innovation as a new technology and associated practices within an existing infrastructure system, which provides an alternative utility (e.g. harvested stormwater runoff or recycled wastewater as new city water supplies). Following Geels and Schot (2007), it is possible that innovations could reinforce and/or disturb the established regime of the infrastructure system, depending on whether their nature is as a replacement, or as a competence-enhancing add-on. Realisation of the innovation's utility is likely to depend on the role of agency and associated institutional structuring processes mediating the dynamics between the innovation and the regime. From an institutional perspective, the maturing of an innovation is reflected by the development of a new set of institutions that could co-exist or undermine those of the established regime. Drawing on Scott's (2008) new institutionalism research, an innovation that is fully institutionalised would be characterised by a mature suite of mutually supportive cultural-cognitive, normative and regulative structures, which collectively provide the 'rules' for reinforcing its realisation within the infrastructure system. The efforts to develop this suite of structures has been described as 'institutional work', which brings focus to the role of deliberate agency in creating, maintaining and disrupting formal and informal institutions (Lawrence and Suddaby, 2006;Lawrence et al., 2011). The evolution of institutional work in relation to the maturity of an innovation is yet to be explored. The aim of this paper is therefore to develop the first set of hypotheses on the type and purpose of institutional work needed to establish innovations within an existing infrastructure system. To do this, the paper focuses on how institutional work to create new institutions evolves between key stages (i.e. from pre-niche, to niche, to niche-regime, to regime) during the maturation of innovations. Three innovations were selected as empirical case studies with different institutional alignments (reinforcing and/or disrupting) with the established regime to ensure an internally valid and reliable base for hypotheses development. The study context is the water system of metropolitan Melbourne, involving a system-scale empirical analysis of the dominant patterns of institutional work that reflected the maturing of desalination (reinforcing), wastewater recycling (reinforcing and disrupting) and stormwater harvesting (disrupting) between 1997 and 2012. These innovations emerged as novel and qualitatively different to the status quo, attracting variable levels of public confidence and controversy as alternative water supply approaches. The three case studies, treated as innovations, were therefore considered ideal for this research. Contrasting within and across these cases allowed for generalising and, subsequently, deriving hypotheses on the dominant patterns of institutional work for maturing innovations. These hypotheses may also contribute to the identification of preliminary indicators of the type and direction of agency required for navigating transitions (Brown et al., 2013). While the empirical analysis led to development of rich descriptions and explanatory detail of agency-related activities (such as individual strategies, networks development and political positioning), this was for the purpose of identifying the types of institutional work employed. Therefore, this paper does not report on the agency of individual actors and their associated power dynamics, but rather the institutional structuring patterns as a result of this activity.",
            "Analytic framework": " This research adopted the multi-pattern approach ( de Haan and Rotmans, 2011;de Haan, 2010) as the conceptual architecture for framing the overall study and individual cases. This framework conceptualises that a societal system is comprised of co-existing subsystems (known as constellations) that interact (Fig. 1a). Individual constellations are distinguishable by the service(s) they deliver and the way in which the service is delivered. Each constellation functions to meet societal needs with varying degrees of influence on the overall system. The proportion of system functioning attributed to a constellation is its power, or relative degree of influence (de Haan and Rotmans, 2011;de Haan, 2010). While power is a continuous measure, the multi-pattern approach identifies ideal types of constellations according to their overall share of system power. Regimes are the most powerful, dominating and determining a system's functioning. Niche-regimes have moderate power, exerting significant influence on system function and regimes. Niches have low power; they are innovations that have some system function but no impact on regimes. Pre-niches are introduced in this paper as constellations that exist but provide no system function and, therefore, have no power. Fig. 1b represents the maturing of an individual constellation over time; its increasing power corresponds to stages of the multi-phase S-curve (Rotmans et al., 2001;van der Brugge and Rotmans, 2007). While the multi-phase concept typically characterises a transition at the system scale, its use in Fig. 1b  of innovation diffusion, which in this paper is conceptualised as the increasing power, or maturation, of an individual constellation. The trajectory of each innovation in the Melbourne case studies was mapped by identifying its key maturity stages (Fig. 1b) according to how it influenced mainstream water supply servicing. A pre-niche existed only as an idea, plan or undeveloped technology, with no implementation in realworld practice (e.g. preliminary scoping, early investigations). A niche's activities were implemented through trials and demonstrations by a small actor network, protected from the mainstream (e.g. pilot projects, guidelines development). A niche-regime's technologies and practices were being adopted by regime actors, but not yet accepted as mainstream (e.g. large-scale trials, medium to long-term contracts). When an innovation had become embedded as a mainstream technology and practice, it was considered part of the regime (e.g. business as usual). From an institutional perspective, increasing innovation maturity is reflected by the creation of new institutions. In order to reveal patterns in institutional development for maturing an innovation along the trajectory in Fig. 1b, the study analysed the purpose and type of institutional work (Lawrence and Suddaby, 2006;Lawrence et al., 2011) undertaken during each key stage of development to create new institutions. The type of institutional work employed was categorised according to Scott's (2008) typology of cultural-cognitive, normative and regulative institutional pillars, well-accepted as a macro-level synthesis of new institutional theory. Indicators for the development of these three institutional categories were inductively identified from examples in scholarship on new institutionalism, supplemented by the study's empirical data to ensure that all relevant institutions created in the cases would be mapped (see Table 1). An innovation would be considered 'fully institutionalised' when all categories of institutions in Table 1 are developed. The alignment of an innovation with the established regime depends on both the institutional and infrastructural fit. For the purposes of this study, the degree of fit was assessed by comparing the indicators for each type of institution in Table 1. Three classes of institutional indicators were defined: (a) already existing in the established regime; (b) new and non-competitive, that could co-exist with the established regime; and (c) new and competitive, that would require the established regime to adapt. Aggregate assessment across the indicators led to classification of the innovation as having a reinforcing (mostly 'existing'), disrupting (mostly 'new and competitive'), or mixed (a mix of all three) institutional alignment with the established regime.",
            "Research design and approach": " Examining the phenomena of institutional work is highly contextual and therefore relies on the triangulation of multiple forms of evidence that have been subjected to internal and external validity testing (Yin, 2009). As such, the research design was a multiple-case analysis within a common sociopolitical and sectoral context.",
            "Case selection and context": " Melbourne is the capital of the Australian state of Victoria and home to 4.1 million people. It is located on Port Phillip Bay and covers approximately 7700 km 2 . The city has recently experienced climatic extremes: drought began in 1997 and lasted for 13 years, followed by 2 years of intense rainfall events and severe flooding. During this period, Melbourne became internationally acknowledged as a world leader in sustainable urban water management (Jefferies and Duffy, 2011;Roy et al., 2008) and significant changes in technology and practice occurred. While there is debate about how sustainable some of these innovations are (e.g. Barnett and O'Neill, 2010), the system is considered to be undergoing transitional change (Ferguson et al., 2013c) and offered a rich empirical case context for study. The case study period extends from the beginning of the drought in January 1997 to December 2012. The embedded cases were selected according to the criterion that they represented viable service delivery alternatives for addressing Melbourne's water security challenges through new public infrastructure. This ensured they would provide a base for comparing and contrasting the maturation trajectories of innovations within a common socio-political, sectoral and scalar context. While a range of significant changes in water supply servicing occurred in Melbourne (such as the introduction of water efficiency measures and the private uptake of household technologies such as rainwater tanks and onsite grey water systems), only desalination, wastewater recycling and stormwater harvesting met the selection criterion (for a full account of Melbourne's water system changes, see Ferguson et al. (2013a)). Fig. 2 depicts the constellations that comprised Melbourne's water system in 1997 and 2012. Throughout the case study period the established regime consisted of three constellations: reservoirs and dams, wastewater treatment and disposal, and stormwater drainage. The innovation constellations for alternative water supplies were virtually non-existent in 1997, growing to a stormwater harvesting niche, wastewater recycling niche-regime and desalination as part of a new regime by 2012.",
            "Data collection and analysis": " Primary and secondary qualitative data were collected, compiled and analysed to develop chronological narratives for the three innovation cases. Oral histories (n = 20) were collected from individual actors who had undertaken institutional work to support the maturing of at least one of the innovations investigated. Four group interviews (n = 9) were conducted, with two or three individuals participating in each. Participants were identified through snowball sampling, which involved finding potential participants through referrals from key actors in major organisations of Melbourne's water system. All participants were directly involved in the changes of Melbourne's water system through the case study period and represented state Government departments, water utilities, local municipalities, academia and the private sector. (Community groups and environmental organisations were not identified in the snowball sampling as having significant influence on the maturation of the three innovations examined in this study.) Participants held middle to senior-level positions in their organisations during the case study period, in both technical and managerial domains. Oral history and group interviews were in-depth and free-flowing, allowing participants to provide detailed narratives of their personal recollections of key system changes in recent decades. Secondary data included policy materials and reports from stakeholder organisations (including government agencies, water utilities, industry associations), media articles (e.g. newspapers) and relevant scientific literature. These data were collected in the context of a larger project; other publications are available that partially make use of the data (e.g. Ferguson et al., 2013a). Interview transcripts and secondary documentation were analysed with the aim of constructing succinct and engaging chronological narratives of the development of the three innovations studied. The themes, perceptions and explanations in the qualitative data were contrasted and compared by the research team to develop converging accounts of the activities undertaken to support the maturing of each water supply innovation. The results from this analytic phase are presented as stylised narratives rather than as raw data (e.g. interviewee quotes). Policy documents that were instrumental in shifting the direction of water management in Melbourne are referred to in the narratives but it is beyond the paper's scope to identify all scientific and policy documents which relate to the maturation of the three innovations studied. The case narratives provided a detailed base for analysing the purpose and type of institutional work undertaken during the maturing of desalination, wastewater recycling and stormwater harvesting. Interview transcripts and secondary documentation were used to identify the types of institutions that were created through institutional work, within the analytic boundaries set by the case narratives. The maturation trajectory of each innovation was then plotted, representing its growing power in response to the institutional development. A comparative analysis of the three innovations was then undertaken, focusing on two dimensions. First, the institutional alignment (reinforcing, mixed or disrupting) of each innovation with the established regime was classified by comparing across the indicators for each category in Table 1. Second, the purpose and type of institutional work undertaken to support each trajectory was compared to identify similarities and differences for each key stage of maturity (pre-niche to niche, niche to niche-regime, niche-regime to regime). This cross-case comparison was an iterative process of explanation building, drawing on analytic techniques that involved comparing patterns (Yin, 2009) across the maturity stage of each innovation, their institutional alignment with the existing regime and the purpose and type of institutional work that enabled their maturation. Hypotheses were then derived from common patterns identified across the different trajectories.",
            "Validity": " Ensuring the validity of qualitative data involves determining that research findings are accurate from the perspective of the researcher, participant and reader (Creswell, 2009). Validity of the case narratives was achieved by triangulating different data sources to build converging narratives from different interviewee perspectives and secondary documentation (Yin, 2009). Disparities and contradictions in the evidence were further investigated and clarified in short follow up interviews with key informants. External validation of the case narratives and maturation trajectories was achieved through a validation workshop, in which tabulated data on the institutional work undertaken for each case of innovation were presented to three water sector leaders. These actors had participated in oral history interviews and were instrumentally involved in supporting the maturing of the water supply innovations studied. They thoroughly reviewed this data and provided critique on whether any were missing, the accuracy of emphasis on the significance of the institutional work types identified and the speed of each innovation's maturation. The consolidated case narratives were also sent to the same actors for further review and critique.",
            "Case narratives": " This section describes the institutions and infrastructure of the established regime and each of the three innovations. A short chronological narrative of the institutional work that enabled the maturing of the three innovations over the case study period is also presented. A full account of changes in Melbourne's water system during the case study period can be found elsewhere (Ferguson et al., 2013a).",
            "Established regime": " Melbourne's established water regime has three major utilities: water supply, serviced by the reservoirs and dams constellation; public sanitation, serviced by the wastewater treatment and disposal constellation; and pluvial flood protection, serviced by the stormwater drainage constellation (Fig. 2). They collectively dominate the functioning of the water system and are deeply institutionalised, having evolved since Melbourne's first water infrastructure was built. The reservoirs and dams constellation serves the need for water supply by providing potable water from regional catchments through a large-scale centralised network of dams, treatment plants, pipelines and pumping stations. This constellation has been evolving since Europeans arrived in Melbourne in 1835 and first established a central water supply system. The water supply network was expanded throughout the following centuries with new dams periodically built in response to water shortages. The wastewater treatment and disposal constellation serves the need for public sanitation and waterway health by disposing treated sewage and treated industrial trade waste to receiving waterways through a large-scale centralised network of pipelines, pumping stations and treatment plants. This constellation emerged in the early 1890s when Melbourne's sewerage system was first built and has expanded as augmentations, including additional treatment facilities, were gradually made over the following century to cope with increasing demand. The stormwater drainage constellation serves the need for pluvial flood protection by draining stormwater from impervious surfaces through a large-scale network of inlet pits, pipelines and channelised, concrete-lined waterways. For Melbourne, unlike many other cities (particularly in Europe), the drainage network operates separately from the sewerage network. This constellation grew powerful after World War II, when pluvial flooding became a serious issue due to the increased imperviousness that resulted from Melbourne's significant urban expansion. Its power continued to grow as drainage infrastructure was built to service new land released for development in the following decades.",
            "Desalination": " The desalination constellation pumps seawater to a treatment plant that removes salt and other contaminants, after which the treated water is pumped into an existing central reservoir. From here, the treated water is reticulated through the existing large-scale network of pipelines and pumping stations for the distribution of potable water. The desalination constellation was non-existent at the start of the case study period but was part of the regime by December 2012. This section describes the activities undertaken in maturing desalination. The water sector was aware of desalinated seawater as a potential resource for several decades before the case study period; however, the assumed high level of water supply security provided by the existing reservoirs and dams meant it was not regarded as necessary. When drought first began in 1997, water resource planners assumed it was part of Australia's natural long-term climate variability. However, by late 2002 the Victorian Government recognised that after six dry years and with projections of population growth, the issue of water security needed action. Upon expert advice (WRSCMA, 2002), its response was initially to reduce demand through a widespread water saving campaign, designed to change consumer behaviour and increase the efficiency of water use by business and industry. Reduced water availability due to climate change was foreshadowed during this period but its degree of impact was uncertain (DSE, 2004(DSE, , 2006;;Howe et al., 2005). The Government began investigating options for boosting supply in the short, medium and longterm (including desalination and alternatives such as recycled water), through broad consultation across the sector to develop its Victorian water policy and accompanying Melbourne strategy (DSE, 2004(DSE, , 2006)). These reports concluded that immediate large-scale augmentation was not required but would be appropriate in the medium term (2015)(2016)(2017)(2018)(2019)(2020). Desalination was identified as a long-term water supply option but since there was no anticipated need for major short-term augmentations, it was not pursued in detail (WRSCMA, 2002;DSE, 2004DSE, , 2006)). The drought continued, becoming acute in 2006; reservoir levels dropped from 49 to 29% between June 2006 and June 2007. In this phase, the prospect of desalination took stronger hold and preliminary investigations were undertaken in late 2006. Melbourne Water modelling showed that if 2006 rainfall levels were repeated in coming years, Melbourne was at serious risk of running out of water from its surface water reservoirs. By early 2007, the need for urgent water supply augmentation was apparent and Victorian Government and water sector leaders explored possibilities for supplying a sufficient volume of water in a short timeframe. The Government commissioned a feasibility study for seawater desalination, which informed discussions among political and water sector leaders about specific details of a possible desalination project (e.g. location, capacity, financing arrangements). In a context of urgency, these discussions were not held with the water sector or community more broadly. In June 2007, the Victorian Government announced that a desalination plant that could supply 150 GL, roughly one third of Melbourne's annual water demand, would be delivered (DSE, 2007). Later it was decided this would be as a Public-Private Partnership (PPP) under a 30-year contract. The desalination projects was, and continues to be, mired by controversy, reflected by community protests and strong media debate that questioned the need for large infrastructure developments, their cost to taxpayers and the wisdom in selecting the desalination project over other alternatives, such as household rainwater tanks and recycled wastewater. The need for urgent decision-making meant the message that desalination was a justified and necessary investment was not well prosecuted by the Victorian Government, with a lack of public explanation or community engagement. Supporters of the desalination plant perceived that the media did not offer objective coverage, which further hampered the Government's message. Within the water sector, some actors were disenchanted with the decision to build a desalination plant, as it had not been seriously canvassed or subjected to debate in the recent strategic and broadly consultative work (such as WRSCMA, 2002;DSE, 2004DSE, , 2006)). Despite the controversy, the desalination project continued and, from July 2007 to July 2009, the Victorian Government developed technical designs, environmental studies and planning approvals, and managed a competitive process for private consortiums bidding to finance, design, construct, operate and maintain the desalination plant for 30 years. Severe drought conditions continued until late 2009, with record-breaking periods of low rainfall and reservoir inflows. Climate scientists were starting to report that these conditions were significantly outside historic statistical variability and were, in fact, due to a climatic shift (Tan and Rhodes, 2008). In this context, the water sector largely accepted the role of desalination as part of a resilient water supply system, although debate over its size and contractual arrangements continued. The successful private consortium, Aquasure, is comprised of design-construction contractors and operations-maintenance contractors. It began construction of the desalination plant in October 2009 and, after suffering significant delays due to adverse weather conditions and industrial action, the project was complete in December 2012. The narrative above identifies the range of new institutions that were developed as desalination grew in power. The types of institutional work undertaken to support the development of these desalination institutions are detailed in Table A.1 of the supplementary data. Table 2 synthesises the type of institutional work undertaken during key stages of the innovation's maturation from being non-existent to a pre-niche, niche, niche-regime and regime. It took time for the drought (a landscape pressure) to drive a system response, with little institutional work undertaken until January 2007. Once the influence of drought intensified, the niche stage was rapid, largely relying on cultural-cognitive work to translate knowledge for addressing a single issue (water supply). The niche-regime stage involved normative and regulative work to add institutions such as new design standards, resources and governance arrangements to the established regime based on reservoirs and dams. By December 2012, only cultural beliefs and public expectations were not fully developed, reflected by ongoing resentment about the desalination project. This level of development indicates the innovation had become embedded in the regime. Overall, the trajectory for desalination was rapid, as the innovation was easily adopted under sufficient landscape pressure due to its reinforcing alignment with the established regime.",
            "Wastewater recycling": " The wastewater recycling constellation comprises small to medium-scale networks of treatment plants, pipelines and pumping stations that treat sewage to a sufficiently high quality to allow its supply for non-drinking purposes (e.g. irrigation, toilet flushing). Recycling wastewater also has health benefits for downstream waterways, since it reduces the discharge of polluted water into rivers and creeks. The wastewater recycling constellation did not exist in 1997 but grew to a niche-regime by 2012. This section describes the activities undertaken in supporting the development of wastewater recycling. New environmental values emerged in Australian society from the 1960s as environmentalism gained momentum as a social movement. People became more aware of the impact of human activities on ecological systems and the earth's limited capacity to support ongoing growth. For Melbourne's water system, these new values manifested in communities caring more about waterway health and urban amenity, which placed sustained pressure on Melbourne's water system to minimise waterway pollution. Point sources of pollution from wastewater treatment plants and industrial factories were regulated from the early 1970s through discharge licensing. Wastewater recycling was initially driven by these environmental values (as a landscape pressure), with a growing need to reduce pollution from treatment plant discharges entering waterways. At the start of the case study period, recycled wastewater had been adopted for agricultural irrigation in inland Victoria. However, less than 1% of treated wastewater collected at Melbourne's two major treatment plants (Western Treatment Plant, WTP, and Eastern Treatment Plant, ETP) was being recycled. In November 2001 the Victorian Government set a target to recycle 20% of Melbourne's wastewater by 2010 to reduce environmental pollution. This target (achieved in 2008) drove significant investment in wastewater recycling and provided justification for expenditure on recycled water schemes that would not have otherwise been financially viable. Environmental studies that highlighted the impact of nitrogen on waterways (Harris et al., 1996) led to planning for major upgrades of WTP and ETP for the primary purpose of achieving discharge licence requirements set by the environmental regulator; production of recycled wastewater was a secondary benefit. Melbourne Water subsequently upgraded WTP in 2004 to reduce nitrogen loads entering Port Phillip Bay, now treating wastewater to \"Class A\" quality (water that is suitable for non-potable urban uses and irrigation of food crops). In 2003, drought conditions meant that water shortages had been experienced by vegetable growers in the region so in January 2005, the Werribee Irrigation District scheme was established to supply Class A recycled water from WTP. Similarly, plans to upgrade ETP to reduce pollutant loads and produce Class A recycled water were made from 2001, although the project did not proceed until late 2006. Meanwhile, Melbourne Water and a private company jointly developed the Eastern Irrigation Scheme (April 2005), including a Class A plant that recycles 3.5% of ETP treated wastewater, to respond to demand for secure supply of nonpotable water during the drought and to make further progress in achieving the Government's 20% recycling target. Schemes that deliver Class A recycled water to customers via a separate pipe (known as 'dual pipe' systems), emerged in Melbourne in the early 2000s. They were initially driven by individual consultants and land developers who saw economic advantage in dual pipe schemes enabling the early development of greenfields that were not yet due to be serviced with conventional sewerage infrastructure. Initial proposals for dual pipe schemes (2003)(2004)(2005), presented significant challenges to water retail companies, which were not organisationally equipped to supply recycled water. However, water companies were incorporating environmental and sustainability principles as strategic business priorities and recognised the role of recycled water in achieving their sustainability goals. An intense period of learning and cooperation ensued, including study tours and international reviews. Multistakeholder steering committees and working groups were established to develop new knowledge, which informed risk management guidelines and design standards published by industry associations and health and environmental regulators (2004)(2005)(2006). In October 2006, recycled water was delivered to its first residential customers via a third pipe as part of the Eastern Irrigation Scheme. Potential greenfield sites for future dual pipe schemes were identified and by 2008 each water retail company had mandated the supply of recycled water for growth areas across Melbourne, totalling approximately 165,000 customers. These schemes are now being rolled out as land is released development and more Class A recycled water becomes available through treatment plant upgrades. From 2006, the water retail companies undertook education campaigns through media and school curriculums to raise the community's awareness about the role of recycled water in Melbourne's drought response. Customer surveys conducted by the water retail companies show the public is highly supportive of recycled water and have generally positive feedback, although there are concerns about occasional colour and odour. Pricing of recycled water has emerged as an issue, since the cost of its delivery is equivalent to potable water but the product is perceived as lower quality. Industrial and commercial water customers also adopted wastewater recycling. A Victorian Government programme was established in 2004 to encourage top industry water users to reduce consumption, giving many businesses incentive to invest in onsite recycling. Environmental rating schemes also led to innovative wastewater recycling projects in commercial buildings. Other initiatives supporting the uptake of recycled wastewater included a Government target of substituting 10 GL/year potable water with alternative sources and amendment of the state planning framework to require integration of alternative water resources in new developments (both in October 2006). The Australian Water Recycling Centre of Excellence was established in early 2010 to develop industry and research partnerships for progressing water recycling. The National Recycled Water Regulators Forum was also established in 2010 to support national consistency in regulation. Since 2010, water sector dialogue has centred on the role of recycled wastewater compared with other alternative sources (Living Victoria MAC, 2012). Other topics include the potential for potable use of recycled wastewater, although this is not on the formal agenda of policy-makers. The wastewater recycling narrative identifies the institutions that were developed as the innovation grew in power. The types of institutional work undertaken to support the development of these wastewater recycling institutions are detailed in Table A.2 of the supplementary data. Table 3 synthesises the type of institutional work undertaken during key stages of the innovation's maturation from being non-existent to a pre-niche, niche and niche-regime. The maturing of wastewater recycling began under the landscape pressure of environmentalism in a relatively short pre-development stage. While initially driven by regulative targets, institutional work in the niche stage focused on building new cognitive and normative institutions, such as knowledge to inform delivery tools and standards. Ongoing institutional work focused on reshaping cultural beliefs and public expectations around the use of recycled wastewater and once a certain level of maturity was reached, goals and commitment were progressively made by different organisations. Many regulative institutions already existed in the established regime. The niche-regime stage featured gradual change in technology and its associated practices as the regime reconfigured. By December 2012, only some institutions were fully developed, indicating that it will be some time before wastewater recycling is considered part of the regime. Overall, the trajectory for wastewater recycling was a relatively moderate pace, with both reinforcing and disruptive forces influencing its uptake within the established regime. ",
            "Stormwater harvesting": " The stormwater harvesting constellation consists of 'green' infrastructure for passively treating and harvesting stormwater runoff from roads and other impervious surfaces. It typically functions through small to medium-scale decentralised networks of technologies such as wetlands, biofilters and swales, as well as storage tanks, pipelines and pumping stations. It supplies non-potable water but also services the needs for waterway health, urban amenity and flood protection, through its reduction of stormwater flows and pollutants to receiving waterways and the provision of green space in urban areas. The stormwater harvesting constellation existed in a different form (stormwater quality treatment) in 1997, before expanding to a niche with the inclusion of harvesting services at the end of the case study period. This section describes the activities undertaken in supporting the maturation of stormwater harvesting. The environmental movement of the 1960-1970s led to communities caring more about waterway health and urban amenity. This brought focus to diffuse pollution in stormwater in the 1990s, stimulating development and diffusion of innovative green technologies (e.g. gross pollutant traps, constructed wetlands, grassed swales, biofilters) to treat, retain and convey stormwater as an alternative to concrete-lined drains. An environmental study of Port Phillip Bay (Harris et al., 1996) sharpened this focus, with recommended targets for reducing nitrogen loads from stormwater entering the Bay. Stormwater harvesting emerged from these innovations in stormwater quality treatment. The associated community of practice (comprising scientists, engineers, ecologists, urban designers and landscape architects) identified the potential for this same green infrastructure to be utilised for stormwater harvesting to limit the detrimental impacts on receiving waterways of the high runoff volume generated from rainfall in urban areas (late 1990s). The drought further highlighted its potential as a water resource and, from 2010, the potential for stormwater harvesting to increase urban amenity through green infrastructure and water retention was also becoming recognised. The Victorian Government's receptivity to stormwater harvesting was reflected two initiatives: (1) a target to substitute 10 GL/year of water from reservoirs with alternative sources, including stormwater; and (2) amendments of the state planning framework to require integration of alternative water resources, including stormwater, in new developments in October 2006. However, industry action did not take off until two major research programmes (the Facility for Advancing Biofiltration and the National Urban Water Governance Programme) were established in 2005, focusing on biofiltration technologies and socio-technical governance for sustainable stormwater management. Scientific developments in these programmes proved the concept that stormwater could be treated with green infrastructure to a sufficient level that would enable its use as a water resource. In early 2010, these existing activities supported the formation of an interdisciplinary research programme, \"Cities as Water Supply Catchments\", which focused on supporting urban liveability through harnessing the potential of stormwater as a water resource and ecosystem service provider (Wong et al., 2011). Stormwater practitioners also saw these research programmes as a hub for innovation, learning and networking. Drawing on the knowledge and networks supported through these research activities, the retail water companies began investigating the possibility of incorporating stormwater as a resource into future plans as a means to achieve better community outcomes. Formal measures to support these initiatives were introduced in late 2009, through the establishment of a large Federal Government grant scheme to subsidise stormwater harvesting projects. This funding enabled the water retail companies to implement their planned trial projects (from 2010 onwards). In July 2009, national risk management guidelines for stormwater harvesting and reuse were published, providing further guidance and support for project implementation. A collaborative programme involving government, water business, municipality and community actors was established in 2011 to explore how urban water, particularly stormwater, can be managed to support public green space and provide health and wellbeing benefits in the driest and hottest region of Melbourne (\"Greening the West\"). Since 2010, water sector dialogue has centred on the role of harvested stormwater compared with other alternative sources (Living Victoria MAC, 2012). Other issues include the potential for potable use of harvested stormwater and development of a regulatory framework for managing health risks. There are also informal discussions about regulating minimum performance levels for municipalities of stormwater management to improve the health of downstream waterways. To progress these and other discussions related to liveability, urban water and planning, in May 2012 the Government established an Office of Living Victoria, whose agenda is to drive generational reform in how Melbourne's water is managed. The stormwater harvesting narrative identifies the institutions that were developed as it grew in power. The types of institutional work undertaken to support the development of these stormwater harvesting institutions are detailed in Table A.3 of the supplementary data. Table 4 synthesises the type of institutional work undertaken during key stages of the innovation's maturation from a pre-niche to a niche. Stormwater harvesting had a long period of pre-development that was directly associated with stormwater quality treatment. The regime (stormwater drainage) could not respond to the landscape pressure of environmentalism, so new technologies were developed to reduce stormwater pollution. The potential for this same technology to be utilised for stormwater harvesting was identified to be in the pre-development stage but it remained a niche throughout the case study as it was not sufficiently developed to take advantage of the window of opportunity presented by the drought. Institutional work undertaken during the niche stage focused on developing new cultural-cognitive institutions, with normative work around new roles, responsibilities, goals and commitments starting to occur more recently. By December 2012, the only institution fully developed was public expectations, which emerged as the community looked for preferred alternatives to the unwelcome desalination plant. Overall, the trajectory for stormwater harvesting was slow, inhibited by disruptive forces from the established regime.",
            "Comparative analysis": "",
            "Innovation-regime alignment": " Table 5 characterises the institutions that support the functioning of the regime and the three innovations according to the institutional indicators used throughout the study. Comparison of these characteristics across the categories of institution types determines the alignment of each innovation with the established regime (Table 6). For example, the 'community of practice' is water supply engineers for both the established regime and desalination, while for stormwater harvesting it is ecologists, landscape architects and urban designers. Institutions that already existed in the established regime prior to the case study period are identified with 'E'; new institutions that are non-competitive and can co-exist with established regime institutions are identified with 'N'; new institutions that are competitive and require established regime institutions to adapt if they are to further develop are identified with 'C'. For each innovation, the relative proportion of existing, new non-competitive and new competitive institutions provided the basis for an overall classification of its alignment with the established regime as reinforcing, mixed or disrupting. The desalination innovation is a highly similar servicing solution (in terms of both institutions and infrastructure) to that provided by the established regime, whose primary function consists of the capacity to transfer large volumes of potable water through a centralised pipeline to an existing hydraulic supply network. As such, the majority of for desalination already existed and only needed to be translated from the regime. New institutions were mostly non-competitive, except for cultural beliefs and public expectations. As such, desalination is considered to reinforce the established regime. The wastewater recycling and regime institutions have some similarities but also core differences. Its regulative institutions are either existing (e.g. revenue collection) or non-competitive (e.g. governance arrangements for of recycled water network), and while there are some new competitive cultural-cognitive and normative institutions (associated with supplying water that is unsuitable for drinking), they also comprise many existing and non-competitive ones. This combination of symbiotic and competitive institutions for wastewater recycling suggests that overall it has a mixed alignment with the established regime. Stormwater harvesting has mostly new institutions that are competitive with the regime, particularly in the cultural-cognitive and normative categories (e.g. technical knowledge about stormwater quality, disciplinary focus of individuals involved). Its regulative institutions overlaps somewhat with those already existing (e.g. governance of drainage services, performance monitoring of key agencies) but there are also competitive regulative institutions. Overall, stormwater harvesting is considered to disrupt the established regime. ",
            "Maturation trajectories": " The trajectories for the three innovations are plotted in Fig. 3, highlighting the speed through stages of maturity (pre-niche, niche, niche-regime, regime) for each innovation throughout the case study period from 1997 to 2012. Key activities that supported the maturing of the innovations during each stage are described, indicated by (a). . .",
            "(n).": " A comparative analysis of the institutional work undertaken and resultant trajectories for each innovation (Fig. 3 and Tables 2-4) is presented in Table 7. For each stage of maturity, it identifies the: (1) maturation speed (the relative time for the innovation to proceed through the stage); (2) limiting conditions (impediments that limited the innovation's continued maturing); and (3) institutional work purpose and type undertaken to overcome these limiting conditions and support the innovation's ongoing maturation by creating institutions.",
            "Generalisations and hypotheses": " Empirical analyses of case studies on institutional work as it relates to innovation are necessarily limited by the scale, scope and replicability of any findings. Advancing the area of inquiry therefore requires the development of testable hypotheses, such that generalised findings from one particular context may be critically examined and reformulated through testing across other contexts, with the eventual aim of developing theory on the institutional work patterns for maturing innovations. As such, this section identifies generalisations about the purpose and type of institutional work that was undertaken during the different maturity stages across all three innovations for the Melbourne case context, as a basis for deriving testable hypotheses. The innovations each emerged as a pre-niche due to landscape pressure. However, the presence of landscape pressure alone was insufficient for continued maturation: actors needed awareness of the significant impacts of the landscape pressure on service delivery and the potential for the innovation to mitigate these impacts. While the speeds of innovations through the pre-niche stage varied significantly for each case, the institutional work employed initially focused on cultural-cognitive work to understand the potential benefits of the innovation in relation to the water system's functioning that was being adversely impacted on by the landscape pressure. The maturation speed of the niche stage of an innovation appears related to its institutional alignment with the established regime. For example, the desalination institutions are symbiotic with the regime and lack of knowledge and commitment were the only limiting conditions. Cultural-cognitive work focused on translating external knowledge rather than developing new knowledge, which led to a fast niche stage. A small amount of normative work for desalination was focused on the key decisionmakers. The regulative institutions for wastewater recycling are well-aligned with the established regime. However, cultural-cognitive and normative work was required to address a lack of knowledge, tools and standards for the innovation's continued maturation, which led to a moderate niche stage. The institutions of stormwater harvesting are largely competitive with the established regime. Cultural-cognitive work was undertaken to develop new knowledge and tools during a slow niche stage. Normative and regulative work was also required to develop new communities of practice and delivery standards, build commitment and mobilise resources, since very few existing institutions could be translated from the regime. The maturation speed of the niche-regime stage appears related to the transactional complexity of an innovation in terms of the interaction of diverse institutions, infrastructures and actors to meet societal objectives. Desalination is a large-scale, mono-functional infrastructure, characterised by centralised ownership and management. Once it became a niche-regime upon securing top-down commitment, resources could be mobilised and there were few limitations to its continued maturation to become part of the regime. The lack of public acceptance could be ignored in the context of the urgent need to augment water supplies, since desalination implementation did not rely on the community's engagement. The speed of the stage was only limited by the pace at which the large-scale infrastructure could be built. In contrast, wastewater recycling is partially decentralised, requiring an integration of delivery scales (small, medium and large-scale technologies). It depends on the involvement of a broader range of actors and a more sophisticated regulatory framework to ensure public health is protected in a fit-for-purpose approach to water supply. Additionally, more complex assessment frameworks are needed for the multiple benefits of recycled wastewater (protecting waterway health, supplying water, recovering resources such as nutrients) to be economically valued so that resources can be mobilised for mainstreaming its implementation. These transactional complexities, which are likely to be even more apparent for stormwater harvesting in the future, led to a slow nicheregime stage. Ongoing landscape pressure was required to provide continued motivation for actors to undertake institutional work to slowly develop the complex institutions required for the innovation's further maturation. These generalisations are represented in Fig. 4 as hypotheses for the purpose and type of institutional work required for supporting an innovation through key stages of maturity, in relation to its institutional alignment with an established regime. Cultural-cognitive work is likely to be most effective for all types of innovations during the pre-niche stage and it is unlikely that normative or regulative institutions will be developed if there is not an existing base of cultural-cognitive institutions. The  institutional work required for maturing beyond the pre-niche stage depends on the alignment of the innovation with the established regime. Innovations that reinforce the regime require a narrow scope of institutional work, building up normative and regulative institutions in the later stages of maturity. In contrast, innovations that compete with the regime requires a broader scope of institutional work, once initial cultural-cognitive institutions have been developed, covering the full spectrum of cultural-cognitive, normative and regulative work during all maturity stages.",
            "Next steps": " This study suggests that the linkage between institutional work and innovation maturation may provide a promising line of further inquiry for advancing knowledge on transitions. The hypotheses developed need rigorous testing, critique and reformulation through a process of replication and examination across socio-political and sectoral contexts. Empirical tests that focus on overall system change or on specific stages of maturity (e.g. niche, niche-regime) in more detail would be valuable. Study of the influence of 'maintaining' and 'disrupting' institutional work on system change, beyond 'creating' work, may also be a useful avenue of research. Moreover, the mutual influence of institutional work between and within different innovations, and how these interactions may relate to a broader system transition, was not examined in reliable detail during this study and should form an additional line of future empirical research. Notwithstanding the need for empirical testing, in the absence of alternatives the proposed hypotheses may serve as a preliminary basis for the following research activities: (1) conceptual and possible theory development of the relationship between institutional work and innovation; (2) development of operational indicators for programmes of transition management, particularly addressing the gap of agency-oriented processes within the acceleration stage; and (3) development of diagnostic and policy guidance for identifying an innovation's position along a trajectory and the types of institutional work are likely to be most effective for supporting further maturation (Ferguson et al., 2013b).",
            "Conclusions": " This paper represents one of the first empirical explorations of the relationship of institutional work to innovation maturity within an established infrastructure regime. Through analysis of three case studies of innovation in the context of transitional change in Melbourne's water system, the purpose and type of institutional work that created new cultural-cognitive, normative and regulative institutions was traced through key stages of maturity. The paper has shown that the type of institutional work that most effectively supported innovation maturation depends on its stage of development (pre-niche, niche, niche-regime, regime) and alignment (reinforcing, mixed or disruptive) with established regime institutions. These characteristics will change over time, which means that diagnostic approaches are critical for understanding agency in relation to the system conditions, stage of maturity and the institutional alignment of upcoming innovations at a given point in time. Comparative analysis of the innovation trajectories led to the formulation of hypotheses on the purpose and type of institutional work that are likely to be most effective for supporting the ongoing development of an innovation. With empirical testing and refinement, these hypotheses may provide insight for actors wanting to deliberately steer a transition in a desired direction by informing the selection and design of strategic initiatives to support the maturation of an innovation. With further testing and development, the analytic framework developed in this paper may also serve as a diagnostic tool for analysing the institutions of both an established regime and new innovations to identify institutional synergies and potential conflicts. Such insights could then inform the design of strategies for creating new competitive and non-competitive institutions, across all three cultural-cognitive, normative and regulative categories, of a desired innovation."
        }
    },
    "10.1016/j.eist.2011.12.002": {
        "file_name": "116 The effects of climate policy on the rate and direction of innovation",
        "title": "Environmental Innovation and Societal Transitions",
        "abstract": "This article aims to empirically assess the impact of climate policy on technological change\u2014a core objective of climate policy\u2014by focussing on the changes it causes in the rate and direction of corporate innovation activities. To this end, we develop a cross-sectional framework based on concepts from evolutionary economics and organizational theory and, resting upon this framework, develop a set of hypotheses. We test these hypotheses using novel survey data on the electricity sector in seven EU countries. We find that the EU emission trading system (ETS) has limited and even controversial effects, and that long-term emission reduction targets are an important determinant of corporate innovation activities. Furthermore, technology policies emerge as an important element of the policy mix complementing climate policy. Based on our findings in this study, we make recommendations for policy makers on how to improve the existing policy mix.",
        "label": "Quantitative",
        "text": {
            "Introduction": " Climate change requires rapid and significant technological change because a \"business-as-usual\" rate and direction is not sufficient to address the urgency of the problem (Pizer and Popp, 2008). Hence, the debate about possible policies to initiate fundamental transitions toward low carbon pathways has been assigned a high priority on political and academic agendas worldwide (e.g., UNFCCC, 2011). \"Technological change is at once the most important and least understood feature driving the future cost of climate change mitigation\" (Pizer andPopp, 2008, p. 2768). The introduction of climate policy is one means of redirecting and accelerating technological change by altering the business environment of relevant actors, especially firms. This article aims to assess the impact of climate policy on technological change by focussing on the changes it causes in the rate and direction of corporate innovation activities. Based on this, recommendations for policy makers are deduced. The effects of environmental policy on innovation have been examined by environmental economists (for literature surveys see e.g., Fischer and Preonas, 2010;Kemp and Pontoglio, 2008;Popp et al., 2010;Requate, 2005). Following a neo-classical tradition, most of these studies leave innovation as a \"black box\" with little consideration of the interactions of actors and their innovative activities (Jaffe et al., 2002;Taylor, 2008). Evolutionary approaches to technological change can help to open this black box and improve our understanding of what fosters technological transitions (Faber and Frenken, 2009;Rennings, 2000). However, there is a lack of a framework \"which takes into account the interplay between relevant variables influencing environmental technological change and all the stages of this process\" (del R\u00edo Gonz\u00e1lez, 2009, p. 861). First steps to develop such a framework have been taken (del R\u00edo Gonz\u00e1lez, 2009;Rogge et al., 2011b), but have not been tested quantitatively. The number of quantitative empirical papers specifically investigating climate policy and its innovation effects is rather limited (Zhang and Wei, 2010): studies are mainly based on purely theoretical models (e.g., Weber and Neuhoff, 2010) or on casestudies (e.g., Hoffmann, 2007;Rogge and Hoffmann, 2010;Rogge et al., 2011b). In order to test and extend the contributions of these papers, quantitative empirical analyses can deliver valuable insights. Our study makes two contributions in this regard. First, we develop a framework mainly based on concepts from evolutionary economics complemented by organizational theory, namely a cognitive perspective, in order to consider a firm's perception of its business environment (Anderson and Paine, 1975). In this framework, we make three important distinctions: we look at (a) emissions trading and (b) long-term emission reduction targets and (c) consider further determinants external and internal to the firm (del R\u00edo Gonz\u00e1lez, 2009). In addition, and in order to holistically capture technological change, we differentiate the rate and direction (by distinguishing emitting and non-emitting technologies) of research, development and demonstration (RD&D) as well as technology adoption. Lastly, as it is not only the regulated firms that are important for technological change, we consider relevant actors across the value chain, namely users and producers of technology (Lundvall, 1985;von Hippel, 1976). Based on this framework we derive hypotheses. Second, in order to test our hypotheses, we apply this framework to the European electricity sector. Currently the most GHG emission intensive sector, a massive decarbonization of the electricity sector is needed in order to avoid dangerous climate change (IPCC, 2007(IPCC, , 2011)). Besides end use efficiency measures, the International Energy Agency (IEA, 2010) identifies three main emission reduction levers: quick and large-scale adoption of renewable energies; substantial improvement of fossil electricity generation efficiency; and the development of carbon capture and storage (CCS) and its early adoption. A decarbonized electricity sector even has the potential for climate change mitigation in other energy related sectors, such as the transport sector via e-mobility (The Economist, 2010;van Essen and Kampman, 2011). As a consequence, one main target of the European Union Emissions Trading System (EU ETS) is the electricity sector (Ellerman et al., 2010). Furthermore, the EU emission reduction targets for 2020 strongly affect the sector (Rogge et al., 2011b). In order to quantitatively test our hypotheses, we perform regression analyses on novel data from a survey of power generators and electricity generation technology providers in seven EU countries. Our paper is structured as follows. We present our framework in Section 2 and deduce hypotheses from it in Section 3. In Section 4, we provide an overview of the data and methodology used. While our results are presented in Section 5, we discuss them and their policy implications in Section 6. Finally, we summarize and conclude our study in Section 7. ",
            "Change in": "",
            "Theoretical framework": " In our framework, we predominantly draw on evolutionary approaches which we complement with concepts from organizational theory, thereby applying theoretical pluralism, which allows us to \"add value to existing approaches\" (Costanza et al., 1997, p. 78). The strengths of evolutionary economics lie in its micro focus, i.e. the consideration of actors and their heterogeneity (Dosi, 1997;Faber and Frenken, 2009). As such, it provides insights into the motivations of firms to contribute to technological change and the role of external incentives (Dosi, 1988a). In order to include the firms' internal 'sense making' (Weick, 1979), we draw from organization literature and introduce a cognitive lens, which represents the interface between the firm's environment and the firm level. Accordingly, two levels are distinguished in our framework: the business environment external to the firm as perceived by the firm, and the firm itself with its innovation activities (see Fig. 1). In the following sub-sections, we explain how we define the four main building blocks of our framework and their interactions: the dependent variable, i.e. changes in the rate and direction of innovation activities (Section 2.1), is determined by climate policy (Section 2.2), context factors (Section 2.3), and the firm characteristics (Section 2.4) Furthermore, we add a cognitive lens, through which a firm perceives its environment (Section 2.5).",
            "Changes in the rate and direction of innovation activities": " Technological change is a non-linear process over time in which three stages, invention, innovation and diffusion of technology interact via feedback loops (Nelson and Winter, 1982;Schumpeter, 1942). Hence, models explaining such change should be of dynamic character. We follow this \"methodological imperative\" (Dosi, 1997(Dosi, , p. 1531) ) and explicitly consider the changes in innovation activity over time. We distinguish two corporate innovative activities: research, development and demonstration (RD&D) refers to activities from basic laboratory research activities, via the development of marketable products to the demonstration of pilot projects, and comprises invention and innovation; adoption of state-of-the-art technologies refers to investments in new installations by users and represents the diffusion stage (Ashford, 1993;Jaffe et al., 2002). For each of these two innovation activities, we explicitly differentiate between the changes in the rate and direction of innovation activities (del R\u00edo Gonz\u00e1lez, 2009;Johnstone and Horbach, 2005). While the rate expresses the changes in overall adoption and RD&D activities, the direction reflects which technological alternatives these changes concern. For this, we differentiate between emitting and non-emitting technologies.",
            "Climate policy": " We distinguish two elements of climate policy: first, emissions trading (ET) as a market-based policy instrument and second, long-term GHG emission reduction targets (LTT) which have been shown to be important for corporate innovation decisions (del R\u00edo Gonz\u00e1lez, 2008;Rogge et al., 2011b). ET and LTT are different elements of a wider policy mix (Kern and Howlett, 2009). If stringent, the instrument ET represents a new cost or income factor for technology users, depending on both their own effective emission levels and the over-or under-allocation of emission allowances. From an evolutionary standpoint, it represents a demand-pull policy which directly influences the market's selection function. By changing the relative profitability of technologies it is likely \"to stimulate the innovation and diffusion of technologies that facilitate compliance\" (Jaffe et al., 2002, p. 46). Evolutionary theory suggests that LTT not only change current and future selection pressures among technological alternatives but also constitute market information which can serve as point of orientation for the relevant actors (McKelvey, 2005) and thereby \"offer a stimulating long-term perspective\" (J\u00e4nicke, 2011, p. 16). Such market information can influence the rate and direction of innovation activities (Dosi, 1982) as the permanence of LTT implies an obvious period of change in the business environment. If such change is \"expected to endure beyond some critical threshold\" firms will address it in their strategy (Dutton and Duncan, 1987, p. 283). Unlike ET, LTT are formulated on a national, supra-national (e.g., EU) and sector level (see e.g., European Commission, 2010a; Herzog et al., 2006), and therefore need to be translated into firm level data by each firm in order to be incorporated into investment decisions.1 ",
            "Context factors": " In addition to climate policy, several other factors in the business environment affect a firm's decisions regarding innovation activities (del R\u00edo Gonz\u00e1lez, 2009). We take three context factors into account within our framework. First, other important policies besides climate policy have been found to affect the innovation activities of firms in case they are stringent (del R\u00edo, 2009;Fischer and Newell, 2008). These policies can either be based on technology-push or demand-pull mechanisms (Dosi, 1988b;Rennings, 2000). Second, market aspects, such as supply, demand and prices for important inand output factors, influence a firm's innovation decisions (Newell et al., 1999). Third, the legitimacy of a technology, represented by its public acceptance, is an important determinant for technological change (Hekkert and Negro, 2009).",
            "Firm characteristics": " In total, we consider four firm characteristics. For the value chain position, we introduced a dummy variable which differentiates technology users, i.e. power generators, from producers, i.e. technology providers. A firm's technology portfolio is described via two variables: first, the share of emitting technologies in the portfolio10 and, second, for adoption, the need to replace or extend existing generation capacity. While the former variable is described in percentage points, the latter was polled on a fivepoint Likert scale from \"no need\" to \"strong need\". Technological capabilities \"comprise the physical and knowledge capital stock of a firm to develop new products and processes\", referring to both financial and human capital (Horbach, 2008, p. 164). To represent technological capabilities, we factorized two commonly used items-percentage of R&D expenses per turnover (Cohen and Levinthal, 1990) and percentage of R&D employees per overall staff (Horbach, 2008)-into one indicator (Kaiser, 1960). 11The size of the firm is quantified via its turnover, which was measured in six exponentially rising categories. The entire set of variables, the question and answer categories as well as their descriptive values can be found in Table A2 in Appendix A.",
            "The role of perception": " The inclusion of perceptions has a long tradition in organizational literature (dating back to March and Simon, 1958) and might be more adequate to explain corporate behavior than basing models on purely objective data of the business environment (Anderson and Paine, 1975;Weick, 1979). Authors grounded in both organizational theory and evolutionary economics have recently expressed that the cognition plays an important role when explaining technological change and innovation (Kaplan and Tripsas, 2008;Nooteboom, 2009). In case of events or changes in the business environment, it is the perception of these shifts rather than the shifts themselves which shapes a firm's strategic choice (Barr, 1998;Dutton and Jackson, 1987;Kaplan and Tripsas, 2008;Ocasio, 1997). Scholars separate perception into two elements: the attention managers devote to a change in the business environment, and the firm's interpretation of that change (Barr et al., 1992;Daft and Weick, 1984). The attention expresses to which extent a change in the business environment is an issue for the firm. Only changes that prompt a manager's high attention typically lead to changed corporate activities (Bansal, 2003;Barr et al., 1992). The interpretation reveals whether a firm-external change is seen as positive or negative for the firm (Barr et al., 1992;Sharma, 2000;Thomas et al., 1993). A different interpretation is likely to cause a different corporate reaction (Dutton and Jackson, 1987;Sharma, 2000). Furthermore, by looking into the future firms are able to anticipate external events and react prior to their occurrence (Ashford, 1993;Requate, 2005). This allows them to direct attention to and interpret future policy.",
            "Hypotheses": " We base our hypotheses on the assumption of stringent climate policy2 and structure them along the dependent variables adoption and RD&D. For each of the two, we delineate the effects of emissions trading and long-term targets. We also distinguish investment changes in total (rate), and in both emitting and non-emitting new plants (direction).",
            "The role of emissions trading for adoption": " In order to react to changes in the business environment, users can adjust their technology portfolio via adoption of technologies with different characteristics on key performance dimensions (Anderson and Tushman, 1990) and thereby determine the diffusion of competing technologies (Nelson and Winter, 1982;Schumpeter, 1942). Emissions trading regulates users of emitting technologies,3 who can choose to acquire emission allowances or invest in abatement technologies,4 whereby their behavior is likely to depend on the perception of the policy (Sharma, 2000). Hence our hypotheses on adoption are limited to users. Dutton and Jackson (1987, p. 84) argue that firms perceiving a change in their business environment as a threat-and firms with a fossil portfolio are expected to do so-will take \"actions of large magnitude\", i.e. increase investments, in order to avoid losses and secure their survival. Conversely, firms with a positive perception of ET are expected to already be aligned with the aims of ET (or at least more than their competitors), which leads to \"actions of smaller magnitude\" (Dutton and Jackson, 1987, p. 84) that do not strongly alter the firm's adoption behavior.",
            "Hypothesis 1a.": " The more negatively a firm perceives emissions trading the more it increases its total investments in new plants. Tradable permit systems, like ET, raise the propensity of the adoption of abatement technology (Frondel et al., 2007;Kerr and Newell, 2003;Popp et al., 2010). Though state-of-the-art emitting technologies do have the potential to reduce specific emissions, the sharpest emission reductions can be realized via the adoption of non-emitting technologies (McKinsey, 2007), lowering the need for allowances. In the case of a stringent design of the ET, high permit prices can raise the often lower generation costs of emitting technologies beyond those of non-emitting technologies (Hoffmann, 2007). For firms with a negative perception of ET, the adoption of non-emitting technologies is therefore more likely than the adoption of emitting technologies. Hypotheses 1b and 1c. The more negatively a firm perceives emissions trading. . . (1b) the more it decreases its investments in new emitting plants. (1c) the more it increases its investments in new non-emitting plants.",
            "The role of long-term targets for adoption": " LTT differ from emission trading as they represent a market information on a national or sector level and thereby rather serve as point of orientation (McKelvey, 2005) than representing a concrete cost factor such as emission allowances (Kirat and Ahamada, 2011). Their cognition allows firms to broadly evaluate their future business environment (Gavetti and Levinthal, 2000). To this end, LTT serve as indicator on the stringency of future regulation (Rogge et al., 2011b). Hence, firms in sectors with longinvestments cycles might incorporate LTT into their investment decisions. As for ET, we expect firms with a negative perception of LTT to increase their investments (Dutton and Jackson, 1987). Other than for ET, we also expect firms with a positive perception of LTT to also increase their total investments. This can serve to maintain and reinforce their competitive advantage over more emission intensive competitors in the long run, because stringent LTT might indicate a 'green' paradigm shift (Freeman, 1992) which opens new window of opportunities (Geels and Schot, 2007;Tyre and Orlikowski, 1994). To sum up, the total adoption is increased by firms that perceive LTT as a threat as well as firms that perceive them as an opportunity. Hence, the reaction is independent from the interpretation. It rather depends on whether a firm directs its attention toward LTT or not, or put another way, whether firms perceive LTT as issue or not (Bansal and Roth, 2000;Barr et al., 1992). Hypotheses 2a. The more a firm perceives long-term targets as an issue the more it increases its total investments in new plants. Firms with a negative perception of LTT anticipate the need to adjust their portfolio to these targets and, thus, increase their investments in non-emitting technologies while reducing the investments in emitting technologies (Jaffe et al., 2002;Rogge et al., 2011b). Similarly, firms with a positive perception, in order to maintain their competitive advantage, strengthen their portfolio's share of non-emitting technologies over emitting technologies. Again the direction of innovation is independent of a firm's interpretation but depends on the attention directed to LTT (Bansal and Roth, 2000;Barr et al., 1992). Hypotheses 2b and 2c. The more a firm perceives long-term targets as an issue. . . (2b) the more it decreases its investments in new emitting plants. (2c) the more it increases its investments in new non-emitting plants.",
            "The role of emissions trading for RD&D": " RD&D activities aim to generate novelty (McKelvey, 2005) and thereby alter technologies on their future performance dimensions (Anderson and Tushman, 1990). However, unlike adoption decisions, RD&D investments are associated with extraordinarily high uncertainty regarding their outcomes (Scherer and Harhoff, 2000). In order to alter their technologies or technology portfolios, firms with a negative perception of ET will be more risk taking and willing to invest into uncertain RD&D, whereas firms with a positive perception will act more conservatively and do not increase investments into RD&D projects with an uncertain outcome (Wiseman and Gomez-Mejia, 1998).",
            "Hypothesis 3a.": " The more negatively a firm perceives emission trading the more it increases its total investments in RD&D. Firms with a negative perception can either increase RD&D investments in order to strongly reduce the specific emissions of emitting technologies (e.g. via efficiency enhancements or CCS) and/or in order to improve non-emitting technologies on other key performance dimensions (e.g., cost or reliability) (Rogge et al., 2011b). Firms with a positive perception of ET will likely not see a need to adjust the performance of the technologies in their portfolio. On the contrary, technology producers with a very positive perception might even shift away resources form RD&D toward new production capacities in order to profit from the now present market opportunities provided by ET (Cyert and March, 2005;Lavie et al., 2010). Hypotheses 3b and 3c. The more negatively a firm perceives emission trading. . . (3b) the more it increases its investments in RD&D of emitting technologies. (3b) the more it increases its investments in RD&D of non-emitting technologies.",
            "The role of long-term targets for RD&D": " In sectors with long R&D cycles, firms include information which concerns the longer-term future in their RD&D decisions (Chen, 2008;Inderrieden et al., 1990). Hence, LTT are an important point of reference indicating the stringency of future climate policy instruments (Rogge et al., 2011a) and thus expected to be very influential for RD&D decisions. As for ET, firms with a negative perception of LTT are expected to increase total RD&D investments as a means of improving their technologies and thereby adapting their portfolios to the LTT. However, LTT also have a strategic relevance for firms with a positive perception. For them, LTT can be an indicator for increasing future markets due to paradigm shifts (compare Section 3.2). Therefore, they are likely to improve their technologies for the requirements of these markets via increased RD&D. As for LTT and adoption, the RD&D investment decision will not depend on a firm's interpretation but on the attention a firm directs to LTT (Bansal and Roth, 2000;Barr et al., 1992).",
            "Hypothesis 4a.": " The more a firm perceives long-term targets as an issue the more it increases its total investments in RD&D. Firms with a negative perception of LTT increase their RD&D activities in order to align their technologies and portfolios (see Section 3.3). We also expect firms with a positive perception of LTT to increase RD&D to make their technologies market ready-be it technologies that significantly reduce specific emissions or non-emitting technologies, which underperform on other performance dimensions. By doing so they prepare for jumping through the window of opportunity implied by LTT (see Section 3.2). Hypotheses 4b and 4c. The more a firm perceives long-term targets as an issue. . . (4b) the more it increases its investments in RD&D of emitting technologies. (4c) the more it increases its investments in RD&D of non-emitting technologies.",
            "Data and methodology": " In order to test our hypotheses we collected novel quantitative data in a survey of power generators (i.e. users) and electricity generation technology providers (i.e. producers). In the following, we describe the operationalization of the survey variables (Section 4.1), the roll out of the survey and the composition of the final sample (Section 4.2) as well as the statistical methods we applied (Section 4.3).",
            "Variables": "",
            "Changes in innovation activities": " To measure the dependent variable, i.e. changes in innovation activities, we compare the innovation activities of the last five years (from the EU ETS' introduction in 2005 to 2009) with those of the previous five-year period (2000-2004), before the ETS was effective. We query how the investment volumes in new plants and in RD&D have changed in the second five year period compared to the first one in a five-point Likert scale ranging from \"dropped sharply\" via \"no change\" to \"rose sharply\" (for the detailed questions see Appendix A). For adoption we take into account all users, i.e. power generators, as all of them have to adopt technology at some point in time. For RD&D we take into account all power generators and technology providers that perform RD&D. For the rate of innovation, we inquire the delta of total investments in RD&D and adoption, respectively. For the direction of innovation, we proceeded as follows. Firms were asked to score the investment change over time for all relevant technologies individually. 5 We then aggregate the answers per technology to an emitting and a non-emitting variable6 via arithmetic averaging.",
            "Perception of climate policy": " While in our study long-term targets represent European and global GHG emission reduction targets for 2020, emissions trading is represented by the EU ETS. Authors have pointed to the importance of policy stringency in triggering corporate innovation (Frondel et al., 2007(Frondel et al., , 2008)). Several authors have pointed to a lack of stringency in the first (2005-07) and second (2008-12) trading phases7 of this mechanism, resulting in relatively low certificate prices (e.g., Betz et al., 2006;Ellerman and Buchner, 2007;Neuhoff et al., 2006a,b). The third (2013-2020) phase of the EU ETS however is significantly more stringent, both in terms of the overall limit on emissions (cap) and the foreseen full auctioning for power generators from 2013 onwards (Benz et al., 2010;EU, 2008). Hence, we distinguish two periods of the EU ETS, i.e. ETS 1&2 (from 2005 to 2012) and ETS 3 (from 2013 to 2020). 8We queried the perception of the climate policy elements using a five-point Likert scale ranging from \"very negatively affected\" via \"not affected\" to \"very positively affected\", following the literature on cognition (Barr et al., 1992;Dutton and Jackson, 1987). In the case of LTT, we used the absolutes of these values to express the firm's attention, transforming the five-point Likert scale used in the survey into a three-point scale from \"not affected\" to \"very much affected\".",
            "Perception of context factors": " The perception of context factors was operationalized in the same way as the one of ET, i.e. via a fivepoint Likert scale from \"very negatively affected\" via \"not affected\" to \"very positively affected\". For the selection of variables we took into account those context factors shown to be relevant in previous studies (e.g., Rogge et al., 2011b): For other policies than direct climate policy, we differentiate the perception of technology-push, i.e. R&D support,9 and RET specific demand-pull policies such as feedin-tariffs. Regarding market factors we include the perception of prices and supply of fuels, as they strongly determine the cost of electricity generation and hence the relative competitiveness of all technologies. Furthermore, we consider prices and the demand for electricity because they are the strongest drivers on the revenue side of firms in the sector. The perception of public acceptance refers to coal-based technologies, as they represent the largest contributor to the sector's GHG emissions and have been subject to controversial public debates (Reuters, 2008).",
            "Procedure and sample": " The survey was conducted on our own account in seven EU countries (see Table A1 in Appendix A) end of 2009, i.e. before the end of the UNFCCC Conference of the Parties in Copenhagen (COP 15). Subsequent to a series of pre-tests, the survey was translated into each respective language and a reverse translation was independently conducted in order to guarantee equality in meaning. After contacting each firm by telephone, invitations for the online survey were sent to a senior manager of each firm. The results presented in this paper are based on the answers of 65 power generators and 136 technology providers. 12 This translates into response rates of 14.6% and 13.1% out of the 495 power generators and 1086 technology providers identified among the population. 13In our sample, 80% of the power generators have undertaken adoption measures, i.e., invested in new plants during the last ten years. Of the power generators, 38% have invested in RD&D within the last ten years. As expected, the number of technology providers with RD&D activities is much higher, namely 77%. 14 These numbers result in a total of 65% of the respondents (130 firms) being included in the regressions on RD&D. More details on the sample can be found in Figs. A1 and A2 in Appendix A.",
            "Statistical methodology": " In order to test our hypotheses, we applied multivariate linear regression analyses based on ordinary least squares and with forced entry of predictors. We conducted six regression analyses, as we are looking at adoption and RD&D each on the level of investments in total, emitting and non-emitting technologies, leading to six dependent variables. 15  In order to arrive at consistent models without omitting variables and at the same time allow for good results despite the relatively low number of observations, we tested our model with several combinations of variables, including a number of variables which are no longer present in the final model 16 presented in Section 5. None of the excluded variables showed significance at a p < 0.1 level in any model and did not notably increase the explanatory power (R sq.) of the models. Additionally we performed several tests. We checked for multicollinearity via a correlation matrix (see Table A2 in Appendix A) and the variance inflation factor (VIF) (Myers, 1990). None of the correlation coefficients and VIFs exceeds the respective tolerance values. 17 To control for common method bias we performed Harman's one-factor tests, whose results 18 suggest that common method bias is not present in our dataset. Finally, we checked our model choice via three measures: a test for heteroscedasticity (Allison, 1999), a test for normality of the residuals (Q-Q-plots) and the Durbin-Watson statistics (Field, 2009). All tests showed good results 19 and corroborate the choice of our model.",
            "Results": " The descriptive results (see Table A2 in Appendix A) highlight that power generators have, on average moderately increased both adoption in total and adoption of emitting technologies in the last five years. Investments in new non-emitting 20 plants experienced a stronger rise. Total RD&D, and of non-emitting technologies experienced a higher increase than emitting technology RD&D activities, which were moderately augmented. The results section is split into two sub-sections, one on adoption and one on RD&D, which each address the effects of the climate policy elements along the hypotheses. For ET we distinguish ETS 1&2 and ETS 3. Above that, we describe and explain all significant effects of further variables.",
            "The role of current climate policy for adoption": " Our regression analysis (see Table 1) indicates a positive relationship (p < 1%) of ETS 1&2 and the total rate of adoption by power generators (Model 1). Accordingly, firms with a more positive perception increase their total investments, contradicting Hypothesis 1a. When looking at the directions, our analysis suggests that ETS 1&2 has a significant (p < 5%) positive effect on adoption of emitting 15 Missing values within the independent variables were replaced with the value chain step's sample mean of the respective variable (De Vaus, 2001). In the adoption model, 2% missing values were replaced (control variables only), with none of the variables exceeding 6.2% replacements. In the RD&D model, 2.6% missing values were replaced, also with none of the variables exceeding of 6 %. 16 Additional variables we tested and which are not present in the final models were: perception of public acceptance for nuclear energy; perception of public acceptance for CCS; perception of equipment prices; Perception of general electricity market regulation; CO2 intensity of production portfolio; environmental capabilities (represented by the two factorized variables: share of employees with environmental training and existence of a certified environmental management system); share of home market in total sales. 17 The maximal absolute correlation coefficient between independent variables is 0.632 and hence below the threshold of 0.8 (Schendera, 2008). All VIFs in our models are well below the critical maximum threshold of 10 ( Myers, 1990). 18 The Harman's one-factor tests for adoption and RD&D resulted in four factors each, whereby the first factor only accounts for 23% (adoption) and 32% (RD&D). This means more than one factor emerges with the first factor explaining less than half of the variance, suggesting common method bias is very unlikely (Podsakoff et al., 2003). 19 All heteroscedasticity tests showed no patterns between the variance and the predicted values, all Q-Q-plots resulted in lines revealing a normal distribution of residuals, and all Durbin-Watson factors were close to 2 (between 1.436 and 2.264). justifying the assumption of independent errors. 20 As none of the firms in the sample has invested in new nuclear generation capacity in the last ten years, the adoption of aligned technology refers to RET only. technologies (Model 2). Hence, for ETS 1&2, Hypothesis 1b is seemingly supported. However, while the hypothesis assumed that more negatively affected firms reduce investments more, we suspect the reverse effect: the more positively firms perceive ETS 1&2, the more they increase investments in emitting technology. This may at first seem surprising, but can be explained by the low stringency of ETS 1&2, both in terms of the generous cap and resulting low CO 2 prices and in terms of the free allocation. Power generators with emitting plants reaped windfall profits (Sijm et al., 2006), and firms investing in new emitting plants benefitted from a large subsidy effect (Ellerman and Buchner, 2007), leading to a positive perception by many firms. The resulting increased investments in new emitting plants also impinge on total investments due to the typically large size of such investments (compared to investment in renewables). At the same time, we do not observe any significant relationship between ETS 1&2 and the adoption of non-emitting technologies (Model 3) in our data, implying that Hypothesis 1c is not supported. The corresponding CO 2 prices caused by the ETS 1&2 seem to be too low to affect the competitiveness of non-emitting relative to emitting plants and thereby significantly support investments in new non-emitting plants. The more stringent ETS 3 and the total rate of adoption are negatively related (p < 5%) implying support for Hypothesis 1a. A more negative perception of this policy element apparently triggered increased total investments. However this relationship is not observed for a distinct direction, as we find neither any significant relation for emitting (Model 2) nor for non-emitting technologies (Model 3). This leaves Hypotheses 1b and 1c unsupported. Correspondingly, we assume that firms which increase investments due to ETS 3 follow heterogeneous strategies, with some choosing to invest in the emitting, others in the non-emitting and yet others in both directions. Other than expected in Hypotheses 2a-2c, we do not observe any significant relation of LTT and the adoption decisions of power generators (Model 1 to 3). Firms' investments in new installations are very much determined by the expected payback of these investments and the associated risk, which are both affected by ET directly and measurably (Hoffmann, 2007). Contrary to that, LTT are not specified for individual companies and therefore hard to factor-in for their decision making. Of the context factors, only RET promotional policies significantly relate to adoption. Firms with a positive perception of these policies increase their non-emitting plant investments (Model 3, p < 1%) to an extent which affects total investments (Model 1, p < 5%). Regarding firm characteristics our data suggests that firms with a higher share of non-emitting technologies in their portfolio tend to increase their adoption of non-emitting technologies (Model 3, p < 5%), which implies a certain path dependency of firms with respect to their technology portfolios. The replacement need is a strong determinant of total investments (Model 1, p < 1%) but has no significant relation with the technological direction (Model 2 and 3). Finally, we find that the size of the firm has a positive relationship with the adoption tendency in total (Model 1) and that of emitting (Model 2) technologies (both at p < 1%). Due to their resources, larger firms might be able to react by investing more and into larger units, such as emitting plants.",
            "The role of current climate policy for RD&D": " Neither ETS 1&2 nor ETS 3 show a significant relationship with firms' total (Model 4) and emitting technology (Model 5) RD&D decisions. Hypotheses 3a and 3b are hence not supported. Also for nonemitting technologies (Model 6), ETS 1&2 does not significantly relate to RD&D decisions. The only ET relation we do observe is that of ETS 3 (p < 5%), which suggests support for Hypothesis 3c. Firms with a negative perception of ETS 3 increase their RD&D in non-emitting technologies while those with a positive perception reduce it. The fact that only RD&D of non-emitting technologies is affected could be based on the development times of RET, which are usually shorter than those of emitting technologies (IEA, 2008). We observe significant (p < 1%) relations of the perception of LTT and total RD&D (Model 4) as well as RD&D of non-emitting technologies 21 (Model 6), supporting Hypotheses 4a and 4c. In contrast, regarding RD&D of emitting technologies (Model 5) we do not find support for Hypothesis 4b. While other studies suggest effects of emission targets especially on RD&D of CCS (Hoffmann, 2007;Rogge et al., 2011b), only very few, large firms (in the entire population as well as in our sample) pursue RD&D of this technology, reducing their statistical impact on the entire sample. We detect several significant context factors in the RD&D models. A positive perception of technology-push policies seemingly drives investments in emitting (Model 5) as well as in nonemitting technologies (Model 6) RD&D (both at p < 5%). Positive effects of R&D support programs (e.g., EREC, 2010;European Commission, 2008, 2009) are predicted by theorists (e.g., Dosi, 1988a). Interestingly, RET specific demand-pull instruments do not seem to directly trigger RD&D in the non-emitting direction. In this regard, a recent study shows that very generous RET demand-pull policies draw the focus from explorative research to rather exploitative development and production (Peters et al., 2011). According to our data, the more positively a firm perceives the development of electricity prices, the main determinant for all firms' past, present and expected future revenues in the sector, 22 the more it seems to increases total (Model 4, p < 5%) as well as non-emitting RD&D (Model 6, p < 1%) investments. Firms with a positive perception of the public acceptance of coal appear to increase investment into non-emitting RD&D (Model 6), which impinges upon total RD&D (Model 4) (both at p < 5%). As the public acceptance for coal in Europe has decreased over recent years (Eurobarometer, 2006), firms with non-coal based technology portfolios perceive the acceptance positively and may interpret it as a future demand driver. Thus, they improve their technologies via increased R&D. Regarding firm characteristics, our analyses suggest that the higher the share of emitting technologies in a firm's portfolio the more it tends to increase RD&D of emitting technologies (Model 5, p < 5%). This highlights the role of firm-internal path dependencies in aligning their technologies to the aims of climate policy and thus defending their business. In line with other scholars (e.g., Horbach, 2008;Rosenberg, 1974), we suggest that higher technological capabilities trigger more RD&D in both emitting (Model 5, p < 5%) and 21 Our results on emitting technology RD&D activities and the interpretation thereof must be read with caution due to the low number of observations (40) compared to the number of independent variables (12). 22 As such, electricity prices strongly influence a firms' availability of financial resources to be invested in RD&D. Hence, we assume that rising electricity prices are perceived positively. As power generators' streams of income are directly coupled to the electricity prices, this argumentation also refers to technology providers. Significantly supported non-emitting (Model 6, p < 1%) technologies. The positive relationships we find regarding the firm size (Models 4-6, at p < 5% for total and emitting and p < 1% for non-emitting investments) can be explained by resource slack, which raises a firm's willingness to take risks and invest in RD&D (e.g. Greve, 2003). Table 2 summarizes all results with regard to our hypotheses. It becomes apparent that the relatively lax ETS 1&2 and the more stringent ETS 3 have several opposing effects.",
            "Policy implications": " Decarbonizing the electricity sector, which is the core objective of climate policy, translates into an immediate increase of adoption of non-emitting technologies and of RD&D for both emitting and non-emitting technologies (IEA, 2010). Despite the high relevance of the topic, so far little empirical evidence on the effects of the current policy mix has been presented (Ellerman et al., 2010). Our analyses suggest there are several effects of climate policy and other elements of the policy mix. The aim of this section is to discuss three major results. For each result, we first show its implications on technological change in the sector, second, relate it to the current academic debate and third, derive policy recommendations on how to improve the current policy mix.",
            "Adverse effects of lax design should be avoided": " Our results show that the EU ETS in its early phases (1&2) triggered neither investments in the adoption of non-emitting technologies nor in RD&D. The only effect we do observe, namely the increased adoption of emitting technologies, undermines the goal of substantial GHG emission reductions. The short period of allocating free allowances to new emitting plants and forfeiting allowances of closed emitting plants causes long-term future GHG emissions. ETS 1&2 have therefore increased the lock-in into fossil centralized power generation, as large firms in particular seem to have increased the adoption of these technologies, which are characterized by relatively long lifetimes and large sunk costs. 23Furthermore, our results show that firms focussing on emitting technologies hesitate to invest in nonemitting technologies, illustrating a self-reinforcing lock-in effect. This makes a lax ET design even more detrimental. While the current academic debate has recognized that a lax ET design might result in effects opposed to the intended effects (del R\u00edo Gonz\u00e1lez, 2008;Ellerman et al., 2010;Sijm, 2005), and \"theoretical arguments are abundant and clear [. . .], empirical evidence on the predicted effects [of the EU ETS early phase and its design] is scant\" (Ellerman et al., 2010, p. 289). At this point our study makes an empirical contribution. The laxity of the first phases of the ETS was intended to increase political acceptability and was planned to be tightened from the beginning (Ellerman et al., 2010). Policy makers in regions which also plan to introduce ET, e.g., China (United Nations, 2011), should be aware of the potential counterproductive consequences of a too lax ET design. In Europe, while it is now too late to adjust the initial EU ETS design, the EU should guarantee a minimum stringency for phase three. While Germany's recent decision to phase-out nuclear power plants before 2022 is expected to cause rising allowance prices (Point Carbon, 2011a), tightening the emission caps would further increase the stringency of the ETS. The auctioning of emission rights, as provided for in the power sector from 2013 onwards (ETS 3), is one way of better incentivizing investments in non-emitting technologies (Hepburn et al., 2006). The free allocation methods of those member states subject to exemptions from full auctioning, should be strictly supervised by the EU in order to avoid similar effects as observed under ETS 1&2. In member states with full-auctioning, free allocations could be used as a reward for those firms which become pro-active in strong GHG emission reducing measures via adoption and/or RD&D. The European Commission's thoughts on an \"innovation/technology accelerator\" (European Commission, 2010b, p. 75) for industrial sectors are in this direction and might be applied also to the power sector. Outside of the power sector, firms in industrial sectors remain partly subject to free allocations via benchmarks of the ETS 3. These benchmarks should be designed in a stringent manner.",
            "Technology-push policies and LTT important to complement minor effects of ET on RD&D": " Our results show the importance of technology-push measures for RD&D. While ET only affects RD&D of non-emitting technologies, R&D support policies led to increased RD&D of both non-emitting and emitting technologies, which is important for moving all levers identified by the IEA (see Section 1). Our results furthermore highlight the role of LTT as a driver for RD&D. They have an orienting function and might, if stringent and credible, indicate a long-term paradigm shift. The long-term nature and high uncertainty of RD&D let LTT appear more important than the effective instrument ET, according to our data. However, LTT and ET interact. First, the credibility of LTT depends on the stringency of instruments that support these targets (Rogge et al., 2011a,b). Second, LTTs' role might be especially important if climate policy is realized via market based instruments such as ET: compared to command-and-control policies, they allow a much greater freedom of choice for concerned actors (Frey, 1997;Smith and Sorrell, 2001). This freedom makes finding an optimal response strategy more difficult for a firm, resulting in a higher need for orientation, provided by LTT. In the academic debate, authors mainly from the neoclassical strand promote one single \"technology neutral\" market based policy (Azar and Sand\u00e9n, 2011, p. 135) which addresses the negative externality GHG emissions and typically prefer ET over other instruments (e.g., B\u00f6hringer and Rosendahl, 2009). Conversely, innovation scholars stress the role of spillover effects and high uncertainty of RD&D investments for private sector RD&D leading to private underinvestment in RD&D (Griliches, 1992;Jaff\u00e9 et al., 2004;Sagar and van der Zwaan, 2006;Scherer and Harhoff, 2000). Technology-push policies in the form of R&D subsidies are suggested as a complementary policy option to address these externalities (Goulder and Parry, 2008;Sagar and van der Zwaan, 2006). Our results support this view as the relatively stringent ETS 3 only has an (not entirely supportive) effect on RD&D of non-emitting technologies. The role of LTT, whose importance we highlight in our study, is so far underrepresented in the academic debate. For policy makers this implies that RD&D support and LTT should be part of an integrated mix which complements ET. While ETS 3 and the R&D funding seem to be \"congruent\" (Kern and Howlett, 2009, p. 395) with LTT to a large extent, it is certainly not the case for ETS 1&2 due to its lack of stringency. 24 In order to provide good orientation and increase the predictability of climate policy, an important aspect for corporate investment decisions (Engau and Hoffmann, 2011;Hoffmann et al., 2009), LTT should be solid and clearly communicated. Besides the European emission reduction targets,25 the approval of an ambitious post-Kyoto agreement could provide such an orienting function. Furthermore, LTT need to be congruent with the existing policy instruments. While this seems to be the case for the European long-term targets and ETS 3 to some extent, it is certainly not the case for LTT and ETS 1&2 In order to avoid such incongruence, \"ambitious and realistic\" LTT \"at the limits of the capacity that is technically feasible for a country\" (J\u00e4nicke, 2011, p. 18) should be formulated first. As lead times in the power sector are very long, the EU should soon provide reliable targets which go far beyond 2020. Based on these targets, it is crucial that congruent instruments are installed in order to make the LTT credible (Rogge et al., 2011a). A breach of this order raises the risk of incongruent targets and instruments (Kern and Howlett, 2009). As transformations of infrastructure sectors are long-lasting processes which experience a lot of resistance from established (fossil) regimes (Gr\u00fcbler, 1990;Gr\u00fcbler et al., 1999) the political practice with its short-term focus and electoral cycles struggle with mapping the pathways for transitions (Meadowcroft, 2011) and providing reliable LTT. This stresses the role of supra-national institutions, such as the EU or the UN, which are able to think and act in longer cycles and more independently from politics of parties than national governments (Gabel, 1998;Schmidt, 2006), for setting and defending targets. The distribution of RD&D funds among different technologies is fundamental in order to not pick the \"wrong winners\" (Azar and Sand\u00e9n, 2011;Hall, 2002) and should be based on clearly set \"research priorities\" (Azar and Sand\u00e9n, 2011, p. 136). Such priorities should clearly reflect the LTT that the government aims to achieve with the policy mix.",
            "To harvest production-based cost reductions, technology-specific demand-pull policies are essential": " Our study reveals that neither ETS 1&2 nor ETS 3 was capable of triggering increased non-emitting technology adoption. Only RET-pull policies had this effect. According to our analysis, RET-pull policies are in fact the only firm-external factor triggering the adoption of non-emitting technologies. Therefore, these policies are essential to avoid a lock-in into currently cheaper technologies positively affected by ET which however, might come at higher cost and/or lower emission reductions in the long-run (del R\u00edo Gonz\u00e1lez, 2008). Scholars have shown that (non-emitting) technologies further away from competitiveness typically have the steepest learning curves (Junginger, 2010;Sorrell and Sijm, 2003). However, permit prices of an ETS are often not enough to close the present profitability gap between these and the dominant technologies (Rogge et al., 2011b). Pure \"technology-neutral\" market based policies such as ET thus pick the wrong winners (Azar and Sand\u00e9n, 2011). Therefore, to avoid a lock-out of new non-emitting technologies and allow for increasing spill-over effects within the attached technology clusters (Bergek et al., 2008;Lim et al., 2003), additional technology-specific demand-pull policies are called for (Azar and Sand\u00e9n, 2011;Jacobsson and Bergek, 2004). They foster production based cost reductions via learning by doing, bring the technologies closer to competitiveness, potentially decrease long-run abatement costs (Azar and Sand\u00e9n, 2011;del R\u00edo Gonz\u00e1lez, 2008;Sorrell and Sijm, 2003) and can also increase the credibility of LTT (Rogge et al., 2011a). For policy makers this means that technology-specific demand-pull policies ought to be another integral part of a policy mix aiming to decarbonize the electricity sector. As these policies are often costly (Peters et al., 2011), it is important that a high share of auctioning revenues from the third phase of ETS are used for their financing (and that of R&D support) as agreed upon in a non-legally binding commitment by the EU member states (UK DECC, 2011). A tightening of the cap could increase revenues from these auctions (Point Carbon, 2011b). In order to minimize costs and provide incentives for RD&D, cost monitoring and corresponding reductions of the support are essential, especially as the steep learning curves result in fast cost reductions (Peters et al., 2011). This means, while LTT should be fixed, policy making needs to be dynamic by adjusting instruments to the alternating competitiveness of technologies and thereby meeting the dynamic character of technological change (Sartorius and Zundel, 2005). Furthermore, the integration of new technologies into an \"open assembled system\", such as the electricity sector, might necessitate the development and diffusion of \"interface and linkage technologies\" (Tushman and Rosenkopf, 1992, p. 331). For instance, in the case of an ample diffusion of intermittent RET, more and potentially new storage technologies or different grid management (see e.g. the current smart grid approaches) might be necessary and imply learning on a system level (Sagar and van der Zwaan, 2006). Hence, demand-pull policies for new technologies should be coupled with policies addressing the enabling environment of these technologies.",
            "Conclusion": " In order to analyze the effects of climate policy on corporate innovation we derive hypotheses based on an \"integrated conceptual framework\" (del R\u00edo Gonz\u00e1lez, 2009, p. 861) which combines evolutionary economic elements and cognitive organizational theory. We test these hypotheses via ordinary least square regression analysis using novel survey data from electricity sector firms in seven EU countries. Thereby, we empirically analyze the effects of climate policy on the rate and direction (by distinguishing between emitting and non-emitting technologies) of RD&D and adoption of relevant firms in the electricity sector, taking into account other determinants. Our study contributes on both a theoretical and empirical level to the extant literature concerning how to politically induce environmental technological change. We find that the flawed design of the first two phases of the EU Emissions Trading System (EU ETS) has created incentives leading to the increased adoption of emitting technologies, and, that even the more stringent third ETS phase has only limited effects on the rate and direction of corporate RD&D and adoption. We identify long-term mission reduction targets as an important trigger of RD&D. Technology policies, in the form of demand-pull and technology-push instruments have significant effects on low carbon technological change, and are therefore also an important factor compensating for the insufficient effect of emissions trading. Our study empirically shows that policy stringency is of critical importance, and supports the need for a more stringent ETS as part of a policy mix aiming to steer the rate and direction of technological change toward low carbon, a non-linear process characterized by lock-ins. Based on these findings, we offer several points for improvement of the existing mix. The novel theoretical contribution of our paper is to include organizational cognitive theory into the study of determinants of (green) technological change. The historic study of energy services by Fouquet (2008, p. 355) shows that one \"source of change is beliefs and knowledge\". While evolutionary studies implicitly contain cognitive elements, partly explaining the bounded rationality of firms (see e.g., Dosi, 1982;Dosi et al., 1997), making the role of actors' perceptions explicit allows the inclusion of the actors' sense of influencing their selective environment, thereby allowing derivation of testable hypotheses. Only recently have scholars started to include cognitive organizational theories which try to explain firms' strategy making into evolutionary innovation studies (Geels, 2010;Kaplan and Tripsas, 2008;Nooteboom, 2009). By incorporating long-term targets into our analysis we go beyond neoclassical studies. Additionally, operationalizing the measurement of policy stringency via the perception of the relevant firms avoids the difficulties that neoclassical studies have in measuring stringency. Our analysis shows potential fields of future research for (sustainable) transition scholars. The role of policy perception, i.e., how much attention firms direct toward policies and how they interpret them depending on their characteristics, is underexplored. While our paper represents a starting point, a study comparing the effects of objective and perceived policy stringency could yield deeper insights and feedback on how to formulate policy that will result in high attention and the requisite interpretation. Policy makers should be supported by transition scholars in finding the right policy mix. Therefore, further studies on the interaction effects of policy instruments and targets should be conducted. Of particular importance is the as yet under-researched role and interaction of LTT with other instruments, which should be analyzed in more detail in both theoretical and empirical studies. In order to increase the influence of the evolutionary school of thinking, the political practicability of evolutionary studies has to be increased. To this end, improving the understanding of political processes in transition studies is an important avenue for future research (Meadowcroft, 2011). "
        }
    },
    "10.1016/j.respol.2013.08.010": {
        "file_name": "138 The pre-industrial energy crisis and resource scarcity as a source of transition",
        "title": "The pre-industrial energy crisis and resource scarcity as a source of transition \u0b1d",
        "abstract": "The historical British \u2018timber famine\u2019 of the 18th century is re-examined in the light of contemporary concerns about transitions in energy use. The alternatives of scarcity-induced and opportunity-led transition are considered in relation to the economics of sustainable fuel timber production for industrial uses. The paper finds that the production of timber was an economically sustainable use of land and that observations of timber shortages may have therefore either been claims made by interests favouring the use of coal or the consequence of abandonment of fuel timber cultivation in favour of coal use. The longer-term sustainability of domestic UK sources for industrial timber fuel timber is shown to be problematic. The consequences of the alternative views of the \u2018timber famine\u2019 for contemporary policies attempting to promote transition to low carbon or sustainable energy use are examined. In particular, if the present is an echo of the past, opportunity rather than crisis may be the more powerful lever of change.",
        "label": "Quantitative",
        "text": {
            "Introduction": " This article examines the issues of resource sustainability from an historical perspective. Historical understandings of the use and depletion of natural resources have played a major role in policy debates in cases such as enclosure (the privatization of agricultural commons land in the UK beginning in the 16th century) (Hardin,  1968; Ostrom et al., 1999) and the decline of the Chilean nitrate industry with the invention of the Haber-Bosch process for fixing nitrogen and thus for making artificial fertilizer substitutes (Hughes, 1969). Among the lessons drawn from these historical cases are ideas about the governance of resource use and the potential for resource substitution given the potential for resource depletion. A major historical reference point for resource depletion debates is the 'timber famine,' the depletion of the forests of the British Isles which began prior to the industrial revolution. Forest depletion has been cited as a motive for technological innovation in the industrial applications of coal, initially for process heat and then as the primary energy resource for the inter-linked development of the iron and steel, steam engine and railroad industries -which, along with textile manufacture, were the defining industries of the English industrial revolution. In the present era, concerns about the accumulation of carbon in the earth's atmosphere have prompted discussion of a 'transition' in the use of energy to sources that are more sustainable, either because they involve lower carbon emissions or employ a carbon cycle which takes up and releases carbon (e.g. the alternating cycle between accumulation and combustion of biomass). Historically, there have been several transitions in the use of fuels as an industrial heat source; wood to charcoal, charcoal to coal and coal to petroleum. 1 Only fragmentary evidence about the nature of the first transition survives from its pre-Roman origins. The second transition occurred in England and Wales between the reigns of Henry VIII (1491-1547) and George III (1760-1820). Coal was known in Roman times. 2 However, in that age of wood and charcoal fuel, as well as for many of the centuries that followed, stones that burned were curiosa in traveller's accounts. There are two primary narratives describing the transition from charcoal to coal. The first is that timber reserves were depleted 1 While electricity is vitally important means of transporting energy, its generation relies upon other energy sources including hydroelectric and nuclear power, neither of which plays a dominant role outside of a handful of countries such as Norway (hydro) and France (nuclear). More broadly, wind and water energy sources are also of historical and contemporary importance, see Nye (1999) for an examination of the interplay of different energy sources in American industrialization. 2 Nef (1932). due to the expansion of industrial activity and the growth of urban populations in the 17th and 18th centuries. This narrative draws upon contemporary accounts of the forest depletion and appeals to national security concerns regarding the use of timber, not only as a fuel, but also to construct ships for the Royal Navy and merchant shipping. The 'timber famine' has been central to the existing accounts of the transition to coal and is supposed to have been of cataclysmic proportions. Two modern accounts state: All the evidence suggests that between the accession of Elizabeth I and the Civil War England, Wales, and Scotland faced an acute shortage of wood, which was common to most parts of the island rather than limited to special areas, and which we may describe as a national crisis without laying ourselves open to a charge of exaggeration. Nef (1932:161)   \"...by the time we come to the end of the sixteenth century, an alarming picture of timber famine is emerging\", though there was still sufficient woodland in the early 18th century to permit \"a last feverish clutching at unexploited forest\". They found that, \"had no alternative to timber been available, the expansion of industry that England experienced in the Elizabethan era would have been abortive\", and see many of the technological advances in English industry of the 16th to 18th-centuries as \"the means whereby a timber starved civilization surmounted its problems. \"  Flinn (1959:109) quoting from Clow et al. (1956)   A contemporary observation made in a petition to Parliament to secure a patent in the production of iron using pit coal stated: This use of charcoal in our iron works, has greatly exhausted our woods; the waste and destruction of which in Sussex, Stafford, Hereford, Warwick, Worcester, Monmouth, Gloucester, Pembroke, Glamorgan, and Shropshire, and many other counties, is not to be imagined. So great is the scarcity of wood in many of those places, that where cord wood had been sold at six and seven shillings per cord, it is now sold for upwards of fifteen and twenty shillings; and in some places is all consumed. As the price of wood-coal [charcoal] therefore is rather upon the increase than diminution, the evil will grow greater and greater. This will either lessen our homemade manufacture of bar iron, and consequently increase our importation of foreign iron or it will render the same dearer and dearer to all British manufacturers, to the great injury of every branch of our iron trade in general. Besides, if care be not take to preserve our timber from those consuming furnaces, they will lay hold of our oak, and deprive us of a supply for the Royal Navy and merchant's shipping, to the greater discouragement of ship-building and navigation, upon which the safety and splendour of these Kingdoms depend. Postlewayt (1747:2-3)   There is no evidence that the author of this petition, Malachy Postlewayt, was aware of Abraham Darby or his son's endeavours at Coalbrookdale (Mott, 1957; Raistrick, 1953). The internal evidence from this pamphlet document suggests that Postelwayt believed that the technological solution to the use of coal for iron production required the building of larger furnaces, an endeavour that would have been difficult to finance without securing a patent, the aim of the pamphlet. In addition, the pamphlet's subtitle 'Thereby to save the nation above two hundred thousand pounds per annum, we at present pay for foreign bar iron' indicates the mercantilist logic underlying the appeal. The second narrative describing the transition from charcoal to coal is an account of how the innovations in the use of coal opened up new production possibilities and heralded the substitution of coal for charcoal, an example of conquest of the material world made possible by the use of technology.3 These writers have expressed an optimistic view of the efficacy of technological innovation in solving a substantive problem of economic growth, the acquisition of adequate energy supply. Moreover, the substitution of coal for charcoal is seen as a key feature of the organizational and technological inventions that we call the industrial revolution. 4 A key turning point in this historical narrative is the successful smelting of iron ore with coke in 1709 by Abraham Darby5 and the later opening of the era of 'cheap energy' resulting first from innovations in coal extraction and then still later, from the use of petroleum, a series of transition that spans over two centuries. 6 Applying these historical lessons to our contemporary energy use problems yields two rather different views of the nature of the causes of technological transitions. 7 In the first view, innovations are the product of \"crisis\"; the anticipation of crisis sets in motion forces of innovation to produce a different path of development in order to overcome the crisis. From a \"crisis\" viewpoint, the contemporary \"denial\" of the consequences of carbon emission in stimulating climate may be impeding the scale and intensity of the innovative effort necessary to achieve a transition to a more sustainable pattern of resource production and use. In the second view, the transition to alternative means of energy production in our era is the consequence of the absence of sufficiently promising technological alternatives to redirect and hasten innovative effort to seize the opportunities provided. These are, of course, simplified views of the processes of transition. Because each has rather different implications for the timing, location and level of effort that can be expected, however, it is worth revisiting the historical example to see consider the path not taken -the continued use of timber and charcoal as an industrial fuel. The principal thesis in what follows is that whatever depletion of timber resources might have been observed from 1600 to 1800, this was largely the result, rather than the cause, of the use of coal as a fuel. In other words, although fuel timber production was sustainable, the use of coal offered several specific advantages that may have discouraged fuel timber production. The ability to transport coal greater distances was helpful in supplying heating for London and other increasingly urban areas. Perhaps of greatest significance, the use of coal offered an opportunity to establish a new pathway for economic development. As Wrigley (2010:21) observes, a '...necessary condition for the escape from the constraints of an organic economy was success in gaining access to an energy source which was not subject to the limitations of the annual cycle of insolation and the nature of plant photosynthesis.' As momentous as subsequent developments have been, it is the beginnings of the path not taken that are considered here, a path in which energy use remained bound by the limitations that Wrigley identifies. Following this path for an extended period would have led to a world very different from our own. One can only speculate as to whether it might have been a path that was sustainable for millennia rather than for centuries, even though it would have been a path that seems likely to have discouraged many other developments that are intrinsic features in our contemporary world. From this perspective, the 'timber famine' seems to be a consequence, rather than the cause, of Postlewayt's pamphlet and similar expressions. In practice, these special pleadings for the financial and industrial interests supporting cheap energy were not matched or bettered by arguments in favour of sustainable energy.",
            "Setting the framework in relation to existing literature": " As noted in the previous section, the 'timber famine,' to the extent that it occurred before the increasingly dominant use of coke in iron making (after the beginning of the 19th century), might simply reflect the consequences of 17th century population growth which increased the demand for charcoal fuel, the demand for crop and grazing land to feed this population, and the demand of this population for iron and other energy intensive products. To investigate the path not taken in which fuel timber continued as a dominant energy resource, several questions are considered that have broader implications for sustainability and renewable energy resources in our own time. First, what would have been the costs of following this path and the economic returns to landowners? This will be the topic examined in the next two sections (Sections 3 and 4). Second, how long might this sustainable energy resource have prevailed against the development of coal and coke as the alternative source of fuel into the 18th century? This question is addressed in Section 5. Third, what would have been necessary with regard to policies regarding land use to sustain the use of charcoal as the principal fuel for iron manufacture? This question is addressed in Section 6 and discussed further in the conclusions (Section 7). In the remainder of this section, we consider the general setting of the problem in the existing historical literature and the analytical arguments that this literature offers. The 'timber famine' topic has received considerable attention in economic history since the 1950s, e.g. Nef (1964), Wilkinson (1973), Wrigley (2010). Each of these authors observes that fuel shortage contributed to the transition from charcoal to coal. In the shortrun, timber is an exhaustible resource, and rapid unanticipated growth in demand for applications like home heating would, in theory, push timber prices up dramatically, a theory noted by Allen  (2003). Timber demand of this type might have depleted the stocks of timber available for other fuel uses including industry, provoking a search for alternatives. Historical evidence for price increases associated with these causes derives from statistics compiled by Beveridge (1939) and Thorold Rogers (1887). These statistics are based upon the school account books of Eton (west of London) and Cambridge (east of London), areas typified by rapid population growth during the period. However, in a critique of the 'timber famine' theory Flinn  (1959:116), also citing Beveridge (1939), notes that the price of charcoal at Westminster in central London, a highly competitive market, remained \"virtually unchanged\" between 1664 and 1780 and that the \"Lord Steward, buying mainly in London, paid barely 20% more in 1760 than he had done a century earlier. Flinn surmises: The truth of the situation is that charcoal-consuming industries continued to expand throughout the 'charcoal era', that the Royal Navy, using almost entirely English oak, grew considerably during the same period, while the merchant navy, also competing for supplies of English timber, developed enormously as a result of the Navigation Acts of the mid-seventeenth century and the general growth of English overseas trade. So far from there being a timber famine, it is abundantly clear that the supply of both timber and cordwood during the two centuries after 1550 was enormously increased with surprisingly little real increase in prices. (emphasis added) Flinn (1959:116)   Flinn's thesis, which is fundamental to this paper, has been borne out by detailed local studies and subsequent examinations.8 This argument does not contest the possibility that there were short-run disequilibrium conditions in certain areas and times. As Flinn asks, however, the question is whether fuel timber shortages were sufficiently widespread or long lasting to be the principal explanation of the beginning of the transition from charcoal to coal. Perhaps the most intriguing of the observations bearing on the issue of the timber famine is an analysis by Clark (2004) which compares the price per unit of energy of coal and charcoal. By deriving an implicit price for charcoal based upon land rental prices (one of the methods employed in Section 5 of this paper), he compares energy prices for coal and wood through 1580-1850 and concludes that, from 1580 to 1700, charcoal and wood were roughly comparable in cost, but that after 1700, coal became increasingly expensive relative to charcoal. This finding strongly suggests that it was not a wood shortage, which would have driven its relative prices up, nor a cost advantage to coal, that were responsible for the energy transition. An examination of the iron industry energy transition has been undertaken recently by Madureira (2012). This study is exemplary in several respects. It provides a broader international coverage which allows consideration of international trade in iron and fuel and it explicitly considers the balance between destructive and creative forces influencing the transition. To examine the feasibility and economics of the alternative, the continued use of timber to produce fuel (charcoal) for domestic and industrial applications in the English context, a model is constructed to examine the incentives governing the production of timber for conversion to charcoal. This model examines the production of fuel timber from the viewpoint of the landowner who might choose to forego rental of land in order to grow fuel timber for traditional heating, charcoal and other uses of timber (e.g. shipbuilding). The aim is to examine whether the supply characteristics of these industries imply alternative interpretations or hypotheses about the operation of pre-industrial age energy use.",
            "Examining the production possibilities for fuel timber": " A variety of tree species comprised the 16th-18th century English forest of which oak, ash, and birch were the most prevalent. Oak produced the only timber suitable for ship-building. All of the species were suitable for making charcoal. Foresters analyze the growth of trees in a variety of ways reflecting the difficulties of ascertaining volumes and weights of the irregular objects represented by bundles, loads, and cords of wood. 9 In what follows, cubic feet of timber are the measure by which quantities of timber are measured. The aim is to analyze a sustainable means of forestry involving stands of trees that are large enough to offer opportunities for rotational harvesting. This means of organizing timber growing is consistent with the historical practice of coppicing, the cutting of trees to ground level, leaving the root system in place to regrow timber rather than planting new saplings and, although the unit of harvest is a single acre, this can be scaled to larger sizes. Table 1 shows the yield per acre of timber in cubic feet illustrating that as a stand of trees matures, the number of trees decreases while the amount of harvestable fuel timber increases. 10 Table 1 is based upon harvesting of wood grown from saplings and therefore may underestimate the yield obtainable through the practice of coppicing and the use of mixed rather than pure stands of a single species. 11 To develop an economic model of fuel timber production involves a number of simplifying assumptions. It is assumed that the values in Table 1 reflect average experience and no adjustments are made for risks of fire, flood, diseases, or other potential losses. The model developed here is based on the idea that timber production competes with other uses of land (e.g. for crops and forage) and that allocating land for the growth of timber foregoes income that might be earned by using the land for other purposes. However, not all farm land is equally fertile and it will be appropriate to discount land rental prices (the opportunity cost of the land as used for timber cultivation) in examining the feasibility and sustainability of growing timber for fuel.",
            "A production function for fuel timber and charcoal production": " The general model is presented here, although it is the fuel timber part of this model that occupies us in this and the next section of this paper. The above assumptions allow us to state the general conditions of producing a quantity of charcoal Q(t) from a plot of timber land producing T(t) amount of timber: Q (t) = f [T (t); L(t)] (1) The quantity of timber produced T(t) at time t will determine the amount of charcoal that can be produced using available charking (charcoal making) technology to convert percentage of the timber (measured in cubic feet) into charcoal where 0 < < 1. Q (t) = T (t) (2) All of the labour costs can be summarized in terms of the amount of charcoal produced because charcoal is simply a share of the timber. So costs of cutting timber, charking, and cartage can be summarized in a single parameter (\u02db). L(t) = \u02dbQ (t)(3) The profit from charcoal making ( ) will be the value of the charcoal (price multiplied by quantity) less the costs for labour inputs and any rent for the land to grow the timber: = p(t)Q (t) \u2212 w(t)L(t) \u2212 R(t)(4) where p(t) is the price for the charcoal, w is the wage rate per unit of the labour requirement L(t) and R (t) are, respectively, the amount of labour required and the present value of rent at time t provided to a landowner (e.g. rent was paid for charcoal production in the Royal Forest). If the charcoal producer is the landowner, R(t) may be ignored because rent can be assumed to be part of the profit. The following Eq. ( 5) simplifies Eq. ( 4) by employing the parameters introduced in ( 2) and (3), first showing the underlying timber production and the associated fixed coefficients that translate this quantity of timber production into the amount of charcoal produced for sale. Then, by employing (2), it is possible to state profit ( ) in terms of charcoal output. Eq. ( 5) assumes the landowner is the charcoal producer so rent R(T) is part of profit ( ). = p(t)[ T (t)] \u2212 w[\u02dbQ (t)] = (p(t) \u2212 \u02dbw)Q (t) (5) To investigate the choice problem we will employ a desired rate of return (r 0 ) so that Q Q (t) = r 0 (6) where Q = Q(t) \u2212 Q(t \u2212 1) and r 0 is the rate of time preference of the fuel wood grower. Hence the decision problem is to choose the appropriate cutting time for the timber stand. The profit equation ( 5) implies that profits will be monotonically increasing in time for those who remain in the industry. This is because Q(t) will increasing with t and (p(t) \u2212 \u02dbw) must be positive for producers to enter or remain in the industry. If it is not positive, it does not make any sense to enter or stay in the industry. Profit maximization involves choosing a time, t, at which to harvest the timber and to make charcoal which will depend on the discount rate of the producer.",
            "An operational form for profit maximization for timber production for charcoal": " We can now proceed to the empirical implementation of the model. The principal problem with implementing the model is that the historical statistics for the value of charcoal p(t) are unavailable to directly estimate revenue (or the value of the charcoal produced for use).12 However, there are historical estimates of land rental prices and the costs for cutting timber, charking the wood, and carting it to the point of use as a proportion of the costs of the timber. By combining the available data noted with the yield of wood species in Table 1 it is possible to estimate the minimum 'price' (value) that charcoal would have to have in order to make its cultivation attractive relative to other uses of land such as renting it out for pasture or other relatively lower value uses. 13 This price can then be compared with the fragmentary observations on charcoal prices and it can also be compared with the price of coal over the period to assess the viability of fuel timber production. An extensive summary of British land rental prices based upon rentals paid to charities has been compiled by Clark (2002) with sufficient detail to provide a statistical representation of their variation. 14 He summarize these observations as follows \"Rents rose sharply in the late sixteenth century before reaching a plateau of about \u00a30.45in the 1640s, at which level rents remained until the 1740s. Then another rapid rise took place, so that by 1805 nominal rents reached a rough new nineteenth century plateau at about \u00a31.13 per acre.\" 15 Clark (2002:296) In his series, land rental prices do not exceed a pound until 1800. Therefore we will examine what the implicit prices of charcoal would have been for three levels of rental prices for the period 1480-1799, 36, 111 and 165 old pence per acre per annum (3, 9.25 and 13.75 shillings, respectively). 16 These correspond to the periods 1480-1639, 1640-1749 and 1750-1799 and represent the entirety of the 16th-18th centuries in terms of decisions that would have been taken about cultivating timber. In order to examine yields, we need to estimate annual timber growth rates. This may be done by using linear regression with the data in Table 1. The regressions employ the following assumptions: (1) the cubic feet of wood in a cord is taken to be 90 17 ; (2) the age at cutting a stand is taken to be the year at which the growth falls to a specific discount rate; and (3) data on the rate of timber growth is estimated from Table 1 according to: T (t) = \u02db + bt + ct 2 (7) The estimated coefficients of ( 5) are shown in Table 2. This specification fits the data on timber yield in Table 1 very well for oak and birch with predicted values for the years reported differing by less than 2% for all values except the ten year yield 13 There does not appear to be much gained by growing timber on the best of cropland and therefore it is reasonable to assume that less fertile areas will be chosen. 14 Clark compares these estimates to other historical compilations of land rental prices from other sources. An alternative series from Turner et al. (1997) from large estates shows a consistently lower level, diverging considerably for the earliest years at the beginning of the 18th century. 15 The decimal values in this quotation are a modern convention, so \u00a30.45 amounts to 108 pence or 9 shillings and \u00a31.13 amounts to \u00a31, 2 shillings and a bit more than 7 pence. 16 These correspond to the national average land rental prices reported by Clark for the periods. 17 This is an estimate based upon the average reported in Dobie and Wright (1975)  omitting the category of crooked wood cords. of oak, which is under-estimated by 6.6%. Ash, however, is more problematic. As Table 1 shows, the pattern of ash growth involves a much more dramatic winnowing of trees between years 10 and 20 and the yield of fuel wood in year 10 is not available, perhaps because of the relatively small size of the trees in that year. 18 These estimates allow us to specify a cutting date for the stand as a function of the producer's discount rate, r, and to determine the resulting yield as reported in Table 3. The amount of timber produced depends upon the time preference of the landholder. High rates of interest would imply more frequent cutting and lower yields per acre. Lower rates of interest result in higher yields per acre of timberland. As noted above, the optimal time of cutting will be determined by this interest rate or 'time preference' of the landowner. It is now possible to infer the minimum prices for timber assuming the land rents noted above and the timber yields summarized in Table 3. The sustainable farming method by which stands are grown to the age at which their rate of increase falls to the annual increase represented by r implies that in every year the number of acres of wood left to grow will be one less than the number of years at which it is optimal to cut an individual stand. For example, with a discount rate of 4% per year, a stand of oak will require 28 acres to remain uncut in every year for every one that is cut. So, for oak, the total rent required to harvest 1242 cubic feet in perpetuity will be 29 times the per acre rental rate. This method allows the calculation of the timber prices that will sustain production. The first step is to calculate the price that would support the rent alone. This is the price per cubic foot of timber that will generate a value sufficient to pay the land rental for the perpetual growth of the timber. The price to be calculated multiplied by the yield must equal the land rent times the number of years (which is the number of acres that are not harvested plus the acre that is harvested). Both the yield and number of years are given in Table 3. Table 4 suggests four observations directly. The prices necessary to sustain the growth of oak and birch are substantially higher than required for ash. This might be of little consequence during the beginning of the period when the qualities of oak and birch as firewood (independent of their use as charcoal) might provide a basis for these species relative to ash. However, the level of the difference becomes more marked over time and perhaps with it, a tendency to favour ash and similarly rapid growing species in English cultivated forests. Second, each of the three periods represents a step change in the price required to maintain the cultivation of fuel timber. If unable to sell at these higher sustainable prices, landowners might well clear the land for pasture or crops. Third, it is to be remembered that the land rents used are average land rental prices for the periods and that land selected for growing timber might not be able to command these rental prices and might generate a small amount of additional income from other uses. Hence, these sustainable prices may be higher than the prices actually required. Fourth, nevertheless, to account for the costs of cutting, charking and carting, the value of charcoal would need to be 40-60% higher than the values reported in this table. The remaining question is whether these sustainable prices for fuel timber would support charcoal production. Two approaches to answering this question are available using existing historical observations. The first is to compare these prices directly with the prices of fuel wood from historical records. Hammersley (1973)  provides a number of observations from primary sources that give prices for wood used to make charcoal for iron making. His observations are almost all drawn from the 17th century and vary widely. For the period 1600-1630 the average of 15 observations is 0.64 pence per ft 3 and the average of 12 observations for 1630-1691 is 0.98 pence per ft 3 .19 However, as noted, within these observations there is substantial variance -for the first period the maximum price paid was 1.22 pence per ft 3 while, for the second, the highest price paid was 1.75 pence. These observations suggest that charcoal iron makers were acquiring wood in the 17th century at prices that implied either that they were procuring timber from land with rental (opportunity cost) substantially below the national average, or that the prices they were paying would not sustain the continued production of fuel timber by the end of the 17th century. Source: Prices in the range suggested by Clark and Jacks (2007:64). During the latter part of the 17th century, however, firewood prices appear to have been increasing. Clark (2004) provides an index of firewood and timber prices which increase by 27% and 56%, respectively between the first and second half of the century. This provides a basis for concluding that the shortfall in the prices observed by Hammersley (1973) were remedied by price rises later in the century. During the 18th century, the remarkable feature of both land rent and wood prices is their relative constancy throughout most of the century. It is not until the last decades when there is a modest increase in the level (and greater year to year fluctuation) in the price of fuel timber. Unfortunately, existing historical data does not allow the direct observation of the value of fuel timber during this period. An approach to assessing whether the continued growth of timber for fuel was sustainable is to compare the price of coal to the sustainable prices reported in Table 4. 20 This has been done in Clark (2004) and Clark and Jacks (2007). Both articles conclude that coal and wood are similar in price until the middle of the 18th century and then coal begins to be more expensive on an equivalent energy basis in the later three decades of the century. The articles also make an important simplifying assumption regarding the sustained output of fuel timber, assuming that coppiced land can produce a sustained yield of up to 100 ft 3 per year as opposed to the sustainable practice analyzed in this article. The articles also make the assumption that coal has an energy value of 12,000 btu per pound and dried wood 8600 btu per pound. A cubic foot of dried wood weighs 29.4 pounds, so the energy equivalence of coal and wood is that it requires approximately 110 cubic feet of wood to equal the amount of energy in an (Imperial) tonne of coal. Table 5 reports the price of coal yielding the same energy as a cubic foot of wood for comparison with the values in Table 4. Table 5 confirms that, compared to the price of coal, the sustainable minimum prices for wood shown in Table 4 would be attractive for mixed stands (ones not solely composed of oak trees) and based on comparable price. Further research might be performed to adjust the simplified models to local conditions and additional tree species. However, the analysis shows timber growing was sustainable at the rents prevailing for more marginal farm land through 1700 Ernle (1936) and sustainable throughout the 18th century based upon direct competition with coal.",
            "An analysis of charcoal iron production": " The previous section has indicated that the production of fuel timber was sustainable at prices typically recorded between 1600 and 1750 and competitive with coal thereafter. In practice, the production of such timber for the purposes of iron making should not be seen as involving a competitive market. 21 Charcoal iron production involves the co-location of fuel and iron ore sources which limits the available areas for production, creating historical patterns of development, initially dominated in the early 16th century by the Weald (the area in Southeast England between the North and South Downs) and Hampshire (an area extending from and including a portion the Weald to the West). 22 By the beginning of the 17th century at which this examination of timber growing commences, the Weald appears to have been in decline and other English regions such as the Forest of Dean (located in the southwest in Gloucester) and Wales (Glamorgan mentioned earlier) began to rise, a pattern which continued through the beginning of the 18th century which marked the start of decline of charcoal iron making in these regions as well. This pattern of regional shift and eventual universal decline is associated with timber famine theories although, as Hammersley (1973) indicates, the continued growth in the 17th century fails to provide evidence of a general shortage of timber and is better explained as a story of following access to richer iron ore deposits and cheaper labour. Moreover, the more pronounced decline in the first half of the 18th century can be explained by the increase in imports from Sweden and other countries with better iron ore deposits, cheaper labour and less exploited wood resources. By end of the 17th century, imports were as large as the entirety of domestic iron production.23 Thus, at best, the 'timber famine' theory is a tenuous explanation for the decline of charcoal iron making. The land requirements are now considered for the sustainable production of iron during the last century of the period of analysis (1650-1750). During this period the size of blast furnaces had grown as the iron-making spread from the Weald where 200 t per year per blast furnace was an average output, to about 300 t per year in the West (with about 250 t average in other parts of the country) Hammersley (1973:602). Hammersley prefers a conservative bias and, in the absence of more detailed data, assumes that the size of blast furnaces remains constant through the middle of the 18th century. Flinn (1958), however, assumes a continuing growth of blast furnace size and thereby a higher estimate of national charcoal iron output in the middle of the 18th century, immediately before the industry's more rapid decline as coke fired blast furnaces came into widespread use. Hammersely and Flinn agree, however, that timber fuel resource was not an important influence in limiting industry growth. Hammersley provides the basic computation concerning the sustainability of charcoal iron manufacture based on three assumptions. First, the cartage area for charcoal would have limited the distance between timber and blast furnace to less than five miles, defining a 50,000 acre land base for growing fuel timber. He concludes that 13,000 acres could provide a permanently sustainable timber resource base for smelting and fining (removing impurities in smelt iron) to make wrought (bar) iron. He also concludes that patches of forested land (without specific efforts to cultivate timber) were sufficiently numerous in the 17th century to have provided such a sustainable resource base and, hence, no specific need to move blast furnace because of the exhaustion of timber resources, assuming that sustainable practices were introduced. As already observed, Flinn (1959) notes coppicing as one of these practices, while he and others have noted iron maker's interest in preserving their resource base. These estimates are consistent with the model of timber supplier behaviour developed above. The amount of fuel timber required to support smelting and fining of iron ore into bar iron in 300 t per year iron works would be 528,000 cubic feet of solid wood. 24 This amount of wood is consistent with various discount rates for timber growing and examples are reported for the less profitable (but perhaps more commonly grown) wood species in Table 6. A sustainable charcoal iron industry would have had to keep up with the growing demand for iron and steel in the 18th and into the 19th century in order to prevent a limitation in overall UK economic growth and the attendant increase in living standards that began with the Industrial Revolution. Barring much more significant technological change, or adjustments that limited the demand, an exclusive use of renewable timber energy resources would have broken down during the 19th century as Table 7 illustrates (based upon the estimates as confirmed to be feasible by the timber production model of this paper). In summary, the search for a coal-based smelting technique was not based on a \"crisis\" of industrial resource supply. In fact, Hyde  (1973) has shown that charcoal and coke smelting were close competitors throughout most of the 18th century. Charcoal and coke produce equivalent thermal energy. Leaving aside consideration of the different qualities of iron they produced, it is to be expected that coke's adoption relied on gradual long run shifts in relative price, particularly, the steady fall in coal prices in the latter part of the 19th century, and the increasingly successful results obtained by using coke as fuel.",
            "An interpretation of efforts to regulate crown forests": " Timber is land and labour intensive in comparison to corn (grain) production and the most important agricultural growth industry of the 17th and 18th centuries, raising sheep. As noted earlier, charcoal requires more labour than merely felling timber -it also requires carting timber, staging, charking, and carting charcoal (Hammersley, 1973). This further complicates interpretation of the available statistics from areas where the factors of labour and land had alternative, and perhaps more profitable uses. Dasgupta and  Stiglitz (1981) have demonstrated theoretically that the anticipation of a successful substitute to an exhaustible resource will increase the rate of extraction of that resource if the available stock is small. They also note the implication of this for the \"timber famine\" theory. 25 During the initial adjustment period, the competitive price of the resource will be the cost of extraction. In the case of timber, where the land upon which it stands is of some economic value, the effect was to create an active market in industrial charcoal, a local market and one that involved land use choices of the Crown and large land owners in allowing \"cutting rights\" to those who would make use of timber to make charcoal. The Timber Acts of 1657 and 1668 were established to reform the prevailing land practice of the Crown. Since the Norman Conquest, the Crown had asserted the rights to control of forested lands generally, and those lands specifically designated as Royal Forests, greatly limiting the use that might be made of the lands. 26 Both acts expressed concern with the maintenance of timber. Arbitrary behaviour by land owners towards charcoal producers renting their land is well chronicled in pre-Elizabethan times (before 1533) and continued through the English Civil War (1642-1651) (Hart, 1966). After the Civil War, substantially more favourable contracts for cutting rights on Royal and adjoining lands were negotiated. The Act of 1657 relaxed some of the controls on landowners while preserving the right of the Authority (the Protectorate in this year) to enclose (coppice) up to one third of woodlands to sustain wood growth and prevent their destruction by cattle. 27 The Act of 1668 more directly stated concerns about timber conservation and re-asserted the right of the Crown to enclose coppices. 28 Both expressed concern about the sustainability of the forests and suggested that they were being depleted. However, these measures can also be understood as an attempt to create more pragmatic policies with regard to the use of Crown forests and the use of forests by large landowners. The situation in the 18th century is better known, though a thorough study of land use patterns does not exist for that century either. We know that areas bordering the Royal Forest were harvested and that other areas experienced similar rapid clearing (Hart, 1966; Anderson, 1961; Fernow, 1907; McCracken, 1971;  and Rubner, 1967). Corresponding price falls from timber clearance were mitigated by the continuing expansion of British shipping, urban housing construction, and the export of textiles which used substantial fuel in washing and dyeing operations (Rees, 1968). We have seen that pure stands of ash and birch are much more prolific than stands of oak for charcoal. The Royal Navy's primary problem was securing sufficient supplies of large oak (Albion,  1926). Albion also notes the extraordinary difficulty of producing this size of oak which required over a hundred years to grow. As the model of this paper demonstrates, oak is the least desirable species for populating sustained fuel timber production. This suggests a reinterpretation of the 17th century British Timber Acts and much of the subsequent discussion surrounding timber shortages. Instead of the these measures being sought as a means of preserving Britain's diminishing timber resources, they may be seen as an attempt to guarantee the Royal Navy an adequate supply of oak by fiat. This decision would be consonant with the mercantilist spirit of the time. It would have appealed as a legitimate and rightful function of government. And it might have reduced the growing dependence on foreign sources for naval timber. Unfortunately, the Crown was rarely in a position to enforce 26 The use of Crown forest as a source of rent, however, led to leases being granted for specific enterprises such as charcoal iron production in the Forest of Dean (Hammersley, 1957). 27 Firth and Rait (1911). 28 Raithby (1819). these edicts. Whether by rational plan or fortuitous custom the oaks disappeared and the land owner and charcoal burner prospered until overtaken by the 19th century innovations that reduced the extraction costs of coal (Clark and Jacks, 2007). We can only speculate what effects a more dramatic set of choices regarding land use policy might have been. As noted earlier, during the later years of the charcoal iron industry, the UK had begun to import as much iron as was domestically produced. If such imports might have continued to grow under a land use regime favouring fuel timber and charcoal production over coal extraction to meet the growing needs of British industry and populace, would they have come at the cost of delaying or deferring the intensification of the English industrial revolution in the first decades of the 19th century? In the previous section, it was demonstrated that if pig iron production were to continue to be accomplished through the sustainable use of forest reserves, more intensive imports would have been necessary. Moreover, that the key technology of the steam engine would have developed at the rate and in the direction that it did without the stimulation provided by pumping water from mines or transporting coal by rail, seems dubious.",
            "Conclusion": " This article has revisited and modernized an important historical debate regarding the energy transition from charcoal to coal with a view to informing debates about current transitions. The debate about the timber famine has not been ignored by students of technological change and it has been an important area of research for economic historians. In terms of policy, however, the idea of a \"shortage-led\" transition continues to be influential and to suggest that innovation will produce substitutes when shortages appear. Without contesting that the changes wrought by \"cheap energy\" have been momentous, this article has examined the path not taken. This path is one where renewable, rather than exhaustible energy resources, might have continued to serve to underpin a principal industry of the Industrial Revolution. In the 21st century, it has become apparent that following the path taken in the conquest of the material world has come with the costs of undertaking yet another transition in the supply and use of energy. Again, the discourse is being shaped by the idea of shortage-led substitution; today those shortages involving resources (e.g. petroleum reserves) or technologies (e.g. low carbon means of energy production and use). By examining the sustainability of timber fuel energy resources in the 16th and 17th centuries, the analysis has illustrated that the timing and rate of transition was subject to choice, rather than arising from a desperate search for alternatives when exhaustion loomed. These choices included policies with regard to land use, international trade, and the treatment of 'obsolete' technologies. The choices taken did not take into account the deferred bill for 'cheap energy' nor did they consider the effects in that era of market expectations of accelerating the perceived rate of depletion. The article also demonstrates, however, that there were inherent 'limits to growth' in following the sustainable energy pathway and remaining bound to the cycles governed by solar energy. This pathway would eventually have deflected, dispersed or deferred the energy intensive transformation of the Industrial Revolution, requiring substantially different approaches to production, not only of iron and steel, but also other energy-intensive manufacturers. It would have constrained important drivers of innovation and growth stemming directly from intensive exploitation of the coal resource such as steam engines and railroads. It may also have served to disperse industrial activity across the countryside to sites where urban competition for fuel was less intensive and, thus, have dissipated the benefits that Alfred Marshall was later argue was a principal benefit of the industrial districts of the 19th century. 29 These are only a few of the many differences that occurred as the result of following the path not taken, the continued primacy of timber fuel. These actual and alternative histories suggest a number of lessons for the impending transition to lower carbon energy use. As in the timber fuel period, some configurations of energy supply and use may imply that the location of energy resources would become more dispersed with hydroelectric, wind, wave and other renewable energy resources located at a distance from current industrial centres, encouraging not only a different national and international distribution of energy production and use, but also a changing distribution of industrial activity. 30 It is also possible that alternative energy sources may emerge that are more centralized and therefore are consistent with existing geographic concentrations of energy use. To the extent that renewable energy resources again link economic growth and innovation to improvements in capturing the current (rather than the geological) benefits of solar energy, the global distribution of energy resources is likely to change with implications for international trade and national specialization, tendencies that are already appearing in the cases of bio-fuels and photo-voltaic installations. In other words, a principal lesson that the historical transition from fuel timber to coal offers for our contemporary era is to contest the view that shortage 'crises' are necessary to foster the creation of substitutes. Instead, the choices taken with regard to patterns of energy production and use will establish new pathways, some of which may offer richer opportunities for economic growth or prosperity than others. This suggests that science and technology policy analysis needs to consider more deeply how processes of adjustment are likely to unfold, not only in energy production and use, but also in the interdependence between energy production and use and the role of these interdependencies in affording (or denying) opportunities for experience-based innovation. The scale and scope of transformation implied by these new pathways is very large, but not unprecedented. The historical record of transition remains a valuable guide to the form, direction and speed of transformation and the impact that policy choices may have on these processes."
        }
    },
    "10.1016/j.enpol.2014.01.046": {
        "file_name": "15 Local civil society based renewable energy organisations in the Netherlands",
        "title": "Local civil society based renewable energy organisations in the Netherlands: Exploring the factors that stimulate their emergence and development",
        "abstract": "In order to alleviate urgent and pressing environmental issues, a transition towards decentralised production and consumption of renewable energy is necessary. The establishment of local renewable energy organisations (LREO) can stimulate this transition. In the recent past the number of LREOs has grown substantially in the Netherlands. However, due to their recent emergence little is known about the factors that stimulate or hamper their appearance and development. This research addresses this knowledge gap. Based on a literature review and five expert interviews, explanatory variables that might determine the emergence and development of LREOs were identified. Second, a first assessment of the factors that stimulate the emergence and development of 26 Dutch LREOs is made. Face-to-face interviews as well as an online questionnaire were used to validate this assessment. We conclude this paper with some recommendations for policy makers and LREOs.",
        "label": "Quantitative",
        "text": {
            "Introduction": " The Netherlands predominantly relies on fossil fuels for its electricity production. In 2010 renewable sources accounted for just 3.8 per cent of the total energy consumption (Blokhuis et al., 2012). However, a transition towards a large share of renewables is considered necessary, among others to reduce CO 2 emissions. Generating renewable energy close to where it is consumed could contribute to as much as 40 per cent of the national electricity demand (Allen et al., 2008;Bergman and Eyre 2011;Watson et al., 2008). Over the last decades a variety of locally initiated civil, public and/ or private organisations aiming at the provision and consumption of renewable energy within their vicinity has emerged in the Netherlands (Agentschap, 2010). Fig. 1 shows the recent emergence of local civil society based renewable energy initiatives or organisations. While the establishment of initiatives in the 1980s and 90s was motived as a statement against nuclear energy, the more recent emergences are said to result from a growth in social responsibility and collaborative entrepreneurship (Zomer, 2012). Scientific literature identifies a couple of terms that are commonly applied to address this phenomenon. However, a coherent terminological reference remains absent due to various interpretations of the degree of consumer participation or ownership and what is considered local. Consumer participation implies an active consumer role, which encompasses the development of energy systems (co-construction), the delivery and generation of energy services (co-production) and/or the ownership and operation of these systems and services (cf. Watson 2004). Furthermore, Allen et al. (2008) and Verbong and Geels (2010) refer to this phenomenon as decentralised generation, which entails a diversity of actors including local utilities and companies, consumer co-operations, housing associations or municipalities, who simultaneously provide and consume energy. More specifically, Walker and Cass (2007) and Warren and McFadyen (2010) emphasise the central role communities play. The notion of microgeneration is used to assess this phenomenon on a household or micro-scale (Allen et al., 2008;Bergman and Eyre, 2011;Sauter and Watson, 2007). In this paper we will use the concept of local renewable energy organisation (LREO). LREOs are defined as organisations, initiated and managed by actors from civil society, that aim to educate or facilitate people on efficient energy use, enable the collective procurement of renewable energy or technologies or actually provide (i.e. generate, treat or distribute), energy derived from renewable resources for consumption by inhabitants, participants or members. The latter live in the vicinity of the place where the renewable energy is generated. So far most literature on the expansion of renewable energy in the Netherlands has focused on the developments of policy instruments (Agnolucci, 2007;Dinica and Arentsen, 2003;Kwant, 2003;Rooijen and van Wees, 2006), the implications of the liberalisation of the green electricity market (Dinica and Arentsen, 2003;Reijnders, 2002) or on the diffusion of specific renewable energy technologies such as wind energy (Agterbosch, 2006), biomass and biomass combustion (Meijer et al., 2007;Negro, 2007) and solar power (Jager, 2006). Related to the decentralisation of renewable energy provision, the literature discusses various aspects like the possible advantages and disadvantages of different micro-generation methods (Allen et al., 2008), the technical implications of embedding distributed energy supply to the central grid (Passey et al., 2011;Schneider and Pehnt, 2006), the implications in regard to social acceptance (Sauter and Watson, 2007;W\u00fcnsterhagen et al., 2007) and the economic and financial considerations (Watson et al., 2008). Furthermore, the body of empirical studies providing data on community-based renewable energy is growing (Denis and Parker, 2009;Devine-Wright, 2005;Devine-Wright and Devine-Wright, 2009;Rogers et al., 2008;Walker et al., 2010). Moreover, Davies and Diaz-Rainey (2011), Ferreira et al. (2011), Harmelink et al. (2006) Scordato (2010) and Toke et al. (2008) have paid attention to the different policy instruments available in EU Member States and their effectiveness to foster decentralised generation of renewable energy. Although Blokhuis et al. (2012), Colijn (2006), Jager (2006) and Vermeulen and Hovens (2006) have researched aspects related to the development of LREOs, there is little scientific research on the factors that stimulate the emergence and development of LREOs in the Netherlands. Consequently, this paper aims to address this knowledge gap. We will identify and give a first assessment of the factors that stimulate the emergence and development of LREO. This will be done step by step. In the next section we will first review literature in order to define a conceptual model and related hypotheses. In Section 3 we will clarify how we have assessed the relevance of these hypotheses. In Section 4 the results will be presented, which will be discussed in Section 5. We end this paper with some concluding remarks.",
            "Towards a conceptual model and related hypotheses": " A specific model to analyse the development of LREOs could not be found in literature. Therefore we developed a model ourselves for which the theoretical foundation is derived from the innovation diffusion literature, as the emergence and development of LREOs can be seen as an innovation. From this body of literature, the integrated framework developed by Dieperink et al. (2004) is selected as a starting point. Although other frameworks that allowed studying the emergence and development were available, the authors are familiar with the framework of Dieperink et al. (2004) which proved to be suitable for empirically studying the diffusion of innovations, as is for example done by Vermeulen and Hovens (2006). The framework is based on a review of several (Dutch) studies on energy-saving innovations in the Netherlands (such as Blok and Farla, 1996). Explanatory variables from the community renewable energy and micro-generation literature were used to refine this model into hypotheses. Relevant literature was found after a Scopus search using combinations of terms like renewable energy, decentralised or distributed generation, community-and micro-generation, innovation and diffusion. To check the applicability of the model and the hypotheses for the Dutch situation, semi-structured interviews were conducted with five Dutch experts originating from different spheres of society. These are listed in Table 1 below. The consulted experts were first asked what factors in their opinion would have stimulated the emergence and development of LREOs in the Netherlands. Second, they could reflect on the conceptual model and hypotheses. All five interviews were recorded and transcripts were written down. The suggestions made by the experts to improve the applicability of the theoretical model to the Dutch situation have resulted in some minor modifications of the model and hypotheses. In general the experts agreed that the factors we derived from literature were potentially relevant. In Fig. 2 our model is presented. The founding process of a LREO is the dependent variable. The identified explanatory variables that are expected to affect one or more steps of the founding process are clustered into six categories: the macro-context, economic and technical characteristics of the envisioned renewable  . ",
            "The founding process as dependent variable": " The dependent variable is the outcome of the founding process, which is the actual establishment of a LREO. The steps in the founding process are based on the model of Dieperink et al. (2004). However, gaining and attaining local support was included in this model as the five consulted experts considered this a vital step in the founding process. The founding process encompasses four phases: the appearance of an occasion, the local perception of a LREO, local support and acceptance and the assessment of the applied technology. To embark in the process of founding a LREO, a serious occasion has to occur and merely serves to prompt the idea or motivate the founders. During the second phase, various actors within the social network or direct surroundings influence the local perception of the founders and the community through for example advocating the merits of such an organisation or amplifying the contested features of renewable energy technologies. Another aspect of the founding process is to ensure the organisation receives sufficient local support and acceptance. Four of the consulted experts suggested that a high level of local support significantly increases the chances of actually establishing a LREO, while minor support can be detrimental. Finally, numerous technologies enable us to harvest renewable energy sources. However, an assessment on both the technological features as well as the economic characteristics of the applied renewable technology provides necessary insights on whether the founding is feasible.",
            "Macro-developments": " Fluctuating energy prices (Praetorious et al., 2010), emerging entry barriers (Jacobsson and Johnson, 2000) and the degree of environmental awareness concerning the impact of anthropogenic climate change (Bergman and Eyre, 2011) are macro-developments that could exert a profound influence on the founding process. To begin with, due to fluctuating energy prices, Bruijne (2012) and Hooijdonk (2012) argue that the general public becomes progressively concerned with their future energy consumption and energy expenditures, which fuel the ideal to gain control over their own energy provision and entails one variable that prompts the occasion to establish a LREO. A primary barrier identified by the academic literature encompasses the existence of market entry barriers (Allen et al., 2008) or system resistance (Collins, 2004). The traditional companies dominating the centralised energy systems are usually focused on system optimisation through incremental rather than radical change, since they have made sunk investments in the existing technologies such as power plants and the required infrastructure. In addition, unequally allocated taxable allowances result in an unlevelled playing field, which discourages the establishment of LREOs. This disparity partly stems from the fact that the present energy system is designed with a centralised method of energy provision in mind and is regulated as such (Bruijne, 2012;Westendorp, 2012;Zomer, 2012). Consequently, a level playing field would ease the entrance to the energy market and therefore prompt an occasion to establish a LREO. In relation to anthropogenic climate change, it is assumed that people unaware of the environmental impact are also less inclined to enquire information on the advantages or benefits associated with renewable energy technologies. Consequently, the degree of environmental awareness plays an important role in improving the local involvement and support and often determines the occasion to invest in renewable energy technologies (Jager, 2006).",
            "Technological characteristics": " Renewable energy technologies enable the members of LREOs to experience a sense of self-reliance and independency from distant and top-down structured energy corporations (Bruijne, 2012;Hooijdonk, 2012;Zomer, 2012) or fossil fuels imported from unstable foreign regimes (Bruijne, 2012;Hooijdonk, 2012;Sauter and Watson, 2007;Verbong and Geels, 2010;Watson et al., 2008), which is anticipated to stimulate the occasion to found a LREO. Although renewable technologies are perceived reliable in terms of energy provision, they are also characterised as innovative and therefore might be perceived as being immature, risky or unreliable (Bergman and Eyre, 2011;Fisher, 2006;Rogers et al., 2008;Watson et al., 2006). It is assumed that a choice for reliable and proven technologies positively affects the assessment. Another distinctive feature is the visibility of various renewable energy technologies. Large visible projects commonly impose substantial impact on the neighbouring community, which in scenic environments is frequently associated as a primary source of opposition and tends to negatively dominate the local attitude towards the organisation (Warren and McFadyen, 2010). On the contrary, in certain situations the visibility of a renewable energy technology could foster local perception as well as acceptance due to increased acquaintance and awareness of the relevance of renewable energy (Devine-Wright, 2005), which is expected to be included in the assessment of the applied renewable technology as well. Furthermore, if energy surpluses are exported to the grid, energy flows have to be monitored. Allen et al. (2008) and Watson et al. (2006) stress that providing the end-users with direct feedback on their energy consumption fosters behavioural change and might improve the local support of LREOs. Additionally, founders of a LREO might include the possibility to monitor energy production and consumption in their assessment of the applied renewable energy technology.",
            "Economic characteristics": " In terms of benefits, the most apparent aspect concerns direct saving on the regular energy bills (Kellett, 2007;Walker, 2008), which might be amplified if the gains are re-circulated through or returned to the community (Kahn et al., 2007;Walker et al., 2007). Apart from financial benefits, LREOs are expected to deliver a range of soft or indirect benefits, which fail to materialise in conventional top-down corporate developed projects (Toke, 2005). Examples of such symbolic benefits are the enhancement of social capital and cohesion within the community (Kahn et al., 2007) and a sense of pride associated with taking part in a social and sustainable organisation (Walker et al., 2007;Warren and McFadyen, 2010). Both economical and soft benefits are expected to motivate civilians to establish a LREO. In contrast to these benefits, economic constraints arise in cases of high up-front investments (Watson et al., 2006), long pay back periods and low price performance ratios. Decreasing prices of renewable technologies resulting in lower up-front investments might also stimulate the emergence of an occasion. Furthermore, lower investments and shorter payback periods are also predicted to positively affect the assessment of the applied technology.",
            "Governmental interventions": " Governments might interfere on various occasions during the founding process. First, institutional barriers may arise from long bureaucratic procedures and/or the absence of a long-term and consistent policy framework. The Dutch policy climate concerning the stimulation of renewable energy generation has been subject to frequent changes (Toke et al., 2008;Zomer, 2012). This creates uncertainties that might lead potential founders to relucestablishing a LREO. Consistent policies are therefore predicted to stimulate the emergence of an occasion. Bruijne (2012) and Zomer (2012) suggest however that a prolonged period of inconsistent policies as well as dissatisfaction arising from the incompetence of the national government to meet their environmental targets has motivated civilians to establish LREOs. Furthermore, the perceived effort to obtain subsidies and planning or licensing applications, discourage the emergence of LREOs (Allen et al., 2008;Watson et al., 2006). In regard to the Dutch situation, it is found that present regulations in combination with the consensus approach result in lengthy procedures that negatively affect the local perception and stagnate the emergence of those organisations that heavily rely on it (Haar et al., 2011). Apart from these institutional barriers, governmental bodies can stimulate the emergence and development of LREOs through providing and facilitating the transfer of knowledge rather than attempting to regulate their development (Zomer, 2012). Jager (2006) showed that providing and facilitating the transfer of knowledge has a positive effect on the perception of renewable energy technologies. However, Jager ( 2006) also stresses that while information provision is necessary to reduce perceived complexities, it is insufficient in itself to foster the deployment of innovative renewable energy technologies.",
            "The influences of the market and society": " Diverse actors operating in the surrounding play a key role by persuading or discouraging members of the local community and ultimately forming or altering their perception and acceptance towards LREOs. The availability of external knowledge and advice is vital in forming the local perception and enhancing local support and acceptance (Denis and Parker, 2009;Rogers et al., 2008;Toke, 2005;Walker, 2011Walker, , 2008;;Walker et al., 2010). In particular suppliers and installers of renewable energy and technologies are argued to affect the local perception towards LREOs (Bersselaar, 2012;Bruijne, 2012). Aside from governments, suppliers and installers, Bruijne (2012) emphasised that there is a growing need to share practical information and receive support from other LREOs or network organisations, which according to Bersselaar (2012) also improves the creditability of an organisation and enhances its degree of local support. Finally, the presence of local protection or opposition organisations is found to be discouraging (Toke et al., 2008). Alternatively their absence is predicted to positively affect the local perception and acceptance of LREOs.",
            "Organisational characteristics": " LREOs might encounter local opposition, which can often be traced back to negligence of the process dimension (Toke et al., 2008;Warren and McFadyen, 2010;W\u00fcnsterhagen et al., 2007). It is advocated that more direct and substantial involvement of local people or the community reduces opposition and enhances local support and acceptance of a project (Haar et al., 2011;Rogers et al., 2008;Walker and Devine-Wright, 2008). Moreover, local support and acceptance within the community towards a LREO is found to correlate with their degree of ownership and expectancy of receiving a fair and equal share of the benefits generated by the organisation (Cass et al., 2010). Alternatively, when the allocated benefits are perceived as unfair or unequally distributed, this might cause hostility and consequently result in a decline in local support for the project (Walker, 2011;Walker and Devine-Wright, 2008). In addition, the degree of social cohesion and interpersonal trust within communities as well as organisations is found to influence the local perception and acceptance of LREOs (Haar et al., 2011;Walker et al., 2010). LREOs characterised by strong social cohesion are expected to be less vulnerable to disagreements arising from for example investment decisions, division of ownership and benefits. As a consequence high social cohesion might improve the local support and acceptance of a LREO.",
            "Hypotheses testing and population characteristics": " We have specified the model into 36 hypotheses (see Tables 3-6) in which we postulate a positive link between independent and dependent variables. Both face-to-face interviews as well as an online questionnaire were used to empirically validate the hypotheses. The hypotheses were formulated as questions (in Dutch), on which the interviewee could point out to what extent a certain variable had influence on the founding process. The answers given in the face-toface interviews were coded by the interviewer on a five-point ordinal scale, ranging from not influential at all (score 1) to very influential (score 5) (Saunders et al., 2009). If an explanatory variable was considered neutral it scored a 3. In the online survey the interviewees were asked to indicate the scores themselves. To test the hypotheses, we calculated the average scores given by the interviewees on the five-point ordinal scales, as well as the standard deviations in the answers given. In cases in which the average score is larger than 3 and the standard deviation is low, i.e. between 0 and 1, there is empirical ground to validate the stimulating impact of the corresponding explanatory variable. By combining expert interview data and desk research findings, we identified 132 LREOs. Of these 132 LREOs, 65 are set up by civil actors or are a partnership between civilians and a private or public party. These 65 LREOs have formalised their status as they are registered at the Chamber of Commerce, either by concluding a cooperative arrangement (36) or by establishing a foundation (22). Most of the organisations (41) were founded after 2007. Other organisations (15) were established before the liberalisation of the energy market in 2004, most of them in the late 1980s. The LREOs also differ in their primarily targeted renewable resource. Wind energy is the main focus of 25 organisations, while 23 organisations primarily orientate on solar energy. The remaining organisations aim at less popular sources such as biomass (5), geothermal (2) or on multiple sources (4). The favoured renewable source of 6 organisations could not be clarified, since their primary focus is on insulation, energy saving or raising awareness. The LREOs also show a considerable variation in the number of members that voluntarily pay contribution, ranging from 2 to over 3000. However most of them have less than 100 members. In general, three types of members can be identified: sympathisers, voluntary contributors and customers. During the founding process, LREOs generally embark with keeping community members that sympathise with the ideals of the organisation updated through for example a newsletter. However, not all organisations favour this form of membership and rather aim at a more restrictive membership, for which members voluntarily pay contribution. Furthermore, an organisation might provide energy related services to its members, who might become consumers. Out of the 65 LREOs identified, the initiators or board members of 26 organisations were willing to participate in our empirical research. The experts we consulted characterised 13 LREOs as well established. With these 13 LREOs we conducted face-to-face interviews. Their organisational characteristics are shown in the upper half of Table 2. The characteristics of the 13 other LREOs that participated in the online survey are shown in the lower half of Table 2.",
            "Factors influencing the emergence and development of LREOs": " In this section we will present our empirical results. We will make clear which factors are reported to have influence on each of the four steps of the founding process. related listed in the tables below. The tables also contain the average scores and standard deviations we have calculated from the faceto-face interview and survey data.",
            "Factors that affect the emergence of an occasion": " When considering the emergence of an occasion the empirical results show that fluctuating energy prices and a high level of environmental awareness within society are two variables from the macro-context that prompt the emergence of an occasion. Furthermore, dissatisfaction arising from a prolonged period of inconsistent policies as well as dissatisfaction stemming from the incompetence of the national government to meet its environmental targets are explanatory variables originating from governmental interference that provide an occasion to establish a LREO. Based on the results, it becomes clear that the urgency to become independent of conventional energy corporations and energy exporting countries are variables derived from technological characteristics of renewable energy technologies that stimulate the emergence of an occasion. Finally, the potential symbolic benefits in terms of a green image and the enhancement of social cohesion within the local community are economical related attributes that foster the emergence of an occasion to establish a LREO. Remarkably four interviewees mentioned that the presence of market entry barriers as well as an unequal playing field was rather a motivation than a barrier for their establishment. The unwillingness of vested interest and national governments to reform the energy market has triggered their motivation. Furthermore, some interviewees also expressed that an absence of entry barriers and an unequal playing field did not form a motivation for their founding, which is reflected in the scores of hypotheses three and four. Similarly, the majority of the interviewees mentioned that their aim is to design a business model without relying on public support and therefore are not necessarily discouraged by inconsistent polices. On the other hand, some interviews mentioned that consistent policies would have contributed to realising larger projects and realising them more easily. However, the lack of consistent policies did not prevent the initiators from establishing their organisations. The same holds for bureaucratic procedures, most of the interviewees stated that they take these procedures for granted and therefore are not discouraged by them. A majority of the pioneering LREOs stated to focus on possibilities given the current constraints rather than being discouraged by market entry barriers, an unbalanced playing field, inconsistent policies and bureaucratic procedures. The empirical findings also fail to confirm that decreasing prices of renewable energy technology form a motivation for establishing LREOs. Despite lacking empirical evidence, the results insinuate a pattern between decreasing prices of solar panels on the one hand and the establishment of LREOs primarily oriented on solar technologies on the other. Additionally, none of the LREOs primarily focusing on other renewable sources mentioned decreasing technology prices as an important factor. Half of the LREOs primarily focusing on solar technology mentioned decreasing prices to be a favourable argument for their establishment.",
            "Factors affecting the local perception": " The empirical findings emphasise the crucial role of actors from the market and society in manipulating the local perception towards LREOs. A high level of social cohesion within the community, the availability of external expertise, other existing LREOs, suppliers and installers of renewable energy technologies and the absence of local opposition have a positive impact on the local perception. Moreover the empirical findings validate that in terms of technological characteristics visible technologies are found to have a positive effect on the local perception. Interviewees and respondents are divided on several factors anticipated to influence the local perception. While interviewees were relatively positive on the role of the government as a facilitator, this role was not acknowledged by the respondents and thus sufficient evidence to validate this hypothesis is lacking. Alternatively, interviewees and respondents also disagreed on the positive influence of the degree of social cohesion on the local perception; however, the relative high average score of the interviews provided enough leverage to alter the slightly indifferent score provided by the respondents, which led to the validation of this hypothesis.",
            "Factors affecting the local support and acceptance": " When considering the local support and acceptance, the empirical results confirm that organisational characteristics play a crucial role in establishing a LREO. More specifically, co-ownership of locals, non-constraining participation of locals, fair and equal distribution of potential benefits and the degree of social cohesion within the community positively determine the local support of LREOs. Moreover, based on the findings related to variables originating from the macro-context, it becomes clear that a high level of public environmental awareness positively affects the local support. When contemplating on the impact of actors from the market and civil sphere on the local support, the findings also validate that the absence of local opposition, engaging in a partnership or receiving support from an external party enhances the local support. In addition, the findings confirm that visibility and the possibility to provide feedback on the generated and consumed energy are technological attributes that improve the local support as well.",
            "Factors affecting the assessment of the applied renewable energy technology": " The final step in the founding process entails the assessment of the applied renewable energy technology. In regard to the technological attributes, the empirical findings validate that the reliability and visibility of an applied renewable technology positively determine the assessment. In terms of the economical characteristics, it is found that both the initial investment and the payback period have a profound impact on the assessment of the applied renewable energy technology. Only one interviewee mentioned that the possibility to provide feedback was considered during the assessment of the applied technology. The other twelve interviewees did not incorporated feedback opportunities in their assessment to establish which technology to apply. This consistency is reflected in a significantly low standard deviation and a marginal positive deviation in the average score. Despite the slightly positive outcome of the average score, the significant low standard deviation caused by the indifference of 12 interviewees, there was not enough empirical ground to validate this hypothesis.",
            "Discussion": " The rapid increase of LREOs in the Netherlands is a recent phenomenon. In this paper we made a first assessment of the factors that foster their emergence and development. Several remarks have to be made about the approach we have chosen. First, a suitable tailor-made model for studying LREOs was absent so it had to be constructed. Since the authors are familiar with the framework of Dieperink et al. (2004) this model was used as a starting point and adjusted after a literature review. However, we acknowledge that other models could have been used as a starting point as well. Other potentially suitable models are the multi-level perspective (MLP) conceptualised by Geels (2012) or the technological innovation systems model (TIS) which Dewald and Truffer (2012) applied in a study on the emerging German PV industry. It would be worthwhile to compare our approach with these two other approaches in order to find out whether the latter would result in other explanations for the emergence and development of LREOs (or not). Second, potentially relevant explanatory variables were sought in bodies of literature on the diffusion of innovations, microgeneration and community renewable energy. Other bodies of literature (for instance on organisation development) could have provided other explanatory variables. The majority of our interviewees did not suggest additional variables not yet included in the model, even though they were given the opportunity to do so. However, some mentioned that the founding process was influenced by the ability to design a sound business case. This factor could therefore be added in future research. Third, we only studied \"success stories\". For the robustness of the results it would have been better to compare our results with initiatives that failed to establish a LREO. We did reconsider this, but identifying such failures proved to be difficult. On the one hand it is hard to conclude whether an initiative has failed or not, while on the other hand examples of failed initiatives were not reported on the Internet or by the experts we consulted. Fourth, a total of 22 variables were found to positively affect one or more steps in the founding process. Although the average scores of these variables could indicate a hierarchy between them, we do not dare to say whether this is the case or not, as this was not explicitly asked in the face-to-face interviews or the survey. In addition to this we must admit that some of the identified independent variables might affect each other. The degree of environmental awareness could for instance depend on variables like the absence or presence of opposition, the visibility of renewable technologies or governmental interventions. Similarly, lower investments often result in a shorter payback period and the degree of social cohesion within a community is generally affected by the degree of local opposition. Our fifth remark concerns the external validity of our findings. We identified 132 LREOs, but focused on the ones founded by civilians. Consequently it should be emphasised that the results concerning the founding process of these 65 LREOs are not necessarily similar for LREOs established by private or public actors. However, the stimulating factors we have found could be relevant to explain the emergence and development of these LREOs too. Their potential relevance is also not restricted to the Netherlands. Haggett et al. (2013) for instance also suggest that economic factors, the degree of social cohesion, transfer of knowledge, governmental interference and organisational characteristics were key factors in the development of Scottish LREOs. They also checked whether deprivation levels mattered, a factor we overlooked and which could be included in our model. In this paper we have explored the emergence and development of LREOs in the Netherlands. Our research has resulted in an indicative list of explanatory factors. Future research is needed to improve the knowledge we have generated. Further research must clarify whether a distinction can be made between key and less relevant variables. Such a distinction could be relevant for civil society organisations or policy makers that want to further stimulate the development of LREOs. Future studies could also address the causal of the variables specified in the hypothesis. We have now for instance hypothesised that social cohesion is a cause of the development of LREOs, but it might of course also be an option that a growing social cohesion could result from such a development. Moreover, future research could also address the diffusion process as such as the founding process of LREOs will likely be fast-tracked as early successful establishments elsewhere became more common place and mimic-worthy. We have opted for a relatively large n-approach. Such an approach has its limitations, which could be compensated by more qualitative indepth case studies that may result in a more detailed insight into the factors we have found. Although our research has identified that Dutch LREO prefer to organise their activities through a cooperative model or a foundation, further in-depth research could for instance shed light on the organisational arrangement that fosters the development of LREOs the best. Future research Possibility to provide feedback on energy consumed and/or generated must also address the impact of LREOs. Haggett et al. (2013) found that so far community renewable energy accounts for less than one per cent (30 MW) of the total energy generated by renewables in Scotland, but it has the potential to expand up to six times in the near future. Allen et al. (2008), Bergman and Eyre (2011) and Watson et al. (2008) even stressed that community renewable energy has the potential to contribute to as much as 40 per cent of the national energy demand. Further research must clarify whether LREOs will really have an impact that high.",
            "Conclusion": " Our empirical analysis provided sufficient ground to validate the stimulating influence of 22 variables on the founding process of 26 Dutch LREOs. Table 7 summarises these factors. These insights into the emergence and development of LREOs could be useful for both policy makers and founders of LREOs. From a policy maker perspective it is useful to understand whether they are able to steer or stimulate the emergence and development of LREOs. When taking into account the factors that provide an incentive to establish a LREO, it is important to keep in mind that the emergence of an occasion depends on a combination of variables in which coincidence seems to be leading. However, policy makers might stimulate the emergence and development of LREOs through influencing the local perception and support by showing potential founders and communities that the concept is successfully applied elsewhere. In addition, policy makers can contribute by enabling the transfer of knowledge or facilitate contacts between potential founders of a LREO with other LREOs or experts. We found that some municipalities actually facilitated LREOs in sharing their experiences. In many cases policy makers only have to facilitate knowledge transfers instead of organising such transfers themselves. Governmental organisations such as AgentschapNL have for instance facilitated NGOs to organise large-scale events like HIER Opgewekt and P-NUTS Awards, at which participants could exchange their knowledge. While not explicitly demonstrated by the results, policy makers might also accelerate the number and size of the projects LREOs undertake through lowering bureaucratic burdens and providing a consistent policy framework. Many interviewees have mentioned that stable policy framework would reduce uncertainties and allow them to undertake long-term projects. Ironically, on the other hand the lack of consistent policies and the incompetence or unwillingness of the national government and vested interest have fuelled and amplified the motivation of civilians to establish a LREO. From the perspective of a LREO, organisational characteristics proved to play a key role, especially in terms of local support. Ensuring direct involvement of locals, fair and equal distribution of benefits and the possibility to become a co-owner of the organisation are vital factors that increase the support for LREOs. However, it should be emphasised that these organisational characteristics are not a magic bullet as local perception and support are for example, also affected by the visibility of the selected renewable technology, which if neglected often forms the origin of local opposition. Apart from the visibility, the investment costs also influence the assessment of the applied technology. However, poor economical performances are not necessarily detrimental to the establishment of LREOs since founders or communities might prioritise other interests before economical ones and are willing to accept higher investments costs and longer payback periods. The liberalisation of the energy market has resulted in a highly centralised market, which is dominated by a few actors. We do however support Schumacher's (1974) notion that globalisation and becoming bigger is not necessarily better. Taking current macro and political developments into account, we expect the growth of LREOs to continue. Acknowledging and empowering this decentralising movement is a good step forward to accelerate the share of renewables."
        }
    },
    "10.1016/j.techfore.2013.06.002": {
        "file_name": "151 The role of the complementary sector and its relationship with network formation and government policies in emerging sectors",
        "title": "The role of the complementary sector and its relationship with network formation and government policies in emerging sectors: The case of solar photovoltaics between 2001 and 2009",
        "abstract": "Understanding the role of government policies in promoting the introduction of renewable technologies can help to catalyze the transition toward a more sustainable energy system. The literature on technological transitions using a multi-level perspective suggests that the co-evolution of the niche market (the new technology) and the complementary regime may have an important role to play in shaping this transition. This paper provides a quantitative analysis of the interactions between different types of solar photovoltaic (PV) networks at the niche level, the complementary semiconductor sector at the complementary regime level, and the solar PV policies in 14 different countries. Using three equations for solar PV knowledge generation, manufacturing, and deployment, we investigate linkages between feed-in-tariff (FiT) and renewable portfolio standard (RPS) policies, network development, and the existence of a complementary sector. The empirical findings show that the complementary sector is an important determinant in solar PV deployment and manufacturing and network effects are dependent on the strength of the complementary sector in solar PV deployment and manufacturing. Feed-in-tariff and renewable portfolio standards are associated with solar PV diffusion and not with manufacturing. Finally, domestic government policies promoting renewable energy markets, which often lead to domestic electricity rate increases, have contributed to increased manufacturing capabilities internationally, including also in countries without a strong complementary sector, such as China, through the channel of manufacturing collaborations from countries with a strong complementary sector.",
        "label": "Quantitative",
        "text": {
            "Introduction": " Novel technologies for existing products such as electricity are constantly challenging existing designs, but only a few of them achieve widespread adoption. New technologies often have higher costs and risks than incumbent technologies and do not have an existing constituency and infrastructure [1][2][3]. However, niche applications or markets have been found to enable the introduction of new technologies even in cases in which there are powerful incumbents. Niche markets form a protected space in which a small group of actors can invest resources and efforts without having to compete directly with existing technologies [4,5]. Niche markets can contribute to technological change and cost reductions and can also give new technologies the opportunity to develop a better fit with existing technological regimes, which are the rule-sets of technological systems embedded in institutions and infrastructures, thereby reducing conflicts with existing (or dominant) technologies [6]. More importantly, niches offer opportunities for new technologies to build on and work with complementary sectors. We define a complementary sector as an existing industrial base with knowledge, capabilities, resources, and cost-benefit structures that are relevant to the new technology. Complementary sectors can help reduce risks and uncertainties associated with emerging technologies and accelerate the diffusion of new technologies by providing personnel, networks, information, and other resources. Recent work has suggested that the technology, capital, institutions, and skills needed to make newer products are \"more easily adapted from some products than from others\" [7]; in other words, that the probability that a country or region will start producing a new product depends on its existing production (also referred to as manufacturing) capacity base. At this point, we have questioned the role of complementary sector on development of relevant emerging sectors and its effect associated with the networking activities and government policies at the micro level. The effect of the complementary sector may not be consistent, but conditional upon the network formation and government policies. Energy technologies are of particular interest when exploring the cross-sectional interactions between complementary sectors and niches because to be widely diffused they need to compete with powerful and cheap incumbents, such as traditional power plants and fossil fuel vehicles. Renewable energy sources have a great potential to contribute to a de-carbonized society and are developing quickly, mostly at the niche market level, but they face many challenges as well [8]. All forms of renewable energy technology have low power densities and face the difficulty of entering an electricity market dominated by assets with long time-scales. Concentrating solar power is one example of a renewable energy technology that uses mirrors to concentrate sunlight for electricity generation and is a technology that is mostly considered for deployment in deserts, as there are high amounts of solar irradiation in the desert. However, this technology comes with another set of challenges as well, since the smarter grids and high voltage direct current lines (HVDC) that are needed to transmit electricity over long distances from deserts to urban areas, create additional technological and political risks [9,10]. Several recent studies have analyzed the introduction of new energy technologies using a multi-level perspective to address the development of niche space and its interactions with technological regimes that either generate or reduce these risks and uncertainties [11][12][13]. For example, van Bree et al. [13] analyzed transition pathways of alternative vehicles on the basis of the multi-level perspective. This type of qualitative analysis evaluates the impact of factors at the landscape, regime, and niche levels in the introduction of new technologies. Solar photovoltaic (PV) power is one of the important renewable energy technologies in terms of its potential to mitigate climate change, among other energy challenges [14]. While solar PV power is one of the fastest growing energy technologies, it is still not cost-competitive with fossil energy sources [15]. The solar PV manufacturing sector has two major characteristics. First, it has strong connections with the semiconductor industry dedicated to computer and other electronic applications in terms of its knowledge base, value chain, and cost-benefit structure. A solar cell is a device that converts sunlight to electricity. There is significant overlap in the fundamental technology for producing silicon wafers, cells, and modules between the solar PV and the semiconductor sectors [16]. Second, solar PV sector has distinctive segments along the value chain, by which we mean that that it is commonly used to carry out different parts of the processe.g., the production of the wafer, the etching of the solar cells, and the assembly into a panel. Because the solar PV manufacturing process can be separated into different steps and each step has different knowledge bases which are: chemical for the wafer, electronics for the solar cells, and construction for the installation, collaborations between entities active along different parts of the solar PV manufacturing value chain can reduce the risk for any individual actor. Some companies work to vertically integrate segments, but in order to accomplish this they need either to make strategic partnerships or to merge with relevant companies in some ways. Thus, collaborations would be one of the key innovation activities of the solar PV sector. In order to promote the development and deployment of solar PV technologies, governments in many countries throughout the world have relied on a variety of policy measures. Different policy instruments (e.g., feed-in-tariffs, renewable portfolio standards, auctions, government procurement contracts, property tax credits, corporate tax credits, sales tax credits, direct R&D investments, etc.) are put in place with different goals in mind and they each have a wide range of possible effects. Thus, the purpose of this paper is not to determine which one is the best for the renewable energy sector, as different policies would perform differently according to different criteria. Prior research has revealed, for example, that tax incentives, including property, sales, and corporate tax incentives, have been effective in promoting small-scale renewable energy development, but that they have not been a primary driver of the development of the sector more broadly [17]. In this paper we focus on two principal renewable energy policies that have been established in a vast number of countries: feedin-tariffs (FiTs) and renewable portfolio standards (RPSs) [8]. They have been shown to have had a significant impact on renewable energy deployment when compared to other policy options [18,19]. FiT and RPS as market pull policies may be because particularly important in the solar PV sector where market has just been created. These policy measures have spurred the deployment of solar PV technologies in the countries where the policy is in place. The impact of two policies on the production of knowledge (e.g., patents) and on the development of manufacturing capacity, however, has not been so well documented. In particular, the extent to which the impact of these policies is associated with complementary sectors and comparison of its impact on diffusion, knowledge, and manufacturing outputs has not been investigated in a systematic manner. This study examines the role of interactions between the development of the solar PV niche space and the existing complementary sector of the solar PV, and the impact of FITs and RPSs on the evolution of the solar PV sector with a focus on the initial stage of the solar PV where risks and uncertainties are mitigated by niche space and government policies. As previous research has examined, the formation of networks is one of the core processes underpinning the growth of niche markets [4,6,20]. The existence of complementary sectors has also been identified as an important body interacting with niches, but research in this area has relied on qualitative case studies including combined heat and power and energy utility sectors [11,21,22] and its interaction with network formation as a proxy for niche has not been discussed so far. The focus of the paper is not whether or not promoting solar PV is a good thing, but rather to evaluate the extent to which the complementary sector and its interaction with network formation and the two policies may have contributed to meeting three goals that policy makers may care about, namely encouraging deployment, manufacturing, and/or knowledge creation. Solar PV technology was chosen for this analysis not because we deem it to be a silver bullet to address the world's energy challenges, but rather because it has an obvious complementary sectorthe semiconductor industryand because its network involving various solar PV segments has been growing at the niche level. This study relies on data gathered from 2001 to 2009 across 14 countries to provide quantitative evidence for interactions between solar PV networks at the niche level, the complementary semiconductor sector at the regime level, and the solar PV policies. It evaluates cumulative solar PV installation, solar PV cell production, and the number of solar PV patents (used as a proxy for knowledge generation) as a function of domestic PV module price, domestic public R&D investments on solar PV, coal and polysilicon prices, global PV installation, FiT or RPS policies, the number of collaborations between different actors in a country's solar PV sector, and the size of the complementary semiconductor sector in that country. The paper is structuralized as follows. Section 2 summarizes the literature on the introduction of new technologies and, in particular, the role of niche markets. Section 3 describes the econometric models and the data sources. Section 4 presents the results from the quantitative analysis, and Section 5 interprets these results. Finally, Section 6 summarizes the key conclusions of this study.",
            "Literature review": " Over time, technologies that are widely dominant develop internal forces that enable them to keep their coherence and stability. These forces can range from supporting institutions, to political constituencies, to complementary technologies and make it difficult for new technologies to enter the mainstream in what is referred to as the lock-in effect [23,2]. In spite of these barriers, there are many historical examples of new technologies replacing established technologies, such as cars replacing horses for transportation, and coal replacing wood for heating [24]. Understanding the processes underpinning the introduction of new technologies for existing uses has become an increasingly important area of research, particularly in the context of the need to transform much of the world's energy system to rely on low-carbon energy sources. The concept of the multi-level perspective (MLP) [5] has been used to explain the process of technological transitions. It provides a comprehensive framework to analyze the introduction of new technologies at the macro-, meso-, and micro-levels, which are also referred to as the socio-technical landscape, technological regime, and niche levels, respectively. At the niche level, new ideas and inventions are created by either individuals or small groups. Niches are important because they provide space to enable technology improvements, and to develop supporting institutions and constituencies. The interaction of different actors and knowledge bases results in the creation of rules, markets, and cultures relevant to the new technology [25,4]. The literature shows that the landscape level can put pressure on the current technological regimes to accelerate the introduction of technologies at the niche levels. For example, increased consensus about the dangers of climate change has influenced the ways in which some people live and consume and also has shaped government policies at the regional, national, and international levels [26]. The concept of the MLP implies that the co-evolution between the technological regime and the niche is a major driver in technological transitions. Co-evolution takes place between the dominant regime and niche in the transition process [5]. Current dominant regimes have adopted some ideas generated in the niche level to improve their technological systems. Niche has also made attempts to fit into the dominant design underlying the current dominant regimes with either the competition or cooperative activities. Other relevant literature highlights the multi-regime interactions. Raven and Verbong [11] and Konrad et al. [21] discussed the interactions between different technological regimes in the energy sector. Raven and Verbong [11] examined a case study on combined heat and power technology in the Netherlands revealing that interactions between the electricity and gas technological regimes are important to understand the introduction of combined heat and power systems. Actors from the gas technological regime were initially opposed to the diffusion of combined heat and power, which was supported by actors from the electricity regime. Cooperation between actors in both the gas and electricity regimes increased after the oil crisis of the 1970s has changed government policies and a government committee was created to promote the introduction of energysaving technologies. Based on the case analysis, Raven and Verbong distinguished four types of multi-regime integration: competition, symbiosis (complementarity), integration, and spillovers. Markard and Truffer [22] noticed the complementary sectors (systems) that weakened the prevailing regimes with niches and other regimes. Complementary interactions, to some degree, have been shown to foster interactive learning and knowledge spillovers [27,7]. Boschma and Iammarino [27] examined that complementary existing sector within regions and across inter-regions contributed to regional economic growth using the Italian case. Other work using a case study on car manufacturing has examined regional knowledge and assets to complement with global car manufacturing value chain so that complementary assets become important in choosing local production sites [28]. Transition activities are not accomplished by a single actor, but by a set of actors making micro-and macro-level adjustments [29,30,22,31]. Research on technology transitions has emphasized the multi-regime interactions with a focus on the interactions between the niche and the complementary sector that stimulate the transition process, but little empirical analysis provides insights about how these interactions can be encouraged [32,31]. Research on understanding the mechanisms and processes that can overcome the lock-in of dominant technologies has also received insufficient attention in the literature. More research in this area would improve our understanding of the strategies that actors can use to catalyze a transition to new technologies [22,31]. However, nearly a decade after the introduction of the MLP, very few studies have undertaken any quantitative research in this area [31]. A quantitative analysis requires methods for measuring the concepts of niches and existing technological regimes to formalize the analytical frame. The formation of networks is one of the core processes in niche development [33,4,6]. The building blocks of innovation systems are often considered to be key components for emerging sectors and networks incorporating key building blocks would be the precursor to emerging sectors in the early stage. For example, Choi et al. [20] showed that, in the case of the hydrogen sector, knowledge networks established from the embryonic period embedded key building blocks of innovation systems. Different organizations have diverse reasons for cooperating in the emerging stage. First, organizations may want to reduce their risk of entering the market with a new technology by forming collaborations [34,35]. Second, in sectors characterized by high risks in technological complexity and technology convergence, organizations are more likely to require additional knowledge and/or resources [36,37]. And third, networks can serve to articulate social expectations and visions by reflecting multiple voices [38,39], therefore building support for a new technology. In the case of the solar PV sector, the creation of networks is likely to be particularly important. The reason for this is that the solar PV sector is divided into wafer, solar cell and panels, and construction stages along the value chain and that in many cases firms have opted to partner with other firms. Previous studies have examined complementary relations between existing regimes and knowledge, but to the best of our knowledge, no study has evaluated the interactions between the complementary sector and the niche and its impact on the transition process. In addition, there is no study on the combined effects of the formation of networks and the existence of a complementary sector. The solar PV characterized by strong relatedness with a semiconductor industry provides a good case to evaluate the relationship among niche, a complementary sector, and government PV policies, which have been found to facilitate the transition of a technology from a niche market to a new technological regime.",
            "Methodology": "",
            "Models": " To examine the role of government policy and the interplay between the formation of solar PV networks and the existing complementary sector in the solar PV sector, we established equations for the diffusion (or deployment) of solar PV panels, the production (or manufacturing) of solar cells, and the solar PV knowledge generation. The diffusion equation was based on the assumption that the objective of solar PV installers is to maximize the present value of the benefits of electricity production. The diffusion equation relied on the model developed by S\u00f6derholm and Klaassen [40] and is as follows: lnCC \u00bc a 0 \u00fe a 1 lnC \u00fe a 2 ln Q \u00fe a 3 ln P c \u00fe a 4 ln Network \u00fea 5 ln CD \u00fe a 6 ln Global \u00fe a 7 ln FiT \u00fe a 8 ln RPS \u00fea 9 ln CD \u00c2 ln Network \u00fe a 10 ln CD \u00c2 ln FiT \u00fea 11 ln CD \u00c2 ln RPS \u00fe \u03b7 \u00fe \u03b5 where CC is cumulative solar PV capacity in MW, C is PV system cost in $/W, Q is domestic solar cell production in MW, P c is the local coal price in $/ton, Network is the number of collaborations by entities in each country (including collaborations between an entity in one country with an entity in another country), CD is the sum of revenues of the top 20 worldwide semiconductor companies in each country for the complementary sector, Global is worldwide annual solar PV installation in MW, FiT is the solar PV feed-in-tariff divided by the average retail electricity price in a country, RPS is a dummy variable to denote the existence of a renewable portfolio standard portfolio in a particular country, and \u03b7 is a country dummy capturing those characteristics relevant to the solar PV competitiveness in a particular country or countries, such as the level of solar irradiation in Germany, Spain, and the United Kingdom as S\u00f6derholm and Klaassen did [40]. We chose an absolute indicator to measure the size of the complementary sector instead of the market share of the semiconductor sector referring to a relative one since it needs to take chronological variations into account as the semiconductor sectors grow constantly. Given that a key objective of this work is to investigate the interplays between government policies, complementary sectors, and the formation of networks, the model also includes several interaction terms. Similarly, we use the following production equation to express the factors that manufacturing firms in a country may consider maximizing profits from the manufacturing of solar PV cells: ln Q \u00bc b 0 \u00fe b 1 ln KG \u00fe b 2 ln C \u00fe b 3 ln CD \u00fe b 4 ln Network \u00feb 5 ln P s \u00fe b 6 ln FiT \u00fe b 7 ln RPS \u00fe b 8 ln CD \u00c2 ln Network \u00fe b 9 ln CD \u00c2 ln FiT \u00fe b 10 ln CD \u00c2 ln RPS \u00fe \u03b7 \u00fe \u03b5 where knowledge generation (KG) is the number of solar PV patents with at least one assignee from a particular country applied to the European Patent Office (EPO) in a year, and P s is the world silicon price in $/ton. The formal model of knowledge generation has been discussed by Griliches [41]. We extend the model used by Griliches, which is a Cobb-Douglas function KG = R \u03b3 KS \u03c6 in which knowledge generation is represented as a function of knowledge spillover (KS) and R&D input (R) as follows: ln KS \u00bc c 0 \u00fe c 1 ln Q \u00fe c 2 ln R & D \u00fe c 3 ln Network \u00fe c 4 ln CD \u00fec 5 ln FiT \u00fe c 6 ln RPS \u00fe c 7 ln CD \u00c2 ln Network \u00fec 8 ln CD \u00c2 ln FiT \u00fe c 9 ln CD \u00c2 ln RPS \u00fe \u03b7 \u00fe \u03b5 where R&D is measured by the public solar R&D budget in each country in 1000$. We tested three types of models: Model 1 was the simplest model and it excluded all interaction terms; Model 2 included the interaction terms between the complementary sector and network variables and between the complementary sector and the FiT and RPS policies; and Model 3 was an extension of Model 2 using a more detailed breakdown of the type of networks (i.e., R&D, manufacturing, and diffusion). For the manufacturing and diffusion-oriented collaborations, we only counted the collaboration contracts that contributed to increases in production and deployment within countries' own territory.",
            "Statistical issues": " To estimate coefficients of three equations, several statistical issues need to be addressed. First, it is important to consider that in many cases there may be a timelag between the independent variable and the dependent variable. For example, solar PV developers may make investment decisions about a new solar PV plant at least a year before the plant is constructed, which means that they will take into account price factors from the year before the plant starts operating. In addition, it is unlikely that manufacturing can be affected by patents filed in the same year. In this context, Popp's [42] work revealed that the appropriate time-lag between patent application and its effect on energy consumption was 3 years. Based on this study, we assume a 2 year time-lag between patent application and PV cell production, if we estimate that it usually takes one year to construct a solar PV plant. We adopt a 1 year time-lag for the price (coal, PV cell, and silicon) and network independent variables. Second, each model is likely to exhibit an autocorrelation, as some of the countries in our sample were in solar PV development trajectories that started before our first year of observation (2001) and that have evolved over time in coherent ways. This autocorrelation could result in autocorrelated errors and biased coefficients. One of the easiest ways to prevent this bias is to include a lagged dependent variable at the left-hand-side of the equations. Prior to adding the lagged dependent variable, however, it is necessary to identify whether the three equations display an autocorrelation. For non-panel data the existence of an auto-correlation is typically examined using the Durbin-Watson (DW) test. To evaluate the existence of auto-correlation in panel data, which is the type of data used in this study, we use Wooldridge's [43] a test for auto-correlation in panel data. We found strong autocorrelation effects in all three equations and therefore we have included first-order (1-year) autocorrelation variables. Third, solar PV cumulative capacity (diffusion), solar cell production (manufacturing), and patent applications (knowledge generation) are likely to be endogenous variables because they appear on both sides of the equations. We applied the Durbin-Wu-Hausman test to check the endogeneity of each model [44][45][46]. Domestic solar PV manufacturing was found to be an endogenous variable in the diffusion equation for all three Model types, 1, 2, and 3 and one in the knowledge generation equation was an exogenous variable except for the Model 3. We also found that solar PV patent applications were exogenous in the production equation for all three models. We find that domestic manufacturing associated with solar PV diffusion is dependent on many variables, including the existence of a strong complementary sector and the formation of networks and it causes endogeneity in the diffusion equation. However, we did not find endogeneity between solar PV knowledge generation and manufacturing. This may be the case because knowledge generation and manufacturing activities can be independent of each other, with knowledge generation being subject to quick international spillovers. As a result of these endogeneity tests, we applied feasible generalized least square models for exogenous variables and three stage least square models for endogenous variables. It is important to note that, even though we tested and tried to control for the endogeneity between solar PV diffusion, manufacturing, and knowledge generation, we did not account for possible endogeneities between solar PV prices and manufacturing and solar PV prices and diffusion. We are assuming that government policy, and not costs, was driving solar PV diffusion within a given country and solar PV manufacturing across the board [47]. However, this is an assumption that future work could try to improve upon. Fourth, we found that the residual terms in our models were heteroskedastic in LT tests, and used robust standard errors in our regression to account for that. In summary, dependent variables were modeled as follows: y i;t \u00bc \u03b1 i \u00fe \u03b3y i;t\u22121 \u00fe \u2211 J j\u00bc1 \u03b2 j x i;t\u22121;j \u00fe \u03b2 J\u00fe1 x i;t\u22122;J\u00fe1 \u00fe \u03b5 i;t where \u03b1 i is the effect of country i, \u03b2 j is the slope for x j , (note that x j represents the independent variables), and \u03b3 is the autocorrelation coefficient. As previously discussed, we included a time-lag t-2 for the knowledge generation variable and a time-lag of t \u2212 1 for the rest of independent variables, including prices and networks. We estimated coefficients of this linear panel model using feasible generalized least squares and three-stage least squares models.",
            "Data and variables": " Our dataset includes data gathered over 9 years, from 2001 to 2009, across 14 countries, which are Australia, Austria, Canada, China, France, Germany, Italy, Japan, Korea, the Netherlands, Spain, Switzerland, the United Kingdom, and the United States. We collected the most recent data as of early 2012, but the range of data available for the analysis ended in 2009 since patent applications measured as a proxy for knowledge generation were not available after 2009. In general, patent applications take some time to become open to the public, which is why 2009 was the latest data that we were able to collect for patents. The dataset is not a fully-balanced panel, since some data are not available. China data is incomplete so therefore we have excluded China data in Models 1-3. Instead, 14 countries including China case were dealt in Model 4 in Section 4.3. All price variables are expressed in year 2005 U.S. dollars using OECD currency exchange rates and deflator data. Table 1 shows the countries and time period covered in the dataset.",
            "Dependent variables": " The three dependent variables in this study were cumulatively installed solar PV capacity by country, solar PV production by country, and the number of solar PV patents with at least one assignee from the particular country per year. Cumulative PV installation captured the degree of diffusion of solar PV technologies for each country. Annual solar cell production measured domestic manufacturing activities in the solar PV sector in each country. The number of solar PV patent applications was used as a proxy for knowledge generation. In spite of some of its drawbacks, which include the fact that not all patents are commercialized or equally valuable, patents have often been used as a measure of knowledge generation [48,49]. We collected solar PV installation and production data from the Photovoltaic Power System Programme of the International Energy Agency (IEA) (http://www.iea-pvps.org/). Records from the European Patent Office (EPO) were sourced from the Korea Intellectual Property Rights Information Service database (http://eng.kipris.or.kr/eng/main/main_eng.jsp) using a set of International Patent Classification (IPC) codes for solar PV technologies presented in the IPC Green Inventory (http:// www.wipo.int/classifications/ipc/en/est/). We chose to represent the knowledge generation variable using patent data from the EPO as opposed to the U.S. Patent Office (USPTO), for example, because Europe is the biggest market for solar PV panels and because a large number of solar PV company headquarters. Nearly three-quarters of the global PV installations are located in European countries [15].",
            "Independent variables": " The objective of this study was to assess the relationship between a range of independent variables on technology diffusion, production, and knowledge generation in the solar PV sector. As discussed in Section 3.1, we included variables to control for the impact of solar PV system price, public solar R&D investments, government policies (FiTs and RPSs), coal and polysilicon prices, and network and complementary regime indicators. We also included interaction terms to understand the impact of (for instance) the size of a complementary sector in cases in which there is also a FiT. Local solar PV system prices, global PV installation, and public solar R&D investments were obtained from the IEA Photovoltaic Power Systems Programme. When data were missing, we sourced data from official government documents. PV system prices for a roof-top sized one were gauged. It included not only the price of solar PV panels, but also the balance of system costs (e.g., inverters and other electronic equipment) and installation costs. The FiT variable was expressed as the ratio between the FiT and the retail electricity price in each country. It represented the extent to which a price premium was paid to stimulate solar capacity in different countries. It is important to acknowledge that to represent more accurately profit-making opportunities for solar PV developers we should have included one variable representing the difference between the solar PV FiT and the cost of electricity from solar PV sources (in $/kWh) in each country over time. Given that the cost of PV electricity by country over time is not available, we use the ratio between the FiT and the retail price. FiT data were sourced from the IEA Photovoltaic Power Systems Programme and retail electricity prices were collected from the IEA database. The existence of an RPS regulation in a country was represented as a dummy variable taking a value of 1 in a country-year with an RPS policy in place and policy data were supplemented from IEA Policies and Measurement Database. Global polysilicon prices were gathered from the Bloomberg Database. Local coal prices were sourced from the IEA Coal Information [50]. The sum of inter-organizational collaborations with at least one partner from a particular country in a particular year was calculated to represent the degree of network development in each country over time. Collaboration data was obtained by collecting news articles covering topics in the area of solar cells in the FACTIVA database, which includes Dow Jones and Reuters. To identify articles in the area of solar cells we conducted searches using the keywords \"photovoltaic\" and \"solar cell.\" The collaborations were also classified as R&D, manufacturing, and deployment collaborations, depending on their stated purpose. The objective of this classification was to determine whether the results were sensitive to treating all collaborations equally or to differentiating them by purpose. The majority of the articles did not provide information about the duration of the collaborations therefore we conducted analysis of the average duration of the collaborations for those news articles that contained that information. We found that collaborations ranged from a minimum of 2 years to a maximum of 4 to 5 years, which led us to assume a duration of 3 years throughout. To measure the degree of development of the complementary semiconductor sector in each country, we analyzed the sum of revenue of the top 20 worldwide semiconductor companies in each year. We computed the revenue (in million 2005$) from those top 20 manufacturers that corresponded to semiconductors produced in each of the 14 countries under investigation for each year. We selected the top 20 manufacturers because companies out of the top 20 had less than 1.5% market share and their market data were not available. Semiconductor manufacturer revenue data were collected from the IHS iSuppli database (http://www.isuppli.com). The final sample consists of a panel of 13 countries over 9 years, or 104 observations, excluding China data. It is important to note that for some variables there are less or more datapoints for two reasons: in some cases data were not available, and in others the use of a timelag increased the number of entries. Summary statistics are presented in Table 2.",
            "Data visualization": " Fig. 1a, b, c, and d displays installed PV capacity, solar PV manufacturing, solar PV patents, and network development, respectively. Fig. 1a shows the large scale in the deployment of solar PV panels that Germany (which reached a capacity of 9956 MW in 2009) and, few years later, Spain experienced between 2000 and 2009. Fig. 1b indicates China, and Japan have been the top manufacturers globally during the period under consideration. Fig. 1c shows the evolution of the solar PV knowledge generation by country using EPO patents as a proxy. Germany, and the United States are leading countries in this metric. Fig . shows the total number of solar PV collaborations active in a particular year in a particular country, assuming that all collaborations last for 3 years. It can be seen that the United States, China and Germany are leading in terms of the number of collaborations. As expected, all four metrics increased over time. Fig. 2 shows the evolution of global PV networks between 2005 and 2008. This visualization shows that the period under consideration was one of large network activities. Fig. 2 only displays the main component of the network, i.e., the largest cluster, to enhance readability. In 2005, few actors were involved in solar PV networks, and the networks were relatively simple. By 2008 not only was the network larger, but interconnections were more complicated.",
            "Results": "",
            "Models with and without interaction effects and with an aggregated network metric": " Table 3 shows the results of the models discussed in Section 3.1 using feasible generalized least squares and threestage least squares models. Model 1 does not include interaction terms while Model 2 does. Both Models include an aggregated network metric. For each Model we show a column with the results from the diffusion, knowledge generation, and production equations. All models included country fixed effects even though we do not report them to improve readability. We first discuss the results of the diffusion regression. The solar PV price variable is negative and statistically significant. This is to be expected, given that lower prices increase project developer's incentives to install solar PV. The global PV installation variable is positive but not statistically significant. It is meant to capture the possibility that when a technology becomes more widespread globally there may be an increase in the pressure to use renewable energy sources at the landscape level [6,26]. The complementary sector variable is a statisticallysignificant and positive factor in the diffusion and production equations in all Models (including Models 1 and 2). This implies that countries with strong complementary sectoral domains may be better positioned to deploy and manufacture solar PV panels. The positive sign of the coal price coefficient indicates that increases in coal prices are associated with investments in new solar PV electricity plants. However, this coefficient is not significant. The FiT variable is statistically significant and has a positive impact on PV diffusion in Model 1, but not in Model 2, which includes the interaction effects. RPS is not statistically significant in the diffusion equation in Models 1 and 2. Results from Mitchell et al. [51] explained that FiT was more effective than RPS in increases of deployment of renewable energy since it reduced risks associated in new energy sources. Johnstone et al. [52] also indicated that utility companies were likely to adopt other renewable options rather than solar PV under RPS system since the cost for solar PV was relatively higher than others. Model 2 shows that interaction terms are not significant in the diffusion equation. We now turn to discussing the results of the knowledge generation regression. PV cell production is a positive and statistically significant factor in Models 1 and 2. The complementary sector and network variables are positive in Models 1 and 2, but only network is statistically significant in Model 1, which excludes the interaction terms. The FiT  and RPS coefficients were not statistically significant in the knowledge generation equation. Public R&D in solar PV are positive, but not statistically significant. Unfortunately data on private sector solar R&D investments are not available to test whether there is an association between increases in knowledge generation and private sector R&D investments. Regarding the production results, solar PV price decreases are associated with increases in production. PV prices are statistically significant in Models 1 and 2. One explanation for this could be that if solar PV costs decrease more rapidly than FiTs, the profit-making opportunities of project developers may increase, resulting in an increased demand for solar PV modules, thereby resulting to increases in production. The   in both Models 1 and 2, but statistically not significant. The global PV installation variable is positive and statistically significant. Our hypothesis that a complementary sector has a positive impact on production is supported by the results presented in Table 3. However, our hypothesis regarding the role of the formation of networks on solar cell production was not confirmed by the results shown in Models 1 and 2. One reason for this could be that the network effect of actors within a country is related to their experience in a complementary sector. For example, while collaborations among solar PV installers may help to promote diffusion (and may not depend much on the existence of a semiconductors sector), they may, at the same time, not contribute anything to production. As a result, the single network variable combining R&D, manufacturing, and deployment collaborations used in Models 1 and 2 may not be a good measure. Model 3 (in Table 4) addresses this shortcoming. The coefficient of the interaction term between the complementary sector and the network variable is positive and statistically significant, indicating that specific networks encourage manufacturing in countries that have a strong complementary sector. Also in the production regression, the signs of FiT and RPS variables in Models 1 and 2 are mixed and not statistically suggest that these policies are not associated with increases in manufacturing activities. These results indicate that PV installers are generally not committed to purchasing domestic PV panels. Unless there are policies with local content requirements or local panels are cheaper, it is reasonable to expect project developers to purchase solar panels in the global market.",
            "Model with interaction effects and with a disaggregated network metric": " To account for the fact that there are different types of networks, Model 3 classifies the network variable into three types of collaborations: R&D collaborations, diffusion collaborations, and manufacturing collaborations. Table 4 shows the parameter estimates for Model 3. We first note that the signs and statistical significance of the common coefficients in Models 2 and 3 are almost identical. There is only one difference worth noting. In the knowledge generation equation, the FiT variable is positive in Models 2 and 3, but only statistically significant in Model 3. It implies that risk associated with the solar PV investment has been reduced through FiT and it has a positive influence on knowledge generation in the solar PV sector as identified in Johnstone et al. [52]. We now turn to discussing the impact of R&D and diffusion collaborations (or networks) on the development of the solar PV sector. The R&D collaboration variable is positive and statistically significant in the diffusion equation and negative and statistically significant in the production equation. It is possible that countries without a strong complementary sector are using R&D collaborations for solar PV diffusion but are not, at least so far, succeeding in turning those collaborations into a solid solar PV manufacturing industry. Indeed, even though the R&D collaboration variable is negative and statistically significant in the production equation, the interaction term between R&D collaborations and complementary domain is positive and statistically significant. Looking back to Model 2, negative network effects on production activities seem to originate, at least to some extent, from the effects of R&D oriented collaborations of countries with the weak complementary sector. Table 4 shows that diffusion collaborations have positive but not statistically significant effects on diffusion and negative but not statistically significant effects on production. We observe a significant positive effect of diffusion collaborations in countries with a complementary sector on solar PV diffusion. These results are not surprising, but anticipated.",
            "Model with interaction effects, with a disaggregated network metric, and with China": " China was not one of the countries included in Models 1 to 3 because of the scarcity of information on China in some of the variables used in this analysis. In particular, data on solar R&D investments and PV system prices was not available, and data on PV installation and production was not available from the IEA database that was used to get information for the other countries. However, given that China is one of the key global players in the solar PV sector, we decided to test the robustness of our Model 3 estimates using Model 4, which has the same specification as Model 3, but includes the best data we could get for China. The results are presented in Table 5. To obtain the Model 4 estimates we collected data on Chinese cumulative installation capacity and solar cell production data from the Earth Policy Institute (http:// www.earth-policy.org/data_center/C23). We assumed that PV system prices and solar public R&D investments in China were equal to the average values for our dataset. We also performed endogeneity tests and found exogenous variables in diffusion and production equations and an endogenous variable in a knowledge generation equation. The production variable in the diffusion equation, which was endogenous in Models 1 to 3, became exogenous when the Chinese data was included. This could stem from the fact that China has a unique industrial structure with a large manufacturing \u204e\u204e Indicates significant level 5%. \u204e\u204e\u204e Indicates significant level 1%. We also tested the US solar investment tax credit as including a dummy variable in Model 3. We find that there are no changes in the results. capacity in the solar PV sector that makes the production variable in the diffusion equation independent. Table 5 indicates that the signs of coefficients of statistically significant variables in Models 3 and 4 are identical except for the interaction variable between complementary sector and manufacturing collaborations in the production equation. This interaction variable becomes negative and statistically significant. It is in contrast with the positive and statistically not significant coefficient as Model 4 adds the China case which has weak semiconductor sector, but shows high manufacturing activities. The sign of another interaction variable between complementary sector and manufacturing collaborations in the diffusion equation is not changed, but it becomes significant in Model 4. We find some other differences between two models in terms of the statistical significance of some of the variables. First, in Model 4 the diffusion collaboration variable in the diffusion equation becomes statistically significant (it was insignificant in Model 3). Second, the manufacturing collaboration variable becomes statistically significant in the diffusion and production equations in Model 4. Overall, manufacturing relevant variables have shown different results after the China data are added. It may be affected by the strong position of Chinese manufacturing in the solar PV sector and needs to be further discussed in the next section.",
            "Discussion": " We find evidence supporting the hypothesis that a strong complementary sector is important for the development of a solar PV sector. In general, the complementary sector has a positive impact on the degree of solar PV manufacturing and diffusion. Moreover, in Model 4, the coefficient of the complementary sector is positive and statistically significant even in knowledge generation. It implies that the complementary sector has a broader impact on diffusion, manufacturing, and knowledge generation than any other factors such as FiT and RPS and three types of collaborations. However, what is more interesting is that the role of network development on solar PV manufacturing and diffusion seems to be dependent on the strength of the complementary sector. Our findings support three arguments. First, in the solar PV sector landscape pressures (which we represented by global solar PV installed capacity) and the existence of a complementary sector (i.e., an active semiconductor industry) are associated with increases in the manufacturing and installation of solar panels at a country level. The complementary sector contributes to the growth of the solar PV sector by providing knowledge, resources, and networks that are initially not present at the niche level. Second, we find that the effect of network development at the niche level depends on the strength of the complementary sector. In Model 2, we can see a positive and statistically significant coefficient for the interaction term between complementary sector and the network variables. In contrast, the network variable, by itself is negative and statistically significant. Disaggregating the network variable into three different types of collaborations (R&D, manufacturing, and diffusion) in Models 3 and 4 allowed us to identify two mechanisms that are occurring simultaneously. (a) R&D collaborations are associated with either manufacturing competitiveness or product diffusion depending on the strength of the complementary sector. In general, countries with a strong complementary sector develop R&D ties to encourage technological advances to maintain manufacturing competitiveness. The interaction term between R&D collaborations and the strength of a complementary sector appears only has a positive impact on manufacturing (see Models 3 and 4). The impact of R&D collaborations in countries without a strong complementary sector, in contrast, seems to be an increase in PV deployment rather than an increase in knowledge generation and manufacturing. (b) Manufacturing collaborations associated with increases both in solar cell production and in solar PV deployment in Model 4. This indicates that manufacturing collaborations have generally played a role not only in accelerating manufacturing activities, but also in extending business networks for solar PV installations. However, manufacturing collaborations are not associated with increases in solar PV diffusion and manufacturing in strong complementary sector. In fact, the result is just the opposite: there appears to be an inverse relationship between the number of manufacturing collaborations and diffusion and manufacturing in countries with a strong complementary sector. This may imply that countries with weak complementary sectors are utilizing manufacturing collaborations to improve manufacturing capability while countries under the strong complementary sector fail to gain additional manufacturing competitiveness through manufacturing collaborations. These results yield some insights on who benefits most from domestic government deployment policies for renewable energy sources. A strong PV deployment policy, implemented by countries such as Germany, Italy, and Spain, contributes to the boom in the overall solar PV manufacturing. Countries with a strong complementary sector experience increases in solar PV manufacturing associated with a global demand on PV panels, but not every country with a strong complementary sector contributes to the global solar PV boom through the creation of PV deployment policies. Indeed, some countries without the RPS and FiT policies have seen increases in domestic PV manufacturing and some countries with RPS and FiT policies (particularly those with weak complementary sectors) are importing solar PV panels from Japan, Germany, the US, and China. Countries with weak complementary sectors, particularly China, also have a chance to benefit from the deployment policies in other countries through manufacturing collaborations. The result of the interaction term between a complementary sector and manufacturing collaborations in Model 4 supports this argument. Manufacturing collaborations have surged as major countries have established FiT and RPS policies. The fact that most of the partner countries in the manufacturing collaborations of entities from countries with a weak complementary sector are entities from countries with a strong complementary sector, coupled with the fact that many of the countries with a weak complementary sector are major beneficiaries of manufacturing collaborations in terms of increased manufacturing, suggests the possibility that manufacturing collaborations could be a channel for technology transfer from countries with a strong complementary sector to countries with a weak complementary sector. In other words, consumers' money in countries with strong deployment policies has helped accelerate technology transfer from countries with a strong complementary sector to China. It is an unintended policy effect because the policy benefits in terms of a growth in manufacturing do not necessarily accrue to countries implementing the policies, but also to manufacturers in other countries, most importantly in China [53]. The fact that manufacturing collaborations could help countries with a weak complementary sector to learn relevant technology also explains how competitive advantage generated from the complementary sector has been eroded. It may be one reason that the market share for both Japan and the US in solar PV has declined. It is worth noting that the goal of this study was to determine the factors that are associated with increases in knowledge creation, manufacturing, and deployment in the solar PV sector during the stage of early growth of the PV industry. Future work should focus on the post-2009 phase, which was dominated by international trade. These interactive patterns are apparent in the breakdown of the types of networks and the strength of complementary sector existing in a subset of the countries investigated. Table 6 presents the network breakdown, the complementary sector, and the diffusion and manufacturing outcomes for major countries. It highlights that countries backed by the strong complementary sector, such as Japan, have a larger number of R&D collaborations (52) when compared to diffusion collaborations (1) and manufacturing collaborations (11) and exhibit high production capabilities. On the other hand, countries with a weak complementary sector tend to have denser diffusion networks and are less likely to be involved in significant manufacturing. For example, in 2008 Spain had a large number of diffusion collaborations (24). Spain has experienced a booming driven by a generous FiT policy, but little manufacturing activity. China also showed active collaborations in the diffusion part, but relatively active manufacturing alliances differing from other countries with the weak complementary sector. As a result, China is likely to have improved its manufacturing capabilities by forming manufacturing collaborations. Third, FiT or RPS government policies are not a silver bullet. We find that FiT policies are generally effective in stimulating solar PV diffusion and knowledge generation but not manufacturing. At the same time, the interacting policy options and the complementary sector are not significant in any of the models. At the same time, the variables interacting policy options and the complementary sector are not significant in any models. This is not surprising, given that they subsidize (or promote) diffusion directly, but some of the rhetoric used to justify these policies sometimes conflates the goals of achieving low carbon electricity to create a flourishing solar industry that includes domestic manufacturing. This result rather reinforces the possibility of the unintended policy effects that the government money spent for the market promotion by advanced countries mostly contributes to manufacturing activities of Chinese firms through their manufacturing collaborations as mentioned earlier. Additionally, the inclusion of the solar investment tax credit (ITC) did not change the results. The ITC policy in the US does not seem to be associated with addition deployment or diffusion in the United States. It is also worth noting that the FiT variable included in our regressions did not accurately represent the profit making drivers facing solar PV manufacturers. Future work should try to evaluate the difference between solar FiTs and solar PV manufacturing costs in each country, should the latter information become widely available.",
            "Conclusion": " Interactions between a niche market and a complementary sector are a key component of technological transitions, in particular in the alternative energy technologies. Theoretical frameworks and case studies provide some insights for the hypothesis that complementary sectors can support emerging technologies by providing relevant knowledge, networks, and resources not easily generated within niches [8,17], but there is little research on interactive effects with the network formation and government policies and quantitative evidence highlighting the mechanisms through which complementary sectors can support the evolution of a niche technology. To contribute to this gap in the literature, we developed a dataset and three econometric models examining the impact of multiregime interactions in solar PV manufacturing, knowledge generation, and diffusion. We relied on network ties (or collaborations) as an indicator of niche development and the sum of revenues of global top semiconductor companies in the countries included in the panel data as a proxy for the strength of the complementary sector. Our empirical analysis allowed us to identify key factors associated with the growth of the solar PV sector. Several conventional variables including PV system price and knowledge generation are meaningful. Like previous studies, we find that solar PV diffusion is driven by government policy [35]. But our analysis allowed us to identify the importance of network development, the strength of a complementary sector, and, in particular, the interaction between these two variables. Our results clearly indicate that complementary sectors are associated with increased manufacturing capacity, but the effects of the development of an \"aggregated\" network metric are not so clear. An evaluation of the impact of three different collaborations specializing in manufacturing, R&D, and diffusion showed that the effect of networks is conditional on the strength of the complementary sector. We have found that R&D collaborations are associated with increases in diffusion in countries with weak complementary sectors and with increases in manufacturing capabilities in countries with a strong complementary sector. We have also found that manufacturing collaborations are positively associated with overall diffusion and manufacturing activities in countries with a weak complementary sector, but not in countries with a strong complementary sector. This analysis may contribute to the evidence that China has enjoyed many of the benefits generated from the government subsidy for the diffusion of renewable energy sources. Thus, even if a complementary sector is present, governments need to consider how to link government policies to the domestic manufacturing activities in order to prevent losing their current competitiveness. As a result of interactions between networks and complementary sectors there seem to be two pathways for the development of the solar PV sector. Between 2000 and 2009, countries with strong complementary sectors have tended to follow a manufacturing-and deployment-oriented pathway and countries with weak complementary sectors have followed a diffusion-oriented pathway. However, the latter pathway does not to apply to China, which has developed a strong PV manufacturing sector during this period in spite of its weak complementary sector on the basis of their manufacturing and learning capabilities. Domestic FiT and RPS policies do not seem to have been able to encourage manufacturing in countries without strong complementary sector without other possible advantages in terms of financing, scale, and speed of project execution. This indicates that governments in countries without a strong complementary sector or other possible sources of comparative advantage should think twice before having the promotion of domestic manufacturing as a policy goal. At the minimum they should develop alternative strategies to strong deployment policies, which could include developing a complementary sector. A good-fit between existing industrial bases and the niche technology could contribute to a successful transition from a niche technology to a larger player. Even though this research sheds some light on the interplay between niche and complementary regimes, an important challenge still lies ahead. This challenge involves integrating the study of a competitive technology regime, i.e., the evolution of coal and natural gas power in this case. Improving our understanding of the interaction between niche technology, a complementary sector, and a competitive sector would be helpful to identify policies and pathways accelerating the introduction of niche technologies with perceived societal benefits. Furthermore, it is necessary to extend the time dimension in data to capture more interesting phenomena like the surge in international trade in the solar PV led by Chinese manufacturers that took place after 2009. study was also supported by a research fund from Chosun University, 2013. The findings, opinions, and conclusions expressed in this paper are those of the authors and do not necessarily reflect the views of the funding organizations. Appendix A. Robustness test for assumption about the duration of collaborations Models 1 through 4 assumed that all collaborations were active for a period of 3 years. To test the robustness of this assumption we estimated the impact of using a cumulative network variable starting in the year 2000. A cumulative network variable implies that the benefits from a collaboration grow over time and/or that collaborations last for a period longer than that covered by our sample. Table A displays the results of making this assumption. In general, these results are similar to those of Model 4 and both show that the signs of coefficients of statistically significant variables are identical except an interaction term between the complementary sector and manufacturing collaborations. "
        }
    },
    "10.1016/j.techfore.2012.04.019": {
        "file_name": "165 A comparative study of hype cycles among actors within the socio-technical system",
        "title": "A comparative study of hype cycles among actors within the socio-technical system: With a focus on the case study of hybrid cars",
        "abstract": "Many forms of technology cycle models have been developed and utilized to identify emergent technologies and forecast social changes, and among these, the technology hype cycle introduced by Gartner has become established as an effective method widely utilized in the field. However, if the hype cycle indeed exists in the various dimensions that constitute the socio-technical system, those who seek to analyze innovative activities using bibliometrics will be confronted with the new problem of actors' choices and the need to analyze their hype cycles. In seeking to overcome such limitations of conventional studies, this paper analyzes the hype cycles of three actors that constitute the core of the socio-technical system through the case study of the successful market entry of hybrid cars. The hype cycle of the user, the first actor, is analyzed based on the search traffic generated by their web searches, and the hype cycle of the producer or researcher, the second actor, is measured based on the data regarding patent applications. Lastly, the hype cycle of the information distributor, namely individuals constituting the market network, is analyzed by examining the exposure in news reports. The outcomes of this research showed that among the three actors, the consumers and the information distributors exhibited hype cycle patterns (bell curves) that were distinct from the market trend, and that there was a difference in time interval of around five quarters. By contrast, it was found that the hype cycle of the producers reflected a logical response, exhibiting a pattern similar to the S-curve during the market's growth period unlike the pattern found in other actors. In conclusion, this study of the particular case of hybrid cars confirmed that the two components of the hype cycle can be respectively verified using consumer search traffic and the patent applications made by the producers. If in the future, such analyses of the hype cycles of producers and consumers are expanded in application to various other industries, it will be possible to obtain more generalizable research outcomes. This is expected to contribute to determining technological life cycles or hype cycles with greater objectivity and efficacy, and furthermore to facilitate the systematic identification of promising technologies.",
        "label": "Quantitative",
        "text": {
            "Introduction": " Various forms of technology cycle models have been developed and utilized for the purpose of identifying new and convergent technologies at an early stage and of forecasting social change, in various academic fields such as management, marketing, technology management, science and technology policy development, etc. Recently, corresponding to the development of bibliometrics, there have been particularly active attempts to analyze life cycles through a quantitative analytical approach and to utilize the results in forecasting [4,5]. Among these technology cycle models, the hype cycle model has received the most notable attention for its superior explanatory power. The hype cycle model was developed by Jackie Fenn of Gartner to express the level of the technology's maturity and the degree of its adoption and commercialization, and has become an effective method that is widely used not only by Gartner but Contents lists available at SciVerse ScienceDirect Technological Forecasting & Social Change also in various other fields. However, in spite of the wide popularity of this model, the currently existing research literature has tended to neglect examining the main actors of the hype cycle. It should also be noted that conventional empirical research on hype cycles has failed to provide a comparative study of the actors in the hype cycle. For this reason, this paper approaches the hype cycle as arising from the three types of actors that compose the socio-technical system [11]. The most distinguishing factor, namely the users' hype cycle, is analyzed based on the search traffic generated by their web searches, while the hype cycle of the producers (or researchers) who constitute the second actor is measured based on patent applications. Lastly, the hype cycle of the information distributors, namely the individuals who compose the market network, is analyzed through the exposure in news reports. Selecting an appropriate subject for case study is critically important for proper analysis, and the target subject selected for this analysis must specifically be amenable to measurements of both the bubble stage (excessive increase in expectation) and the disillusionment stage (decline in expectation) which characterize the hype cycle. In other words, to examine the hype cycle, it is imperative to select a technology that requires a relatively long period to reach the growth stage following the initial stage of its introduction, and technologies which have only recently entered into its growth stage are particularly helpful in facilitating measurements. In the U.S. market, the case of hybrid automobiles was determined to satisfy these conditions. This paper analyzes the hype cycles of three actors in regard to hybrid cars in the United States, and interprets the results in linkage with the conventional product life cycle or consumer adoption models, thereby empirically demonstrating that hype cycles exist in multiple dimensions. The outcome of this research is expected to make major contributions to the utilization of hype cycles, life cycles and consumer behavior models in various efforts to analyze and forecast markets and technologies hereafter.",
            "Theoretical background and preceding studies": "",
            "Theoretical background": " The technology hype cycle model is a model that can be implemented to explain users' expectations that differ from the conventional life cycle, which reflects users' purchasing behavior. Jun [16] has already demonstrated that this model can be empirically verified based on search traffic patterns. The socio-technical model provides a useful frame for explaining technological innovations and adoption with the inclusion of consumers, rectifying the problematic neglect of consumers that occurred in the past when technological innovation processes were presented with an exclusive focus on producers or researchers. This model also provides the basis for selecting the actors meriting attention in the adoption of new technologies and the significance of these actors within the adoption system. The major theoretical backgrounds to this study are briefly outlined in the following.",
            "Technology hype cycle model": " While the conventional product life cycle (or technology life cycle) constitutes a producer-oriented and outcome-oriented approach in that this cycle seeks to explain indices related to the producer such as sales, sales revenues, and operating profits, etc., by contrast, the hype cycle (or attention cycle) model is an approach that focuses more on the consumers and procedural aspects. In general, when a new technology has been introduced, the Technology Hype Cycle Model is used to explain the process by which the expectations regarding that technology evolves and the process by which the technology becomes established in the market and utilized by companies. The phase-by-phase technology hype cycle presented in Fig. 1 yields the following observations. The Technology Trigger phase (i.e., the technology generation phase, or the incipient phase) is when the technology commodity emerges driven by the potential of the technology. In this phase, however, though the technology receives attention from the media, it may appear to be deficient in merchandising potential or it may fail to become commercialized. The Peak of Inflated Expectations phase (bubble phase) is the period of heightening interest when numerous initial success stories are publicized but not many companies participate. The media tend to report unrealistic and excessive market forecasts regarding the technological success. The Trough of Disillusionment (the disillusionment phase) is the phase when the hype rapidly declines due to falling interest regarding the results of the experiment or due to the failure of commercialization, and this is the phase in which the technology must be developed into a commodity that can satisfy early adopters if it is to secure continued investment. This is a period of realistic re-adjustment marked by a rapidly declining curve, and the media lose interest in providing coverage other than expressions of suspicion regarding the technology. The Slope of Enlightenment (the stabilization phase) is the phase in which a wider understanding can be gained regarding the specific means by which the technology in question will generate profit, and sometimes a second or third generation version that represents an improvement over the initial commodity makes an appearance. This is the phase in which conservative companies remain cautiously attentive to how the technology will proceed. The Plateau of Productivity (growth phase) is the phase in which the commercial viability is recognized, and advancement into a broad market for the technology in question can take place (www.gartner.com). One characteristic that distinguishes the hype cycle in comparison to the life cycle is that when a new technology emerges and is evaluated to have potential for applicability (Technology Trigger), the expectations of the market and the consumers regarding the new technology rapidly rise and reach a peak (Peak of Inflated Expectation), but as in the case of the majority of new technologies, as the new technology that has reached its peak begins to be disseminated more broadly, there arises a gap between the expectation and the level of actual satisfaction, resulting in the collapse of the bubble (Trough of Disillusionment). This subsidence of the bubble and the return of the level of expectation almost back to its original point are attributed to technological problems in the new technology itself and the deficiencies in the related infrastructure that is required for the implementation of the new technology. The hype cycle has its origins in the \"marketing hype,\" which is a concept that explains the negative effects of excessive marketing, or in other words, excessive exposure. Therefore, the visibility in the hype cycle brings about the rapid bubble phase arising from technological vision or from the media, and such visibility becomes hyped according to the content and the amount of the exposure. This technology hype cycle model is currently applied to almost all newly emergent informational technologies, and in the case of the Gartner Group, this type of technology hype cycle model is used to explain which phase has been reached by the new informational technologies that have been hitherto introduced, as in the following.",
            "Socio-technical system": " The majority of existing methodologies that embody the innovation system approach are based on supplier-centric thinking in regard to the creation of innovation. The socio-technical system, which was proposed in response to a critical awareness of this problem, distinguishes the consumer aspect in its approach (refer to Fig. 2). The socio-technical system presented by Geels [11] encompasses not only production but also the dissemination and usage of technology. This socio-technical system is composed of artifacts, knowledge, Fig. 2. The basic elements and resources of the socio-technical systems. Source: [11]. capital, labor and cultural meaning, etc. Though this socio-technical system does not function independently, the system ultimately cannot help but be regarded as the outcome of the behavior of human actors. Also, various social actor groups (for example, consumers) that are active within the socio-technical system take actions autonomously [11,12]. This theory explains the role of various social groups including not only consumers and producers but also the distributors of technology, and this paper accordingly focuses on mass media groups in addition to users (or consumers) and producers. Information distributors (for example, the mass media) who perform the role of building social networks and generating cultural and symbolic meanings have assumed an important role in the socio-technical system, particularly since the advent of the 20th century.",
            "A review of preceding studies providing empirical verification of the hype cycle and the differentiating features of the present study":" Dahlberg and H\u00f8rl\u00fcck [3] and Osterwalder [25] respectively utilized the equity value graph and the NASDAQ index to empirically define the technology hype cycle, and thereby identified patterns that were similar to the hype cycle. However, the relationship between equity values and visibility remained unclear. In particular, while it is possible to conduct an analysis of the equity values and index for a specific company or a specific industry, there are significant limitations impeding the analysis of specific technologies or products. In addition, though Romiszowski [27] has analyzed the adoption patterns for education and TV, since his analysis pertained not to the visibility of technologies but rather to their adoption (market share), his work should be considered to be rather an analysis of one type among the various conventional product life cycles. In regard to visibility, Lind [21] was able to clearly illustrate the hype cycle pattern involving the usage of the word \"convergence\" in IT-related articles found in the databases of news reports. Though this cannot be considered an empirical study of the hype cycle since it did not consist of an analysis of technology, Lind's work has presented the possibility for using the visibility measurement indices provided by news reports. Such bibliometrical approaches to the hype cycle or the life cycle can also be found in the works of Watts and Porter [29], who identified the bibliometrical indices that enable approaches at each phase, as presented in Table 1. Although, according to the results of a study by J\u00e4rvenp\u00e4\u00e4 et al. [13], the phase-by-phase categorization indicated in Table 1 cannot be regarded as the general, representative characteristics of each phase, it is certain that each index offers a valuable resource for empirically analyzing the technology hype cycle. J\u00e4rvenp\u00e4\u00e4 [14] actually analyzed the case of DVD technology using news articles, one of the indices included in Table 1, with the objective of identifying the technology hype cycle but failed to demonstrate a clear hype cycle pattern for DVD technology in all of the English-language newspapers examined. J\u00e4rvenp\u00e4\u00e4 attributed this failure to the inclusion of DVD films rather than DVD technology. However, the study also achieved some progress in this area by demonstrating that the press specializing in technology and the general press have differing bubble phase peaks. In another study conducted by J\u00e4rvenp\u00e4\u00e4 [15], the target technologies were expanded to include MP3, Bluetooth, and Blu-ray technologies, and the indices were also modified to include both news reports and technological literature (\"Compendex\"). As a result, the study succeeded in identifying a clear hype cycle in the news pertaining to MP3 and Bluetooth. On the other hand, however, the study managed to detect only the decline of the bubble phase for Blu-ray. Even in the identified patterns, there were difficult challenges to interpreting the results since the study overlapped with the period of the collapse of the dot-com bubble and falling expectations. Jun [16] conducted comparative analyses of macroeconomic indicator variables such as oil prices and GDP growth rates to demonstrate that consumers' hype cycles can be observed through search traffic. Although this study provided a more direct measurement of consumer expectations compared to previous studies, it was limited to comparing sales volume resulting from consumer behavior reflecting consumer expectations. As examined above, there have been many efforts to empirically demonstrate the technology hype cycle up to recent times, and there have been positive developments such as the identification of indices and the various attempts at analysis, but these efforts were also beset by many limitations. In particular, because of the absence of consideration given to the technology life cycle, it has been difficult to provide an adequate interpretation of the bubble phase and the disillusionment phase. More effective interpretations will become possible when a comparison is made of the hype cycle indices in conjunction with the conventional technology life cycle, as undertaken in the research by Chen et al. [2]. Early on, Ernst [8] had argued that patent related activities undergo a period of decline during the growth phase of the technology cycle, though he did not adduce the hype cycle in his explanation. As implied in these preceding studies, it is necessary to analyze the life cycle and the hype cycle in correlation with  1. In particular, while the life cycle is regarded as a producer-centered cycle, the hype cycle by contrast has the advantage of enabling the analysis of the hype cycle for each specific actor within the diverse socio-technical system. While applications for patents or the publication of papers enable measurements of the expectations of researchers or producers as shown in the preceding literature, news articles will make it possible to measure the expectations of the opinion leader group within the market. However, there is one index of the hype cycle that has been overlooked by J\u00e4rvenp\u00e4\u00e4, Watts and Porter, and this is none other than the consumer's hype cycle. This paper seeks to analyze the consumer's hype cycle using web-searching traffic, which can be defined as part of the index of information collection within the five stages outlined in the consumer behavior model. In the works of J\u00e4rvenp\u00e4\u00e4 or Fenn, who created the hype cycle model, expectation was defined simply as the manifestation of human nature, but the project to connect the life cycle with the hype cycle must be preceded by the demonstration that hype cycles exist for multiple participants within the market including the users and by efforts to compare these cycles. This paper therefore undertakes to empirically identify and compare the three representative actors in the market. Linstone has set a precedent for applying this method which approaches the issue from the perspective of the actors in the socio-technical system. Linstone [23] identified three multiple perspectives, namely the technological (T), organizational (O), and personal (P) perspectives, and presented their respective criteria as analysis, value, and image. Linstone argued that this perspective-based approach is useful for technology assessment and risk management. In addition, Linstone [22] also utilized the T-O-P concept to provide an insightful explanation of the complexity of the science adaptive system. What is particularly notable is that the criteria or characteristics respectably applicable to the three types of perspectives presented by Linstone [22] point to the possibility that their respective hype cycles may have differing patterns. This present research has similarities to these early studies conducted by Linstone or Geels in that it also adopts multi-perspective approach, but the unique significance of this research is that actors' behavior is simultaneously approached through a quantitative and empirical approach employing big data. The present research also considers the possibility of lags when analyzing the relationships among the expectations or behaviors of these actors. Winthrop et al. [30] have analyzed the lag effect that occurs between the time of the producers' investments and the producers' achievement of outcomes in the course of their analysis of R&D investments and paper publications (quantitative progress), citation of published papers (qualitative progress), patent applications, and patent citations, etc. Daim et al. [6] also succeeded in analyzing the effect of lagging outcomes based on an examination of research funding and patents for emerging technology, publication of papers in academic journals, and papers presented at academic conferences. Martin and Daim [24] even progressed as far as to present a technology roadmap, predicting the technological outcome deriving from research funding based on such intelligence analyses. Such bibliometric researches are most often characterized by a producer-centered approach focusing on paper publications and patents. In this context, the present research can be regarded as distinctly significant because it performs a bibliography analysis that includes both consumers and media. Kostoff [17][18][19], one of the early pioneers of research on the effects of investment in research and development, examined the issue in terms of the directionality of factors influencing scientific and technological innovation. In the present study, I analyzed the relations of influence that exist among actors through cross-correlation analysis and the Granger causality test. Also, as in the preceding studies, analyzing visibility or measuring expectations using only quantitative data (counts or number of hits) entails the risk of reflecting changes in the media environment concomitant to the development of the internet environment in the form of noise. In other words, the concept of exposure through news, etc., can be interpreted more accurately when compared through frequencies or intensities rather than through absolute values. For this reason, this paper refrains from the analysis of simple quantities (number of counts), and instead uses frequencies or intensities to analyze the hype cycles of producers (researchers), the market, and consumers.",
            "Research methodology and case studies": "",
            "Variables and method of measurement": " To measure the hype cycle from the user perspective, this study used the methodology of bibliometrics that measures statements and information in documents. Bibliometrics is an effective methodology for historically and systematically analyzing large volumes of documents. Bibliometrics is capable of analyzing embedded technology life cycles, and has even been utilized in linkage with consumer adoption forecasting models such as the Bass model to predict the future of technologies [7]. The subject matter of bibliometrics encompasses search traffic, news, and patents. The key target of this analysis is search traffic, which reflects the hype cycle of consumers, and news reports and patents as presented in Table 1 are also analyzed for the purpose of interpreting the hype cycle indicated by search traffic and drawing comparisons to preceding research. Because the case study under analysis consisted of hybrid cars, the bibliography was limited to documents originating in the U.S. or produced in the English language. Also, each item was respectively postulated to represent distinct actors; the contents thereof are presented in Table 2. The categorization of actors as shown in Table 2 was founded on distinctions of the basic component factors and sources for the socio-technical system indicated by Geels [11] (refer to Fig. 2), and the operationalization of the variables of measurement for each actor was based on existing research literature and theories, as explained in Table 2. Upon examining each respective measurement methodology in further detail, it should be noted that for the purpose of measuring the user's expectations (visibility) from the perspective of consumer behavior, measurement was made based on the intensity of search traffic for searches made on a website, in contrast to the method used in other preceding studies. The site selected for analysis was Google, which provided the search statistics for this study and which occupies the highest global market share of searches, reaching 82.8% as of May 2011 (www.netmarketshare.com). The search traffic on Google was adopted as the index of consumer behavior for the reason that Google's search engine already occupies a monopolistic position in the market. Moreover, though producers also use Google searches, the majority of the Google users in this regard consist of consumers who are restricted from access to other specialized DBs. Google's search statistics analyze a portion of web searches to calculate the number of searches for the terms input by the user within a specific time period in relation to the total number of searches conducted on Google. This is equivalent to expressing the probability that a particular individual user will search for a certain search term within a specific time period in a particular region. The search statistics set the criteria of minimum traffic for the search term and hence search terms with low search volume are not indicated in the statistics. Also, search terms that were repeatedly input by a particular user over a short time period are also excluded from the tally, preventing the possibility of artificially manipulating the level of interest through repetition (www.google.com). Another advantage of utilizing Google trends is found in its process of normalization. Research case studies in the past used absolute values (for example, the number of hits, etc.) and hence failed to exclude environmental factors impacting consumer exposure that result from the overall increase in news volume or the number of web pages. By contrast, all of the results of the search statistics in the Google trend data undergo a normalization process, dividing them by a common variable to eliminate the influence of variables. This method makes it possible to compare the basic features of each set of data. If only the absolute values are indicated without the precaution of this normalization process, the data collected from regions or time periods with high search volume will always receive the highest score. The frequency of all other indices for measuring the hype cycle, such as news and patents, is also measured in relation to the total data for the time period in question, and is again divided by the total average to ensure that normalized intensities are used in all comparisons. The market sales volume is also divided by the total sales volume to yield the sales market share of new products submitted to analysis. The sources for the major variables and the comparative data are listed in Table 3.",
            "Case study: hybrid automobiles": " The hype cycle has been actively utilized by Gartner in the IT industry. The elements that differentiate this hype cycle from the conventional technology life cycle are the bubble phase marked by a rapid rise in expectations (Peak of Inflated Expectations) and the phase of disillusionment marked by declining expectations (Trough of Disillusionment), which are distinguished from the market growth which occurs in the life cycle. In the IT industry, these two characteristic phases take place over a relatively short time period, and there are many problems that complicate attempts to distinguish these phases from the noise in the external environment even when the phases are actually observed. I chose the hybrid car as the target for analysis, since this case study will allow me to empirically verify whether the hype cycle exists in industries other than the established IT industry and since hybrid cars have a long-term technology life cycle that makes it relatively conducive to excluding the external environmental noise. Hybrid cars have been developed with an almost exclusive focus on the U.S. market. In the United States, hybrid cars have grown into a market that occupied up to 2.5% of the new car sales volumes for 2010, with the cumulative sales volume reaching 2 million vehicles as of May, 2011. When estimating the cumulative maximum market to determine the growth cycle, I took into consideration that 25% of the car transactions in the U.S. consist of new cars and that the total number of registered vehicles is 250 million (as of 2007), and thereby estimated the cumulative maximum market for hybrid cars to be around 60 million vehicles (maximum potential number of cumulative consumers in the Bass model [1]). Comparing with the consumer innovation adoption model of Rogers [26], I observed that the cumulative market share since 2009 exceeded 2.5% (around 1.5 million vehicles) and therefore concluded that the market has grown from a market for innovators into that of early adopters. In terms of the conventional life cycle, the market has passed the introductory phase and entered into the early growth phase.",
            "Research model and statistical hypotheses": " The research model adopted to explain the hype cycle of each actor and the causal relations among them are shown in Fig. 3, and this model has a dual regression analysis structure similar to Path Analysis. Path Analysis was not performed in this research; instead, I established hypotheses regarding individual relations and sought to identify the causal relations through simple regression analysis. According to the consumer behavior model, consumers' purchasing activities and their information searching activities cannot help but exercise an influence. In particular, the stimulus-behavior model dictates that internal and external stimuli are great motivators for consumer behavior. Therefore, the behavior of the actors constituting the socio-technical system can mutually influence one another by serving as stimuli. The following is an attempt to find the factors influencing the consumer hype cycle by identifying the correlations of influence that exist among the behaviors of such actors. First, I set up a hypothesis to examine the problem of multicollinearity between media activities, which serve as the dependent variables to consumer activities or hype, and the producer's technology development activities. H0A1. Media activities are not influenced by the producer's technology development activities. In the above analysis, if multicollinearity is not high, or more specifically, not high enough to merge the independent variables, then the two stimulating factors can both be regarded as independent variables. If there is no multicollinearity among the independent variables, the null hypothesis for the research model explained in Fig. 3 can be established as follows according to the general consumer behavior model and the stimuli-behavior model. H0A2. Consumers' information searching activities are not influenced by media activities. H0A3. Consumers' information searching activities are not influenced by the producer's technology development activities. H0A4. The proportion of hybrid car purchases is not influenced by media activities. H0A5. The proportion of hybrid car purchases is not influenced by the producer's technology development activities. H0A6. The proportion of hybrid car purchases is not influenced by the consumer's information searching activities. As previously explained, in the above hypotheses, the media activities were operationalized based on the proxy variable representing news reports and the producer's technology development activities were operationalized based on the number of patent applications, while the consumers' information searching activities were considered to be the outcome of consumer hype, with search traffic serving as the proxy variable. In addition to the correlation of causality examined above, I also needed to take into consideration the time sequence of occurrence. It is possible that the existence of a period of delay between the technology development activities or media activities and the consumers' hype may have induced the rejection of the hypotheses above, or resulted in low correlations. To examine the validity of this argument, I presented the following additional null hypotheses. If an original hypothesis that was previously adopted is rejected, or if an original hypothesis that was rejected is again rejected and the correlation coefficient increases, then it becomes possible to claim the possibility of a delayed influence among the behavior of the actors. H0D1-1. Media activities are not influenced by the producer's delayed technological development activities. H0D2-1. The information searching activities of consumers are not influenced by delayed media activities. H0D3-1. The information searching activities of consumers are not influenced by the producer's delayed technological development activities.",
            "Results": " 4.1. Technology statistics for each variable 4.1.1. Search traffic Fig. 4 shows the measurement results for search traffic, which I use to assess consumer expectations. The figure shows the weekly search traffic for hybrid cars standardized by a non-dimension scale. To reduce the risk of interpretive errors that may arise due to external environmental factors pertaining to hybrid cars, I simultaneously analyzed the search traffic for electric cars, using hybrid cars as the norm. Because the intensity of the search traffic has been standardized, 1.0 was set as the average intensity of hybrid car search traffic, which I adopted as the norm, and the average for electric cars reached 1.82. Up to the first half of 2006, there was almost no difference in comparison to the web search traffic for electric cars. However, beginning in the second half of 2006, when the sales of hybrid cars stabilized above 1.5%, the gap between the search traffic for electric cars and the search traffic for hybrid cars began to widen steadily. Rather than attributing this increasing gap to a change in the users' method of collecting information on electric cars, I deduced that the expectations of users regarding electric cars had once been focused on hybrids but gradually expanded to include other alternatives. Fig. 5 provides information regarding the search terms selected by users when search for data on hybrid cars. Consumers searching for hybrid cars used the term \"hybrid car\" far more often than the term \"hybrid vehicle\", and though some did use the term \"hybrid vehicle,\" the trend for the usage of this term was similar to the trend for \"hybrid car.\" For this reason, I examined only the data for the term \"hybrid car\" when analyzing the intensity of search traffic (Google Trends does not support multi-term searches (and, or, etc.)).",
            "Sales percentage of hybrid cars": " The sales of passenger cars in the U.S. The hybrid car sales percentage (market share), which is the variable obtained by dividing the sales volume of hybrid cars by the sales volume of new cars, continued to increase rapidly in contrast to the decline in new car sales volume or hybrid car sales volume. Upon entering 2010, however, the hybrid car sales percentage stagnated due to factors such as the economic recession, the quality problems that emerged in Japanese vehicles, and the obsolescence of released models. The sales percentage of hybrid cars had an average of 1.88% from 2004 to the 1st quarter of 2011.",
            "Patent application percentage": " When a phrase search was conducted for \"hybrid car\" within titles and abstracts, the results differed greatly depending on the search terminology used, a factor which had not been an issue when analyzing search traffic. In the phrase search, the number of patent applications I found increased by a large margin when the term \"hybrid vehicle\" was included in the analysis, compared to when only the term \"hybrid car\" was used. Classified based on the date of the application, from 2002 to 2010 the number of patents related to \"hybrid car\" totaled 1027. When the term \"hybrid vehicle\" was also included, however, the total reached 7855 patents, which was more than 7 times higher than the previous total. For this reason, I included not only the phrase \"hybrid car\" but also \"hybrid vehicle\" when performing our analysis of the patent application percentage. Prior to 2001, the United States only disclosed information on registered patents, but from 2001, the patent public disclosure system entered into effect, and hence I was able to eliminate any complications arising from undisclosed patents in my analysis of all patent applications made public since 2002, as shown in Fig. 6. However, the decline in the total number of patent applications since 2010 is implicated with the issue of undisclosed patents, due to the patent public disclosure system explained above. Hence caution needs to be taken when utilizing this data. To minimize the problems arising from this complication, I undertook to analyze patents based on percentage analysis rather than on hits. As presented in Fig. 6, the total number of patent applications in the 9 years from 2002 to 2010 was 2.68 million, and the quarterly average was 74,552. Among these, the quarterly average of hybrid-related patent applications (\"hybrid car\" or \"hybrid vehicle\") was 218. In this paper, the \"patent application percentage\" refers to the percentage obtained by dividing the number of patents related to hybrid cars by the total number of patent applications. The patent application percentage for each quarter had an average of 0.3%, and the overall trend showed a great increase beginning in late 2005, similar to the trend found in the hybrid car sales percentages.  ",
            "News coverage percentage": " My examination of the trend in reports and articles related to hybrid cars that received exposure in the news revealed that the trend differed from that found in the case of patents or search traffic. In the phrase search, though an analysis using the phrase \"hybrid car\" yielded a greater number of searches compared to analysis using the phrase \"hybrid vehicle\", the difference in number was not significant enough to dismiss the phrase \"hybrid vehicle\" as I had done in the case of search traffic. Upon classifying articles by the date of publication, I found that there were 2901 articles related to \"hybrid car\" between 2002 and 2010. When the phrase \"hybrid vehicle\" was included, however, the number increased to 2303, which amounted to 79% of the number for \"hybrid car\". Therefore, in the analysis of news coverage percentage, I included both the phrases \"hybrid car\" and \"hybrid vehicle\", and after searching for articles related to each respective phrase, I subtracted the number of news articles searched when using both phrases (eliminating redundant searches), so that the pool consisted of articles in which one or more of the phrases were listed. In the nine years from 2002 to 2010, the total number of news items was 129.36 million, and the quarterly average was 3.89 million news items. Meanwhile, the number of news articles related to hybrids (searchable by \"hybrid car\" or \"hybrid vehicle\") totaled 4823, with a quarterly average of 134 articles. The peak was reached in 2008-2009, and the number of articles continually increased, and this trend was impacted by the great increase in the total number of news articles from 2007. To exclude the factor of this environmental change, I analyzed the news coverage percentage as shown in Fig. 7. I obtained the news coverage percentage by dividing the number of news related to hybrid cars by the total number of news articles. The average was 0.0037%, and unlike the number of articles published, this percentage reached a peak in the early half of 2007.",
            "Hype cycle observation results": " According to Fenn and Raskino [9] of the Gartner group who presented a systematic understanding of the hype cycle, expectation can be defined as the human response to the new and the novel, and the hype cycle consists of two elements which can be explained by two separate curves. As shown in Fig. 8, the first curve is a bell curve, which represents the initial enthusiasm or disappointment driven by positive or negative outcomes. The second is an S-curve showing how an innovation's performance improves slowly at first, then picks up steadily, and finally yields diminishing returns. When these two curves are combined, it is evident how the shape of the hype cycle arises from the offset timing of the two factors (refer to Fig. 1). The hype cycle is driven upward first by the collective emotional response and then, on the Slope of Enlightenment, by the logical response to an innovation's improving performance. Therefore, up to the Trough of Disillusionment phase, consumer behavior that reflects the emotional responses of the consumers can be measured by search traffic, but after the Trough of Disillusionment phase, it would be more appropriate to measure the rational response embodied in the innovative efforts of the producers. As demonstrated in Jun [16], when the market share in the U.S. exceeded 1.5-2.0% between 2007 and 2008, the market share and the search traffic began to exhibit notably contrasting patterns. While the market share followed an exponential trend, the search traffic exhibited a polynomial (3-4 terms) trend (refer to Fig. 9). By contrast, according to the data in Fig. 10, WTI oil prices and the market share followed nearly identical trends over the course of the entire time period, corroborating the generally held view that oil prices probably exercised a great impact on the expansion of the hybrid car market. (Meanwhile, the GDP growth rate had almost no influence on changes in the market share). Therefore, it was possible to attribute the fall in search traffic to the characteristics of the users rather than to external environmental factors such as oil prices. The above analyses verified that the information research behavior of consumers (users) using the web exhibited the same characteristics corresponding to the bubble phase and the disillusionment phase within the hype cycle, in contradistinction to the exponential growth that takes place throughout the introductory and growth phases in the market. ",
            "Results of the comparison of the hype cycle of each actor": " According to the five-stage model of the purchasing process provided by the consumer behavior model that helps explain the forms of searches performed by users, after the consumer (or user) is exposed to external stimulants (news or technology information) and searches for information, the consumer undergoes a process of evaluating alternatives before making the decision to buy. This consumer behavior model explains the operating mechanism behind the bubble phase and the disillusionment phase of the hype cycle. During the bubble phase, the heightening expectations among producers or in the media lead to the technology's high exposure to consumers, but as the producers or the media become aware of the realistic limitations of the technology, the technological development also normalizes in reversion from the excess, and when the external stimulants acting on the users are thus reduced, the consumers' expectations also declines. This explanation can also be corroborated using the Bass diffusion model provided Bass, who has researched the consumer adoption model [26]. The Bass model postulates that the potential adopter is influenced by two types of communication channels, namely the mass media channel and the interpersonal channel. Cases in which the adopter selects the new product through the impact of mass media messages (news, etc.) occur continually throughout the diffusion process, but they are relatively more concentrated in the early stages of the innovation diffusion. Therefore, the mass media messages in the early phases of the innovation plays a critically important role. The correlations among the analysis models were as follows. I have already presented my comparison between the hybrid car sales percentage and the search traffic in Fig. 9 above. Because the activities of the producers or the media may have influenced the trends in the search traffic or the hybrid car sales percentages, I compared the major variable for each actor, and Fig. 11 presents the comparisons of the changing trends in patent applications and news coverage and the changes in search traffic. Since each of these variables represented the expectation of each respective actor, the comparisons were based on normalized intensity. Because in the socio-technical system, the activities of the producers or the media may occur in advance, I measured the intensity of the patent application percentage and the news coverage rate from 2002 to 2010, which I had not done for my measurements of search traffic. The results shown on the left in Fig. 11 indicate that though both news and search traffic exhibited patterns corresponding to the Peak of Inflated Expectations phase and the Trough of disillusionment phase of the hype cycle that is distinguishable from the life cycle (sales percentage), their respective peaks differed. The peak for news occurred slightly earlier. Patent applications did not exhibit any significant positive (+) correlation to search traffic, and instead showed a relationship closer to the negative (\u2212) direction.  The data on the right in Fig. 11 show the results of comparing the external variables consisting of patents and news to the internal variable consisting of sales percentages. In contrast to the results shown on the left in Fig. 11, the intensity of patents application percentages had tendencies similar to the sales percentages, while only the news coverage percentage shows trends similar to the hype cycle.",
            "Model verification": " Table 4 presents the results of the regression analyses I conducted on the major variables, including patent applications, news reports, and search traffic. The results indicate that the market sales percentage (market share), which had a life cycle pattern between the introductory phase and the growth phase, possessed a significant correlation to patent applications and news reports. The level of significance was high and the correlation coefficient was also relatively high. However, while the patents exhibited a positive (+) correlation and therefore could be considered to have significance, the news variable inversely exhibited a negative (\u2212) correlation, and therefore could not be considered significant (refer to the results of t-test). As for the correlation between the search traffic, which had exhibited a hype cycle, and the patent applications and news reports, only the correlation to patent applications yielded statistical significant results, but the correlation was negative (\u2212) and hence impossible to dismiss. Hypothesis H 0 A1, which had been established to examine multicollinearity, also displayed a statistically significant correlation but was not dismissed since the relationship was negative (\u2212). I was thus able to demonstrate that each individual independent variable had its own separate significance. When using the results of the regression analysis above to examine the outcome of hypothesis verification, H 0 A6 was the first to be adopted. Therefore, purchasing activities and information searching activities show divergent tendencies that cannot be explained by the consumer behavior model alone. In my verification of the other hypotheses, I rejected only H 0 A5 and adopted all other hypotheses. Though hypotheses H 0 A3 and H 0 A4 could be statistically significant, the directions of the coefficients were not appropriate, and therefore I adopted the null hypothesis (refer to the results of t-test). I thus concluded that news coverage either does not influence the information searches and purchasing activities of the consumers, or inversely exercises a negative effect. By contrast, patent applications had a high correlation to the sales volume of hybrid cars. It is necessary, however, to take caution here when determining the relation of cause and effect. Though it is possible that efforts at performance enhancement such as patent  applications increased sales volume, it is also plausible that the rising sales stimulated research and development or encouraged efforts to secure the rights to the related technology. As regards the hype cycle, patent applications do influence the purchase of hybrid cars, but does not influence the consumer hype cycle or rather serves as an environmental variable that exercises a negative (\u2212) influence. Since this outcome also fails to explain the behavior of consumers, it can be regarded as reinforcing the argument for the existence of the consumers' hype cycle. When I took into consideration the lag effect of the environmental variables, namely news and patents, the level of significance in the correlation of the intensity of the news coverage percentage and the search traffic improved by a large margin (refer to Table 5). Between the patent applications and search traffic, there was a statistically significant correlation when the lag was not taken into account but the direction was in inverse relation and therefore meaningless. Meanwhile, when I took into consideration the lag effect as shown in Table 5, the level of significance also decreased. As for the correlation between news coverage and search traffic, the correlation lacked significance when there was no lag effect, but when the search traffic was regarded as lagging 1 year behind news coverage, there was a high level of significance and the correlation coefficient also greatly increased. The results were significant even in the case where the news was considered to be 2 years ahead of the search traffic, but the level of significance and the correlation coefficient were both lower than in the case of a 1-year lag effect. In the correlation between patents applications and news exposure, the 1-year lag effect inversely resulted in lowering the level of significance and the correlation. In conclusion, the information distributors (market opinion leaders) exhibited hype cycle changes approximately 1 year in advance of the users, while the producers' behavior did not have a significant impact on the hype cycles of the information distributors or users (and instead only exhibited a statistically negative relation). Table 6 presents the results of the verifications I made in the research model through the hypothesis verifications explained above. In conclusion, producers' activities do not raise the expectations of consumers, but is capable of exercising a positive impact on sales volume. Media activities do not directly influence the sales of hybrid cars, but does have a lagged effect on consumers' expectations. Media activities have an influence on consumers' behavior related to their expectations after a lag of around 1 year. This phenomenon is in clear accordance with the conceptual definition of the hype cycle, in which the rising expectation in the mass media leads to energized consumer activity, followed by continued technological innovation that creates the S-curve of the cycle in the latter half of Fig. 8. Therefore, news and patents can be seen as variables that are highly capable of explaining the consumer behavior that follows the hype cycle.  To determine the lag effect between the patent application percentage and the intensity of the news coverage percentage, the possibilities of lags in each case were compared (the possibility of lead or lag). \u204e Significant at the 5% level. \u204e\u204e Significant at the 1% level. Note: the items in bold are statistically significant.",
            "Discussion": "",
            "The producers' hype cycle": " I have examined patent applications which reflect the expectations from the producers' perspective, news reports which reflect the expectations of the media (information distributor), and search traffic which reflects the expectations of the users. Among these three, the media and the users were found to exhibit hype cycle patterns. When I examined the trend in patent applications by broadening the scope to the 1990s, I found that the trend followed a similar hype cycle pattern. As demonstrated in Fig. 12, after passing the 1st peak in 2000, it was only in 2006 that the percentages of patent applications finally managed to rise back to the level of 2000. This trend is also a manifestation of the typical hype cycle. When the public disclosure system for patents was implemented in the U.S. in early 2000, the number of patents available for my searches naturally increased, but because the figures in Fig. 12 have been normalized to reflect changes in percentage, the outcome cannot be attributed to the public disclosure system which only influences the absolute number of searchable patents. Rather, it would be more reasonable to explain the increase in the percentage in the early 2000s as attributable to the initial commercial release of hybrid cars. As indicated in Fig. 12, there were almost no differences between the percentage of hybrid car patents within the total number of patent applications and the percentage of hybrid car patents within the total number of patents for cars, which is a relatively older technology. The impact of external variables on patent applications did not diverge in any significant way in the case of cars. The producers' hype cycle examined based on the percentage of patent applications differs from the hype cycle identified through news exposure rates or search traffic, and this can be explained by Fig. 8. Among the consumers (search traffic) and the information distributors (news coverage percentage), the escalation was led by collective emotional responses (expectations) and then subsided. By contrast, in the case of producers, after the Slope of Enlightenment, it was their rational responses regarding performance improvements through innovations that were manifested in efforts at performance enhancement as embodied in the patents applications or paper publications. This is the reason that two different types of hype cycles were formed. This phenomenon can be explained not only in terms of the components of the hype cycle but also in terms of the three perspectives referred to as T-O-P identified by Linstone [22]. The technological (T) perspective corresponding to the producers has an analytical character, while the personal (P) perspective corresponding to the consumers has an image-driven characteristic, and therefore it is understandable that their expectations will differ. Note: the items in bold are statistically significant. ",
            "Consideration of the time lag correlation": " Examining Table 5 and Fig. 11, I concluded that there may be an influence that takes place between news and search traffic over a lag of time, and in Fig. 11, I confirmed that patent applications and sales percentages may also exhibit a slight time lag. To examine these temporal relations, I presented cross-correlations in Fig. 13. First, the outcome of the cross-correlation analysis between the intensity of the news coverage percentage and the search traffic showed that the cross-correlation coefficient was the highest in the -5th quarter. Considering that in the consumer behavior model, news listings can supply stimuli in prior to the consumers' behavior, I regarded the results of the statistical analysis to be significant, and concluded that news exposure influenced search traffic after a time lag. Fig. 13 presents the coefficient of the cross-correlation between patent applications and sales percentages. According to these results, the time lag correlation coefficient was highest in the -1st quarter for patent applications and sales percentage, but there was almost no difference in comparison to the 0th quarter. This indicates that though the patent applications and the sales percentages have a high correlation, there is no time lag. The Granger Causality Test is a method applied to analyses of time series data such as search traffic to test how well a past value of another variable is able to explain the current value of one variable. The test thereby analyzes the relation of causality between the variables. To more rigorously examine the causal relation between the percentage of news exposure and search traffic, I performed a Granger Causality test on the relation between news coverage percentage and search traffic. The results are presented in Table 7. The results showed that the news coverage served as a Granger cause of search traffic only in the case where there is a 5-quarter lag. Therefore, the outcome of the Granger Causality Test demonstrates that using the news coverage percentage to explain search traffic will be significant only in cases where there is a 5-quarter lag. By examining the consumer behavior model, regression analysis, cross-correlation analysis and the Granger causality test, I was able to conclude that the expectations of the information distributors (news coverage) did have a lagged influence on the changes in expectations among the consumers. Also, I judged that the activities of the producers continually maintain a significant correlation to sales percentage once the early phase of market growth has passed. The question of why news and search traffic may exhibit a lagged correlation can be explained based on the Bass model, purchase delay, and construal level theory. First, as discussed above, the Bass model explains not only that the cases in which the adopter selects a new product based on messages from mass media such as news exposures continually occur throughout the diffusion process, but also that such cases are relatively more concentrated in the early stages of the innovation diffusion. Therefore, the mass media messages constitute an external stimulus that plays a critically important role in the early stage of innovation, and to fulfill this role, prior media activity must have taken place significantly in advance. Regarding the issue in terms of the purchase delay effect, it should be noted that it is the nature of durable consumer goods to have a long replacement cycle, and particularly in the case of highly priced products such as automobiles, there is a difference in time between the point at which the potential consumer perceives the marketing stimulus and the point at which he or she completes the purchase, and therefore it is for these reasons that the media activities occurred significantly in advance. Lastly, another explanation is offered by construal level theory. This theory explains the phenomenon based on the desirability of the product's features and the feasibility of its purchase. When purchasing a car, comfort, safety and fuel efficiency are factors that continually influence the consumer from the moment of information perception to the moment of purchase, and constitute the factor referred to as the desirability of the product's features [29]. On the other hand, price discounts, financing (installment plan) conditions, etc. are elements that determine the degree of difficulty involved in the product's purchase and constitute the factor of the feasibility of its purchase. This latter factor only begins to impact the consumer at the time the purchase is being made. In the light of these explanations, the temporal delay between the media activities and the consumers' search activities can be attributed to the relatively long-term impact of the news coverage on desirable features such as the environmental benefits and high fuel efficiency of hybrid cars. Such differentiating features of hybrid cars constitute the desirability of the features that maintains influence even after a period of 1 year or longer. However, when compared to Table 5, such delayed correlation did not differ greatly in significance from regression analysis without such delay, raising the possibility that the simple precedence in the media hype cycle became manifest as a weak level of Fig. 13. The cross-correlation coefficient of between news and search traffic (left) and between patent and market share (right). significance. In other words, further examination is needed to determine whether the temporal discrepancy between the media hype and the consumer hype could have been interpreted as a preceding causal relation.",
            "Estimation of the hype cycle through bibliometrics": " The two components of the hype cycle identified in Fig. 8 can be explained by the two separate curves derived in this paper. As seen in Fig. 8, the first is the bell curve that can be obtained based on changes in the search traffic, which reflects the positive and negative responses arising from the initial enthusiasm and disappointment (Gartner's Hype Cycle). Secondly, the performance S-curve that shows how the accomplishments of innovation gradually reveal methods of improvement can be composed based on the trends in patent applications, which reflects the rational responses of the producers. By combining these two curves, I was able to confirm the pattern of the technology hype cycle as in Fig. 14, which combines the two components which exhibit a time lag. The trend line for search traffic presented in Fig. 14 presumes a quadratic curve, and the trend in the intensity of the patent application percentage presumes an exponential growth with an intercept of 0. There remains the need, of course, to reconsider the time point at which the Trough of Disillusionment phase of the actual hype cycle passes, but nonetheless, this paper proposes a new method for measurement and observation based on an empirical demonstration of the hype cycle using only bibliometric data such as search traffic and patent application percentage.",
            "Conclusion": " This study offers multiple conclusions with implications for various cases in which it will be desirable to utilize the hype cycle or the technology life cycle. Firstly, this paper demonstrates that hype cycles can exist not only in the IT industry but also in other traditional industries. Secondly, the hype cycle can emerge for each of the various actors constituting the socio-technical system, but these cycles may differ in temporal periods. Thirdly, the two distinctive curves that constitute the hype cycle can be measured by trend analyses of search traffic and patent applications. However, the conclusions must not be overgeneralized to apply to all cases. As argued by J\u00e4rvenp\u00e4\u00e4 et al. [13], among various technologies, there have been differences in the disclosures of information that would enable estimations of the technology life cycle. This is the reason that it will be necessary to continue the study of the hype cycle in other industries and in various other forms of innovation.  Though my case study analysis offers only a limited value for generalization, there are other significant implications that can be derived from this study. In the process of securing a more objective understanding of consumer behavior through a bibliometric approach, I raised the caveat that the promise of a particular technology should not be evaluated based exclusively on the frequency changes found in indices such as search traffic. Consumer groups are not homogenous, and therefore it is possible that the search traffic trend may inversely exhibit a decline during the growth phase. For this reason, a more objective assessment of the promise or diffusive potential of a technology can be made when the life cycle (or adoption model) is simultaneously analyzed in conjunction with the hype cycle. In particular, the hype cycle, which exhibits more dynamic movements compared to the life cycle in the early stage of the introduction of a new product, will enable these changes to be measured with greater ease, and in the same vein, I also demonstrated that from the growth phase the measurement of indices related to the conventional life cycle will provide much information. Also, this paper has confirmed that for the purpose of estimating the speed of diffusion in accordance with innovation diffusion models such as the Bass diffusion model, various indices such as search traffic, news exposure, patents, etc. can be used as the subject of bibliometric analysis. In particular, by verifying that these indices can demonstrate the hype cycle, I confirmed the need for cautious consideration of the possibility of the existence of the hype cycle when applying the innovation diffusion model along with the bibliometric approach. If empirical studies of various industries and types of innovations are hereafter implemented based on the results and methodology presented in this research, such studies will contribute to enhancing the objectivity and explanatory power of various analyses and forecasts utilizing technology cycles such as the hype cycle or the life cycle. Furthermore, I expect that these findings can also apply to the consumer behavior models utilized in many fields such as marketing, thereby even further extending the contribution of this study to the establishment of actual corporate strategies including marketing strategies. One limitation of this study was that it ultimately relied on secondary data for the analysis of user hype cycles, despite the benefits of using Google, which provides a large volume of information regarding raw data and research methodologies. Henceforth, there will need to be various additional empirical research to secure more generalizable conclusions about the hype cycle, as well as additional model research to illuminate the differences between the hype cycles of different actors within the socio-technical system as revealed in this paper. Further research ought to study the impact of decreases in patents and search traffic on the diffusion of technological innovations and new products over the mid-term and long term, as in the case of hybrid automobiles."
        }
    },
    "10.1016/j.techfore.2010.03.010": {
        "file_name": "168 Infrastructure investment for a transition to hydrogen automobiles",
        "title": "Infrastructure investment for a transition to hydrogen automobiles",
        "abstract": "This paper describes work undertaken in the MATISSE project to explore the potential for a sustainable hydrogen transition within Europe and the implications for infrastructure investment. Stakeholder engagement work conducted within MATISSE identified unsustainable aspects of current transport and desirable characteristics of sustainable hydrogen road transport. Key criteria were: emissions reduction, security of energy supply, affordability and economic competitiveness. Results from the ASTRA model show that a transition to hydrogen transport fuels would have an increase in GDP, employment and investment; and growth in a number of sectors (electronic, chemical, mechanical and automotive) associated with hydrogen fuel cell technology. A hydrogen diffusion model shows that in a few years after 2040 all cars in Germany could be hydrogen driven cars. Fast build-up of a network of at least 500 filling stations (in urban areas and at highways) is very important for the market acceptance of hydrogen vehicles and compared with subsidies for vehicles and fuel the necessary investments are very small. For fuel infrastructure: Only a total amount of approx. 200 million Euros are necessary for infrastructure build-up in urban areas. Additional support is needed for installation of hydrogen filing stations on highways (approx. 100 million Euros).",
        "label": "Quantitative",
        "text": {
            "Introduction": " This paper reports on work undertaken within the EU 6th framework MATISSE project (http://www.matisse-project.net) to assess the prospects for a transition to hydrogen fuel vehicles within Europe. The analysis is based on the concept of a technological transition as one of the possible transition pathways identified by case studies in transition theory. In addition to the development and adoption of vehicles, the adoption of hydrogen as a fuel requires the development of a new infrastructure to produce and supply the hydrogen. The question then arises as to what extent the infrastructure development and investment costs form a barrier to the adoption of a technology which requires expensive development programmes for the vehicles themselves? Two models have examined issues of infrastructure provision as part of a transition to hydrogen vehicles. An integrated transport policy assessment model (ASTRA) has been adapted to assess the prospects forand overall environmental and economic impacts ofa transition to alternative fuel vehicles (including hydrogen fuel cell vehicles (FCVs) within transport). Also, a new model has been built to assess the prospects for a hydrogen transition within transport, with a focus on economic policy analysis and exploring the co-evolution or interdependent development of fuel infrastructure build-up and vehicle adoption. Together these tools have enabled us to explore the prospects and sustainability of a transition within the transport sector to a low-carbon vehicle fleet. Both models were calibrated using data for Germany; Germany is a major market for cars with manufacturers in Germany actively developing hydrogen technologies and there are estimates of the necessary infrastructure developments available. Surprisingly, the results indicate that the provision of a hydrogen distribution (as well as production) infrastructure is not a major economic barrier to the adoption of hydrogen vehicles. Transport is crucial for our economic competitiveness as well as for commercial and cultural exchanges [1]. However the current transport system does not correspond to the requirements of sustainability in many respects. Recent studies on the negative impacts of transport systems (e.g., [2][3][4][5][6]) highlight problems for environment and health, including climate change, local air pollution, noise and accidents. To date, policy measures to influence individual travel decisions (e.g., congestion charging, vehicle taxation) have had little effect relative to the underlying growth in demand. In some cases, interventions to reduce demand or foster modal shift have had the reverse effect (e.g. [7]). Similarly, the benefit of technical measures to reduce vehicle emissions and noise has often been outstripped by the increase in vehicle numbers, engine size, travel frequency and trip length [8]. It appears that incremental technological or policy improvement (the current use of the usual fiscal, informational and R&D support policies) is unlikely to be sufficient to address this type of persistent problem. Instead, radical, systemic innovationa 'transition' (e.g., [9][10][11])is necessary to move away from the current road-based transport regime and towards a more sustainable transport system. This radical innovation involves the development of new networks of consumers, suppliers and also regulatory structure, to enable a very different technology to become attractive to society. The literature on transitions highlights the interdependency of institutions and infrastructures constituting societal systems and sub-systems, which has created various types of lock-in that stifle innovation [11]. The dominant transport paradigm constitutes a regime locked-in to a stable state of oil-and car-dependence (personal mobility, using internal combustion and steel chassis technologies) with infrastructure, manufacturing, and consumer behaviours enforcing the regime. In relation to infrastructure, the built environment has co-evolved alongside automobility, so that amenities and workplaces are often only accessible by car. Vehicle manufacturing has developed along 'technological trajectories' [12], which constrains the development of vehicle and fuel technologies to the development of core competences, particularly in internal combustion engine and Buddtype steel chassis [13]. Consumer decisions fulfil emotional-symbolic functions (e.g., status, comfort, safety) as well as practical requirements (space, cost, etc.) [14]. Socio-cultural normsfor example, the expectation that quality of life entails vehicle ownershipand habitual behaviour serve to lock in these preferences and patterns of behaviour [15], presenting a major challenge for tackling unsustainable actions. Due to these psychological, technological and institutional dependencies, there is typically widespread resistance to radical change [16]. This is often described as a 'lock-in' to the current regime and its technology. It is to overcome this lock-in that radical change is necessary. The key insight of this literature for the present analysis is that if there is to be a technological transition, an already existing niche technology must have a supportive policy and socio-economic environment if the take-off phase, where adoption accelerates and the technology becomes widely used and accepted as the obvious next main technology, is to be successful. Therefore, it is necessary to identify a niche and then analyse the conditions under which it can expand and diffuse to become a new regime. Hydrogen-powered vehicles have been recognised as such a niche. This interest in developing and diffusing hydrogen and fuel cell vehicle technologies is based on the assumption that hydrogen offers effective solutions to both emission problems and concerns about security of energy supply, since hydrogen is an energy carrier that: \u2022 is emission-free at final use1 ; and \u2022 can be obtained from a variety of different primary sources and readily stored2 . Furthermore, fuel cell vehicles contribute to reduced noise pollution since: Furthermore, fuel cell vehicles contribute to reduced noise pollution since: \u2022 the drive system is nearly noiseless. In respect of transport technologies, hydrogen and fuel cell vehicles have become a focus of considerable investment by public and private sector organisations in Europe (see e.g., [17]). The European Commission has been investing in a range of hydrogen technology research, development and demonstration projects in recent years (e.g., HyWays, HySociety, Zero-Regio, ECTOS, Renewable-H2, CUTE). Furthermore, the Commission has made the hydrogen economy one of its long-term priorities for Europe's energy system. The Commission has also set a target of substituting 20% of traditional fuels by alternative fuels by 2020, with a proportion of hydrogen vehicles of 5%. Hydrogen and fuel cell technologies also contribute to the Commission's vision of Environmental Technology for Sustainable Development [18] which posits that use of clean technologies can create 'win-win' situations, where economic benefits can be achieved without resulting in environmental degradation. However, the adoption of hydrogen will be dependent on the provision of a new infrastructure for hydrogen production and distribution [20]. This has been extensively debated, with the suggestion that providing this infrastructure will be expensive and time-consuming, if a sufficient number of filling stations are to be provided to make hydrogen vehicles acceptable and if consumers' concerns about safety are to be properly addressed. Assuming that a hydrogen vehicle future would have as many refuelling stations as there are petrol stations today, this implies a very large investment. An important question is that for consumers to buy vehicles, a refuelling infrastructure must already be there, but it cannot be used until people have bought vehiclesa version of the chicken-and-egg problem [21]. Therefore, an initial investment in infrastructure for refuelling is necessary, in addition to investment in vehicles. In the case of hydrogen, society would have to place a high priority on reducing emissions, such that the initial higher costs of hydrogen relative to conventional fossil fuels and their infrastructure are accepted by consumers and firms purchasing new cars. In the current analysis, is assumed that government subsidies are the policy tool that can make the hydrogen technology competitive to at least those consumers and firms who are willing to be technology leaders. An analysis of different policy scenarios provides an insight into the conditions for vehicles and infrastructure necessary for a successful technological transition.",
            "Model descriptions": " Two models were used for the analysis, because they perform complementary analyses. ASTRA provides an assessment of the economic and overall emissions impact of a scenario of hydrogen diffusion, while the hydrogen transition model explores the economic and consumer choice factors that determine the pathway of the diffusion of hydrogen vehicles and infrastructure. The hydrogen adoption scenario developed using the ASTRA model was used as a calibration basis for transition model to simulate successful hydrogen penetration of the automobile market i.e. the achievement of significant sales in the market and diffusion. While the models do not consider all the aspects of a socio-economic transition as discussed in e.g. [9] or [11], they explicitly consider the economic and policy conditions under which a hydrogen niche can successfully expand to form a mass instead of niche market and hence challenge the current fossil fuel vehicle regime. We use Germany as the case study for the analyses. Data on German vehicle sales, average vehicle running costs, vehicle emissions, modal split, and transport demand (pkms) were obtained from the Fraunhofer ISI database, and supplementedwhere necessaryfrom the Eurostat database [22].",
            "ASTRA": "ASTRA (=Assessment of Transport Strategies) is a dynamic simulation model generating time profiles of variables and indicators needed for policy assessment. A detailed description of ASTRA is provided by [23]. The ASTRA model consists of eight modules and the version described in this section covers the 25 European Union countries (EU25) plus Norway and Switzerland. The major interlinkages and feedbacks between the eight modules are shown in Fig. 1. The model includes the technical and economic characteristics of road and rail transport. For this project, hydrogen technologies and a scenario of hydrogen diffusion were added to the set of vehicle technologies.",
            "Modelling a hydrogen economy in ASTRA": " Modelling of a hydrogen economy in ASTRA concentrates on the adaptation of the transport system and its related energy supply. It requires input from other studies concerning (1) the time path of adoption of hydrogen cars and the build-up of hydrogen supply infrastructure, and (2) the build-up of renewables' capacity to produce hydrogen from non-fossil energy sources. The basic framework of the analysis is provided by the business-as-usual (BAU) scenario of the ASTRA model that is extended in particular by inputs on hydrogen technologies from the HyWays project [24] and a study on growth and employment impacts of renewables where ASTRA is connected with the GreenX model [25,26]. Market entry of hydrogen cars is taken from the HyWays project, which involved an intense stakeholder process with car manufacturers and fuel suppliers to develop a scenario for market penetration of H 2 cars [23]. For the presented analysis the HyWays high penetration scenario was taken. For simplification in the ASTRA model H 2 -ICE cars and H 2 -ICE hybrids were aggregated into one category (H 2 -ICE) as well as H 2 -FCVs and H 2 -FC-Hybrids (H 2 -FC). The applied market development of these two categories is shown in Fig. 2. In terms of implementation ASTRA estimates the total purchase of new cars endogenously and then subtracts the exogenously provided numbers of the hydrogen cars to get the distribution between hydrogen-powered cars and conventional cars. In 2030 this leads to shares of hydrogen cars of about 30% of all new purchased cars. In terms of production location of vehicles the structural identity scenario is taken implying that hydrogen cars are manufactured with the same spatial distribution as conventional. It is expected in HyWays that at the time of introducing the first hydrogen cars in 2013 subsidies by the government have to be provided due to the high cost of the fuel cells. These subsidies diminish over time such that the peak of absolute subsidy amounting to \u20ac3 Billion for the EU25 countries, of which about \u20ac700 Million are allotted to Germany, is reached in 2020, though the number of H 2 cars sold continuously increases (see Fig. 2). The higher prices of cars, which is balanced by subsidies, has two impacts in ASTRA: first, car manufacturers increase their revenues and output compared to BAU, and second, a few other sectors that manufacture significant shares of the fuel cell also benefit. HyWays estimates that about one third of a car's price is related to the drive-train. For H 2 fuel cell cars out of this one third  about 30% are assumed to be provided by the chemical sector and 40% by the electronics sector in ASTRA. The remaining 30% are still manufactured by the vehicle sector. Hence, the shares of demand for hydrogen FCVs are shifted from the vehicles sector, which before produced 100% of the drive-train, to the chemicals and electronics sectors, respectively. This sectoral shift of demand affects the sectoral final demand and the input-output-table calculations in ASTRA. Analyses on the cost of producing hydrogen conclude that some production pathways even today are competitive compared with fossil fuels for transport [27]. Under this hypothesis it is feasible to build-up the infrastructure for hydrogen production and fuelling from revenues generated by hydrogen sold i.e. there is no financial need to subsidise hydrogen filling stations. Consequently, the required infrastructure investments to build-up the fuelling infrastructure for hydrogen cars are calculated endogenously from the hydrogen fuel demand of the hydrogen cars in service using the efficiency values from HyWays (25.9 kWh H 2 / 100 km for H 2 -FCVs and 46.4 kWh H 2 /100 km for H 2 -ICEs) in 2010 and an efficiency improvement curve that reduces this hydrogen consumption between 2010 and 2050 by -30%.",
            "Hydrogen transition model": " This model is designed to assess the conditions for a transition to a mass adoption of hydrogen FCVs, through a detailed representation of FCV vehicle and filling station economics and consumers' decisions. The analysis considers three aspects of the introduction of FCVs into the car market: the relations between the stakeholders of the car market, the \"costs\" for the state (subsidies and tax waiving during the introduction phase) and market penetration curves of FCVs. Like ASTRA, the model is a dynamic simulation model. The FCV transition model consists of four modules: the FCV demand and supply module, the attractiveness module, the filling stations module and the module of balance of payments. Fig. 3 shows the linkage between the different modules and their impacts on each other. The four modules are shown as the blue titles. In each time period, the evaluation starts from the current values of the green variables. These then determine intermediate (yellow) variables and output (orange) variables. The \"FCV demand and supply\" module analyses the impacts of the commercial and social attractiveness [28], which summarizes the effects of technical and economic properties of FCVs, on the demand for vehicles with a hydrogen power train. Public demand involves the demand for FCVs which comes from local bounded commercial traffic (i.e. buses, taxis, etc.) and if 50% of the urban commercial traffic switches to fuel cell vehicles, interurban commercial traffic also adopts FCVs. Private demand includes urban and interurban traffic. Social attractiveness is the main indicator representing the influence of the social environment on individual decision of private people [29,32]. The attractiveness module models the consumer view of the attractiveness of FCV. The introduction of hydrogen driven vehicles depends on different parameters, i.e. price and performance of FCVs, range of the fuel tank, costs for hydrogen fuel, share of hydrogen filling stations (HFS) among all fuel stations. Both the commercial and the social attractiveness are based on the Fig. 3. The four modules and their connections. compared utility (CU) function (see Eq. 1). The system elements, which form the compared utility of FCVs, correspond to the price effect (PE), the performance effect (PerfE), the range effect RE, the fuel price effect (FPE) and at last but not least the refuelling effect (RFE). The range effect increases with increasing range of an FCV without refuelling. The refuelling effect increases with increasing availability of filling stations i.e. increasing convenience of refuelling. All effects are ratios between the parameters for FCVs and those for fossil fuel driven ICEVs (internal combustion engine vehicles). CU t \u00f0 \u00de = PE t \u00f0 \u00de\u204ePerfE t \u00f0 \u00de\u204eRE t \u00f0 \u00de\u204eFPE t \u00f0 \u00de\u204eRFE t \u00f0 \u00de:\u00f01\u00de The analysis of the amount of subsidies as well as of tax allowance is done in the \"balance of payments module\". The main elements of this module are the subsidies for urban and highway filling stations, the subsidies for FCVs, the tax deficit and the extra income caused by an extra tax on fossil fuel. Infrastructure is calculated as the number of available urban and highway filling stations (highway FS), the dominating element is the share of urban FS providing hydrogen fuel (only 376 filling stations of the 14.500 German FS are on highways). A standard HFS with 120 tons annual capacity and \u20ac305,000 investment costs is chosen as representative HFS for the model [30]. The number of new filling stations depends on the demand for hydrogen fuel. Initial FSs are also funded by subsidies. Investment in filling stations is calculated using a Net Present Value approach, including subsidies. There is a positive feedback between FCV demand and filling station investment (Fig. 4). The FCV demand and stock have positive effects on the number of hydrogen filling stations (FS) and these in turn affect FCV demand via the attractiveness function (higher number of filling stations increases the attractiveness for FCV from the consumer perspective). Also, if the number of produced FCVs increases, the price of these vehicles will fall. Falling prices will lead to a greater demand and so to a higher production rate. The initial number of filling station is different in different scenarios. This has an important effect, because this strongly influences the starting value of the attractiveness function (Eq. 1) and therefore the speed with which the positive feedback can become an important factor in FCV demand. The number of hydrogen filling stations is asymptotic to the (constant) total number of filling stations.",
            "General assumptions": " It is assumed that a production line (capacity 160,000 vehicles/year) which can produce FCVs and a minimum number of hydrogen filling stations exists at the starting time. Further lines are set up as demand increases. There is a learning curve relation between the price and the number of produced vehicles [31], from \u20ac63,000 at 1500 production to \u20ac24,000 at 2,600,000. Conventional vehicles have a constant cost of \u20ac20,000. Petrol prices are also assumed constant, but the price for hydrogen is strongly affected by the demand for hydrogen fuel, especially in the introduction phase, from 280 \u20ac/kWh down to 20 \u20ac/kWh [31]. The first adopters of FCVs in local traffic are assumed to be in six metropolitan areas (Ruhr area, Berlin, Hamburg, Munich, Stuttgart and Frankfurt) as [32]. Interurban commercial traffic adopts FCVs if the share of local FCVs reaches 50% of the total local used car stock of the metropolitan areas. This value is also the indicator for the establishment of HFS on highways, also subsidised by the State.",
            "Results": "",
            "ASTRA model results for economic growth, CO 2 emissions and investment": " Based on the framework of economic development, energy prices, hydrogen car penetration and structure of renewable hydrogen production described in the previous sections, the hydrogen cars' high penetration scenario of HyWays is simulated with the ASTRA model and the results for Germany are compared to the BAU scenario. Overall, the economic development proves to be positive with an increase of close to + 0.5% of GDP in 2030, +0.3% of employment and a stronger increase of investment by + 2.4%. This increase of investment has several reasons: first, the additional investment into hydrogen production and fuelling infrastructure as well as for the additional renewable capacities required to produce 'renewable' hydrogen are both funded by revenues of selling hydrogen as a fuel; second, the changed structure of final demand reducing non-transport related consumption by 0.5% and increasing it for the purchase of vehicles, triggers stronger investments in other sectors than the sectors losing consumption shares; and third, the wider economic effects following these additional investments i.e. effects like increased employment and income leading to higher GDP, in turn increase demand, and hence produce a 'Keynesian' multiplier effect. A further positive economic impact besides increased investment is the change of imports of fossil fuels. For crude oil this amounts to a value of annual savings in the year 2030 of \u20ac12 Billion for the EU25 and of \u20ac2.8 Billion for Germany with a minor compensation of increased imports of natural gas reaching more than \u20ac1 Billion (EU25) and \u20ac300 Million (Germany) in 2030. Total CO 2 emissions from transport are reduced by about \u22123.5% in 2030. However, emissions from driving decrease by \u22124.6%, which is significantly stronger than the reduction for total transport CO 2 . The reason is that ASTRA calculates the life cycle emissions for the total transport CO 2 emissions and these include upstream emissions i.e. those emissions that are generated during the production of fuel. Since to some extent hydrogen is produced by non-renewables, e.g. gas or by-product hydrogen, some upstream emissions occur such that the change of CO 2 emissions while driving and of total CO 2 emissions differ. The ASTRA results show that a transition to hydrogen transport fuels would have positive economic and environmental impacts. Overall, economic development proves to be positive with an increase of close to +0.5% of GDP in 2030, + 0.3% of employment and a stronger increase of investment by + 2.4%. This increase of investment has several reasons: first, the additional investment into hydrogen production and fuelling infrastructure as well as for the additional renewable capacities required to produce 'renewable' hydrogen are both funded by revenues of selling hydrogen as a fuel; second the changed structure of final demand reducing non-transport related consumption by 0.5% and increasing it for the purchase of vehicles, triggers stronger investments in other sectors than the sectors losing consumption shares; and third, the wider economic effects following these additional investments i.e. effects like increased employment and income leading to higher GDP, in turn increase demand, and hence produce a 'Keynesian' multiplier effect. There are two critical assumptions that underpin the results of the analysis with ASTRA. Firstly, from the HyWays study, there are the market penetration rates of hydrogen cars and associated subsidy levels of hydrogen cars, together with cost of production of hydrogen. Secondly, the positive macroeconomic results are based on the assumption that there is underinvestment in the German economy in the baseline. This is generally acknowledged to be a major issue for German economic growth in the medium to long term, because there has been less investment than desired in recent decades. In this situation, it is not just investment in hydrogen that would improve economic performance, and productive investment will stimulate demand and lead to the multiplier effects described.",
            "Results from the hydrogen transition model: hydrogen vehicle and infrastructure diffusion": " Four scenarios were analysed: a lead scenario of a successful transition to FCVs and three alternative scenarios to examine the sensitivity of the results to the main policy assumptions. In the lead scenario 500 subsidised Hydrogen Filling Stations are set up at the beginning of FCV transition. These 500 filling stations are built up in the six metropolitan areas. Subsidies for FCVs are assumed to equal the cost difference between FCV and diesel cars minus \u20ac2000, assuming that consumers are willing to pay \u20ac2000 more for \"clean\" technology. Besides, the FCV becomes more attractive as the State does not ask for sales taxes at the beginning of market penetration (see above). Another policy achieving a successful market penetration is the tax allowance for hydrogen fuel. In this scenario hydrogen fuel is completely tax-free until the FCV stock reaches a level of 500,000 cars. Having passed this mark the number of FCVs directly affects the amount of taxes on hydrogen. A linear growth relation between the number of FCVs in the system and the tax level is used, whereas hydrogen taxes reach the level of fossil fuel if one million FCVs are in the system. In this case the amount of taxes for hydrogen fuel that is needed for a distance of 100 km is equal to that for fossil fuel needed by a diesel car to cover the same distance. That means that the state has the same tax income from hydrogen fuel as it has now from fossil fuels, if one million FCVs or more are on the roads. The first alternative scenario analyses the importance of subsidies for FCVs during the introduction phase. In this scenario the consumers will not get any subsidies for the vehicles. So the costs for the State will be lower at the beginning of market penetration. The second alternative scenario compares the high level of available hydrogen infrastructure (see Lead scenario) with that of a low infrastructure at the beginning of FCV market penetration. Instead of 500 filling stations only 50 are assumed to be installed via subsidies, before the first cars are in the market. This is also a scenario which reduces the costs in the introduction phase. The third alternative scenario, another cost-reducing scenario, at least at the beginning of market transition of FCVs, is the hydrogen fuel taxing scenario. In this scenario the State introduces hydrogen taxes, even at the beginning of market penetration. So the comparison with the lead scenario should identify the lagging effects of hydrogen taxing policy. Fig. 5 compares the results of the lead and alternative scenarios for the most important output variable, the FCV vehicle stock. The lead scenario shows a transition by 2040, with a fleet of 16 million vehicles in Germany (approximately 30-40% of the total projected vehicle fleet). The alternative scenarios are much less successful, with only the second alternative scenario showing signs of a large scale adoption by 2043 with a fleet of almost 4 million vehicles.",
            "Lead scenario": " The policy-mix and the assumptions in the lead scenario are defined so that the market penetration of FCVs succeeds within an acceptable time period. In fact the FCV stock increases from the starting year 2013 to more than 17 million vehicles in 2040 in Germany, i.e. more than one third of all passenger cars. The development of the FCV stock conforms at first to that of exponential growth (Fig. 5). Later, after 2040, it is assumed that the growth of FCV stock slows and is asymptotic to the upper limit \"total car stock\". The pattern of growth is thus logistic and is typical for the market penetration of innovations [33]. Similarly to the development of FCVs the number of hydrogen filling stations increases very rapidly after 2020 in this scenario. Nearly all of the some 14,700 filling stations are equipped with hydrogen filling pumps in 2040 (Fig. 6). Due to the learning effects in production caused by a higher production rate, the costs of FCVs sink rapidly to the level of diesel cars, so that the state has to subsidy FCVs only for a short period. Fig. 7 shows subsidies and tax deficits for the lead scenario. With rapidly increasing FCV sales the amount of subsidies is high at the beginning. However, after around five years the production costs will fall so much that vehicle subsidies are not necessary anymore. That means the sum of vehicle subsidies given by the state will be less than those which are necessary in scenarios of low penetration, because in scenarios of low penetration the costs for FCVs do not fall as fast as they do in the lead scenario. The same effect can be noticed for the tax deficit. After a short time period with a high level of hydrogen tax deficit the policymakers can ask for the same level of taxes as they do for fossil fuel, because the critical mark of one million FCVs will be achieved. After around ten years these policies will pay off and there is nearly no need for subsidies or tax waiving in the lead scenario. After this the only subsidies necessary are for highway filling stations, if 50% of the vehicles in the six metropolitan areas are FCVsin the lead scenario this occurs in 2025.",
            "Alternative scenarios": " The impacts of vehicle subsidies are significant, if the results of the lead scenario are compared with those of the first alternative scenario. The State keeps its costs at a low level, but the market penetration of FCVs fails, because in the first alternative scenario high production rates will never be reached and so production costs will not decrease. The results of the second alternative scenario stress the necessity of a sufficient starting hydrogen infrastructure. The small number of available hydrogen filling stations blocks the penetration of FCVs and it takes some decades to overcome the wellknown \"chicken-and-egg problem\"that no one buys hydrogen cars because there are no filling stations, but because there is no Fig. 6. Simulation results of the lead scenario (high growth scenario due to favourable policies) -FCV and filling station development. demand, no filling stations are built. In this scenario the State saves some hundred million Euro subsidies at the beginning, but the critical mark of one million FCVs is not even reached in 2040, while the cumulative total deficit rises above the deficit in the lead scenario in 2040. In the third alternative scenario, due to the small cost reduction, it does not make sense to introduce hydrogen taxes at the beginning, because their impacts on the FCV sales and FCV stock are immense. Only 20% of the lead scenario's FCV stock is reached in the third alternative scenario in 2040. Because the FCV stock is lower the demand for hydrogen fuel does not grow as fast as in the lead scenario and so the growth of hydrogen filling stations is slower. While in the lead scenario more than 90% of all filling stations offer hydrogen fuel in 2040, only 20% do so in the third alternative scenario. Therefore the refuelling effect and the attractiveness of FCVs are also lower in this alternative scenario. The main conclusion is that the lead scenario is the only one with a high penetration rate, although the cumulative costs for the State are nearly the same or lower than the costs in the other scenarios. So it is advisable that the State supports the market penetration of FCVs with a higher deficit during the introduction phase, as in the lead scenario. Both price support for hydrogen vehicles and a minimum level of investment in filling station infrastructure are However, subsidy or tax waiving policies are not necessary eventually, because the penetration succeeds. The lead scenario shows a comparable level of market penetration to that assumed for the model analysis with ASTRA (the market penetration is 20% lower than the ASTRA assumption). This shows that the assumptions made for model calculation of ASTRA are optimistic, but seem to be achievable by designing an appropriate policy scheme for market introduction of hydrogen vehicles.",
            "Implications for sustainable transport infrastructure and policy": " The development of a sustainable transport system involves overcoming a current regime that is very strongly locked-in to fossil fuel vehicles. It is therefore a very suitable case for the application of a transition theory analysis. Transition theory considers the levels of landscape, regime and niche. If a transition is to occur, a niche must arise and either grow to form a new regime or force the regime to change to adopt the new technology and practices of the successful niche. The models applied here show that it is possible to simulate the growth dynamics of a new niche technology. This is a wellknown result; the original aspect of this paper is that infrastructure provision does not form a major barrier, if there is a moderate initial subsidy. The major factor here is that hydrogen cars are designed to use the same transport infrastructure as current cars, so it is not necessary to builds a new transport infrastructure network, only the refuelling network has to be developed. The vehicles themselves can also be produced using the current regime technology; it is only the prime mover and power train that involve a change in technology. In transition theory language, the hydrogen vehicle niche has strong complementarities with the regime. The development of a hydrogen refuelling infrastructure may require new entrants for the supply of equipment. Current ownership and operation of filling stations is diverse, with the major international oil companies, national oil companies, but also retailers all owning and operating filling stations. There is also rapid entry and exit in filling stations, because filling stations are operated as single units and the investment for a filling station is not very large. Therefore, if there is a moderate financial incentive, it can be expected that there will be a range of filling station operators prepared to enter the hydrogen niche. At the landscape level, there has to be an increasing consensus in society that climate change is a major social issue that must be addressed, even if it involves considerable initial expense. Only then will there be enough pressure on the regime for the government to provide a significant level of subsidy to the new technology for a considerable length of time, probably up to 10 years in the case of hydrogen vehicles. The hydrogen FCV transition model shows that, since a transition to hydrogen as an energy fuel in the transport sector is a disruptive innovation, relevant support is needed in different areas for a limited time periodin an optimistic case around eight to ten years. In particular, support is needed in three areas: \u2022 subsidies for vehicles (highest support necessary); \u2022 subsidies for at least 500 filling stations (in urban areas and on highways); and \u2022 no VAT and no taxes for hydrogen in the introduction phase (first one million H 2 FCVs). After a period of support hydrogen vehicles will have a lower total cost compared with conventional vehicles (assuming that the cost reduction targets of hydrogen vehicles will be reached; this depends on learning curves). It is important to reach very rapidlywithin around 10 years from the start of the policya certain level of market penetration of hydrogen vehicles and infrastructure build-up. this does not happen, hydrogen will fail. Also, overall financial support is much lower in a case of quick market penetration compared with a low market penetration (this is approximately \u20ac5 Billion overall costs in the lead scenario). If the penetration rate is lower, the State has to do without hydrogen taxes for a longer time period to make hydrogen vehicles still attractive, leading to a higher tax deficit. Financial support is needed to bring the hydrogen vehicle cost down (the policy area of highest priority); additionally, tax policies to support hydrogen are necessary (starting with no tax on hydrogen). The conclusions relating to policy support for vehicles are: \u2022 The State should avoid VAT on hydrogen vehicles to achieve a higher acceptance. \u2022 The amount of subsidies for hydrogen FCVs should compensate the cost difference to ICEVs. \u2022 Without the willingness-to-pay amount of \u20ac2000 per hydrogen the State has to support hydrogen production with an additional \u20ac500 Million to bring down the prices of the vehicles. There are some important implications for infrastructure. A transition to hydrogen cars has the fundamental advantage that the service provided by the vehicle remains more or less the same. It provides personal mechanised transport using the same road network as current road vehicles. This means that the requirement for new infrastructure is limited to refuelling facilities. Our study has shown that for low levels of adoption of vehicles, a small number of filling stations (500) can cover an adequate urban area. Since there are very few filling stations on highways (376 of 14,500 total in Germany) the investment cost is not very high. However, these filling stations must be provided before hydrogen cars are sold on the market, as consumers will not buy vehicles that they cannot fuel. Therefore, filling stations do require an initial subsidy, if the new technology is to be successfully adopted. Fast build-up of a filling station network (with at least 500 filling stations at the beginning) is very important for market acceptance of hydrogen vehicles, and compared with subsidies for vehicles and fuel the necessary investments are very small. This conclusion will also hold if the investment costs of a filling station are up to twice the value assumed. Conclusions relating to policy support for fuel infrastructure are: \u2022 Only a total amount of approx. \u20ac200 Million are necessary for infrastructure build-up in urban areas. \u2022 Additional support is needed for installation of hydrogen filing stations on highways (approx. \u20ac100 Million). However, even with a massive relevant financial support only one third of all vehicles will switch to hydrogen vehicles by 2040. Nevertheless, exponential/logarithmic growth means that in a few years after 2040 all cars in Germany could be hydrogenpowered cars. There are two surprising policy conclusions:The most important result of this work is that the subsidy required to provide enough supply and distribution infrastructure for the initial adoption and take-off of hydrogen vehicles is small, compared with the necessary subsidy for vehicle costs. The common conclusion that the move to a hydrogen transport technology faces a major barrier because of issues of infrastructure provision is not supported by our analysis. However the overall result is that, as shown in other studies, a transition to hydrogen vehicles will take a long time and will require sustained (fiscal) policy support for their introduction. Given the large uncertainties in the future costs of hydrogen vehicles and fuel, policymakers should not solely concentrate on hydrogen technology as the solution for reducing the carbon emissions of transport. It is still necessary to support a range of low-carbon transport technologies. Secondly, the overall impact on the economy is positive: growth and employment increase, because of the increased investment compared to a business-as-usual case. Eventually, there will be large scale investment in infrastructure. This is in contrast to the common perception that environmental technologies are expensive and will therefore divert economic resources away from more 'productive' uses. This, however is quite a general result in the literature on macroeconomic analysis of environmental policies in a world which is not at an ideal economic optimum. In real-world economies with significant unemployment and periods of low demand and economic growth, a policy-driven increase in demand can improve economic performance.",
            "Summary": " This paper describes the work undertaken within the MATISSE project to explore the potential for a sustainable hydrogen transition within Europe and the implications for infrastructure provision and policy for infrastructure support. Two models have examined issues of infrastructure provision as part of a transition to hydrogen vehicles. An integrated transport policy assessment model (ASTRA) has been adapted to assess the prospects forand overall environmental and economic impacts ofa transition to alternative fuel vehicles (including hydrogen fuel cell vehicles (FCVs) within transport). Also, a new model has been built to assess the prospects for a hydrogen transition within transport, with a focus on economic policy analysis and exploring the co-evolution of fuel infrastructure build-up and vehicle development. Together these adapted/new ISA tools have enabled us to explore prospects and sustainability of a transition within the transport sector to a low-carbon vehicle fleet. There are two surprising policy conclusions. Firstly, the subsidy required to provide enough supply and distribution infrastructure for the initial adoption and take-off of hydrogen vehicles is small, compared with the necessary subsidy for vehicle costs. This is in contrast to [34], who find that infrastructure for a transition in the electricity supply system will require major investment. This also supports the findings of [35]. They also use an agent based model to examine the diffusion of hydrogen vehicles and find that the availability of hydrogen refuelling stations is a prerequisite for the widespread adoption of hydrogen vehicles. The main assumptions for these results are that a production line and a minimum number of hydrogen filling stations exist at the starting time. There is a learning curve relation between the price and the number of produced vehicles such that with mass production, hydrogen vehicles are 20% more expensive than conventional vehicles. Petrol prices are assumed constant, but the price for hydrogen rapidly decreases as demand increases. Interurban commercial traffic adopts FCVs and hydrogen filling stations are established on highways if the share of local FCVs reaches 50% of the total local used car stock of the metropolitan areas. Secondly, the overall impact on the economy is positive: growth and employment increase, because of the increased investment compared to a business-as-usual case. There are two critical assumptions that underpin the results of the analysis with ASTRA. Firstly, from the HyWays study, there are the market penetration rates of hydrogen cars and associated subsidy levels of hydrogen cars, together with cost of production of hydrogen. Secondly, the positive macroeconomic results are based on the assumption that there is underinvestment in the German economy in the baseline. The overall result is that, as shown in other studies, a transition to hydrogen vehicles will take a long time (at least 30 years from today) and will require policy support for their introduction. In terms of transition theory, the paper shows how engineering-economy models of technological change can be used to assess the conditions under which a transition can occur. In the case of a transition to hydrogen vehicles, this niche has the major advantage of having strong commonalities with the fossil fuel transport regime. It uses the same road infrastructure and can use the same production technology, with only the prime mover and power train being radically different. It is necessary for climate change to become a strong part of the landscape, such that the regime (i.e. the government part of the regime) is willing to direct considerable public funds to subsidising hydrogen vehicles and to a lesser extend filling stations for a period of up to 10 years until the niche can be expected to take off."
        }
    },
    "10.1016/j.techfore.2014.06.001": {
        "file_name": "186 Responsible innovators",
        "title": "Responsible innovators: open networks on the way to sustainability transitions",
        "abstract": "This paper elucidates ways in which small high-technology companies through using open knowledge networks may contribute to sustainability transitions. The analysis focuses on young university spin-off companies as an important channel for bringing responsible innovations from university to market while it connects the micro-level with the meso-level of networks supporting socio-technical system changes. A conceptual reflection on responsible innovation, openness in knowledge networks and socio-technical systems\u2019 transitions, is followed by an empirical research. Based on a hundred companies and four case studies, the results indicate that responsible innovation is one of the drivers of openness in knowledge networks. However, partner diversity in openness tends to have a negative effect on growth of the companies. Our preliminary evidence indicates that focus (product\u2013market) and selectivity in the choice of partners connected to professional (venture) capital, market access, credibility and complementary assets are highly relevant when it comes to influencing change in socio-technical systems. A discussion of the implications of this study and suggestions for future research close the paper.",
        "label": "Quantitative",
        "text": {
            "Responsible innovation and networks": " There is an increasing awareness that innovative entrepreneurship can play a major role in enhancing changes towards higher levels of sustainability and respond to the world's major challenges concerning food, water, the environment, energy and health. Innovative entrepreneurs recognize new opportunities using existing or new, disruptive, technologies and create new markets in interaction with important players in the socio-technical system [1][2][3]. The idea that sustainability can work as a driver of innovation and entrepreneurship is not new and embraces various types of entrepreneurship, including small ones and multinationals [4][5][6][7]. However, various studies have emphasized a higher level of complexity if innovation is motivated by sustainability goals, mainly due to a higher complexity in learning and innovation networks [8][9][10][11]. This higher complexity refers to a wider variety of subjects (knowledge domains), like regulation, customer needs, industry standards and to a wider variety of partners involved, like public policy-makers, pressure groups, testing institutes, and specialized financial investors. More recently, there has been a renewed interest in the role of entrepreneurial companies, indicated by new pathways highlighted by the World Business Council for Sustainable Development in 2010 [12]. In addition, the emphasis on gearing the innovation process towards societal needs and desirable outcomes is much stronger today than it has been in the past, as evidenced by many high-level policy and strategy EU documents, such as the EU Innovation 2020 strategy, designed to create smart growth, and the Horizon 2020 program, which defines Societal Challenges as one of the main priorities [13,14]. A concept that has increased in popularity in this context is responsible innovation, and connected with this is responsible entrepreneurship. Due to novelty of the use of this concept and the different perspectives ",
            "Contents lists available at ScienceDirect": " Technological Forecasting & Social Change involved, there is not yet a unified set of accepted definitions. In a preliminary way, responsible innovation can be described as a transparent, interactive process by which societal actors and innovators become mutually responsive with regard to the (ethical) acceptability, sustainability and societal desirability of an innovation and its marketable products, as forwarded by Von Schomberg in 2012 [15] and adopted in some European policy documents and processes [16,17]. A broader definition is provided by Owen et al. and Stilgoe et al. [18,19] including a prospective notion in terms of taking care of the future through collective stewardship of science and innovation in the present. This broader definition is translated into three sets of questions of public concern, namely, on the product, the process and the purpose, for example, how will the benefits and risks of the innovation be distributed, how should these be measured and who is in control, and is the motivation behind the innovation transparent and in the public interest [19]. While the above definition is clearly on the (public) governance level, responsible entrepreneurship has been defined on the micro-level of companies already some years ago, (early 2000s) with different emphases. For example, responsible entrepreneurship may refer to the relation with the own workforce and customers, but also to the relation with the community and the environment [20,21] and not necessarily to sustainability goals through bringing innovative products/ processes to market. The definition used in the current paper includes both sustainability aims through innovative products/ processes and the relation with the community as follows: involved in improving healthcare and making healthcare more affordable, in sustainable energy, sustainable transport, energy saving, efficient use of materials (including recycling), and improving safety. As a result of the broader context, R&D of the companies involved deals with a high degree of interaction and knowledge exchange with interest groups, customer groups, testing institutes and policy-makers. Policies supporting responsible innovation aim to avoid innovations that are contested, to focus on areas of societal needs that have been neglected so far, and to carry on developing successful innovations already recognized as responsible, like in sustainable energy [17]. The openness needed in responsible entrepreneurship can be perceived as a particular type of the model of open innovation, as has been forwarded in the general innovation literature in the past decade [22,23]. For example, understanding the needs of customers, as well as increasing legitimacy and credibility by connecting with prominent partners, tends to be vital ingredients in taking steps towards sustainability. However, research into the relation between openness, legitimacy, competitive power and progress in sustainability to date has been sparse, meaning that it is an area that deserves more attention [24][25][26][27]. Also, differentiation in open networks and underlying causes have rarely been revealed, with the exception of a few authors [28][29][30][31]. Gaining progress in sustainability or any other important societal change involving technology is usually perceived through the lens of socio-technical systems [32][33][34][35]. Sociotechnical systems are complex systems in which one or a set of technologies is dominant and changes, like following from responsible innovation, that are detrimental to the system are prevented from taking place by the impact from existing infrastructures, institutions and the vested interests, i.e., the interaction between society's complex infrastructures and human behavior [32,33]. By adopting a multilevel approach to socio-technical systems, a distinction is made between three levels, namely, the niche level, where novelty is created, the regime level, as the structures of current practices and routines, and the landscape level, as the processes of long term change. Using such distinction, pathways to change (named transitions) can be conceptualized [34][35][36]. According to this approach, high-technology companies at the niche level cannot bring about changes in the system on their own, but they can contribute to change by acting in well-selected supportive and powerful networks (niches, platforms). Through a set of interrelated strategies in open networking and resource acquisition and through a strong market (customer) focus, entrepreneurial companies may contribute to system change, eventually by targeting early majority customers [7,26,[37][38][39]. A related perspective is that of technological innovation systems (TIS). The key difference with the socio-technical system is that a TIS is conceived as being built around a particular new technology, like fuel cells. Accordingly, it comprises a set of actors and institutions whose (inter) actions contribute to the development and diffusion of a new technology, but does not necessarily adopt a multi-level perspective [40][41][42][43]. In the take-off phase of a TIS very few actors are involved and institutions may hinder progress of the new technology; however, after some time, the number of actors may grow, supporting networks get stronger and institutions get aligned in order to support the technology. In general, there are two main routes in bringing technology inventions from universities to the market, namely, licensing agreements with existing companies and other organizations, and the creation of spin-offs. Licensing agreements are usually seen as the least complicated and safest way for the university [44,45]. The current study has a focus on university spin-off companies, because these constitute the entrepreneurial route in bringing technology inventions to market. Spin-offs are young and flexible and may cause an entrepreneurial boost, eventually work as a 'trigger' and break with path-dependency in enhancing the emergence of a new technology innovation system. The study thus adopts a micro-level approach and connects the micro-level with the meso-level of networks that potentially support system changes [46]. Although spin-off companies are a channel of knowledge transfer and commercialization, generally speaking they lack resources, like investment capital, marketing skills and market knowledge, and management skills and time, etc. [47,48] and their growth in Europe is on average relatively modest [49] questioning the amount of support to them. A slow and small growth however, does not mean that the efforts of spin-off companies in bringing university knowledge to market may be in vain. Aside from the direct technology transfer or commercialization, there are also effects, particularly in the region, through the labor market and knowledge spillovers on developing regional innovative capacity and supporting economic growth [50]. Given the small growth in general and higher complexity faced by spin-offs specifically dealing with responsible innovation, we assume that such spin-offs need to be careful in the selection of network partners, a phenomenon already addressed for small companies in general [51,52]. To our experience, no study to date has investigated responsible innovation and openness in networking linked to system changes among university spin-off companies. The current paper contributes to the existing literature by connecting responsible innovation to open knowledge relationships at a micro-level, looking at potential impacts on the system level. We draw on a sample of 105 spin-off companies and four in-depth case studies from two technical universities, in Norway and the Netherlands, and address the following questions: ( The paper proceeds with theoretical background (Section 3), followed by the methodology (Section 4) and results of the empirical study (Section 5). In the empirical study, first, a descriptive analysis is provided on the involvement of spin-off companies in responsible innovation and the degree in which the involved ones employ open knowledge relationships. This is followed by a model estimation of open knowledge relationships to identify to what extent responsible innovation acts as a driving factor of openness. Next, attention focuses on growth of the spin-offs, including an estimation of the influence of responsible innovation and openness in knowledge networks. The subsequent case study analysis provides deeper insights into the role of openness in knowledge networks, alongside other factors important in gaining progress in the way to sustainability transition. The paper closes with implications of the results and suggestions for future study (Section 5).",
            "Theoretical background": "",
            "Open innovation and open knowledge relations": " Open innovation has changed the landscape of innovation since the early 2000s. Learning in innovation has become an interactive process involving a wide range of organizations, like suppliers, customers, competitors, and universities [22,23,[53][54][55]. Open innovation can be defined as the use of purposive inflows and outflows of knowledge to accelerate internal innovation and expand markets for the external use of innovation, respectively. Three core processes are involved in open innovation [22,55]. First, there is an outside-in model, which means that innovation within a company benefits from external inputs (inbound), for instance advice from university technicians to spin-off companies in facility sharing at the university. Secondly, there is an inside-out process, which refers to the marketing of ideas, selling intellectual property (IP) and enriching technology by transferring them to the outside environment. Companies that have adopted this practice focus on externalizing their knowledge and innovation to bring ideas to market in a faster way than they could have done through internal learning and development. The third process is the 'coupled' process, which refers to collaborative research and development, in which 'give and take' are a basic condition for success in combining the outside-in process with the inside-out process. Specific cases are co-creation with a launching customer, which happens more often among small university spin-off companies, and co-creation with civic groups (inhabitants) in design projects, such as in sustainable housing. Open innovation in itself is not a new phenomenon. Many companies were already engaged in open innovation before the early 2000s, for instance through outsourcing and research collaboration with lead customers, but the urgency to practice open innovation in a conscious and systematic way has increased over the past decade, due to the increased speed of technology development and an increasing global competition [56,57]. That the role of open innovation varies, like across sectors and technologies, is increasingly understood given the different degrees of within company learning and learning with other companies/organizations, and given the different emphasis on science-based learning and problem-based learning. Also, a different importance of protection of intellectual ownership between sectors may play a role in relevance of open learning [30,58,59]. In the current paper, we focus on openness in knowledge relationships which is a precondition in open innovation; other aspects of open innovation like the nature of the collaboration and joint activities fall beyond the scope of our quantitative analysis, but are included in the case study analysis. In recent empirical studies, a distinction is made between two dimensions of openness in knowledge relations, i.e., the size of the external knowledge pool, called capacity, and the diversity in this knowledge pool [31,53]. Capacity in openness can be seen as being composed of different types of knowledge (domains) and tie strength with the partners involved. Openness diversity deals with heterogeneity among partners in terms of the types of organizations involved, like universities, a large company as launching customer, a small company, public authorities, etc. and the regions of their location. These two dimensions are taken into account in the empirical analysis. A common theoretical approach to company growth is the resource-based view [60,61], in which a company's 'difficult to imitate resources' are seen as determining its competitive advantage. In this vein, open knowledge relations are established when the partner(s) provide(s) knowledge complementarities, which in the case of spin-offs, often refer to support programs (in niches), low cost market entry, (technological) capability building, access to investment capital, etc. At the same time, the spin-offs can only establish such relations if they own sufficient resources by themselves to 'afford' open relationships, like the time, absorptive capacity and skills to search and identify the best partners and to manage the collaboration and benefit from it [62]. There is not much understanding of what exactly drives openness in knowledge relations at the micro-level of companies. The few existing studies point to strategy-related factors, like offensive strategies ('first movers'), the nature of research and development and connected ways of learning [29,30,58] and external factors, like uncertainty due to quickly developing technology or delaying impacts from regulation [23], or a combination of factors internal to the company and external factors [30,31]. Openness may also increase with the increasing learning abilities as the company becomes older and bigger [24,30,[60][61][62], but the increase may slow down due to decreasing returns caused by stiff routines and eventually locked-in situations grown at the same time, pointing to inverted U-shaped relations [53,[62][63][64][65]. What may also happen after some years of existence is that knowledge previously sourced outside the company becomes 'internalized' by improving expertise of the management team, causing a decrease in openness. Factors in the urban environment with regard to knowledge density and knowledge spill-overs, and other agglomeration advantages may also play a role in the need for adopting openness in knowledge relationships, though with different underlying assumptions [66][67][68].",
            "Socio-technical systems and transitions": " We adopt a socio-technical system including the technology innovation system perspective [33,40] in examining the specificities of the technology innovation and the networks, eventually niches, that enable taking steps towards higher levels of sustainability. Technology in itself does nothing, and there are many examples where the adoption of new technology has been prevented by social factors, for example, vested interests in the old technology and its infrastructure, like of gasoline producers and distributors in the case of electric cars and routines in reimbursement among insurance companies in healthcare. The entire socio-technical systemincluding institutionsshould be aligned and coordinated to bring about a transition [32][33][34][35][36]. Transitions towards higher levels of sustainability inhibit three characteristics which prevent them to be achieved in a quick manner [69][70][71]. Firstly, sustainability transitions are goal-oriented, different from some other, emergent, transitions in history. Private actors have limited incentives to address sustainability transitions because the goal is related to a collective good (higher sustainability), implying behavior characterized among others by free riding. Instead, public authorities and civil society are seen as crucial to address collective goods, to change economic frame conditions, and to support 'green' niches [39]. Because sustainability is an ambiguous concept, there are also different opinions about the preferred direction(s) of sustainability transitions, the (dis)advantages of particular solutions, as well as the most appropriate policy instruments. Secondly, sustainability solutions often do not offer obvious user benefits to individuals or individual organizations; by contrast, they mostly score lower on price-performance compared to conventional solutions. This situation makes it unlikely that sustainability innovations will be quickly adopted, without changes in economic context conditions, like regulatory frameworks, taxes, subsidies, etc. Such changes will therefore not be brought about by policy measures without a fierce 'struggle' between vested interests and proponents of the new solution. As a third point, conventional markets in the domains involved in sustainability, like energy, transport, and healthcare are often dominated by large incumbent firms, like electric utilities, gasoline manufacturing, car industry, and pharmaceutical industry. These companies not only own large market shares, they also benefit from their complementary assets, like large scale test facilities, access to distribution channels, supporting service networks, and complementary technologies, in fact all supporting their vested interests. Aside from these circumstances, transitions are often rather unpredictable due to manifold complexity and uncertainty [72][73][74][75]. For instance, cause and effect relations are not always clear, unexpected dynamics may occur, and public policy measures may lead to absence of effects or adverse effects, etc. In these 'tough arenas', young high-tech companies proposing a new sustainability solution may only play a key role if these 'trigger' existing path-dependencies, like in business models, offer a strongly improved price-performance of their solution and connect with the right incumbent firms and their network of complementary assets [4,7,25,26,37,76,77]. Though much is still unclear from empirical research, young high-tech companies also need to link themselves to niche-like networks supported by local policy and civic society, and aimed at providing a certain protection against competition from the conventional technology, including opportunities for experimentation and interactive learning, such that at one point in time they are sufficiently strongincluding credibilityto survive in the conventional system or system that has slightly changed [36,39]. Overall, it seems that as a minimum the networks need to provide access to financial capital and to a large customer (both providing credibility) or to market (channels) and other complementary assets, and enable the spin-offs to perform under niche-like circumstances. Important milestones in such development could be a successful pilot project, the move from pilot production to series production, and some early mass production, if mass markets are involved. It seems that a selective building of networks, including the most beneficial partners, for example, providing access to complementary assets, is crucial given the small resources that young high-tech companies own. Despite similarity, the technological innovation systems involved may vary with regard to degree of rigidness, complexity, uncertainty, internal differences, etc. For example, the health sector tends to be more complex than the energy sector due to a high level of fragmentation derived from the diversity in therapeutic areas and different compositions of large companies active in these areas, and derived from the influence of additional stakeholders, like insurance companies and national approval institutes [26,78]. The traffic technology system with regard to electric vehicles seems also quite fragmented by including stakeholders like automobile manufacturers, battery manufacturers, electricity producing companies, charging equipment producers, car consumers, and public authorities dealing with infrastructure [79].",
            "Methodology": " The research design of this study is exploratory in nature, mainly using a quantitative approach in investigating the involvement of 105 university spin-off companies in responsible innovation and the importance of open knowledge networks in their growth and progress towards sustainability. In addition, four case-studies are investigated to explore through which open innovation networks they contribute to progress in socio-technical system changes. We draw on data from two technical universities in Europe, Delft University of Technology (Delft, the Netherlands) and the Norwegian University of Science and Technology (NTNU) (Trondheim, Norway). No differences are assumed in the national general innovation systems between the two countries, as they share a fairly risk-avoiding entrepreneurship culture, show similar scores on the main European Innovation Scoreboard indicators [80,81] and have relatively small domestic markets. However, in two particular technology innovation systems, there is a difference between the countries, namely, concerning wind energy, which has been promoted more strongly by national policy in Norway, and sustainable vehicle technology, which has been promoted more strongly in the Netherlands. The population of companies satisfied important conditions: they were involved in knowledge created at the university, had an age between 1.5 and 10 years in 2006/7, and enjoyed some support from the incubation organization/university (150 in total). The overall response rate in 2006/7 was 70% and data were collected using a semi-structured questionnaire in faceto-face interviews with principal managers, focusing on the following themes: firm characteristics such as firm size, founding team size and pre-start experience; strategic choice including type of innovation activity (sustainability aim, dominant learning mode) and product/market (focus); and profile and openness of the knowledge networks. In 2012, data were collected from the same companies mainly regarding growth in employment and turnover using an e-mail questionnaire and website study. In addition, the four case studies (2012) included a more detailed analysis of strategic choice, main investors (prominence), other network partners and niche-like conditions, and stage in the process of market introduction (e.g. pilot, small series), all gained to assess the potential contribution of the company and its network to progress in system change. The selection of the four case studies was based on the following criteria: different growth, diverse openness in the networks and different types of technological innovation systems, the last in terms of national support and fragmentation (Netherlands and Norway; energy and healthcare).",
            "Results": "",
            "Involvement in responsible innovation": " A distinction is made between a full involvement and a partial involvement in responsible innovation. The former means that all activities of the company are focused on producing a responsible innovation product or service, while the latter means that only part of the activity can be labeled as such. It is important to note that, in this study, the processes that have led to responsible innovation are not examined, except for the underlying openness in knowledge networks. This means that we cannot identify the values and nature of the processes in interaction with society and economic actors, but we can identify and characterize the nature of the networks, the type of partners involved and concerns related to impacts of the innovation, the last in the case studies only. A small majority of the sampled companies (56%) is engaged in responsible innovation, either fully or partially (Table 1). Conversely, some 40% of the companies are not dealing with responsible innovation in terms of bringing a sustainability product/process to market. Full involvement mostly refers to the medical sector and sustainable energy, both at 19% of all involved companies, with the last sector also partially involvement (at a level of 10%). Sustainable mobility (including vehicle technology) follows with 12% full involvement and 12% partial involvement. Overall, new technology in medical care and sustainable energy and mobility tends to be the most important, at a level of 40% of the full sample of spin-off companies. The medical sector includes new medicines, instruments for minimal invasive surgery, ergonomic furniture and practical help in daily care of the elderly using sensor technology. Sustainable energy refers to new types of solar cells, improved batteries, improved windmills in terms of blades and turbines, as well as energy saving in cooling systems. The explanation of the above composition of responsible innovators may be as follows. The composition reflects the typical specializations at the two technical universities involved, which are in energy, maritime activities, transport and the medical sector, and it reflects the larger opportunities for small companies to be innovative in the medical sector and sustainable energy, compared to for example, industrial process technology and waste treatment/recycling where inventions are more often brought to market by large civil engineering companies. Also the first sectors encompass many different segments increasing the chance for spin-off entrepreneurship, thus, the medical area encompasses diagnostics, medicines, instruments, and health care, thereby covering many different therapeutic areas. Sustainable energy also encompasses many different segments, such as energy production including solar, wind, hydrogen, biomass and hydro, and energy storage (batteries) and distribution. In a next step of identifying responsible innovators, we select only those ones involved in responsible products, processes etc. at a relatively high level of innovativeness (Appendix A). Accordingly, depending on whether using a narrow definition or a broader definition, we can qualify 27% and 33% of all sampled spin-off companies as 'highly innovative responsible innovators'.",
            "Openness in knowledge networks": " We explore to what extent responsible innovators have adopted open knowledge networks using two dimensions, i.e. openness capacity and openness diversity [31,53] (see Appendix 1). The first dimension, openness capacity, is measured using breadth and depth. Breadth is the number of different types of knowledge (domains) and depth is tie strength between the company and partners involved, and these constitute the knowledge pool accessed by the spin-off. The mathematical modelling used is unique in the sense that it assigns weights to three strength variables, namely, frequency of contact, duration of the relation and emotional intensity, using entropy-weight method, which measures the effective amount of information of the data and better reflects reality than other measures [31]. The second dimension, openness diversity, describes the heterogeneity in the social background of partners, including spatial orientation (local versus regional). A distinction is made between partners from large companies and from small ones, government representatives, university professors, (lead) customers, family and friends, financial investors, etc. We may assume that responsible innovation requires relatively high levels of openness in knowledge relationships. Comparing the openness capacity and openness diversity of responsible innovators with other spin-off companies shows that the first are indeed more engaged in open relations, but only as far as capacity is concerned (Table 2). The results are robust because using both the narrow and broad definition of responsible innovators yields statistically significant results. Responsible innovators have an average score of 5.5, compared to 4.4 among the other spin-offs. This pattern indicates that the knowledge accessed differs in number of domains and intensity of partner contact per knowledge domain. The similarity in the openness diversity scores, however, indicates that there is no need or possibility to be engaged with knowledge partners from many different socio-economic circles among responsible innovators compared to other spin-offs, a situation that may be attributed to limited (managerial) capacity and need for a careful selection of a few beneficial partners. In a next step, we explore whether being involved with responsible innovation is a driver of open knowledge relations, in terms of openness capacity and openness diversity. We use multiple regression analysis in which we start with a model including all relevant factors, divided into three blocks: firstly, enabling factors like size (company and starting team) and experience, secondly, strategic choice factors, including among others responsible innovation, and thirdly, one control variable for the region emphasizing a different presence of knowledge sources and knowledge spillovers. Table 3 shows the end-results of the stepwise reduction procedure, namely, the best model structure in terms of largest R 2 and smallest number of factors. With R 2 at 0.52, the openness diversity model is a quite strong model. The results indicate that involvement in responsible innovation plays a clear role among various other factors. Interestingly, while many factors are not significant for both dimensions of openness (capacity and diversity) orif significantshow different directions of influence, involvement in responsible innovation is significant to both dimensions with a positive influence. Responsible innovation tends to drive openness in both dimensions of capacity and diversity, aside from other strategic choices, namely, concerning the nature of innovation activity (science-based innovation for the dimension of openness diversity) and the type of market (strong competition for the dimension of openness capacity). The result that responsible innovation is the only consistent and positive influence on openness capacity and openness diversity may suggest that responsible innovation is a solid and multidimensional driver of openness in knowledge gaining and exchange. Note that company size also tends to positively influence openness diversity (not openness capacity), pointing to relevance of the previously indicated management capacity concerning partners from different socio-economic circles which tends to increase with size [30,52].",
            "Growth trends": " Next, we address the question to what extent beinginvolved in responsible innovation influences the growth of spin-off companies. The literature does not provide clear indications on whether responsible innovators show different growth trends compared to other companies. Based on the idea that more radical innovations are involved in solving sustainability problems, one may expect a slower growth due to resistance from traditional solutions or existing technologies and institutions. On the other hand, one may also assume a stronger growth if the solutions are developed in interaction with (future) users and other stakeholders, and are protected and supported in a kind of niche environment [36,39]. With regard to job growth in the past five years (2006-2011) responsible innovators tend to perform better in the category strong growth, as witnessed by a share of 36% among responsible innovators (narrow definition) compared to 18% among other spin-offs (Appendix C). The last trend also holds for turnover growth, as witnessed by a share of 32% among responsible innovators versus 11% among other spin-offs. Overall, the trends are somewhat ambiguous, witness the class of negative/no growth for job growth, which indicates a relatively large share among responsible innovators, namely, 43% versus 33%, reason why in our next step of the analysis we explore a growth model (Table 4). This simplified model includes both responsible innovation and openness, and also moderating effects between them, as well as two control variables, namely, age of the spin-off and growth strategy set at early age. The narrow definition of responsible innovation is used as it leads to the best outcomes. The results can be summarized as follows. Firstly, the model outcomes show no significant influences of openness on growth, except for a weak trend of negative influence of openness diversity on turnover growth. This trend may conform to our previous finding of absence of a difference in degree of openness diversity between the two subsamples, responsible innovators versus other spin-offs. Secondly, the interesting results are the moderating effects between responsible innovation and openness, indicating an opposite trend for openness capacity  (positive for turnover) compared to openness diversity (negative for jobs). Accordingly, open knowledge relations tend to play a role in the influence of responsible innovation on growth, with a large capacity (knowledge pool) stimulating growth and a large diversity (partners) hampering growth. Apparently, diversity in partners follows an inverted U-shaped pattern in which increase in partner diversity after an early point tends to be difficult to handle due to limited managerial capacity and vulnerability in the uncertain start of a new technological innovation system. This situation suggests the need for a careful selection of the most appropriate or beneficial partners and not to exceed a certain number of them, in other words, a 'selective openness' in terms of diversity [52]. On the other hand, we must also mention that the period of growth taken into account in the study, 2006 to 2011, covers the first years of the economic crises since 2008, in which markets were shrinking and investors became increasingly reluctant, reinforcing uncertainty [82].",
            "A microscopic view on networks and system changes": " The four case studies qualify as responsible innovators, have adopted open knowledge networks and have shown a different employment growth in the past five years (Table 5). All four case studies are relatively young, established between 2003 and 2005, and deal with technology that is protected by patents. Our next analysis focuses on the strategic choices in product-markets (focus or diversified), the types of partners in early and later knowledge networks as well as the main aim of the later networks, niche-like conditions, progress made with regard to testing and pilot studies, and a guess on the potential impact on a higher sustainability. But first we reflect on the responsible innovation. Case study A is involved in wind energy by elaborating a generic technology named boundary layer suction and applying it to the optimal shaping of rotor blades in order to increase energy productivity. This companyfor the time it is still active in wind energyis recently also involved in re-shaping the rotor blades aimed at a reduction of noise annoyance of turning blades. Accordingly, one of the objections against wind energy, particularly on land among inhabitants of living areas, may lose ground on the basis of their solution. Case study B is also involved in wind energy, by focusing on increasing energy productivity, that is by applying a gearless drivetrain in larger turbines on sea and solving problems of stability of the turbine body. Case study C has developed a charger (hardware and software) for electric vehicles that shortens the charging time significantly without damaging the battery, and accordingly has increased the user value of electric vehicles. The main parties that already benefit from the improvement are transport nodes (airports, seaports). In addition, some municipalities in the Netherlands intend to improve air quality in their area through emission reduction and perceive electric vehicles as a solution. Furthermore, electric vehicles produce less noise compared to conventional vehicles and electricity may be cheaper during night, reason why some companies/municipalities consider to make distribution trips (like of beer to pubs and express delivery services of mail/parcels) and collect waste in the city during the night, thereby relieving the traffic burden during the day. And finally, Case study Dactive in a small segment of healthcare, namely, eye carecontributes to getting eye care more accurate and cheaper through laser-based retinal imaging, which is also more comfortable for patients. Through the mobile character of the equipment and ease of connecting to laptops, the innovation is a good solution for developing countries in mobile clinics. The company particularly challenges a better diagnosis of retinal damage from diabetes, an illness which is worldwide increasing, and preventing blindness. Case study A started to reduce its activity in wind energy a few years ago, due to the decrease in national support, and diversified with a broader application of its technology in other products and sectors, like construction of buildings and food processing industry, while remaining active in optimal shaping of vehicles. This situation of a relatively weaker focus tends to exclude a main contribution of the spin-off to change in the wind energy technology system. Aside from reduction of national government support to wind energy, the company is also faced with small domestic players in the Netherlands' wind turbine market. The large diversity in the network originates from the different sectors of application involved, namely, companies as (launching) customer. Case study B illustrates a consistent focus on wind energy while the company benefits from various national support in Norway and actively connects with main players in Denmark (through a subsidiary there). In elaborating a gearless drivetrain and a solution for greater stability of the main turbine body, the company in the past years attracted national government investment and venture capital from consortia, including support by two national test customers, among others Statoil Hydro, and accordingly benefited from niche-like conditions. However, this case study also illustrates a path in which a 2nd generation of the new technology (gearless drivetrain) has to be developed, causing some delay. Job growth of the company is clearly larger compared to the previous case study. Case study C seems most successful and combines a quick growth, namely, 9 full time equivalents per year in 2006-2011, with an increased technology focus and focused network. The networks after 2008 covered various pilots of fast charging stations, dealing with five different knowledge partners: car manufacturer, electricity company, battery manufacturer, public authority (for pilot testing), and multinational electrical installation company. At the same time, the company benefited from national subsidies in research and (more indirectly) favorable taxation on electric vehicles, and from municipalities eager to reduce emission levels in their area. The company also benefited from two rounds of venture capital funding from Canada, by a 'respected' partner in the sector, thus increasing its international credibility. In 2012, the companywith a workforce of 80 peoplejoined its former multinational collaborator, for reasons of accelerating the process of scalingup the production and achieving complementary assets, mainly market access. The multinational perceives itself as world leader in charging equipment due to this acquisition [83]. The fourth case study illustrates a consistent focus on a relatively small part of the medical sector, i.e. eye-care and within that segment on a specific diagnostic field. However, what caused some delay is that market introduction usually has to wait for approval by the US Food and Drugs Administration (FDA). In addition, large-scale market introduction in the near future in developed countries has to wait until the conventional equipment can be replaced in eye-hospitals and eye-doctor practices according to existing replacement regimes. The company was successful in a first market introduction in 2011, right after the FDA approval, and its subsequent success can be attributed to its focus and later networks including national and international venture capital (Switzerland) from the medical sector improving credibility, and collaboration with a market-focused company, providing access to complementary assets concerning market access. The most recent investment allows the company to accelerate the global roll-out of its innovations.",
            "Practical insights from comparison": " Overall, we may note differences between the early knowledge networks and the later networks, particularly the university is involved in the first, while professional venture capital is involved in the last networks (except for case study A). With regard to the number of different partners in the later networks, we may think of five at maximum for already grown companies, as illustrated by case study C, and three at maximum for smaller ones, including a (launching) customer or market-focused partner providing complementary assets, a venture capitalist or other investor from the sector, and a public authority which co-finances research and pilot testing or creates any other niche-like condition. However, the minimum number of network partners needed depends on the complexity in the sector, and in addition on whether a particular partner can serve as a bridge (or platform) towards other partners, allowing the spinoff to be connected without managing the relationships, or can take two essential roles simultaneously, namely, a main investor and testing/launching customer, as illustrated by case study B. Remarkably, two companies (A and B) accessed other regional technology clusters than the one of their location, by means of opening a second site and/or a subsidiary. This illustrates gaining assets in other regions, like subsidy, regional venture capital and access to localized knowledge networks in automotive (Province of North Brabant, the Netherlands) and a variety of assets in Central Denmark for high-tech wind turbines, like new technology and access to various segments of the value chain. Although the companies in all four case studies are active in responsible innovation, only two of them (C and D) can be considered as bringing about changes in the system context in a relatively short time, i.e. seven/eight years after establishment of the company. Considering the previous findings, we may conclude that market introduction and progress on pathways to sustainability are influenced by specific factors in openness in networks, related to the issue of capacity and diversity, including: -Public support on a national or municipal level: This includes a range of measures such as subsidies for research programs, favorable taxation for consumers, financial investment, and acting as a pilot initiator or launching customer. In the absence of such niche-like conditions, spin-offs face a strong uncertainty and tend to diversify. -Professional (venture) capital: This is necessary to finance a refining of the invention or a market introduction; it also provides credibility, particularly if the investment is international and from the sector. -Access to the market: This may work through linking with a launching customer or a market-oriented company; credibility of the spin-off increases if multinational or respected national players are involved. -Complementary assets through the network: These assets include key services, complementary technology and specific market channels, and can be gained through an alliance with a large company, a market-focused company, or an additional site of the spin-off in a leading technology cluster where large parts of the value chain are present. The first condition is beyond the direct power of spin-off companies, but the second to the fourth, along with the need for selectivity in the choice of partners are within the scope of spin-offs' decisions and may serve as broad guidelines.",
            "Discussion and conclusion": " This paper has connected responsible innovation with open knowledge networks and has extended the issue by including potential progress in socio-technical change among a specific type of high-technology companies, university spin-offs. As one of the first, this paper has adopted a micro-level approach linked to the meso-level in the context of socio-technical systems. The main distinctive characteristic of spin-off companies is their lack of resources, including financial capital, time and management experience, but they are also able to break with path-dependency that constitutes a limit among large incumbent firms. A sample of 105 companies was used, in addition to four in-depth case studies. The study showed that almost 60% of the sampled companies engage in responsible innovation, with medical care, sustainable energy and sustainable mobility as the largest sectors, and that some 40% of the companies are not involved in responsible innovation. The emphasis in this study has been on open knowledge networking as an important process characteristic of responsible innovation. The results of the quantitative analysis indicated that responsible innovation drives openness with regard to capacity (knowledge domains) and diversity (knowledge partners), among other factors. However, results on the growth of the spin-offs pointed to a negative influence of openness diversity, calling for a 'selective openness' regarding types of network partners. This finding was supported by case study evidence from which it would appear that for larger spin-offs a set of five different partners and for smaller ones a set of three different partners is the maximum they can manage. However, when one of the partners acts as an intermediary or platform, or can adopt two different roles at the same time, the situation is different and larger benefits can be gained. Connected with this, networks need to provide access to professional (venture) capital and market channels, gains in credibility and access to complementary assets. At the same time, it was also found that the potential of spin-offs to contribute to system changes depends on the systems themselves, including fragmentation and complexity (e.g. regulation in testing), but also the amount of national or other policy support in creating protective nichelike circumstances. Despite the interesting results, this study does have some limitations, the first of which has to do with the relatively limited definition of responsible innovation as a qualification based on the sustainability goal of the product/services being brought to market. A large part of the role of values in the interaction with society was left outside the analysis, and as a result, for example, those responsible innovators that have withdrawn from involvement in a contested technology and the role of civic groups might have been overlooked. The current paper thus gives various unique but partial insights into responsible innovation among university spin-off companies. The second limitation refers to the countries from where the sample was drawn, i.e. the Netherlands and Norway. The results can be generalized on the basis of similarity with a limited number of regional economies encompassing strong maritime and energy clusters and medical clusters, like in Sweden, Denmark and parts of the northern UK (e.g. Scotland). These countries cover a rather small section of the European Union, and together with the assumption that the interpretation of responsible innovation may be culturally defined and context-dependent, this calls for extending the research on other parts of Europe. Future research could first of all focus on a more comprehensive construction of the responsible innovation variable connected with values being negotiated with societal actors, including more attention for value-sensitive design and customer participation [16,17,84]. Secondly, ways need to be found to increase the involvement of university spin-offs in responsible innovation, even though their lack of resources places limits on the possible number of different partners and complexity in open networks. Our preliminary evidence indicated that focus (product-market) and selectivity in partner diversity connected with credibility and complementary assets are highly relevant. These findings need to be tested rigorously, which leads to a third area of future research, moving away from the company to the network and niche, and moving away from a static to a dynamic perspective [85][86][87]. Accordingly, in longitudinal research, networks need to be characterized in terms of benefits and, at the end, an increased competitiveness and outlook on system changes. Regarding longitudinal research, there are sufficient indications that knowledge networks change over time, given the different development stages of spin-offs [48,88]. More solid indicators need to be designed and tested such that they reflect critical events and changes in these networks in relation to transition, while at the same time accounting for differences between the technological innovation systems concerned. Appendix A. Responsible innovation and level of innovativeness. We define highly innovative 'responsible innovators' as category 1 (28 companies) or as category 1 plus category 2 (35 companies).",
            "Appendix B": " The value of openness capacity was calculated as: Cap \u00bc X n i\u00bc1 B i \u00c2 D i \u00f0 \u00de \u00f0 A:1\u00de where n is the number of knowledge domains, like market, technology, etc. The breadth B i is the counted number of partners within a type of knowledge. There are B i partners within the knowledge domain i; each has a \"depth\" as d j (j = 1 \u2026 N), which is a composite variable derived from frequency of interaction (r), duration of relationship (u), and closeness of the relationship (c, M-rank categorical variable) calculated as: u j r j \u00bc r \u00c2 l \u00bc In u \u00fe 1 \u00f0 \u00de c j \u00bc c M 8 > < > : \u00f0A:2\u00de where r j , u j and c j are the frequency of interaction, duration of relationship and closeness of the relationship for the partner j. r \u00d7 l can be seen as \"frequency-distance product\". Next, a weighting method is used derived from thermodynamic theories. Entropy is a measure of the degree of disorder, uncertainty, or randomness of a probabilistic system, while information entropy can also measure the effective amount of information of the data. If there are m criterions and n objects which need to be evaluated, the entropy of the ith criterion is defined as H i : Where H i \u00bc \u2212k n j\u00bc1 f ij In f ij i\u00bc f ij \u00bc r ij \u2211 n j\u00bc1 r ij , and k \u00bc 1 In n \u00f0 \u00de . And we assume that if f ij = 0, f ij In( f ij ) = 0. Basically, the larger the entropy Hi, the less information it is possible to provide. For instance, if most of the partners are judged as very close to the entrepreneurs, the assessment of closeness (r) would not be an efficient indicator for the tie strength, since it cannot provide enough information or distinction to differentiate various strengths of tie. Therefore, the entropy weight of the ith criterion can be calculated by: w i \u00bc 1\u2212H i \u00f0 \u00de = m\u2212 X m i\u00bc1 H i \u00f0A:4\u00de The entropy weights for the three indicators of tie strength can now be calculated, as w u = 0.30, w r = 0.38, w c = 0.32 And the formula for the tie strength is as follows: D j \u00bc w u u \u00c3 j \u00fe w r r \u00c3 j \u00fe w c c \u00c3 j \u00f0A:5\u00de where for D j a higher value indicates a relatively tighter relationship, thus a deeper \"depth\". Diversity describes the heterogeneity of partners' social background, including spatial orientation. The knowledge partner diversity is calculated as:  \u00bc 1 \u00fe EI 2 \u00c2"
        }
    },
    "10.1080/09537325.2014.890706": {
        "file_name": "193 Strategic management implications for the adoption of technological innovations in agricultural tractor",
        "title": "Technology Analysis & Strategic Management",
        "abstract": "Technological innovations in agricultural tractors have revolutionised farming, increased labour productivity and reduced operator's hazards. The purpose of this paper is to analyse the relation between agricultural tractors\u2019 technological innovations and farm size, as well as users\u2019 attitude on environmental impact of agricultural tractors according to their age and years of activity in the farm. Results, concerning Italy, highlight that high technological innovations of tractors are associated to larger farms, which are managed professionally by more efficient and sophisticated agricultural machineries. Empirical evidence also shows that the older the tractor adopters are and the longer they have been working in agriculture, the higher is their commitment to environment protection and safe working conditions. These results could be important for critical strategic management implications to spur technological innovation in agricultural tractors that better satisfy farmer's needs and to support the fruitful adoption of innovations for an efficient and safe modern agriculture.",
        "label": "Quantitative",
        "text": {
            "Introduction": " Agriculture is an area with significant application of high technology and, during the last century, exceptional advances in engineering knowledge have revolutionised farming (Sassenrath et al. 2008). In fact, diffusion of technological innovation by agricultural machines, a vital technological paradigm, 1 has received much attention by economics of technical change since 1960s because it tends to increase the productivity and to generate more social surplus (Rogers 1995;Korsching 2001;Ball and Norton 2002;Wright 2012). The Hicksian concept of induced innovation 2 has been the most important topic of analysis by economics in agriculture (Possas, Salles-Filho and Da Silveira 1996;Sahal 1981a,b;Coombs, Gibbons and Gardiner 1981;Coccia, 2004Coccia, , 2005a,b),b). Agricultural tractors have to cope with complex working conditions and play a vital role in farm operations (Tanelli et al. 2011). They remain the most important machine on the farm and for the agricultural market (Day, Field and Jarvis 2009;Iftikhar and Pedersen 2011;Singh and Singh 2011;Glenna, Jussaume and Dawson 2011;Aubert, Schroeder and Grimaudo 2012). The demand for agricultural machinery is strongly dependent on a farm's income, which is influenced by exogenous variables (e.g. agricultural policy, socio-economic environment, people attitude, climate conditions and public policies). In recent years, the European crisis (Coccia 2012) and structural changes in European agriculture have affected income and R&D investment behaviour (Coccia 2009a), increasing the level of uncertainty and reducing farmers' propensity for new equipment investment with higher technological content (Vieweg 2012). An interesting problem for the economics of innovation and management of technology, in the agricultural industry, is to analyze the attitude of users towards the technological innovations adopted in agricultural tractors. Considering this context, the purpose of the paper is to answer the following research questions: (RQ1) Does farm size structure affect the adoption of new technological innovations in agricultural tractors? (RQ2) How does farmers'age affect their sensibility to environmental impact of agricultural tractors? In order to analyse these issues concerning structural change and dynamics of innovations of agricultural tractors in farms, the paper is laid out as follows: section 2 describes the theoretical framework of the study, whereas section 3 presents the hypotheses and research design; section 4 shows the empirical evidence and discusses the relationship between observed facts. Then concluding remarks are drawn.",
            "Theoretical background": " Current technological innovations in agricultural tractors are generating several technological trajectories to improve efficacy, efficiency and safety (Da Silveira 2002;Kemp, Schot and Hoogma 1998). These technological trajectories are, in general, driven by demand-pull and technology-push forces associated to learning processes (Dosi 1982(Dosi , 1988;;Nelson and Winter 1982;Consoli 2008). In particular, demand and technological opportunities can affect the direction of technological advance in agriculture. Teece (2008, 509, original emphasis) argues that: Technological paradigms impose behavioural structures associated with 'normal' problem-solving activity. Paradigms imply the use of established problem-solving routines; they indicate where to focus resources and help identify blind alleys to avoid. Nelson (2008) seeks to pinpoint the causes of fruitful scientific advances of technological paradigms in some fields in comparison with other fields that have scientific and technological infertility. Some determinants, according to Nelson (2008), are the economic and human resources invested to find a solution to 'relevant problems' (Dosi 1982(Dosi , 1988)), and to a lesser degree \"'effective demand\"' (Nelson 2008, 487). As a matter of fact, advancements in some technological pathways are easier than others and an intensive scientific research activity can support a faster progress of some technological paradigm, though 'relationships between the ability to advance practical know-how and the strength of scientific knowledge underlying that know-how are complex' (Nelson 2008, 487). Technological trajectories also depend on other elements in addition to economic resource such as effective demand, institutional interest, needs of society and scientific research (Rosenberg 1983;Da Silveira 2002;Kemp, Schot and Hoogma 1998). Nelson (2008) claims that the evolutionary growth of knowledge and technology is also supported by a process of accumulation based on the ability to identify, control and replicate practices, in other words, the technological progress is based on 'a certain amount of the \"routine\"' (Nelson 2008, 488;Nelson and Winter 1982, passim). In general, the technology incorporated in a tractor has a considerable influence on tractors' production costs and on retailers' price. A global company, for example, sells the same basic concept of an 80-100 hp (horse power) tractor in India for US$150/hp, in China for US$250/hp and in Europe and North America for US$1400/hp. The remarkable difference is mainly due to the increasing complexity in safety, comfort and environmental technical solutions adopted (Von Pentz 2011). The modern farm tractor has a design very similar to that of the self-propelled steam traction engine of the late nineteenth century (Sahal 1981a, 132). In the statement of Baker (1970, 32): 'the tractor has evolved around an essentially unchanged configuration. The only true innovation has been the three-point linkage and control system.' Patterns of technological innovations of agricultural tractor are based on minor and major innovations, as a consequence of an accumulation of design and production experiences over time. Nowadays, most of the technological innovations of agricultural tractors are due to improvement of safety and comfort for users and reduction of the environmental impact (cf. Coccia 2009b). For example, exhaust emissions from diesel engines fitted on agricultural tractors have a detrimental impact on human health and environment. In order to reduce these emissions, the European Union (1997) has, over time, introduced strict emission requirements requiring the adoption of catalytic converters or particle filters. Larsson and Hansson (2011) notice that some technological innovations, such as diesel oxidation catalyst (DOC)/diesel particulate filter (DPF) systems decrease the impact on human health, while selective catalytic reduction (SCR) catalytic converter decreases the acidification and eutrophication impact. In general, the adoption of agricultural tractors and associated technological innovation in agriculture have played a main role for increasing the productivity (Coccia 2008). Sahal (1981a) remarks that advances of technological innovations in agriculture can be driven by some characteristics of the farm system and organisation, rather than a change of the farming system in response to the technology. For instance, the garden tractor has been necessitated by the needs of very small farms (Sargen 1979). Baker (1970, 391) claims that: 'The future of tractors appears most vulnerable to new methods of land preparation, planting and cultivating'. In addition, Sahal (1981a, 137) argues that long-run development of tractor technology is likely to be driven by farm organisation and farm size structure and this one-way dependence of patterns of technological innovation could persist in the foreseeable future. To sum up, considering this theoretical framework, we proceed to analyse some vital epistemological positions concerning the adoption of technological innovations concerning agricultural tractor in farms.",
            "Hypotheses and research design": " The study here explores the role of scale factor and farmers' environmental attitude in relation to agricultural tractors innovations. The research questions, described above, can be used to design the two scientific hypotheses (HPs) that we are going to test: (HP1) Scale factor of agricultural tractor innovations: agricultural tractor innovations are positively associated with larger farms. (HP2) Adopters' environmental learning: agricultural tractor innovations that reduce environmental impact are positively associated with higher farmers' expertise. The purpose of the present study is to see whether statistical evidence supports the hypotheses. The results can be important to understand the socio-economic conditions that support new technological trajectories in agricultural tractors as well as the determinants of the strategic change of farms. 3",
            "Study questionnaire": " A survey was carried out during the 37th edition of the most popular event in Italy in the field of machinery technologies for agriculture: the International Exhibition of Agricultural Machinery (EIMA). During the event over 300 questionnaires were filled up by owners and/or users of agricultural tractors, randomly selected among the people visiting the agricultural tractors pavilions. A computer-assisted personal interview was used to administer the questionnaire, designed using web-based survey software (www.surveymonkey.com). Data were collected on a group of mobile devices (iPads) and trained interviewers administered the questionnaire, assisting respondents if needed (Ferrari et al. 2013). The use of the iPad as a survey instrument has undoubtable advantages over traditional paper-and-pencil questionnaire and provided a new and engaging way to gather information (Greenlaw and Brown-Welty 2009). The questionnaire is a close-ended structured instrument, divided in 10 sections, containing both objective contents and attitudinal/opinion questions (subjective content). Table 1 shows the information included in the questionnaire: background data on the farm (i.e. farm size and number of tractors) and on the user, such as work type, years of work and age group (objective content). Other questions concern the opinions of farmers on what they consider important in tractor usage and what technological innovations are useful for (subjective content). Additionally, among a list of technological innovations available on the market (see Table 2), they were asked to express their opinions on the more useful innovations (subjective content), to list those they have and those they do not have on their tractors (objective content) and finally to report the innovations they wished their tractors were equipped with (subjective content). To gather the opinions farmers we apply a four-point Likert scale (very much, somewhat, a little, not at all).",
            "Data analysis": " Data analysis has been conducted exclusively on subjects who affect directly the tractor market, being those who make the actual purchase of machines. The data set was cleaned by removing students, people working in the agriculture machinery trade or service sector and people whose primary work activity is not related to agricultural sector. As a result, 228 questionnaires, accounting for 75% of the total number, were analysed. Descriptive analysis was conducted with SPSS statistical software version 17 (SPSS 2007). In order to know the relationship between and among the variables investigated chi-square test (\u03c7 2 ) and Cramer's V were calculated. While the \u03c7 2 value is affected by both the strength of the association between the two variables and the size of the sample, Cramer's V removes the effect of the sample size, leaving a measure of the strength of the relationship between two variables. To investigate the direction of relationships, Spearman's rank correlation coefficient a nonparametric measure of statistical dependence between two variables was calculated as well as for all variables representing ordinal measures. Additionally, a multiple correspondence analysis (MCA) was conducted using R software, applying FactoMineR (Escoffier and Pag\u00e8s 1994) and CA (Nenadic and Greenacre 2007) packages. The percentage of explained variance of the first two factors was re-evaluated using the Benzecri (1973) method.",
            "Empirical evidence and discussion": " The analysis is applied considering a main case study: Italy. In 2008 Italian farms had about 1.75 million tractors (Unacoma 2008), placing Italy third in terms of international tractor fleets after USA and Japan (World Resources Institute 2012). Italy is a world leader in tractor production [CVT] Continuously variable transmission Tractors are equipped with mechanical transmissions that offer a fixed number of gear ratios. CVTs can change steplessly through an infinite number of effective gear ratios between minimum and maximum speeds. CVTs provide better fuel economy, enabling the engine to run at its most efficient revolutions per minute (RPM) for a range of vehicle speeds. Alternatively, CVTs can be used to maximise tractor's performance by allowing the engine to turn at the RPM at which it produces peak power making possible to improve productivity, work precision, energy efficiency, environment protection and driver comfort (Renius and Resch 2005). The most known CVT is the 'Vario' transmission developed by Fendt and produced since 1996. Its outstanding success motivated competitors to follow and design CVTs solution for their tractors. [GPS] Assisted guidance system In agricultural tasks, tractors usually need to follow a trajectory equidistant to a previous pass. This action can be easily accomplished when the tractor is equipped with an assisted global positioning system -GPS (Yao, Zhang and Minsan 2005), a guidance system that controls the tractor along a trajectory (Bell 2000). The system uses a combination of a positioning system, tractors' onboard sensors, a computer to process the information and mechanisms to control the trajectory, relieving the operator from many of the tasks involved in guiding a vehicle. [NCfuel] Alternative fuels Considerable attention has been paid to alternative renewable liquid fuels production (Hansen, Zhang and Lyne 2005). Biodiesel is the most relevant fuel for tractors because it does not require modifications in existing diesel engines (Patterson et al. 2006), can be used directly or as blends with diesel fuel (Demirbas 2009), and only a small decrease in performances is reported compared with mineral diesel (Bozbas 2008;Tomic et al. 2013). Biodiesel is derived from edible and inedible vegetable oil, animal fats, used frying oil and waste cooking oil. This fuel can contribute to reduce the global warming and environmental degradation. [POWER] Overpower/Power-boost It makes possible to deliver additional engine horsepower in specific working conditions, such as high-power PTO (power take-off) applications and road transport operations, improving the tractor's efficiency. [RD] Remote diagnostics system Recent advances in remote communications and embedded system technologies have led to share in-vehicle sensors and diagnostic information with remote computers, enabling remote vehicle diagnosis, communicating when maintenance is necessary (You, Krage and Jalics 2005). [ISO] ISOBUS/CAN-bus ISO 11783 (International Standards Organisation 2007) is a standard for electronics communications protocol for agricultural and forestry equipment based on controller area network (CAN) data bus developed by Bosch Company (Cox 2002). This standard has been developed to meet the needs for electronic communication among sensors, actuators, control elements, information-storage and display units embedded in tractors, implements, and other self-propelled agricultural machines. It supports precision farming applications, operator interfaces and communications with an off-board management information system. The system can be used to coordinate machine components, to allow information to be shared among components of a machine and to be distributed across components of a machine (Stone et al. 1999;Renius 2009). [Speed] Speed greater than 40 km/h Since 1994, responding to customers' demands to increase tractors' transport performance, manufacturers started to offer tractors with a maximum speed higher than 40 km/h. All major tractor manufacturers are now offering tractors at 50 km/h. [ABS] Assisted braking systems The assisted braking system gained great popularity in agricultural tractors. Compressed air and hydraulic brake systems are integral parts of the tractors or available as retrofitting components. [FLEET] Fleet Management Fleet Management is a tool commonly adopted in transport and construction business to improve fleet of vehicles operational measures (S\u00f8rensen and Bochtis 2010). Agriculture application of fleet management systems permits to have better timing of field work and co-ordination of available equipment, resulting in less traffic and number of trips, more adequate co-ordination of transport vehicles and site-specific accumulation of goods, machinery use and decrease in energy and labour costs (Auernhammer 2001). [ELECT] Electric actuators Current manufacturers present agricultural machines with electrical driven actuators: trailed sprayer from Amazone region, mechanical and pneumatical fertiliser spreaders and pneumatic seed drill from Rauch. The benefits are the optimised controllability and distribution of power flows across and between agricultural machines, real 'plug & play' for implements, increased flexibility in arrangement of components, enhanced productivity and operator comfort, and reduction of input costs (Buning 2010). (Unacoma 2008) and its agricultural machinery manufacturing industry is made out of large globally active groups and small and specialised companies that are closer to their clients and better placed to know their needs (cf. Vieweg 2012). In general, large companies dominate the tractor market and roughly 80% of the vehicles are manufactured by 20% of the manufacturers -(Pareto principle, Vieweg 2012). In 2008 and 2009 the Italian agricultural tractor manufacturers assembled more than 27,000 vehicles. In 2011 this number decreased to 23,500 units, as a consequence of the global financial crisis (Coccia 2010;Federunacoma 2012). Approximately 1,729,000 farms are operative in Italy, utilising an area of 12.7 million hectares (ha) 4 (Istat 2005). Based on data of The National Institute for Statistics of Italy (Istat), 80% of farms are smaller than 5 hectares and their average size is 7.6 ha (Istat 2009). Moreover, Italy has a farm tractor density of approximately 138 every 1000 ha; this is higher than Germany (85.8), France (64.5) and the USA (26.8) (World Resources Institute 2012). More than 75% of the analysed sample is represented by farmers. Figure 1 and 2 show that the majority owns or works in a farm larger than 20 hectares and deals with a number of tractors between 4 and 6. Table 3 displays main results concerning the relation between variables.",
            "Test of HP1": " A significantly strong association is found between farm size and comfort, acknowledged for its importance in tractor usage; in the larger farms, more comfort in agricultural tractors is recognised as an important aspect (No. 1). Moreover, farm size has an association statistically significant with many technological innovations. In particular, the larger the farm is, the more useful the technological innovation is believed to be: assisted guidance system (No. 7), CVT (No. 8), overpower/power-boost (No. 9), and remote diagnostics system (No. 10). The only exception to this positive association is related to the opinions on alternative flues (No. 11). In contrast, remote diagnostics systems (No. 12) and fleet management (No. 13) are significantly associated with the number of tractors in the farm to support the efficient management of farmers. A graphical representation of relationships between variables is reported in Figure 3 by MCA. The variables with objective content are directly applied for computing the factorial plane, while variables with subjective content are added as supplementary information. A significant contribution to the interpretation of the MCA output is given by respondents' ownership of technological innovations (participants reported the technological innovations available on the market that they had, or not, already adopted: variables labelled OWN_[X] and NO_[X]; where X = technological innovation, such as GPS, ABS, etc.) and by the technological innovations they wished their tractors were equipped with (variables labelled Next_[X]). Figure 3 shows, on the right side of factorial plane, the adoption of technological innovation on agricultural tractors (dark gray boxes). In fact, a dichotomy is visible between farmers positioned on the left area of the quadrant (i.e. those who do not work with tractors equipped with technological innovations) and those on the right area (i.e. those who have these technological innovations on tractors). Farm size (circled) and fleet dimensions (underlined) present a similar pattern. The smaller farms, both in terms of size and fleet, are positioned on the left side of the graph (the less technological area), while on the  1) and questions on technological innovations desired (10 in Table 1). Note: CVT: continuously variable transmission; GPS: global positioning system; NCfuel: alternative fuels; POWER: overpower/power-boost; RD: remote diagnostics system; ISO: ISOBUS/CAN-BUS; Speed: Speed greater than 40 km/h; ABS: assisted braking systems; FLEET: fleet management; ELECT: electric actuators. Source: Ferrari et al., 2013. right-hand side of the factorial plane (the more technological area) we find larger farms (both in terms of size and of fleet). Hence, the first dimension (horizontal) shows the presence (right-hand side) and the lack (left-hand side) of technological innovations on agricultural tractors. In short, the statistical evidence seems to support the HP1 that technological innovations in agricultural tractors are positively associated to larger firms.",
            "Test of HP2": " A significant association emerged between age and importance given to the reduction in environmental impact in the use of agricultural tractors. The literature suggests that younger people are more environmentally concerned than older people (Olli, Grendstad and Wollebark 2001). On the contrary, the analysis shows a weak but statistically significative positive correlation between age and importance of low environmental impact (No. 2; see r s ). People aged 46-55 assigned the highest score to the importance to reduce the environmental impact of tractors. (cf. Figure 4). Nevertheless, a significant association is found between the importance assigned to the environmental impact in agricultural tractor usage and respondents' years of activity (No. 3; see \u03c7 2 ). Respondents working in this sector for more than 10 years seem to consider very important a low environmental impact in tractor usage (No. 3; see r s ) (cf. Figure 5). At the same time, the more years they had spent working in this field, the more they believed that technological innovations of agricultural machines enable environmental impact reduction (No. 6). The hypothesis of adopters' environmental learning effect concerning the technological innovations of tractors is supported by other critical relationships. In particular, farmers working in the agricultural sector for more than 3 years believed that technological innovation increases agricultural machine safety greatly compared with farmers who had recently (less than 3 years) started working in this field (No. 4). Similarly, years of activity is significantly related to the technological innovation that amplifies machine reliability (No. 5; see \u03c7 2 ), showing that the more years farmers are working in the agricultural field, the more they consider that technological innovation increases machine reliability (No. 5; see r s ). In brief, the statistical evidence tends to support the HP2 that technological innovations in agricultural tractors that reduce environmental impact are positively associated to higher expertise by farmers.",
            "Lessons learned and concluding remarks": " In advanced countries, since the 1990s, the trend of the technological innovation is driven by the development and adoption of sophisticated technology by the introduction of electronics and information and communications technologies (ICTs) within all areas of agricultural machinery (cf. Vieweg 2012). Knowing the preferences, expectations and needs of tractor operators could improve the allocation of human resources, budgets of innovative projects and founding of agricultural subsidies. The empirical evidence supports that technological innovation in tractors is relevant for larger farms (HP1). Large farms are managed more professionally and require more efficient and sophisticated machinery. On the one hand, groundbreaking technological products of tractor engineering are targeted to professional farmers, where manufacturers can capitalise on these trends (Richenhagen 2009). On the other hand, technological innovation in tractors is not the main characteristic taken into consideration by agricultural users (eg. workers). The evidence shows that technological innovation is very important to improve comfort and safety. In particular, comfort is important especially for larger farms, where the workers spend several hours on agricultural tractors. In short, the evidence highlights that high technological innovation tends to be associated to larger farms. In contrast with the literature (Olli, Grendstad and Wollebark 2001), the evidence here shows that the older the tractor users are and the longer they are working in agriculture, the higher is their commitment to environment protection and safe working conditions (HP2). This result seems to suggest the need to improve the environmental and safety education among young and new tractors' users. Nevertheless, the study reveals a general interest on environment protection, especially when alternative fuels are considered. It is less available and highly desirable among the innovative technologies investigated. These conclusions are of course tentative. There is need much more detailed research into the relations between adoption of technological innovations in agricultural tractors, scale factors of firms and environmental attitude of adopters."
        }
    },
    "10.1016/j.enpol.2012.01.041": {
        "file_name": "2 Decarbonising the power sector via technological change",
        "title": "Decarbonising the power sector via technological change -differing contributions from heterogeneous firms",
        "abstract": "In the power sector, technological change is a key lever to address the decarbonisation needed to avoid dangerous climate change. Policy makers aim to accelerate and redirect technological change by targeting relevant firms via climate policy, e.g., the European Union Emissions Trading System (EU ETS), and climate-relevant technology policies, e.g., feed-in tariffs. Changes in firm's behaviour, i.e., their research and development (R&D) as well as diffusion activities, are at the heart of technological change. However, firms are heterogeneous actors with varying attributes which perceive policy differently. Hence, they can be expected to react very heterogeneously to these new policies. Based on an original dataset of 201 firms, we perform a cluster analysis grouping firms along their R&D and diffusion activity changes. We then compare these clusters with regards to the characteristics of the contained firms. Our analysis results in seven clusters showing very diverse contributions to low-carbon technological change, suggesting potential for policy to become more effective. A comparison of the firms' characteristics allows us to derive indicative recommendations on how to adjust the policy mix in order to induce contributions from most firms in the power sector.",
        "label": "Quantitative",
        "text": {
            "Introduction": " Climate change resulting from anthropogenic greenhouse gas (GHG) emissions is a major challenge for societies worldwide (IPCC, 2007a). While the power sector is one of the main sources of GHG emissions, it also has high decarbonisation potential 1 : The International Energy Agency (2010) assumes that it could contribute over 40% of the 21 billion tonnes CO 2 emission abatements that are needed by 2035 to achieve the 450 ppm target. 2 Besides unlocking the large demand-side efficiency potential, the development and diffusion of renewable energy technologies (RET), carbon capture and storage (CCS) and highly efficient fossil fuel power plants are key levers for achieving these emission cuts. 3  While the IEA estimates that the specific CO 2 emissions of power generation will drop to a quarter of today's value by 2035, other scenarios are even more aggressive (IPCC, 2011;Krey and Clarke, 2011 provide recent Scenario overviews). Notwithstanding the differences in the assumptions of each scenario, they all conclude that technological change (TC) must be accelerated and redirected onto a low-carbon pathway if the 450 parts-per-million (ppm) target is to be achieved. This has to happen in a timely manner, given that global emissions continue to rise strongly (ESRL, 2010). In spite of the fact that low-carbon TC is the most important factor for achieving the 450 ppm target, it is not yet well understood (Pizer and Popp, 2008). This paper focuses on the role of policy, which aims at the decarbonisation of the power sector, in inducing an acceleration and redirection of technological change (TC). The European Union (EU) and its member states have introduced and reinforced climate policy and climate-relevant technology policies (del R\u0131 \u00b4o, 2009;Rogge et al., 2011b;Sijm, 2005) with the aims to reduce emissions at low cost and spur innovation (European Commission, 2005). The few studies to date that have analysed the effects of these new policies (for an overview over the role of the EU ETS see e.g., Zhang and Wei, 2010) on lowcarbon TC mostly stem from the neoclassical environmental economic school or from evolutionary innovation studies. While environmental economists look at the role of policy for inducing innovation at a sectoral level, assuming rational firm behaviour (for a recent overview see e.g., Popp et al., 2010) scholars stress the role of the tactiness of technology and firm heterogeneity (Dosi, 1997;Nelson and Winter, 1982). They argue that in order to study the role of policy in the acceleration and redirection of TC, it is vital to look at the level at which innovation takes place: the firm level. 4TC encompasses three interacting stages, from invention via innovation to the diffusion of new technology (Schumpeter, 1942). As such it is a non-linear process over time (Dosi, 1997;Silverberg et al., 1988), which is embedded in a historic and institutional context (Dosi, 1988;Malerba et al., 2001). Firms contribute to technological change via two activities: research and development (R&D) and diffusion activities. The former refers to activities from basic laboratory research to the development of marketable products (Gatignon et al., 2002) and encompasses the first two stages of Schumpeter's definition of TC (invention and innovation). The latter encompasses the production and sale of new technologies by producers and the adoption of these technologies by users (Ashford, 1993;Gort and Konakayama, 1982) and refers to the last stage of Schumpeter's definition (diffusion). Thus far, empirical studies looking at the effect of climate and climate-relevant technology policies on TC using firm level data are either of qualitative nature (e.g., Cames, 2010;Ikkatai et al., 2008;Rogge et al., 2011b), focus on a single innovative activity, i.e., R&D or diffusion (e.g., Laurikka and Koljonen, 2006), and/or analyse both activities separately (e.g., Rogge et al., 2011a;Schmidt et al., 2011). However, firms typically consider both activities simultaneously in order to arrive at a consistent investment decision (Lavie et al., 2010;March, 1991). Hence, there is a lack of quantitative analyses looking at firms' integral behaviour, i.e., the totality of a firm's decisions on how to devote resources to the R&D and diffusion activities of different technologies. Of particular interest for policymakers is how firms adjust behaviour in new regulatory environments. Such information may be used to answer the question of whether readjustments of the policy mix are needed. Firms are expected to change their behaviour in different ways; i.e., a population of firms is expected to exhibit behavioural heterogeneity (Nelson, 1991). Observing behavioural heterogeneity, i.e., whether firms change their behaviour to which extent and how, can provide quick feedback on the state of the acceleration and redirection of TC. The behavioural heterogeneity is explained by the different characteristics of the firms, i.e., their characteristic heterogeneity (Nelson, 1991). Should the findings on the behavioural heterogeneity show a need for policy readjustments, information about the characteristic heterogeneity of firms is also valuable for policy makers. Knowing which kind of firms follow a certain pattern of behavioural change allows for deriving policy recommendations for specific actors and thereby addressing the question of how to adjust the policy mix. By covering both aspects, the behavioural and the characteristic heterogeneity, we address the following research question: How do firms with diverse characteristics differ regarding their contributions to low-carbon technological change in the power sector? In order to address this question, we analyse original survey data on power generators and power generation technology providers in seven European countries. First, we perform a cluster analysis to identify different patterns of corporate behaviour changes. Second, we compare these clusters regarding observable firm characteristics. The paper is structured as follows. We develop a research framework in Section 2, explaining our variables and highlighting both important aspects of the heterogeneity of firms in the power sector. We then present the surveyed variables, provide details about the sample of firms and explain the statistical methodologies applied in Section 3. From the results portrayed in Section 4, we derive recommendations on whether and how to improve the existing policy mix in order to better target heterogeneous firms in Section 5. The paper is concluded in Section 6.",
            "Framework": " TC can be analysed on different levels. While most environmental economists analyse the role of policy for TC on a sectoral level (e.g., Betz and Owen, 2010;Weber and Neuhoff, 2010), evolutionary innovation scholars inscribe a central role to the actors involved in innovation, e.g., firms, stressing their heterogeneity (Dosi, 1997). We follow this tradition and, rather than analysing the role of the policy on the sectoral level (compare the dashed arrow in Fig. 1), descend to the firm level. The findings generated at this level allow us to draw initial conclusions on the acceleration and redirection of TC at the sectoral level. Fig. 1 depicts our framework and can be summarised as follows. Various policy elements affect firms with heterogeneous attributes differently. Consequently, their reactions in the form of behaviour change can vary strongly. This in turn is likely to affect the acceleration and redirection of TC. In the following we explain our framework, starting with the acceleration and redirection of technological change and moving in an anti-clockwise direction.",
            "Acceleration and redirection of technological change": " For an acceleration and/or redirection of technological change in a sector, the relevant actors have to alter their behaviour (Archibugi and Planta, 1996;Peneder, 2010;Schumpeter, 1912). For instance, increased R&D by a firm can lead to an improvement in technology and thereby enhance its competitiveness against rival technologies (Nelson and Winter, 1982;Suarez, 2004). If the R&D and diffusion lead to a change in the sectoral structure, TC at the sector level has taken place. Therefore, in order to accelerate and redirect TC it is necessary that the behaviour of individual firms is altered in a way that supports low-carbon TC. However, due to long lead times in the power sector, caused, inter alia, by the construction time of power plants (Roques et al., 2008), the measurability of TC at the sector-level is delayed (Cames, 2010). Therefore, analysing changes in the behaviour of firms can serve as an early indicator of the acceleration and redirection of TC.",
            "Policy": " The policy mix aiming at low-carbon TC in the power sector can be differentiated into climate policy and technology policies (e.g., Azar and Sande \u00b4n, 2011;Jaffe et al., 2005). Climate policy alters the competitiveness of technologies by putting a price on carbon, such as through a carbon tax or an emission cap and trade system. Emitting technologies are financially disadvantaged, whereas non-emitting technologies are not directly affected but may benefit from increased electricity prices. Nevertheless, climate policy is regarded as technology neutral as emissions are targeted independently from the source (Azar and Sande \u00b4n, 2011). In the European Union it is operationalized via the EU ETS (European Commission, 2005, 2010a) and via emission reduction targets, which have been shown to be an important element of the climate policy mix (Rogge and Hoffmann, 2010). Besides these technology-neutral policies, technology policies, which -as the name implies -target specific technologies in different ways, are an important element in the policy mix. Among technology policies, technology-push and technology-specific demand-pull instruments can be distinguished (Rennings, 2000;Taylor, 2008). The former are designed to induce or directly fund private R&D in order to improve technologies in important performance dimensions (Nemet, 2009)-examples are the R&D subsidies devoted to CCS and RET by the EU (European Commission, 2009b). The latter create demand for technologies whose competitiveness is currently inferior to other technologies but which have significant cost reduction potential (Taylor, 2008). In the power sector, preferential feed-in tariffs or quotas for renewable energy technologies are instruments which are often utilised (Mendonca, 2010;Ringel, 2006). While some of the technology specific policies are enforced by the EU, most renewable energy policies are introduced on a local level. Those national policies show different levels of stringency depending on the instrument and design features. Table A1 in the Annex shows the national renewable energy polices enacted during the period from 2005 to 2009 according to the IEA ''Global Renewable Energy Policies and Measures Database'' (IEA, 2012).",
            "Characteristic heterogeneity: attributes and policy perceptions": " The policies outlined above impact on a population of heterogeneous firms in the power sector. The characteristic heterogeneity of firms within one sector refers to a firm's structure and capabilities (Nelson, 1991). In the power sector and for the purpose of this study the heterogeneity of firms regarding structure and capabilities can be expressed by four attributes (Panda and Ramanathan, 1996;Rogge et al., 2011b): the size, the value chain position, the technology portfolio and the technological capabilities of a firm. Fig. 2 depicts some examples of relevant firms in the power sector portrayed along these differences. The first characteristic is the size of a firm, which is assumed to be positively correlated to its resource slack (Dimick and Murray, 1978). Resource slack is defined as ''a cushion of actual or potential resources [y] which allows an organisation to adapt successfully to [y] external pressures [y]'' (Bourgeois, 1981). Larger firms can therefore react differently from smaller firms during changes in their business environment (Cyert and March, 2005). Second, regarding the value chain position of the firms (Rogge et al., 2011b), we differentiate between technology users and technology producers. In the power sector, the term technology user refers to power generators who select between alternative electricity generation technologies when building new capacity. Above that, users are the firms directly regulated by the EU ETS. The term technology producer refers to power generation equipment suppliers. Third, firms' technology portfolios can differ significantly as firms can either be active in one or several technologies, each of which can be GHG emitting or non-emitting. In the power sector, GHG emitting technologies are based on the combustion of fossil fuels, whereas non-emitting technologies use other sources of energy. We therefore differentiate between fossil and non-fossil technologies. The composition of the portfolio thus determines -Climate policy -Technology policy -Attributes -Policy perceptions -R&D, diffusion -Emitting, non-emitting technologies   the emission intensity of the portfolio (Rogge et al., 2011b) and the impact of a policy on a firm (see below). Finally, a firm can have high or low technological capabilities, i.e., ''patents protected by law, technological knowledge and production skills that are valuable and difficult to imitate by competitors'' (Lee et al., 2001, p. 618). It has been shown that firms with higher technological capabilities tend to react with more innovation to external stimuli, such as the introduction of policy (Rosenberg, 1974). Organisational theory scholars argue that besides their attributes corporate perceptions are essential determinants of firms' behaviour changes (Bansal, 2003;Buysse and Verbeke, 2003;Dutton and Jackson, 1987). Each individual firm perceives its business environment and changes therein (e.g., via the introduction of climate policy) differently (Dosi et al., 1997). Firms can perceive such changes neutrally or as opportunities or threats to different degrees (Barr et al., 1992;Dutton and Jackson, 1987). Besides their heterogeneous attributes, firms' ''limited understanding [y] of the environment in which they are embedded'' leads to different perceptions (Dosi et al., 1997(Dosi et al., , P. 1540)). Furthermore, firms are active in different countries, i.e., embedded in dissimilar environments with different policies (compare Table A1 in the Annex) which are of various stringency levels and can be dynamic over time. 5 This of course also impacts on the firms' policy perceptions. We summarise the attributes and policy perceptions under the term characteristic heterogeneity.",
            "Behavioural heterogeneity: changes in R&D and diffusion activities": " Firms with varying attributes and policy perceptions are expected to react differently to changes in their business environment regarding their behaviour (Nelson, 1991). This means that firms can decide to alter the existing allocation of internal resources to the different innovative activities, i.e., R&D and diffusion, of different technologies (Oltra and Saint Jean, 2005). R&D refers to the continuum from basic laboratory research potentially leading to radical breakthroughs (e.g., through new materials for turbines) to applied development resulting in the better performance of products (Gatignon et al., 2002). Besides few large technology users it is mainly technology producers who create novelty via R&D in the 'supplier dominated' power sector (Cames, 2010;Pavitt, 1984). It is therefore important to not only include the firms that are causing the emissions during the usage phase but also the firms positioned one step up in the value chain. Diffusion refers to adoption decisions on the user side (Ashford, 1993) and production and sales activities on the producer side (Gort and Konakayama, 1982). With their behaviour changes, firms can contribute to the acceleration and redirection of TC. Hence, looking for different patterns of behavioural change is the first step towards answering our research question. In order to better understand which firms follow which specific pattern, we also analyse their characteristics.",
            "Methodology": "",
            "Survey and sample": " Our data stems from an original survey conducted in November and December 2009 amongst power generators and technology providers from seven EU countries, namely Germany, France, Italy, Poland, Slovakia and Spain plus -in the case of the technology providers -the UK. Subsequent to a series of pre-tests in Austria which served to improve our survey, the final survey was translated in each respective language and a reverse translation was independently conducted in order to guarantee equality in meaning. In order to identify the most suitable respondent each firm in the sample was contacted by phone. To ensure the survey was answered by the senior manager identified, a letter and email with an individual access code was then sent. Follow-up calls were made to increase the response rate. In the following we describe how we operationalised the variables set out above. The analyses performed in this study are based on the answers of 201 firms, 65 power generators and 136 technology providers. This represents a response rate of 13.1% and 12.5% of the population of 496 power generators and 1088 technology providers, respectively. The population of power generators in each country was identified based on the EU's ''Community Independent Transaction Log'' (CITL) comprising all firms which fall under the EU ETS. The technology provider population in each country was identified on the basis of the ''KKS'' power plant classification system of ''VGB Powertech'', the respective European industrial activity classifications (NACE Rev.2) and the firm registry ''Amadeus''. Table 1 shows the respondents' countries of origin. As a result and in contrast to most other survey-based studies on the power sector, our dataset also includes firms which are not publically listed. Regarding power generators, the strong bias towards Germany is partially based on its very high number of (small) firms compared to the other countries. A similar trend can be observed in the producer sample. With the exception of France and the UK -which are underrepresented -these numbers provide representative drawings of the entire population of technology providers. Of the power generators, 76% have undertaken adoption measures (i.e., invested in new plants) and 37% have conducted R&D within the last ten years, which is our time horizon for innovation observations. As expected, the number of producers undertaking R&D activities is higher, namely 69%. The remaining 31% focus on technology assembly and do not invest in formal R&D.",
            "Variables": "",
            "Behaviour change": " In order to capture behaviour changes, we distinguish between R&D and diffusion for both fossil (lignite, hard coal, gas, oil) and non-fossil (nuclear, renewable) technologies,6 resulting in four variables. We surveyed the four variables by asking how the a The strong bias towards Germany is to a large extent based on the very high number of (small) utilities in that country compared to the other countries. A similar trend can be observed in the technology provider sample. While France and the UK are clearly underrepresented in our sample, the other numbers roughly represent the entire population of electricity generation technology providers in the population. 5 For more details on the national renewable energy policies in the EU member states see e.g., Blok (2006), Klessmann et al. (2011) and Fouquet and Johansson (2008). monetary volumes of R&D investments and investments in new plants (power generators) or sales (technology providers) have changed in the last five years (2005)(2006)(2007)(2008)(2009), since climate policy was introduced, compared to the previous five years (2000-2004, this period thus serves as benchmark.) The answer categories of the five-point Likert scale ranged from ''dropped sharply'' ( \u00c0 2) via ''no change'' (0) to ''rose sharply'' ( \u00fe2). This is of course a relatively rough gauge, however firms are typically unwilling to report exact investments. The statistical purpose of all variables, how they were queried in the survey or indirectly constructed as well as their descriptive statistics are depicted in Table 2.",
            "Climate and technology policy": " Five policy variables are taken into account, each representing policies that aim to induce a low-carbon transition in the power sector. The European Union's Emission Trading System (ETS) is considered via two variables as we distinguish the more short-term and lax phases 1 and 2 (from 2005 to 2012) from the medium-term and more stringent phase 3 (from 2013 to 2020). In the first two phases, the allowances market was rather long, i.e., over-allocations of emission rights to many firms were common (Betz et al., 2006;Ellerman and Buchner, 2007). This situation changes in phase three when a rising share of emission rights will have to be auctioned. Though the market might still be long as the financial and resulting economic crisis led to decreased industrial production and thus electricity consumption (Point Carbon, 2011), an individual firm will have to spend money on each emission allowance via the auctioning. Furthermore we consider long-term targets (LTT), which represent European and global GHG emission reduction targets for 2020. Besides climate policy, two types of technology policy instruments were considered: technology push (such as R&D subsidies) and technology-specific demand-pull measures (such as preferential feed-in tariffs for RET). We queried the perception of each policy variable again via a five-point Likert scale ranging from ''very negatively affected'' via ''not affected'' to ''very positively affected'' (Barr et al., 1992;Dutton and Jackson, 1987).",
            "Firms' attributes": " As mentioned above, we use four variables to describe the firms' structure and capabilities. The value chain position is represented via a dummy variable, which ascribes the value 1 to power generators and 2 to technology providers. The size of the firm is expressed by its turnover. We surveyed the turnover via exponentially rising answer categories. The share of fossil technologies in a firm's generation portfolio (power generators) or its sales (technology providers) as of 2009 describes its technology portfolio and can range from 0% to 100%. The technological capabilities were measured via two factorised7 items, the percentage of R&D expenses per turnover and the percentage of R&D employees per overall staff. As for all supplier dominated sectors, in the power sector the rate of R&D activity differs strongly between users and producers of technology and thus correlates with the value chain step dummy. Hence, we standardized the variable per value chain step via z-scores before merging the sub-samples. National subsidiaries of international firms active in more than one of the countries included in our survey were treated as individual firms.",
            "Statistical methodology": " Statistically we proceeded in two steps. First, in order to identify different patterns of behavioural change of the firms in the sample, a cluster analysis based on the four variables describing the changes in behaviour was performed. For the cluster analysis we chose a two-step approach. To this end, we conducted a hierarchical cluster analysis based on Ward's method in order to identify the optimal number of clusters based on the elbow criterion. Based on these results, we then performed a nonhierarchical K-means analysis to allot the 201 firms to the respective clusters on the basis of their behaviour changes (Hair et al., 2006). Second, in order to compare the clusters along their characteristics we used non-parametric tests for each variable. We decided to use these tests as they can also be applied to samples whose variables are not normally distributed. First we tested whether there are significant differences between any of the clusters via Kruskal-Wallis tests (Field, 2009;Hair et al., 2006). The Kruskal-Wallis test is also applied to the behaviour change variables in order to check whether the clusters differ significantly regarding these variables. Second, we conduct Mann-Whitney tests in order to compare clusters in a pairwise manner (Field, 2009;Hair et al., 2006). As each test is conducted on the same statistical sample, the familywise error rate leads to an alpha inflation, making a Bonferroni correction indispensable (Field, 2009). As conducting too many Bonferroni-corrected tests lead to a restrictive significance level (Field, 2009), we limited the number of pairwise tests to five (see Section 4.2).",
            "Results": " The results section is split into three parts. First, we report the statistical results of both the cluster analysis revealing the behavioural heterogeneity and the comparison of the clusters along their characteristics. Second, we describe each cluster along its behavioural and characteristic heterogeneity. Third, we summarise our findings and give an overview in Table 3.",
            "Statistical results": "",
            "Behavioural heterogeneity": " Our analysis resulted in seven clusters. 8 Table 3 shows the respective clusters, their centres (means) with respect to the changes in R&D and diffusion activity of fossil and non-fossil technologies as well as their size in absolute and relative terms. The names of the clusters are chosen to summarise their behaviour change. Generally three groups can be identified (compare the three shades of grey in Table 1). The cluster centres can theoretically vary from \u00c0 2 via 0 to \u00fe2, indicating whether the respective activity was strongly decreased, kept constant or strongly increased. First, almost 40% of the firms (Business as usual, BAU) show no major changes regarding their behaviour. Second, 15 firms (fossil diffusion) contribute to increased fossil technology diffusion (1.67 out of a maximum possible increase of 2) and thus play a rather controversial role in the low-carbon TC. Third, more than 50% of the firms contribute to low-carbon TC but to varying degrees and in different ways. This indicates that on the one hand some acceleration and redirection of TC is taking place in the sector, but that on the other hand the contribution of many firms is limited and of some might even be controversial.",
            "Characteristic heterogeneity": " The results of the cluster comparison regarding the four attributes and five policy perceptions of the firms are summarised in Table 2. This shows the mean and standard deviation (std d) of the respective variables as well as the cluster size. For all variables, the Kruskal-Wallis tests resulted in a rejection of the null-hypothesis. Hence, at least one cluster differs significantly (at po5%) on each variable from at least one other cluster. In order to better understand the differences between the clusters, we used the BAU cluster -the biggest cluster which does not show major changes in behaviour -as a reference case and compared each cluster against it to find significant differences (at po5%) via Mann-Whitney tests, adjusting the significance level with Bonferroni corrections, as mentioned above. In Table 4 the means of the variables significantly different to BAU are underlined. 9Several clusters differ strongly regarding both the firms' attributes and their policy perceptions. While the BAU cluster seems to contain very heterogeneous firms (the variance of the distribution is quite high), other clusters show strong peculiarities, e.g., the fact that all firms in the fossil exit cluster are power generators. In the next section, we will show that firms' heterogeneity of attributes and policy perceptions can be linked -to some extent -to their dissimilar behaviour changes. Therefore, in order to better understand the role of firm heterogeneity for the role of policy for TC, we now turn to each individual cluster and discuss both the behavioural and characteristic aspects of heterogeneity.",
            "Description of each cluster with regards to both aspects of heterogeneity": " In the following we derive each cluster's individual contribution to the acceleration and redirection of TC from the observed behaviour changes and the cluster size. We then discuss the role of characteristic heterogeneity and -where applicable -highlight significant differences to the BAU cluster.",
            "Business as usual (BAU) cluster": " The firms in the BAU cluster did not change their behaviour and hence maintain a more or less constant speed and direction of TC. The fact that almost 40% of firms exhibit such behaviour points to considerable inertia within the sector. The BAU cluster encompasses one third of power generators and two thirds of technology providers. They are medium sized and have mixed portfolios (with a high variance) with moderate technological capabilities (but also exhibit a large variance). Their perception of policy seems to be relatively neutral, with RET pull policies being perceived as opportunity (again showing a high variance). To summarise, the heterogeneity of firms within this cluster is very high, indicating that firms which follow this pattern of no considerable behaviour changes vary considerably.",
            "Fossil diffusion cluster": " While the BAU cluster contributed very little or not at all to an acceleration and redirection of TC the 15 firms in the fossil diffusion cluster do so, but in a fossil fuel-based direction. The only behavioural change identified is their strong increase in fossil diffusion activities. As current fossil technologies' emission reduction potential is rather limited, and the increased diffusion of these technologies at present represents future GHG emissions for at least the typical 25 years minimum lifetime of fossil power plants (Roques et al., 2008), these firms counteracted low-carbon TC. Firms in the fossil diffusion cluster show several peculiarities. About 70% are power generators, which is a significantly higher rate than in the BAU cluster. They are relatively large in size and their portfolios already tend to be dominated by fossil technologies-significantly more than those of the firms in the BAU cluster. Their technological capabilities are rather low on average, and their perception of climate policy is slightly positive regarding ETS 1&2 and negative (significantly more than that of BAU firms) regarding ETS 3 and LTT. Technology policies are perceived relatively neutrally on average (but variant).",
            "Clean focus cluster": " Of the roughly 50% of firms contributing to low-carbon TC, the clean focus cluster represents the biggest group. These firms strongly increased R&D and diffusion activities in the non-fossil direction while keeping their innovation activities in fossil technologies constant. They thereby contributed to both an acceleration and redirection of TC in the low-carbon direction. Almost all firms in the clean focus cluster are technology providers (significantly higher share than in the BAU cluster). The firm size is rather small (but has a high variance) and the share of fossil technologies in their portfolios is low (significantly lower than of the BAU cluster). Their technological capabilities are close to the average of all firms. The three climate policy elements are perceived as an opportunity to a significantly higher extent than in the BAU cluster. Technology-push and RET-pull policies are also seen positively, with the latter significantly more so than by the firms in the BAU cluster. The cluster shows the most positive perception of RET pull policies (however not significantly higher than the BAU cluster).",
            "Overall diffusion cluster": " These 17 firms contributed to a mere acceleration of TC. They strongly increased their technology diffusion activities in both technological areas while keeping their R&D activities constant. Thus, their contribution to low-carbon TC in the sector was limited. 10 The cluster is comprised of power generators and technology providers half-and-half. While they are large in size and have mixed portfolios, their technological capabilities are moderate (with a high variance). Their policy perception is tends towards neutral (but is highly variant), except for RET pull policies which are seen as an opportunity. Significant differences to the BAU were neither detected for the attributes nor for the policy perceptions.",
            "Overall innovation cluster": " Similarly to the above cluster, these 15 firms contributed to an acceleration of TC, with the addition that they simultaneously increased R&D and diffusion activities in both technological areas. While the increased activities in non-fossil technologies are a certain contribution to low-carbon TC, the increased diffusion of fossil technologies is controversial (see above). To which extent the increased fossil R&D activities represent a positive contribution depends on whether it results in drastic specific GHG emission reductions of the respective technologies. About one third of the firms are power generators, two thirds technology providers. They are the largest firms on averagesignificantly larger than the firms in the BAU cluster. While their portfolios are mixed (and variant), their technological capabilities are higher than average (but also highly variant). They perceive climate policy as slightly positive. Technology policy is seen as an opportunity, with R&D push policies reaching the highest value of all clusters. Significant differences to the BAU cluster were not detected regarding their policy perceptions.",
            "Clean shift cluster": " Similarly to the clean focus cluster, these five firms strongly increased non-fossil R&D and diffusion activities. However, they went one step further by drastically decreasing their innovative activities in fossil technologies. In doing so they contributed to a redirection of TC in the low-carbon direction. However, due to the limited number of firms in the cluster as well as the small size of the firms (see below) their contribution was limited. The clean shift cluster is dominated by smaller-sized technology providers (these show a high variance however). Their shift away from fossil technologies resulted in portfolios constituted entirely of non-fossil technologies. Their technological capabilities are the highest of all clusters (though showing a high variance). They are the cluster which perceives all three climate policy elements most positively. Technology push policy has a slightly negative mean with a high variance. RET policies are also seen as an opportunity.",
            "Fossil exit cluster": " Like the cluster above, the ten firms in the fossil exit cluster contributed to a mere redirection of TC in the low-carbon direction. Yet, they showed a rather hesitant or passive behaviour change. They strongly reduced their fossil diffusion activities but kept all other activities relatively constant. The fossil exit cluster is entirely made up of power generators (i.e., significantly different from the BAU cluster). The average firm size of the fossil exit cluster is the lowest of all clusters (but exhibits a relatively high variance). Despite their fossil exit strategy, the firms of this cluster still have very high shares of fossil technologies in their portfolios, significantly higher than firms in the BAU cluster. On average, the firms in the cluster exhibit relatively low technological capabilities. Their perception of climate policy is throughout negative (but relatively variant), with LTT reaching the most negative value of all clusters and being significantly more negative than that of the BAU cluster. Technology policy is seen as rather neutral (with a high variance especially for RET pull).",
            "Summary of results": " Our findings illustrate the strong role of firm heterogeneity when analysing policy induced technological change in the power sector. Many firms do contribute to the acceleration and redirection of TC but in a very heterogeneous manner and often also differ regarding their characteristics. One important characteristic which is often overlooked is the value chain position as most studies focus on a single value chain step which is appropriate in other industries (Cames, 2010). In order to highlight the importance of this aspect Fig. 3 shows how the firms of the two different value chain steps are distributed to the clusters. While the percentage of BAU is similar for both value chain steps, we find remarkable differences for the other firms. Power generators show very different behaviour changes, e.g., 17% increasing their fossil adoption activities and 15% reducing them. This picture is different for technology providers, where most of the non-BAU firms follow the clean focus pattern. From an evolutionary standpoint this is important as in the supplier dominated electricity sector it indicates that the firms relevant for creating novelty through R&D (technology providers) are contributing more to low-carbon TC than the regulated ones (power generators). Policy should therefore secure the growth and survival of these firms in order to assure TC at the sectorlevel. Table 5 summarises all findings regarding the behavioural and characteristic heterogeneity from which we draw implications for policy makers (see next section).",
            "Policy implications": " Our study provides first feedback on the decarbonisation of the power sector via TC-an important objective of European energy and climate policy (European Commission, 2005, 2010a). Firstly, our results show that firms' contribution to low-carbon TC differ strongly. The fact that about 40% of the firms do not contribute to an acceleration and redirection of TC and another almost 8% contribute to a redirection to the fossil direction is important information for policy makers which casts doubt upon whether the current policy mix is able to trigger an acceleration and redirection of TC in the magnitude needed to meet the 450 ppm target. Our results thus imply that the policy mix might need to become more effective. Secondly, the comparison of firms' attributes and policy perceptions provides novel information on the characteristic heterogeneity of differently behaving firms. While the policy mix might accomplish its purpose for some firms, other firms with potentially very specific characteristics need further incentives if large scale changes are to be achieved. Therefore, we hereafter proceed in two steps: first, we shortly discuss the firms' contributions to the acceleration and redirection of TC and derive implications for policy; second, we propose several policy measures and discuss how they could alter the behaviour of the firm groups and thereby accelerate and redirect TC, taking into account more recent market and policy developments.",
            "Firms' differing contributions, implications for policy": " The largest group of firms (BAU) does not significantly change its behaviour. Hence, they unveil the large inertia present in the sector. The main policy task is to stimulate increased activities in a low-carbon direction. Interestingly, the firms in this cluster are not a very specific group but are instead highly heterogeneous regarding their attributes. One commonality appears to be the rather neutral perception of policies.  their business environment (compare Rogge et al., 2011a) pointing to a certain lack of stringency of the current policy mix. In order to become a decisive element, the stringency of policy needs to be increased. Additionally, providing a higher level of regulatory certainty might break-up the inert behaviour of these firms (Engau and Hoffmann, 2011a,b;Hoffmann et al., 2009). The fact that climate policy did not prevent power generators (fossil diffusion) with fossil fuel-heavy portfolios from predominantly investing in new fossil technology might seemingly point to a strong firm technology lock-in. However, the portfolios of these firms are not as fossil technology-heavy as those in the fossil exit cluster. An explanation might be the inverted incentives set by the allocation rules under the first phases of EU emission trading-this would explain why these firms perceive ETS 1&2 rather positively whereas they exhibit a negative perception of ETS 3 and LTT. While Ellerman and colleagues (2010) expect such effects ex-ante based on their economic models, first empirical studies (Schmidt et al., 2011) affirm these expectations. These effects are limited to the first two phases of the EU ETS in the power sector, as future allowances will mainly be allocated via auctioning. However, even auctioning might not result in major behaviour changes, given the current situation: the economic crisis in Europe raises the expectation that the allowance market will be long for several years, resulting in low carbon prices (Point Carbon, 2011), which in turn results in a low incentive to alter the behaviour of the firms in this cluster. Measures that prevent a price decline need to be taken, against which, however, lobbying pressure of the firms can be expected. Firms accelerating TC without clearly redirecting it (overall innovation and overall diffusion) are mainly larger firms with mixed portfolios. Their contribution to low-carbon TC depends strongly on the kind of investments made in fossil technologies. Should these investments lead to the significant decarbonisation of these technologies (e.g., via R&D in CCS) their contribution can be very important. Therefore, policy needs to ensure that fossil innovation is targeting substantial emission reductions and not incremental ones, which instead of opening it for new non-fossil technologies rather cement the fossil regime and thereby exacerbate or delay deep emission cuts on a system level. For another group of firms, the fossil exit cluster, climate and technology policy has served the purpose of decarbonisation only to a certain point. These power generators are heavily invested in fossil plants and directly targeted by climate policy. They perceive the new policy as a threat and took a first step by strongly reducing fossil investments. However, the policy mix does not (yet) prompt the second step of decarbonisation: investments in nonfossil technologies. Besides the potential influence of investment cycles, these results point to a certain lock-in of these firms in a fossil trajectory and/or the role of regulatory uncertainty in their hesitant behaviour (see also BAU above). Policy thus needs to provide further incentives to become active in technological fields new to a firm backed by higher levels of regulatory certainty. Finally, two clusters (clean shift, clean focus) have been identified which contribute to a redirection and acceleration of TC. Firms in these clusters perceive climate and technology policy as an opportunity. They are mainly providers of already aligned (non-fossil) technologies which gave up their small existing shares in fossil technology. Interestingly, the policy mix aiming at the decarbonisation of the sector seems to have only fully achieved its target for technology providers, though these companies are only indirectly affected by climate policy. As the power sector is a supplier dominated sector (Pavitt, 1984), the firms in these clusters are highly relevant for low-carbon technological change and should be further supported.",
            "Policy measures and their potential effects on the heterogeneous firms": " Having discussed the differing roles of firms and the resulting policy implications, we now propose a non-exhaustive list of policy measures on different institutional levels which could support the derived policy implications. We differentiate three institutional levels, mainly focusing on the EU level. Table 6 summarises the proposed measures, their general desired effects and how they could trigger behaviour changes of the various firm groups. On the EU level, the first measure we propose is the formulation of targets which reach beyond 2020. The long investment cycles and lead times in the sector demand clearly communicated targets for the time post-2020. In early 2011, the EU formulated a 2050 roadmap (European Commission, 2011a) containing sectorspecific targets for 2050 and 2030. However, at least the 2030 targets should be stipulated (currently they range from 54% to 68% reductions compared to 1990 for the power sector) and substantiated with an outlook on future instruments in order to make them credible. This would result in a lower level of regulatory uncertainty and provide an improved basis for investment planning and strategy making for firms in all clusters. In order to increase the stringency of the ETS, we propose two measures. First, to increase the 2020 target beyond 20% reduction and lower the cap accordingly; second, to decrease the allocated allowanced for industry sectors. While the first proposal -30% for 2020 are being discussed (European Commission, 2010b) -would directly target the power sector and counteract the fact that the market will be long on certificates till 2020 (see above), the second measure would affect the power sector only indirectly. While for the power sector, most emissions will be auctioned, a large amount of emission allowances will still be allocated for free for industry sectors based on performance benchmarks, starting with 80% in 2013 (Cl o, 2010;Cooper, 2010;European Commission, 2011b;Parker, 2010). Decreasing the rate of allocated allowances for the industry would increase the demand for credits and thereby counteract the price decline due to the economic crisis thus raising the stringency. To this end, the benchmark rules might be tightened, e.g., for process emissions beyond the allocation of 97% of the historical emissions (European Commission, 2011b). A further measure against the price decline would be to introduce price floors 11 , i.e., setting a minimum price for emission rights. Another effect of such price floors is the reduction of regulatory uncertainty (Hepburn et al., 2006;Neuhoff, 2011). While an ETS without price floors is the better option if its sole objective is to meet an emissions target (Wood and Jotzo, 2011), price floors can support the second target of the EU ETS: ''driving global innovation'' (European Commission, 2009a, p. 5). The recently enacted Australian emission trading scheme contains a price floor (and ceiling) after the first three years in which the price is fixed (Commonwealth of Australia, 2011). All three measures -raising the target, decreasing allowances for industry sectors and price floors -are expected to have the following effects on the different clusters. The increased stringency could raise the climate policy perception of the firms in the BAU, Overall Innovation and Overall Diffusion clusters, thereby breaking the inertia of the first and redirecting the investments of the latter two cluster towards low-carbon. At the same time, it would make incremental reductions less attractive and thus potentially alter the behaviour of the fossil diffusion cluster. Finally, firms proactively supporting the redirection and acceleration of TC (clean shift, clean focus) would be encouraged to continue their strategy. While each of these measures could produce similar effects on its own, the measures can be combined, e.g., depending on the underlying political and legal practicability. Another measure we propose is to apply an ''innovation/technology accelerator'' to the power sector. Such mechanism is discussed for the industry sectors to ''reward companies that invest in top performing technology and make significant emission reductions [y] by giving those installations additional free allowances on top of what could be expected from a normal implementation of the benchmark rules'' (European Comission, 2010, p. 75). Applying this mechanism to the power sector, could alter the perception of climate policy by linking low-carbon innovation with positive incentives to become innovative and invest in demonstration projects. This might break the inertia of the BAU-firms and trigger the second step of behavioural change of Fossil Exit-firms. Regarding fossil R&D support, a re-focus of policies might be considered in order to avoid incentives that lead to incremental change in the fossil regime, preventing non-fossil fuel technologies from becoming competitive and thereby undermining ETS and RET pull policies. Also national R&D policy should be harmonised with such revised EU policies in order to avoid undermining of the latter. Both measures would encourage firms which currently also invest in incremental fossil R&D to re-allocate resources towards R&D in fossil technologies which allow for substantial emission cuts or towards non-fossil technologies (partly BAU, Overall Innovation). This brings us to a measure on the national, i.e., member state level: expanding technology-specific support schemes for RET to more member states and thereby increase the overall demand for RET in the EU. So far, RET demand pull policies in Europe differ substantially (e.g., Klessmann et al., 2011) with high potentials remaining untapped. Similarly, on the international level, large markets for RET could be created by supporting emerging economies and developing countries in their mitigation efforts. Nationally Appropriate Mitigation Actions (NAMAs), i.e., efforts to scale up GHG emission abatement in developing countries (Hoehne, 2011;UNFCCC, 2011) could be one way. These measures would on the one hand ensure the survival and growth of low-carbon providers (clean shift, clean focus) and incentivise large innovative firms, which often innovate for global markets, to redirect their innovation activities towards low-carbon activities (partly BAU, Overall Innovation). Apart from concrete measures, technological change at the sector level can mean that certain firms dwindle in size or even disappear as market shares are taken over from firms which are more adapted to the new situation (Smith et al., 2005). The resistance of these firms can result in lobbying pressure on any institutional level to decrease stringency (Hepburn et al., 2006). Policy makers at all institutional levels should be prepared for these pressures and need to withstand them. Finally, in order to result at a stringent and consistent (Kern and Howlett, 2009) mix of climate and technology policies, all measures need to orient themselves along the same decarbonisation goals. However, designing a consistent and effective policy mix which is congruent to long-term targets is complicated in the political reality (Kern and Howlett, 2009;Meadowcroft, 2011). The EU generally has longer political time constants than those of the national governments in the member states and ''avoids [y] to a large extent the politics of the party [y]. This results in the fact that apolitical EU civil servants rather than partisan legislators and their staffs are the primary drafters of legislation, and base their decisions primarily on technical and economic [and not political] grounds'' (Schmidt, 2006, p. 105). For instance, pressures and lobbying from the aforementioned threatened firms can be more easily resisted by the EU than national governments. Hence, the EU should keep its guiding function for climate policy and enhance its role for coordinating technology and climate policies.",
            "Conclusions": " This paper delivers two main contributions. First, it presents novel empirical quantitative data on the role of the EU ETS and other important policies for technological change in the power sector. The results suggest that the current policy mix might not be effective enough to trigger the effects needed to achieve the 450 ppm target. Second, our study complements existing empirical and theoretical studies which analyse the effectiveness of the policy mix in the power sector. Apart from the innovation system literature (e.g., Rogge and Hoffmann, 2010), the role of differences between relevant affected actors has often been overlooked in the academic debate thus far. Most studies are predominantly concerned with the effects of the different instruments and/or their interactions (for an overview see Fischer and Preonas, 2010). However, these studies mostly exclude the fact that these instruments' effects and their interactions can differ for heterogeneous firms. Our study places special emphasis on this dimension, which is very relevant for explaining technological change. This allows us to derive indicative recommendations on how to adjust the policy mix in order to induce contributions from the heterogeneous firms in the power sector. Our study, however, has several limitations which call for future research. Further attributes of firms in the power sector might be included in future analyses, such as firm ownership and the national or international market orientation of a firm, both of which touch on a firm's innovation decisions. Above that, other important policies in the power sector such as energy price regulations have been omitted. It would also be of great interest to track the firms' organisational change as it is a condition 'sine qua non' for changing behaviour (Nelson, 1991). Finally, our analysis is based on relative numbers regarding the innovation activity changes. Firms with different sizes are thus counted equally, although their contribution to technological change can diverge widely. The results of our study should therefore be compared to those of studies based on macro data, which shows trends in R&D and diffusion for the entire sector, as soon as this data is available.",
            "Annex": " See Table A1."
        }
    },
    "10.1016/j.enpol.2014.12.030": {
        "file_name": "20 Uncertainties in future energy demand in UK residential heating",
        "title": "Uncertainties in future energy demand in UK residential heating",
        "abstract": "Fossil fuels are the main source of space heating in the UK, and therefore climate mitigation implies a systemic change in\u00a0space heating systems. The challenge is difficult because of an inefficient building stock and high penetration of natural gas. We present new quantified scenarios for residential energy use in the UK to 2050. With minimal policy intervention the UK will remain locked into a gas based heating system, which would conflict with the policy goal of\u00a0decarbonisation. However, there is a range of scenarios in which this is avoided. A system heavily reliant on\u00a0heat pumps\u00a0powered by low carbon electricity is UK policy makers' currently preferred alternative. We conclude that some shift in this direction is likely to be required, but complete reliance on this solution raises a number of problems. Greater use of energy efficiency and biomass can also play a significant role. These options have different risks, but a more diversified strategy would be more prudent. We conclude that the future of UK residential space heating is very uncertain, but meeting low carbon heating goals is better conceptualised as reducing reliance on gas rather than necessarily mass\u00a0electrification. Our analysis has implications for any country with high use of fossil fuels in space heating and ambitious decarbonisation goals.",
        "label": "Quantitative",
        "text": {
            "Introduction": " In terms of the energy challenges provided by residential heating the UK is, in many ways, a paradigm case for the developed world. The challenge is that there is an inefficient building stock, with relatively slow and piecemeal refurbishment; the climate is cool and temperate, so that heating is a much more significant energy service than cooling; and the energy supply infrastructure is well-established with a very high penetration of natural gas, which has historically been cheap. The result is that the residential sector is an important user of energy and main end use sector for natural gas, the majority for space and water heating in gas boilers. Long term trends have seen rising household numbers and internal temperatures drive increased heating service demand. Although homes built in the last four decades have been subject to energy performance requirements, their energy use for heating is only slightly lower than older dwellings (Hamilton et al., 2013). Until the last decade, these trends outstripped increases in energy efficiency in building fabric and heating systems, so that energy demand rose. From 2004 to 2012, this trend reversed. In the absence of lower internal temperatures (for which there is no evidence), this is due some combination higher prices and public policy driving improved energy efficiency (Summerfield et al., 2009). Large programmes to install loft and cavity wall insulation and condensing boilers have outpaced rising service demands, so that residential heating energy fell over this period. However, the rapid decline in energy efficiency activity since 2012, due to policy changes during a period of high energy prices, clearly indicates that public policy rather than prices tends to be the key driver (Rosenow and Eyre, 2013). This more recent evidence suggests that the period 2004-2012 may be an atypical period characterised by the availability of relatively easy, low cost energy efficiency improvements and an effective policy framework to deliver them and that this trend is now likely to change due to the declining availability of low cost measures and the recent large reductions in the scale of UK residential energy efficiency programmes. At the same time, the UK has adopted a legally binding commitment to reducing greenhouse gas emissions by 80% by 2050, with the need for significant progress by 2030. There is broad agreement that this is incompatible with retaining a residential heating sector with anything like the current structure. There is, therefore, an apparent disconnect between ambitious goals and historical trends. On the one hand, the rates of change required to meet climate goals are large; on the other the rates of change of heating systems and practices have typically been rather low. This paper seeks to explore the uncertainties implicit in this disconnect by examining the uncertainties in future residential heating demand in the UK. Section 2 explores the different narratives that have been developed for UK residential heating futures in the context of the low carbon transition. Section 3 sets out the different qualitative sociotechnical scenarios examined. Section 4 describes the methodology employed for quantification of different key uncertainties and Section 5 gives the results. We end with a discussion of the implications for policy in Section 6 and conclusions in Section 7.",
            "Low carbon heating transitions": " Early explorations, e.g. (PIU, 2002;RCEP, 2000) of the UK residential sector heating implications of deep carbon mitigation focussed on the continuation and reinforcement of trends, with greater use of efficiency, CHP and on-site renewable energy. These were in the context of calls for a 60% reduction in emissions by 2050 and, even with this target, a greater use of zero carbon vectors was found to be needed in higher growth scenarios (PIU, 2002). With the change in the UK's 2050 target to an 80% reduction, in the 2008 Climate Change Act, a new narrative emerged (CCC, 2008;Ekins et al., 2010;HMG, 2009) of large scale conversion to low carbon electricity (with this assumed to be the norm for UK supply after 2030). These latter results emerged from economy wide assessments, using optimisation models, with rather limited detail on the diversity of the building stock and the practical issues involved in its refurbishment. They also use only a single projection for demographic and economic growth. However, there is also evidence of the potential value of electrification in decarbonisation of heating from more detailed analyses of the building stock (Lowe, 2007). The potential for mass electrification of heating has been received with some scepticism in the building energy research community, with a number of critiques of the feasibility of near-universal deployment of heat pumps (Eyre, 2011;Fawcett, 2011;Hoggett et al., 2011;Speirs et al., 2010). Following these critiques, there has been some moderation of the role of electrification of heating in the most recent UK policy statement (DECC, 2013b). In the light of rather slow progress in heat pump deployment, the strategy now includes a greater role for heat networks in dense urban areas. Concerns about the medium term implications for increasing electricity demand have been addressed by allowing for large scale use of some intermediate technologies in the 2020s and 2030s, notably gas-fired absorption heat pumps and hybrid boiler/heat pump systems. However, as neither technology has yet been deployed at scale, assumptions about rapid and widespread deployment (i.e., for most households at the next point of heating system change) raise some interesting issues. The UK has much lower levels of deployment of heat networks than most other northern European countries. Bulk movement of heat has no intrinsic merit and requires significant capital investment. However, whilst most district heating, in most countries, has been gas-fired, heat networks can utilise a diverse range of heat generating technologies, including waste to energy schemes, waste heat from power generation and industry, biomass and large heat pumps. They therefore enable a range of low carbon heating strategies. The use of dedicated biomass, in principle, can supply large amounts of energy for heating, through a variety of vectorswood in building-scale boilers and stoves, larger boilers (without or without combined heat and power) to supply heat networks, bioliquids to replace oil fuels and biogas. The global resource is potentially very large but raises problematic issues with respect to land use; the potential UK resource is substantial (Slade et al., 2011), but unlikely to supply a large fraction of UK heat. With constrained supply, choices will need to be made between using biomass in heating, transport and power generation (Jablonski et al., 2010). Whilst the current demand for energy for residential heating is well known and unlikely to change quickly, very significant changes are possible in the long term through changes to energy services demand and/or energy efficiency. It is well established that the thermal efficiency of both new and refurbished buildings can be better than current typical practice by a large factor (Urge- Vorsatz et al., 2012). However, real world practice to date has been less encouraging with a major gap between planned and actual energy performance (Chiu et al., 2014;Hamilton et al., 2013). In these circumstances, predicting the future of UK residential heating energy is fraught with uncertainty. It depends on the nature and extent of the commitment to delivering 2050 climate targets, as well as a range of technological, social and institutional factors that affect building energy efficiency and heating system choice. Key uncertainties include future heat demand, driven by comfort needs and insulation levels, and the penetration rates of different low carbon heating fuels (biofuels, solar and electricity). Trends in both areas depend on decisions about refurbishment that are strongly affected by technical change, prices, social norms, building industry skills and supply chain capacity. Lower heating demand and fuel switching potentially interact anti-synergistically, as high capital cost heating systems inevitably will be less economically attractive for buildings with low heat demands. Other uncertainties include the scale of the most basic drivers of housing demandpopulation growth and household sizewhich have been neglected in previous studies in this field.",
            "Scenario descriptions": " Our approach has been to consider the future of residential sector heating in the context of the different infrastructure strategies that the UK might adopt over coming decades. As the world's first industrialised country, the UK has some very old urban infrastructure and therefore faces some challenges earlier than other countries (Hall et al., 2014;Tran et al., 2014). Potential strategies that might be adopted for energy infrastructure as a whole, and our broad approach to quantifying them, are set out elsewhere (Baruah et al., 2014a). The strategies that might be adopted all seek to deliver a high level of energy security, as we normatively assume that this policy goal is extremely unlikely to be abandoned in any highly developed modern economy. We treat other current policy objectives, notably affordability and carbon emissions reduction, differently, recognising that priorities within these might change and that the effectiveness of different technologies to meet these goals and other social aspirations is inevitably uncertain on long timescales. Divergent futures are possible as any specific technical solutions adopted can lead to path dependence and lock-out alternative options (Unruh, 2000). We therefore use a scenario approach to understanding the range of possible future socio-technical systems in which different technical, social and policy changes lead to different pathways. We focus on four broad scenarios, described in Sections 3.1-3.4 below, that emerge for residential space heating. We recognise that this, like all scenario exercises, is arguably over simplistic. The intention is that they map the space within which actual futures are likely to fall. Even so, they neglect some possible futures, including large scale deployment of energy storage technologies and/or use of hydrogen.",
            "Minimum policy intervention (MPI)": " In this scenario, there is no significant strengthening of UK energy policies to meet climate mitigation goals, and therefore longer term carbon targets requiring very significant decarbonisation are not a driver of residential heating policy. Concerns about energy security continue and ensure that there is sufficient investment in electricity and gas infrastructure and supply to ensure reasonable levels of energy security in heating and other energy services. The recent decline in energy use in the sector comes to an end, as efficiency programmes stall; longer term growth trends in energy demand are reasserted with upward pressures from population and economic growth only partially offset by improvements in energy efficiency. Only limited change is driven by regulatory standards, tax incentives and support programmes. The energy supply sector changes rather slowly, with continued dominance of large scale, fossil fuel investments by large companies. There is no significant investment in nuclear or carbon capture and storage (CCS). Renewables investment continues as costs fall, but capacity increases only slowly. Smart meters begin to be rolled out as currently planned in 2015, but there is no need for significant use of demand response to balance the electricity system. Power sector investment continues to rely largely on combined cycle gas turbines (CCGTs) with gas supplies from largely imported, but diverse, sources. In these circumstances, residential heating remains largely dependent on gas with modest continued efficiency improvements in building efficiency. Innovation is not a priority in the sector, and the heating services industry structure remains broadly unchanged.",
            "Electrification of heat and transport (EHT)": " In this scenario, there is a continued emphasis in the UK on strong climate policies with future targets generally met. Energy and climate policy remain centralised. Concerns about energy security continue and are addressed by large investments in low carbon electricity generation. Existing long term trends in demand continue due to upward pressures from population and economic growth. The impacts of these on demand are offset to some extent by improvements in building energy efficiency, but the priority on the demand side is increased electrification of demand of heat (and transport). Smart meters are rolled out and increasingly used in demand response programmes in all demand sectors. Distributed solar PV adoption is moderate. Control of electric vehicles and building heating systems becomes critical for the effective management of electricity loads. There are rapid increases in the capacity of electricity generation, especially after 2030. Transmission and distribution networks are strengthened and additional transmission lines built where needed. The gas grid falls into decline and large parts are decommissioned by 2050, with most heating of buildings electrified. The large and rapid investment in low carbon power generation technology is delivered by the incumbent large companies. Within this broad scenario, it is possible to set out a number of possible electricity supply options, depending on the balance between offshore wind, fossil fuels with carbon capture and storage, and nuclear. These are explored elsewhere (Baruah et al., 2014a), but the low carbon supply side choices have limited impact on heating scenarios.",
            "Local energy and biomass (LEB)": " In this scenario concerns about energy security continue, but faith in national government and its institutions to deliver this outcome is eroded. Concerns to protect energy security are reflected in much greater emphasis on individual and small scale action, with more reliance on local resources, in particular solar energy and locally produced biofuels. Existing long term trends in demand are reduced as upward pressures from population and economic growth are more than offset by higher efficiency heating systems (heat pumps and CHP) and moderate improvements in building fabric energy efficiency, stimulated by a combination of Government policies and rising awareness of energy security driving local action. After 2020, solar PV costs fall to below the costs of retail electricity and solar energy deployment becomes mainstream for companies and households, reducing net building electricity demand, although leaving peak (winter evening) demand unaffected. Smart meters are rolled out, initially with a high emphasis on consumer information and demand reduction, although their capability to support diurnal demand response is then valuable. New demands for electricity in heating are more moderate than in the EHT scenario. The electricity supply sector changes steadily. Initial investment is largely in wind, with greater acceptance of onshore wind turbines, and much increased diversity of ownership, including by community groups, local authorities and cooperatives. There is increased deployment of distributed generation, resulting in a more active role for electricity distributors. The emphasis on local fuels leads to more use of bioenergy from local sources for heating. A number of bioenergy business models emerge, including solid fuel use in household scale wood pellet boilers and wood chip stoves, some larger biomass CHP systems, biofuels to replace oil-fired systems and biogas from a variety of sources, used both directly at the point of production and through introduction into the existing gas grid. The key similarity of all the approaches is that heating is decarbonised more through modifications of the existing infrastructures for solid, liquid and gaseous fuels, rather than via electrification.",
            "Deep Decarbonisation with Balanced Transition (DDBT)": " In this scenario, there is a continued emphasis on strong climate policies with existing targets met. Social acceptance of the need for energy system transformation leads to strengthened and consistent government policy, as well as greater decentralised action. Concerns about energy security continue and are addressed in part by large investments in energy efficiency, with a mix of low carbon energy sources, including microgeneration driven by significant carbon prices. Low carbon electricity generation and biomass technologies are adopted, but less strongly than in the EHT and LEB scenarios respectively; and the economy becomes more electrified with less dependence on natural gas. There continues to be a high level of energy security. Previous long term trends in demand growth are never reasserted. Upward pressures from population and economic growth continue to be more than offset by improvements in energy efficiency, stimulated by a combination of active policy and rising awareness. Smart meters are rolled out and used effectively for both demand response and demand reduction. In buildings, significant efficiency improvements in both fabric and heating systems, coupled with greater conservation, drive a major reduction in heating final energy demand. The performance gap between design efficiency and actual energy use is addressed, with greater user engagement in energy issues and improved supply chain skills, although the level of efficiency achieved still does not reach that of the most optimistic predictions. Residual demand is met by a combination of low carbon technologies, including heat pumps and micro-CHP in homes and through heat networks in large urban areas. This is the only scenario in which district heating plays a significant role, with local authority led initiatives in cities, largely supplying urban centres. Most schemes are based on large commercial and/or public sector heat loads, but also supply neighbouring residential areas, where the heat density is sufficient to justify this. The potential heat sources are diverse and location dependent. We assume most comes from waste to energy schemes and waste heat from power generation, with some residual gas-firing. However, it is clear that other options are possible, including bioenergy crops and large heat pumps, which are more efficient than single building scale heat pumps (Blarke and Lund, 2007). Given the penetration assumed for heat networks is assumed to be limited to dense urban areas, our overall results are not very sensitive to these choices. Solar PV and solar thermal costs fall and they are adopted widely. The electricity supply sector changes quickly with rapid investment in low carbon power generation technologies, so that the UK decarbonises electricity supply very quickly up to 2030. Renewable technologies capture a high market share in the electricity supply mix, with gas-fired generation used at low load factors to provide continued flexibility in the face of high levels of intermittency.",
            "Methodology": " Our basic assumption is that there are two categories of uncertainty that are broadly separable. The first category is uncertainty in broad socio-economic trends that are normally considered exogenous to the energy sector, primarily population and economic activity. Engineeringeconomic models of space heating demand implicitly assume that socio-economic uncertainties are manifested through impacts on the floor area and the temperature to which it is heated. The key underlying drivers of these are likely to be population and income. The former drives housing demand (and therefore housing construction and supply); the latter potentially affects floor area, internal temperature and refurbishment rate. Our methodology assumes that the service demand for heating is principally driven by population, but the quantitative outputs are probably better understood as resulting from the combined uncertainty of socioeconomic drivers of service demand. As our principal aim is to assess the potential scale of overall socio-economic uncertainties, it is important to avoid double counting. Income effects on internal temperature in the UK are only $0.6 C between the highest and lowest income groups (Kelly et al., 2013), so neglecting income effects is an acceptable simplification, unless either income inequality or the energy price/income ratio increases significantly. By allowing for socio-economic uncertainties our approach contrasts with the overwhelming majority of long term energy and carbon emissions scenarios for the UK, including the major policy assessments, e.g. (CCC, 2008;HMG, 2009), which neglect these uncertainties completely, by using the mid-range number from the relevant official UK Government projections (e.g. Office of National Statistics population projections and HM Treasury projections of economic growth). Given the implications of population for infrastructure this is a surprising omission from most long term energy analyses. Neglect elsewhere is a major reason for our decision to assess its effects. The second category of uncertainty is socio-technical-the future trajectory of UK energy system futures. To understand these implications we use the scenarios set out above. For each qualitative scenario, we use expert judgement to specify the quantitative trends in socio-technical variables in the period 2010-2050, from which we compute residential heating energy demand. These include conservation measures and heating controls (via internal temperature change), improvements in building fabric thermal performance, heating system efficiency, use of onsite heat and power production and other heating system technology change (including fuel switching). Fig. 1 shows a taxonomy of the drivers of residential heating energy demand. Drivers not directly modelled in this study are light coloured. The logic of these choices is as follows: dwelling type is only significant in so far as it affects thermal performance, which we model directly; average floor area is captured in the stock profile as part of our metric of envelope thermal efficiency; energy management technology improvements are captured in our assessment of internal temperature and appliance efficiency; energy prices and household incomes are clearly important in econometric models of energy demand but would 'double count' the changes we model through changes in energy service demands. Climate is a potentially significant influence, as changes in the differences between internal and external temperatures affect energy demand by approximately 10% per degree K (Summerfield et al., 2009). Temperature changes are dependent on scenarios of mitigation, but globally rather for the UK, any therefore mitigation scenario impacts on UK winter temperature depend on assumptions outside the scope of our analysis. For both types of uncertainty, quantification of energy outcomes requires additional detailed assumptions to translate broad descriptions of uncertainty in model parameters. The process logic of the calculation is set out in Fig. 2, and key parameters used for each scenario are in Table 1. In essence we use a simulation-accounting model approach, with change in space heating demand over the base year (2010) modelled as a function of demand drivers (exogenous to the model) and the energy system transition parameterised as set out in Table 1. We focus on energy use for space heating, which is $ 80% of residential heating demand (DECC, 2013a), although this figures varies significantly from household to household. Space heating demand with the 2010 technology mix is estimated for each of 11 geographical regions of Great Britain. (Due to data limitations we exclude Northern Ireland, which has $ 2.5% of the UK population, $3% of energy demand and a different energy infrastructure and market). Space heating demand for 2010 is weather corrected and has been validated against actual energy use. The uptake level of each sociotechnical parameter is modelled each year to 2050 and space heating demand calculated by region by fuel. In general, we use S-curves to model rates of technical change, reflecting historically observed processes of technical change (Shorrock, 2011). The seasonal performance factor (SPF) of heat pumps is an important assumption in some scenarios. We assume that the SPF of an air source heat pump (ASHP) in an individual dwelling rises from 2.00 in 2010 to 3.00 in 2050, and that of a ground source heat pump (GSHP) from 2.50 in 2010 to 4.00 in 2050. The majority of this effect derives from an assumed improvement in technology and installation practice, with a higher proportion of heat pumps operating at lower temperatures in underfloor heating as time progress. Our assessment of the impacts on peak electricity demand, in the discussion section below, recognises that efficiency at peak load will be lower as external temperatures are lower at times of peak demand. To calculate the efficiency at peak load, we apply to the seasonal performance factor an adjustment factor of 0.8, which is derived from EST heat pump trial data (EST, 2010) and consistent with other UK sources (Baster, 2011). The model is designed to allow a wide range of heating system choices, rather than to provide a detailed state of the art assessment of any particular technical option. Our approach to the energy performance of buildings is rather straightforward. Rather than modelling heat demand through a bottom up assessment of the design thermal performance of different building types, which is notoriously bad at replicating actual energy use, we calibrate the model to actual demand in 2010 and then, for different scenarios, model the change in demand due to building fabric and occupant behaviour change, using the assumptions set out in Table 1. As the aim is to map a plausible range of futures, there is no attempt at spurious accuracy based on detailed building models. Our approach to biomass futures is similar. We model one 'high biomass' future (the LEB scenario) based on transparent assumptions, rather than attempting to address whether this constitutes the 'best use of biomass' to meet the combination of energy policy objectives. The full modelling methodology we have employed for quantification of energy demand and fuel mix is set out elsewhere (Baruah et al., 2014a). In this paper we focus on the approach used for residential heating and the quantitative outcomes generated. The model has some clear limitations including: dwelling numbers are represented by proxies of regional population, no explicit price-induced effects are modelled, no explicit assessment of social, cultural or behavioural drivers (except as internal temperature), no direct modelling of technology supply chain issues (except through diffusion rates), and no allowance for adaptation to climate change. ",
            "Results": " 3-6 show the effect of different scenarios for the main fuels for residential heating in the UK. In the Minimum Policy Intervention (MPI) scenario, recent trends driven by energy efficiency policy go into reverse, so that fuel use grows modestly over the period to 2050. Gas remains the dominant fuel, rising in use from the existing level of 230 TWh/ year to over 250 TWh/year, with electricity confined to its existing market niches, largely in rural (off-gas grid) areas and flats. In the Electrification of Heat and Transport (EHT) scenario, which most closely reflects the conventional wisdom on deep decarbonisation of heat, gas demand initially remains broadly stable, then falls quickly from 2030 to 2050, by a factor of six, to less than 40 TWh/year. As heat pump technologies and markets mature and electricity system decarbonisation allows major carbon mitigation from electrification, electricity use for space heating rises to 75 TWh/year. With an additional 17 TWh/year estimated for use in residential water heating, this doubles existing residential electricity demand. In the Local Energy and Biomass (LEB) scenario gas demand also falls quickly from 2030, but the fall moderates by 2050 as heat pumps prove less suitable for some homes. Heat pump technologies and markets develop from 2030, but the rapid rise in electricity demand seen in the EHT scenario is not mirrored here for three reasons. First there is more rapid improvement in building efficiency; secondly, biofuels are developed as alternative low carbon fuels, using the existing infrastructure; and thirdly there is a major increase in solar PV generation in the residential sector, with a large fraction used for space heating reducing the demand on external supply. Biofuel use for residential heating rises to over 60 TWh/year, which exceeds the likely resource from wastes, but falls well within estimates for potential UK biomass production in 2050 (HMG, 2011). In the Deep Decarbonisation Balanced Transition (DDBT) scenario, some of the same outcomes are observed as in LEB. In both scenarios gas demand continues to fall, and more quickly from 2030, but in the DDBT scenario, this is due to a combination of more radical efficiency improvement than in other scenarios and fuel switching. The fuel switching is delivered by a combination of heat pumps and larger (i.e. not micro) CHP technologies, with the latter via district heating systems in urban areas supplied with waste fuels and waste heat from power generation (supplying 27 TWh/year by 2050). In this case, the major increase in PV generation in the residential sector reduces net electricity demand to very low levels, and therefore the demand for electricity is significantly lower than in other scenarios. Figs. 7 and 8 illustrate the impacts of population uncertainty on electricity and gas demand for low and high population projection variants for the scenarios with the highest and lowest projected demands in 2050. In each case, the only significant effect is on the dominant fuelgas in MPI and electricity in EHT. Whilst the effects are not as radical as the socio-technical scenario effects, they are significanttypically $ 25% variation, implying that population sensitivities cannot be neglected in system analysis and planning on these timescales. It should be noted that the data presented in Fig. 7 are for residential sector gas demand. Total national demand for gas also depends on final use in other sectors and in power generation. Use in non-domestic buildings may follow some of the same trends as the residential sector, but industrial fuel substitution is widely expected to be more problematic. Like the fuel mix in electricity generation, these issues are outside the scope of this paper. However, any scenario with a very substantial share of intermittent renewable electricity, without alternative flexibility mechanisms, is likely to require back-up from flexible fossil fuel-fired  Building fabric Change in heat loss (%) Fuel switching is also allowed from resistance heating, oil boilers and solid fuel boilers.  generation plant. \u00c0 1 \u00c0 5 \u00c0 1 \u00c0 5 \u00c0 7 \u00c0 30 \u00c0 12 \u00c0 50",
            "Discussion": " The UK's ambitious greenhouse gas emissions reduction targets, especially for 2050, are widely interpreted to imply almost complete decarbonisation of residential heating services (CCC, 2013;HMG, 2011). However, our analysis shows that with minimal policy intervention, the UK will continue to use substantial quantities of natural gas for home heating, which is inconsistent with climate policy ambitions. The other scenarios investigated produce impacts on fossil fuel use, and their carbon emissions, which are broadly consistent with ambitious climate policy goals. Whilst rapid decarbonisation of electricity followed by wholesale conversion of heating to heat pumps is the most widely discussed strategy, it is not the only one. Other approaches place more emphasis on alternatives, notably biofuels and energy efficiency, indicating that there is some flexibility in delivering carbon mitigation policy, although a substantial emphasis on heat pumps seems likely. The implications for different infrastructures are profound. With minimal policy intervention, the UK will remain dependent on a natural gas-fired heating infrastructure. Any move away from this creates a substantial reduction in gas demand, and consequential issues for owners of the gas infrastructure. With one notable exception (Dodds and McDowall, 2013), these are not well recognised in the research and policy literature and therefore warrant further attention. This 'destruction of demand' for gas might be mitigated by greater use of biogas through the existing infrastructure. The extent to which biogas can be sourced in a country with as high a population density as the UK is controversial, but the numbers set out in the high biomass scenario above (LEB) seem feasible without heavy reliance on imports. In principle, hydrogen (produced from biomass or any other low carbon energy source) might also be use either to enrich or substitute for natural gas. This would however require upgrading the gas infrastructure to accommodate higher level of hydrogen in the mix. The scenario which places a very high dependence on electrification and heat pumps (EHT) poses challenges for electricity infrastructureboth distribution and generation. The additional space heating load of 75 TWh/year will be strongly peaked in winter, and heat pumps are less efficient at lower temperatures. Whilst heat storage and electricity system demand response, within buildings or elsewhere, can mitigate diurnal demand peaks, seasonal impacts cannot be mitigated without very large scale, and therefore very expensive, heat storage. Although the impact of 75 TWh/year spread equally over the year is approximately 9 GW, when the effects of seasonality and heat pump efficiency are taken into account, the impact on peak demand in cold weather in midwinter will be over 40 GW on a Great Britain system where peak load is currently $ 60 GW. Transport electrification will, of course, potentially exacerbate the effect (Tran et al., 2014). The potential implications for electricity sector investment are very significant. Capital costs of power generation range from $d500/kW for peaking plant to in excess of d3000/kW (declared net capacity) for low carbon technologies (PBP, 2011). We assume that, to meet carbon goals, the increase in average winter load ( $ 20 GW) would need to be met by low carbon capacity, with the shorter term (diurnal and cold weather) peaks met by low capital cost technologies. This implies a generation programme to electrify residential heating demand would require investment of $d70 billion. There will also be additional transmission costs, but these are likely to be an order of magnitude lower (Baruah et al., 2014b). This is additional to the cost of the heat pump and its installation, currently estimated to be d8000 per household, with the scope to fall to d5000 by 2030 (Element, 2012). Of course, other strategies are not cheap either, implying significant investments in the building stock, district heating and/or photovoltaics, but, in Great Britain, d70 billion is almost d3000 per household just for the additional generation capacity. These figures illustrate that attention is required to peak demand issues. As a sensitivity, we have calculated the implications for additional power generation capacity investment if heat pumps were sized only to meet average winter conditions ( $5 C), as opposed to cold weather conditions ( $ \u00c05 C). We estimate the capacity requirement would be $ 40% ( $ 15 GW) lower if secondary heating systems are used only to meet the difference in heat demand caused by unseasonably cold temperatures. Once secondary systems are installed, more radical options are possible, including replacing the whole of residential heating electricity demand at times of system peak demand. 9 presents the impacts of such an approach for the UK system in the EHT scenario, using back-up heating systems (for example a hybrid heat pump/gas boiler system) during times of system peak demand. The peak load on the GB electricity system is reduced by the full 40 GW of residential peak demand, reducing peak load by more than 30% (Baruah et al., 2014a). If determination to deliver on carbon emissions goals is neglected, continued high dependence on gas looks the most probable outcome, if for no other reason than that the infrastructure exists. The corollary is that overcoming the gas 'lock-in' is essential to delivering climate mitigation goals. This has major implications not just for the energy sector, but for the myriad of small enterprises that deliver the end use technologies involved. The UK has approximately 100,000 gas fitters; the implications of the scenarios other than MPI is that these jobs need to be replaced by heat pump fitters (involving electrical and refrigeration skills), district heating providers, PV installers and a range of energy efficiency trades. Uncertainties in socio-economic drivers, in particular population, have been neglected by most analysts and policymakers. They are certainly not as dramatic as the uncertainties arising from qualitatively different infrastructure systems. But they are significant and, in scenarios that are very heavily reliant on a single fuel, the uncertainty is concentrated in that fuel, so that high population projections exacerbate the investment implications of high electricity scenarios. On the other hand, strategies with high efficiency combined and on-site electricity generation reduce the range of demand uncertainty from demographic change. Other research (Cooper et al., 2013) has shown that there are economic synergies between heat pumps and micro-CHP, arising from the propensity of the latter to generate at times of highest heat pump demand. These benefits are not well represented in most energy system models, due to their limited temporal granularity. Micro-CHP systems have currently failed to enter the market in large numbers due to performance and reliability issues, but if these problems could be resolved, a mixed deployment of heat pumps and micro-CHP would have some significant advantages in peak load avoidance. It seems very likely that the optimal strategy for delivering a low carbon residential heating system at minimum cost is a mixture of the three 'low gas' options set out above. The 'all electrification' strategy has a number of problems, not just electricity generation capacity needs. However, it remains difficult to see a very low carbon system without some element of this approach. Other options for system change also have associated risks. Greater reliance on efficiency requires delivery of high thermal performance in retrofitting that has yet to be widely achieved (Chiu et al., 2014). Greater use of biomass in CHP systems has led to a number of reliability problems and the technologies for both single dwellings (e.g. pellet boilers) and biomass gasification have not been widely deployed in the UK. The extent to which these risks will prove tractable cannot currently be known. This points to a short term strategy of 'opening options'. Whilst the costs associated with development, demonstration and early deployment of a number of options may be significant, they will be less than those associated with a whole-hearted commitment to a pathway that ultimately fails. The implication for public policy would seem to be that opening up all of these options is prudent at this stage.",
            "Implications for the UK Government's Heat Strategy": " In this sub-section we compare our analysis with that of the UK Government as set out in its Heat Strategy (DECC, 2013b) published by the Department of Energy and Climate Change (DECC). In the Heat Strategy, gas continues to play a major role into 2030s with diminishing role thereafter, but no role for gas boilers by 2050, by when heating demand is met by mass deployment of heat pumps, supplemented by urban heat networks (supplied largely from nuclear and CCS power stations). The primary modelling tool used to support this analysis, the Redpoint Energy System Optimisation Model (RESOM), suggests that hybrid systems comprising an air source heat pump with a supplementary gas boiler to meet peak demand (hybrid air source heat pump, HASHP) is likely to play a significant role, given carbon constraints, after 2020. Other modelling, with the ESME model (Heaton and Davies, 2010) suggests gas absorption heat pumps (GAHP) might also be able to play a bridging role. Nevertheless, 'no role for gas' by 2050 means HASHP and GAHP are seen as bridging technologies before electric heat pumps and district heat networks (supplied by low carbon technologies) take over. The RESOM core model runs indicate this bridging role, showing around 80% of residential and water heating delivered by heat pumps by 2050. Our analysis is supportive of this analysis in so far as the heat pump uptake in our EHT scenario is broadly consistent with that in the Heat Strategy. Moreover, the inclusion of some different technologies, such as GAHP and HASHP, in the Government's Heat Strategy may help address some concerns about the over-reliance on ASHP, both in earlier UK Government analysis and our EHT scenario. However, our exploration of other social and technology issues, in the wider range of potential scenarios for UK residential heat policy that we consider, raises some important concerns about the Heat Strategy. The Heat Strategy appears to the potential for building energy efficiency. Its analysis indicates building energy efficiency improvement by about 20% over 40 years (0.5% per year). This is substantially less than the recent rates of energy demand reduction in the sector, which are most probably due to building efficiency improvement, and small compared to the potential set out by DECC elsewhere (HMG, 2011). It seems to be inconsistent with DECC's own high ambition for improved building energy efficiency (DECC, 2010), as well as the legal requirements of the European Union's Energy Performance of Buildings Directive. There is no justification of the choice in the evidence annex to the Heat Strategy, nor any sensitivity analysis. It implies that the heating demands modelled are higher than is cost effective and therefore that the cost effectiveness calculations for new heating technologies are based on implausibly high demand, and therefore over-optimistic. There is no explicit role for biofuel technologies in the Heat Strategy. The optimum use of biomass in carbon constrained economies is a complex topic, and many analyses find it is optimally used outside the building sector. However, there is no apparent exploration of the use of biofuels. Biomass boilers are listed in the technologies available to RESOM, but not deployed in the scenario reported. Biogas technologies are not listed. As biogas and hydrogen are the only plausible routes to retaining the dominant gas network, this omission risks pre-determining the importance of the other key network infrastructure-electricity. There is some use of biomass in supplying heat networks, but this is very limited by 2050. The Heat Strategy modelling involves a remarkably rapid phasing out of gas boilers. These are assumed to be phased out by 2030, which implies no new installation after about 2018 if they are not to become stranded assets. For such a fundamental policy shift to occur for a key mass market product in less than 5 years seems highly improbable. There are very optimistic assumptions about the deployment of HASHP in the Heat Strategy modelling. Energy output from HASHP rises to $ 30 TWh/year by 2015 (which clearly will not happen) and $ 100 TWh/year not long after 2020. This implies the installation of $ 1 million systems per year in the very near future, which is extremely optimistic for a technology that is currently deployed in very limited numbers. The Heat Strategy itself, as opposed to the modelling supporting it, focuses on providing short and medium term incentives for heat networks in dense urban areas and low carbon, single home technologies for off-gas areas. These are initial niche investments that are reasonably robust against the different low carbon scenarios we have considered, and therefore our analysis tends to support the Heat Strategy itself, whilst conflicting with some of the modelling used in its evidence base. There is no certainty that the projected long term outcomes of the Heat Strategy are those represented in the results of the models used by DECC. Such a heavy reliance on electrification has not been the outcome of analysis in other EU countries, in particular in Germany (Schlomann et al., 2014) and Denmark (DEA, 2014), where greater reliance is being placed on energy efficiency and alternative heat vectors respectively.",
            "Implications for the UK 4th Carbon Budget": " Given the importance of residential space heating for UK energy demand, and its current carbon intensity, there are obvious implications of this work for UK carbon mitigation. In this section we compare our key findings with the analysis of UK Committee for Climate Change (CCC) for the 4th Carbon Budget (CCC, 2013). Reflecting its legal mandate, the CCC (CCC, 2013) outlines costeffective pathways to meet the 2050 carbon target embodied in UK Climate Change Act. In this sense, it has very clearly different objectives and methods from our analysis. In the CCC analysis, energy prices and abatement costs are key factors in modelling technology uptakes into the future. In contrast, the focus of our analysis has been to draw out the possible uncertainties in heating energy demand from exogenous drivers and a diverse set of transition pathways. We make no attempt at strict cost minimisation, although, of course, the modelling assumptions reflect the fact that costs will be an important issue. So our assumptions about technology change are not solely dependent on prices, costs and demand elasticities. In essence, we assume that different, internally consistent, pathways of socio-technical change are possible under different economic, social and political conditions, rather than focusing on a single goal (climate mitigation) and minimising its costs as the CCC analysis is required to do. The central population estimate in our scenarios aligns closely with the single projection used in CCC analysis. We consider that the absence of any alternative demographic assumptions in the CCC work is a significant weakness of their analysis. In particular, given the strong dependence on heating electrification in the CCC analysis (and that of DECC), neglecting the possibility of higher population growth implies under-estimating the risk of more problematic outcomes related to higher electricity use and peak demand. And the absence of alternative scenarios limits the capacity of their analysis to be robust against uncertainties in future demand, technology cost and end-user acceptability. In our study, building envelope efficiency is modelled through transparent assumptions about the achievable rates of improvement of thermal performance of the building stock, ranging from modest changes to a 50% reduction in average heat loss by 2050. The latter is in line with the high ambition level for efficiency improvement in DECC's 2050 analysis, but less ambitious than set out in recent international assessments (Lucon et al., 2014;Urge-Vorsatz et al., 2012). The CCC uses more detailed 'bottom-up' modelling of individual measures, both energy efficiency (Element, 2013) and low carbon heating (Frontier, 2013). This provides a more robust basis for short to medium term assessment and costing, but neglects the potential for more radical low carbon upgrades in deep refurbishment. The CCC assessment of 50 MtCO 2 potential for energy efficiency is broadly consistent with the 50% improvement in energy efficiency assumed in our DDBT scenario. Both are far more ambitious than the potential of 20% in the DECC Heat Strategy, and this is a major source of analytical difference. Conservation measures leading to reductions in internal temperature are slightly more ambitious in (CCC, 2013), with a 1 C temperature reduction by 2030, where as we assume a reduction of 0.5 C by 2035 and 1 C by 2050 in the DDBT strategy only. Recent energy use trends in UK housing imply that the trend towards higher internal temperatures has ended. This may be a temporary phenomenon associated with higher energy prices, but it implies that such modest downward changes are credible. Our analysis of the potential for district heat networks is broadly similar to that of the CCC. The DDBT scenario is where we explore relatively high penetration of district heat networks, reaching 2% by 2030 and 20% by 2050. The 4th Carbon Budget report raises the CCC goal to 6% of heat demand by 2030, in the context of new evidence suggesting a potential of 40% by 2050. However, closer examination of the 40% number indicates that the majority (28%) is contingent on heat recovery from large power plants, which we judge to be uncertain. Our 20% estimate is consistent with heat mapping (Poyry, 2009), which estimated that 20% of UK heat demand is at densities exceeding 3 MW/km 2 . Despite the increased focus on district heating in the 4 th Carbon Budget report, the predominant technical change remains towards heat pumps, principally ASHP. The 4th Carbon Budget report projects 30.6 million household heat pump installations are required by 2050 to meet the carbon target, supplying 232 TWh to 80% of all properties. The number of installations by 2030 has been revised down from a previous estimate of 7 million, based on supporting analysis, due to relatively slow progress to date (Element, 2013). The 4th Carbon Budget report projects a heat pump market penetration of 4 million by 2030, i.e. $13% of the total housing stock. The pathway is broadly consistent with EHT scenario set out in our analysis, i.e. it is a pathway that still moves decisively towards electrification of heating, with all the benefits and risks set out in our analysis of the EHT scenario above. As shown in Fig. 10, it requires approximately double the substitution of gas boilers by heat pumps compared to a more strategy such as modelled in our DDBT scenario. In contrast to the DECC Heat Strategy, the 4th Carbon Budget Report does not include quantified projections for hybrid heat pumps or gas heat pumps, due to the commercial uncertainties in their availability and performance. There is qualitative attention to GAHP, noting their benefits in peak electricity reduction. The supporting analysis to (CCC, 2013) has conducted a sensitivity analysis of HASHP deployment. This notes that HASHP will have some important advantages: better compatibility with higher heat loss buildings and existing heating systems; a lower cost of adapting the heating systems; reduced heat pump capacity making the installation costs comparable to ASHP; and improved performance (a Seasonal Performance Factor 0.3 higher than an ASHP). Most importantly HASHPs can be installed as an addition to an existing boiler. On the other hand, space and environmental (noise and visual) constraints may be broadly similar and the operating costs will be comparable. Importantly, the carbon benefits of HASHP are lower than ASHP and GSHP. However, the CCC analysis provides no quantified evidence on HASHPs' ability to reduce peak load. Neither is the attractiveness to users of installing quite complex heating systems in low energy homes explicitly considered. Overall, the supporting analysis for the 4th Carbon Budget report finds that HASHP can reduce the need for conventional heat pumps in 2030. However, it agrees with the DECC Heat Strategy analysis that the imperative of meeting the 2050 carbon target leaves no role for gas-based systems, and therefore requires phasing out of HASHP by 2050. The implications of our analysis for the CCC projection are therefore similar to that for the DECC heat strategy: that reliance on a single strategy with high levels of electrification lacks robustness against technical, commercial and policy risks to mass deployment of heat pumps.",
            "Conclusions": " Direct use of fossil fuels is the main source of space heating in the UK and this drives a major part of national greenhouse gas emissions. Climate stabilisation therefore implies a systemic change in approaches to space heating, involving some combination of radical efficiency improvement and low carbon vectors. The challenge in this area for the UK is made particularly difficult because of the combination of the legal commitment to an 80% reduction in emissions by 2050, an inefficient building stock and a very high penetration of natural gas as a heating fuel. We present new quantified scenarios for residential energy use in the UK to 2050. These address both factors that are exogenous to the energy system, such as population, but also some systemically different approaches to delivering residential heat. With minimal policy intervention the UK will remain locked into a gas based heating system, but there is a range of scenarios in which this is avoided. Heat pumps powered by low carbon electricity are an option, but complete reliance on this as a solution raises a number of problems. Very high levels of electrification imply the disuse of much of the gas infrastructure and major changes in heating installer products, supply chains and practices. The performance and acceptability of heat pumps in UK homes remains unproven. Meeting peak heating demand with heat pumps alone would need approximately 40 GW of additional electricity generation capacity, much of it low carbon, at an investment cost of approximately d70 billion. These pressures might be exacerbated by high population growth. However, they might be reduced using some hybrid heating technologies, notably hybrid boiler/heat pump systems as bridging technologies, although these are currently unproven and may be difficult to deploy at scale by 2030. Much greater use of energy efficiency and biomass can also play a significant role in decarbonisation and diversify the risks associated with a high electrification strategy. Substantially higher use of biofuels raises concerns about sustainable sourcing, but seems feasible within projected available resources. There is also a potential role for heat networks in dense urban areas, but this still requires low carbon sources, if heat is to be decarbonised. Improved efficiency is helpful in reducing overall demand, and therefore reduces costs and pressures on supply side solutions. Meeting low carbon heating goals is better conceptualised as reducing reliance on gas (and other fossil fuels) rather than necessarily mass electrification. Any low carbon heating system will require the deployment of unfamiliar technologies at scales requiring major investment and changes in supply chain practices and consumer acceptance. We conclude that the future of UK residential space heating is very uncertain. Either gas or electricity could be the major fuel supplier; and biofuels and district heating might or might not make significant contributions. The nature of the required infrastructure is very different in each case. A continuation of the existing pattern of demand with a heating sector dominated by natural gas is possible, but conflicts with current UK policy goals for decarbonisation. UK policy makers currently preferred alternative is a system heavily reliant on heat pumps supplied with low carbon electricity. We conclude that some shift in this direction is very likely to be required to meet current UK policy objectives, but that a very heavy reliance on this approach poses a number of risks. A more diversified strategy, with greater emphasis on energy efficiency and biofuels has lower risks, and therefore is more prudent. Our analysis focusses on the UK, but has implications for any country with high demand for fossil fuels to provide space heating in buildings and ambitious decarbonisation goals. Some move towards electrification of heating seems very likely, but the risks, in particular, to peak winter electricity demand need to be more carefully considered than in most analyses to date. research fellowship from the Frank Jackson Foundation."
        }
    },
    "10.1016/j.enpol.2012.08.071": {
        "file_name": "26 The energy and environmental implications of UK more electric transition pathways",
        "title": "The energy and environmental implications of UK more electric transition pathways: A whole systems perspective",
        "abstract": "Electricity generation contributes a large proportion of the total greenhouse gas emissions in the United Kingdom (UK), due to the predominant use of fossil fuel (coal and natural gas) inputs. Indeed, the various power sector technologies [fossil fuel plants with and without carbon capture and storage (CCS), nuclear power stations, and renewable energy technologies (available on a large and small {or domestic} scale)] all involve differing environmental impacts and other risks. Three transition pathways for a more electric future out to 2050 have therefore been evaluated in terms of their life-cycle energy and environmental performance within a broader sustainability framework. An integrated approach is used here to assess the impact of such pathways, employing both energy analysis and environmental life-cycle assessment (LCA), applied on a \u2018whole systems\u2019 basis: from \u2018cradle-to-gate\u2019. The present study highlights the significance of \u2018upstream emissions\u2019, in contrast to power plant operational or \u2018stack\u2019 emissions, and their (technological and policy) implications. Upstream environmental burdens arise from the need to expend energy resources in order to deliver, for example, fuel to a power station. They include the energy requirements for extraction, processing/refining, transport, and fabrication, as well as methane leakage that occurs in coal mining activities \u2013 a major cotribution \u2013 and from natural gas pipelines. The impact of upstream emissions on the carbon performance of various low carbon electricity generators [such as large-scale combined heat and power (CHP) plant and CCS] and the pathways distinguish the present findings from those of other UK analysts. It suggests that CCS is likely to deliver only a 70% reduction in carbon emissions on a whole system basis, in contrast to the normal presumption of a 90% reduction. Similar results applied to other power generators.",
        "label": "Quantitative",
        "text": {
            "Introduction": "",
            "Background": " Electricity generation contributes approximately 30% of United Kingdom (UK) carbon dioxide (CO 2 ) emissions (POST, 2007), the principal 'greenhouse gas' (GHG) having an atmospheric residence time of about 100 years (Hammond, 2000). This is predominantly due to the use of fossil fuel (coal and natural gas) combustion for this purpose. Indeed, all the main power sector technologies [fossil fuel plants with and without carbon capture and storage (CCS), nuclear power stations, and renewable energy technologies (available on a large and small {or domestic} scale)] involve differing environmental impacts and other risks (El-Fadel et al., 2010;Hammond and Waldron, 2008) dramatic increases since 1950 in the 'basket' of GHGs incorporated in the Kyoto Protocol; concentrations rising from 330 ppm to about 430 ppm presently (IPCC, 2007). Prior to the first industrial revolution the atmospheric concentration of 'Kyoto gases' was only some 270 ppm. The cause of the observed rise in global average near-surface temperatures over the second half of the 20th Century has been a matter of dispute and controversy. But the most recent scientific assessment by the Intergovernmental Panel on Climate Change (IPCC) states with 'very high confidence' that humans are having a significant impact on the global warming (IPCC, 2007). They argue that GHG emissions from human activities trap long-wave thermal radiation from the Earth's surface in the atmosphere (not strictly 'greenhouse' phenomena), and that these are the main cause of rises in climatic temperatures. In order to mitigate anthropogenic climate change, the Royal Commission on Environmental Pollution in the UK (RCEP, 2000) recommended at the turn of the Millennium a 60% cut in UK CO 2 emissions by 2050. The British Government subsequently set a tougher, legally binding target of reducing the nation's CO 2 emissions overall by 80% by 2050 in comparison to a 1990 baseline (DTI, 2007). The history of electricity generation since the time of Edison has been based around the concept of employing large, centralised power stations (see, for example, Alderson et al., 2012;Buchanan, 1994;Hammond, 2000;Hughes, 1983). Thus, the bulk of electricity in Britain is still generated by large thermal power plants that are connected to a high-voltage transmission network, and is then distributed to end-users via regional low-voltage distribution networks (Hammond and Waldron, 2008;POST, 2007). A simplified model of energy flows in the UK is illustrated in Fig. 1 (Hammond, 2000). It should be noted that heat is wasted and energy is 'lost' at each stage of energy conversion and distribution, particularly in the process of electricity generation. The schematic energy flow diagram shown in Fig. 1 hides many feedback loops in which primary energy sources (including fossil fuels, uranium ore, and hydro-electric sites) and secondary derivatives (such as combustion and nuclear-generated electricity) themselves provide upstream energy inputs into the 'Energy Transformation System'. The latter is that part of the economy where a raw energy resource is converted to useful energy which can meet downstream 'final' or 'end-use' demand (Slesser, 1978). 'Renewable' energy sources are taken to mean those that are ultimately solar-derived: mainly solar energy itself, biomass resources, and wind power. This centralised model has delivered economies of scale and reliability (Allen et al., 2008a), but there are significant drawbacks. It suffers, for example, from overall energy system losses of about 65% in terms of primary energy input (Allen et al., 2008b;DECC, 2010;Hammond, 2000;Hammond and Stapleton, 2001). These losses predominantly result from heat wasted during electricity production (58%), but there are smaller losses rising in transmission and distributionapproximately 1.5% and 5% respectively (Allen et al., 2008b;POST, 2007). The use of micro-generation and other decentralised or distributed power technologies has the potential to reduce such losses. It has recently been predicted that micro-generation could provide 30-40% of the country's electricity needs by 2050 (Allen et al., 2008a).",
            "The issues considered": " Three transition pathways for a more electric future out to 2050 (Foxon et al., 2010) have been evaluated here in terms of their life-cycle energy and environmental performance within a broader sustainability framework (Hammond and Jones, 2011b). An integrated approach is used (see, for example, Allen et al., 2008a) to assess the impact of such pathways, employing both energy analysis and environmental life-cycle assessment (LCA), applied on a 'whole systems' basis. Energy analysis required estimates of the energy outputs of the power generators during use, and the energy requirements for their construction and operation. In contrast, the LCA yielded estimates of pollutants or wastes released into the environment as a consequence of the power network (in terms of 17 separate impact indicators, together with a tentative 'single score', aggregate LCA metric). Carbon footprints have become the 'currency' of debate in a climate-constrained world. They represent the amount of carbon [or carbon dioxide equivalent (CO 2e )] emissions associated with a given activity or community, and are generally presented in terms of units of mass or weight [kilograms per functional unit (e.g., kgCO 2e /kWh)]. Embodied energy and carbon appropriate to the various power generators specified in the current work have been determined using proprietary LCA software tools and databases, together with the 'Inventory on Carbon and Energy' (ICE) [developed at the University of Bath (Hammond andJones, 2008, 2011a)]. 'Embodied energy' is here defined as the total primary energy consumed from direct and indirect processes associated with power production and within the boundary of 'cradle to gate' (Hammond and Jones, 2011a). This includes all activities from material extraction (quarrying/mining), manufacturing, transportation and right through to fabrication processes until the power plant is constructed for operational use. Similarly, 'embodied carbon' is the sum of fuel-related carbon emissions (i.e., embodied energy which is combusted, but not the feedstock energy which is retained within materials) and process-related carbon emissions (Hammond and Jones, 2011a). The present study highlights the significance of 'upstream emissions' and their (technological and policy) implications. Upstream environmental burdens arise from the need to expend energy resources in order to deliver, for example, fuel to a power station. They include the energy requirements for extraction, processing/refining, transport, and fabrication, as well as methane leakage that occurs in coal mining activities -a major contribution -and from natural gas pipelines. Thus, 'whole system' GHG emissions \u00bc upstream GHG emissions \u00fe operational GHG emissions where the 'operational' or 'stack' emissions are those directly associated with the combustion of fossil fuels within power stations. These whole system emissions amount to those related to the 'Energy Transformation System' as defined by Slesser (1978): see Fig. 1 above. The impact of upstream emissions on the carbon performance of various low carbon technologies [such as large-scale combined heat and power (CHP) plants and CCS] and the pathways distinguish the present findings from those of other UK analysts. The present contribution is a part of an ongoing research effort aimed at evaluating and optimising the performance of various sustainable energy systems (Allen et al., 2008a(Allen et al., , 2008b;;El-Fadel et al., 2010;Hammond, 2011;Hammond et al., 2011aHammond et al., , 2011b) ) in the context of transition pathways to a low carbon future for the UK (Alderson et al., 2012;Foxon et al., 2010).",
            "The UK Electricity Supply Industry": " The UK Electricity Supply Industry (ESI) currently has a heavy reliance on primary fuels, particularly coal and natural gas (Alderson et al., 2012). Cheap coal from overseas is unlikely to cause a security of supply problem, but the increasing reliance being placed on imports of natural gas for Combined Cycle Gas Turbine (CCGT) power plants brings with it potential risks. Britain became a net importer of natural gas in 2004 as reserves in the UK continental shelf declined (DECC, 2010;DTI, 2003;Hammond and Waldron, 2008). In the long-term there is considerable uncertainty about the security of imported gas supplies. The largest natural gas reserves globally are found in Russia, North Africa, and the Middle East. Even without the obvious political problems associated with these regions, there will be difficulties in terms of the transportation of gas from these areas. Long pipelines, additional port and storage capacity will all be required. The natural gas interconnector between Norfolk and Belgium means that gas can flow out of Britain to the continental market, as well as inward to meet domestic demand. In 2005 the UK produced 1,026,900 GWh of indigenous natural gas, with its net imports amounting to some 77,000 GWh (DECC, 2010;Hammond and Waldron, 2008;POST, 2007). But imports are likely to grow quite rapidly in the near future. The UK electricity system is made up of companies performing different functions: the generators, network companies, and suppliers (Alderson et al., 2012;DTI, 2003;Hammond and Waldron, 2008;POST, 2007). National Grid (NG) acts as the system operator with responsibility for balancing power supply and demand. The 'generators' own and operate large power stations: coal-fired stations, CCGT plant, nuclear power stations, wind farms, and various smaller contributors. Thirty large ( 41GW e ) power plants meet the bulk of electricity demand. This is typically $ 40GW e , although it rises to $60GW e at peak. NG is also the Transmission Network Owner (TNO) for England and Wales, whilst Scottish Power and Scottish and Southern are the TNOs in Scotland. The 'grid' is made up of $25,000 km of high voltage overhead lines (275 kV or above) that minimise energy losses over distance. There are currently some 14 regional distribution networks in Great Britain with 800,000 km of overhead lines and underground cables (POST, 2007). They deliver lower voltage (132 kV and below) power from grid supply points to consumers. These regional networks are managed, in turn, by seven companies that act as Distribution Network Operators (DNOs). Much of the grid was constructed in the 1950s and 1960s. It is therefore heavily reinforced in former coal-mining areas, and is nearing the end of its design life (Alderson et al., 2012;DTI, 2003;Hammond and Waldron, 2008). There are 'bottlenecks' restricting power flow from Scotland to England (2.2GW e ), and via the interconnectors (in the form of high-voltage undersea cables) to France and Northern Ireland (POST, 2007). The grid will require both renewal and reconfiguration to accommodate distributed generation. 3. Transition pathways to a low carbon, more electric UK economy",
            "The transition pathways approach": " A consortium of roughly equal proportions of UK engineers and social and policy analysts have been developing a set of 'transition pathways' to a low carbon, more electric economy by 2050 (see Foxon et al., 2010). This project aims to (a) learn from past transitions to help explore future transitions and what might enable or avoid them; (b) design and evaluate transition pathways towards alternative socio-technical energy systems for a low carbon future; and (c) understand and, where appropriate, model the changing roles, influences and opportunities of actors in the dynamics of transitions. It has followed the Dutch transitions approach by applying a multi-level perspective for analysing socio-technical transitions, based on interactions between three levels: niches, socio-technical regimes, and landscapes (Geels, 2002;Rip and Kemp, 1998). The transition pathways are a form of socio-technical scenarios, which explore the potential future development of socio-technical systems through interactions between ongoing processes at the three levels (Elzen et al., 2002;Elzen and Hofman, 2007;Hofman et al., 2004;Meeuwsen, 2007). They also draw on a wider review and analysis of lessons from UK and international low carbon energy scenarios, undertaken as part of the project (Hughes and Strachan, 2010). This analysis has shown that scenarios could play a significant role in helping to build consensus between different actors for a shared vision and complementary actions needed to bring about a low-carbon transition.",
            "The selected pathways": " An initial set of transition pathways for a UK low carbon energy system were developed (Foxon et al., 2010) by applying three main steps (Foxon et al., 2010): (1) characterising the existing energy regime, its internal tensions and landscape pressures on it; (2) identifying dynamic processes at the niche level; and (3) specifying interactions giving rise to or strongly influencing transition pathways. They were devised via stakeholder workshops (involving UK energy researchers, industrialists, and policy advisers and decision-makers), a narrative descriptive of each pathway, and their subsequent technical elaboration. This eventually resulted in the following three selected pathways that have been evaluated in the present study: Market rules (MR): this envisions the broad continuation of the current market-led governance pattern, in which the government specifies the high-level goals of the system and sets up the broad institutional structures, in an approach based on minimal possible interference in market arrangements (Foxon et al., 2010). Large, vertically-integrated energy companies (the regime actors) are assumed to dominate, and landscape pressures -such as climate change and energy security -on these actors leads to an emphasis on the reduction of carbon emissions and a concentration on large-scale technologies: capture-ready coal, nuclear power, and offshore wind [see Fig. 2]. Small-scale renewable technologies, and distributed generation generally (Allen et al., 2008a;Foxon et al., 2005), fail to emerge from niches. Successful demonstration of CCS (Hammond et al., 2011a) leads to its deployment from 2020 onwards, whilst a high carbon price makes CCS, nuclear and large-scale renewables economical to build, and enables rollout of CCS retrofit to remaining coal and gas power stations. 80% of this generation capacity is still connected via high-voltage overhead and underground lines by 2050 (Elder et al., 2006), with conventional power plants being sited at existing locations, whereas offshore wind is presumed to be concentrated around Scotland. The latter implies a need for high levels of grid/ transmission reinforcement (Elder et al., 2006). Central co-ordination (CC): this envisions greater direct UK (central or national) government involvement in the governance of energy systems (Foxon et al., 2010), e.g., issuing tenders for tranches of low-carbon generation. But there is still a focus on centralised generation technologies, such as coal and gas CCS (Hammond et al., 2011a), nuclear power (Hammond, 2011), offshore wind, onshore wind, and wave and tidal power (Foxon et al., 2005)   with large energy companies, as the regime actors. This might be achieved via the creation by central government of a 'Strategic Energy Authority' (Foxon et al., 2010), which could use central contracts with large energy companies to reduce the risks of low-carbon investments. Niche-level activity would be focused on large-scale technologies, particularly offshore wind and CCS, with less emphasis on small-scale technologies. 80% of generation capacity would still be connected via highvoltage power lines by 2050. The coal and natural gas CCS and new nuclear plants are likely to be sited at existing locations. In contrast, offshore wind would be constructed around Scotland and in the North Sea, implying the need again for high levels of grid/transmission reinforcement (Elder et al., 2006). Thousand flowers (TT): this envisions a sharper focus on more local, bottom-up diverse solutions: ''let a thousand flowers bloom'' (Foxon et al., 2010). This decentralised power network is driven by innovative local authorities and citizens groups, such as the Transition Towns movement (Hopkins, 2008). Energy service companies (ESCOs) -both new entrants and diversified existing energy companies-become key actors who are assumed to develop local micro-grids (Foxon et al., 2010). Landscape pressures (particularly climate change and energy security) on these regime actors, and government support for small-scale and community-level initiatives, leads to a focus on demand reduction and key small-scale technologies with 50% distributed generation. Small-scale renewable technologies emerge from niches (Foxon et al., 2010), including onshore wind, offshore wind, renewable CHP, solar PV, wave and tidal power, as well as imports [see Fig. 4]. Positive feedbacks lead to 'virtuous cycles' in deployment of small-scale distributed generation technologies (Allen et al., 2008a;Foxon et al., 2005), and greater community ownership of generation, including onshore wind and biomass CHP. However, 50% distributed generation will require the development of 'smart grid' technologies to handle two-way power flows (Elder et al., 2006), with the remaining 50% centralised generation still connected at highvoltage overhead and underground lines by 2050, dominated by high-efficiency CCGT and offshore wind concentrated around Scotland and in the North Sea, implying the need for significant levels of grid/transmission reinforcement (Elder et al., 2006).",
            "Whole systems appraisal": "",
            "The sustainability and 'whole systems' context": " Over a period of some 20 years, the international community has been grappling with the task of defining the concept of 'sustainable development'. It came to particular prominence as a result of the so-called Brundtland Report published in 1987 under the title ''Our Common Future''; the outcome of 4 years of study and debate by the World Commission on Environment and Development [WCED], (1987) led by the former Prime Minister of Norway, Gro Harlem Brundtland. This Commission argued that the time had come to couple economy and ecology, so that the wider community would take responsibility for both the causes and the consequences of environmental damage. It thereby attempts to balance economic and social development with environmental protection (encapsulated in the 'strapline' for the 2002 Johannesburg World Summit on Sustainable Development of ''people, planet, prosperity''); the so-called 'triple bottom line' (Parkin, 2000), or what others term 'The Three Pillars'. The Brundtland Commission envisaged sustainable development as a means by which the global system would satisfy ''the needs of the present without compromising the ability of future generations to meet their own needs'' (WCED, 1987). It therefore involves a strong element of intergenerational ethics. The interconnections between the economic, environmental social domain can also be illustrated by a sustainability Venn diagram [see, for example, (Clift, 1995;Hammond and Winnett, 2006;Parkin, 2000)]. The notion of whole systems analysis and thinking is open to a variety of interpretations. Here it is viewed as providing a transparent sustainability appraisal framework (of economic, social, environmental and technical benefits) for the transition pathways that are being explored (Hammond and Jones, 2011b). Several economic, social and environmental appraisal techniques may be employed on a life-cycle, 'whole systems', or 'full fuel cycle', basis (Hammond and Winnett, 2006). These linked methods can provide a 'toolkit' for interdisciplinary sustainability appraisal (Gibson et al., 2005). The 'Three Pillars', or a more limited sub-set as employed here, can also constitute a mechanism for illustrating the interconnections within the energy  (principally electricity) system, and for identifying significant constraints associated with the adoption of the selected routes to a highly electric, low carbon economy.",
            "Quantitative appraisal methods": " A range of 'whole systems' ('full fuel cycle' or life-cycle) energy and environmental appraisal techniques have been employed here to study the evolution of the three selected transition pathways to a low carbon UK economy in 2050. They are interrelated in the sense that energy analysis (EA) was one of the precursors for environmental life-cycle assessment, and is typically performed in parallel with environmental appraisal in most modern LCA software packages. Both EA and LCA avoid the examination of products on a 'sub-system' basis, whereby only one part of the life-cycle is examined. They can also be employed to estimate impact inventories that can then be coupled with environmental cost-benefit analysis (CBA) to yield their environmental costs. Such methods help to provide a performance 'snapshot' in time, based on quantitative evaluations.",
            "Life-cycle energy and environmental impact analysis": "",
            "Energy analysis": " In order to determine the primary energy inputs needed to produce a given artefact or service, it is necessary to trace the flow of energy through the relevant industrial sector (Hammond and Jones, 2008). This is based on the First Law of Thermodynamics (the principle of conservation of energy) or the notion of an energy balance applied to the system. The system boundary should strictly encompass the energy resource in the ground (known as the 'cradle'-for example, oil in the well or coal at the mine). In the present analysis the downstream boundary is known as the 'gate' [hence, 'cradle-to-gate' (Hammond and Jones, 2011b)], or the power delivered by the generators to the national electricity network (operated by TNOs and DNOs). Consequently, it effectively accounts for all UK power sector primary energy use (and associated emissions). Energy analysis yields the whole-life or 'Gross Energy Requirement' (GER) of the product or service system (see Hammond and Jones, 2008;Roberts, 1978;Slesser, 1978). Likewise, the sum of all primary energies required to yield one unit of delivered energy is known as the 'Energy Requirement of Energy' (ERE). Thus, the sum of all the outputs from this system multiplied by their individual energy requirements must be equal to the sum of inputs multiplied by their individual requirements. The process consequently implies the identification of feedback loops, such as the indirect, or 'embodied', energy requirements for materials and capital inputs. Several differing methods of EA have been developed, the most significant being statistical analysis, Input-Output (I-O) analysis, process analysis (or energy 'flow charting'), and hybrid analysis (see again Hammond and Jones, 2008;Roberts, 1978;Slesser, 1978). A variety of LCA software tools and inventories have been used in conjunction with the present study (see Section 1.2 above). That effectively means that a combination of methods has been used, based on a judgment as to which was most fit for a given purpose.",
            "Environmental life-cycle assessment (LCA)": " Energy analysis preceded LCA and as such they share much of the same fundamental methodology. In order to evaluate the environmental consequences of a product or activity the impact resulting from each stage of its life-cycle must be considered. This led to the development of ecotoxicology, or a study of the harmful effects of releasing chemicals into the environment, and a range of analytical techniques that now come under the 'umbrella' of life-cycle assessment. The aim of the LCA is often to identify opportunities for environmental improvement (Allen et al., 2008a) by detecting the areas with the most significant impacts. In a full LCA, the energy and materials used, and pollutants or wastes released into the environment as a consequence of a product or activity are quantified over the whole life-cycle, ''from cradle-to-grave'' (see Heijungs et al., 1992;Udo de Haes and Heijungs, 2007). Here the downstream boundary is effectively taken as the point of electricity end-use: in the home, by the commercial service provider, or in the factory. An LCA is often geographically diverse; that is, the energy and material inputs to a product may be drawn from any continent or geo-political region of the world. There are four main stages of an LCA (see ISO, 2006aISO, , 2006b) which are shown to follow a logical sequence of goal definition and scoping (outlining aims, methodology and boundary conditions), inventory analysis (data collectiondetermining inputs and outputs of materials, fuels, and process emissions), impact assessment (determination of the life-cycle environmental impacts for the pre-determined inventory), and recommendations for improvement. Gathering data for the life-cycle inventory (LCI) can be a time-consuming task, as many companies either see such data as confidential or simply do not have the sort of detailed records needed for a credible whole-life study. The impact assessment and interpretation stages are still undergoing refinement; although they have been codified in the ISO 14040-14044 standards (launched in 2000, but revised in 2006). The LCA software package SimaPro (Version 7.1) was used for the present study [following Allen et al., 2008a)]. It is a commercial package developed from that originally reported by Heijungs et al. (1992) at the Institute of Environmental Sciences (CML), Leiden University, The Netherlands. This software enables the manipulation and examination of inventory data in accordance with the ISO LCA Standards (ISO, 2006a(ISO, , 2006b)). In undertaking an impact assessment a variety of life-cycle impact assessment (LCIA) methods exist. For the present study 'Eco-indicator 99' (Goedkoop and Spriensma, 2001) was selected. Eco-indicator 99 is a damage-oriented LCIA method which tries to take the 'real potential effects' (see Goedkoop and Spriensma, 2001) based on marginal damages. The method starts with constructing a 'technosphere', or inventory table, which includes the description of life-cycles and emissions, including the allocation procedures. It then models the changes in damages that are 'inflicted' in the environment by the impacts in the inventory table, under what it terms the 'ecosphere'. Finally, the 'valuesphere' models the seriousness of perceived environmental damages along several belief-oriented choices to provide the Eco-indicator value (Goedkoop and Spriensma, 2001). This study did not extend to the stage of weighting for the three damage categories (damage to resources, damage to ecosystem quality, and damage to human health). The present LCA analysis was terminated at the normalisation stage, with the results in the form of 17 different environmental indicators. Normalisation offers a reference situation for the pressure on the environment compared to sustainable levels for each LCA environmental impact category [see, for example, El-Fadel et al., 2010), who employed a limited set of nine impact categories]. It typically refers to expressing results in terms of so-called 'person emission equivalents'. These normalised results, however, do not reveal which impacts are more significant (to the environment). For this to be achieved the impact categories need to be weighted, which is typically achieved by expert panel judgement. However, weighted indicators are highly subjective and have greater uncertainties (El-Fadel et al., 2010) was, in any case, only practical display the results for a limited range of indicators here. The full set helped to identify and focus on key categories, and were subsequently incorporated into a single score LCA indicator (although this must be used with some caution). Three of the most significant categories or indicators in the present context are: 1. Climate change: a measure of the release of greenhouse gas (GHG) emissions into the atmosphere. When released into the atmosphere these gases absorb and emit thermal infrared radiation, trapping heat within the atmosphere, and contributing to climate change. 'Carbon footprints' represent the amount of carbon [or carbon dioxide equivalent (CO 2e )] emissions associated with a given activity or community, and are generally presented in terms of units of mass or weight. These emission factors reflect the amount of carbon that is released as a result of using one unit of energy, and have units of kgCO 2 /kWh. This could be in terms of kWh of electricity or thermal energy (sometimes denoted by the subscripts 'e' or 't' respectively). 2. Human toxicity: a measure of the release of substances [such as toxic heavy metals (Cd, Pb, and Hg), persistent organic compounds (dioxins and furans, PCDD/Fs, polycyclic aromatic hydrocarbons, PCBs, etc.) and organic substances (PVC, etc.)] that are released into the environment, and which can then accumulate in organisms and cause various types of damage. The target system is not one organism as in human toxicity, but a variety of organisms (see Sonnemann et al., 2004). 3. Particulate matter formation: Particulate matter (PM), with a diameter of less than 10 mm (PM10), represents a complex mixture of organic and inorganic substances, of which the organic fraction is especially complex, containing hundreds of organic compounds. Primary particles are emitted directly from sources. Secondary particles are formed from chemical reactions in the atmosphere involving atmospheric oxygen (O 2 ) and water vapour (H 2 O); reactive species such as ozone (O 3 ); radicals such as the hydroxyl ( d OH) and nitrate ( d NO 3 ) radicals; and pollutants [such as sulphur dioxide (SO 2 ), nitrogen oxides (NO x ), and organic gases] from natural and anthropogenic sources (Wilson et al., 2002). 6. The technical, environmental and policy implications 6.1. Evaluation of the UK transition pathways",
            "The context": " The development of the UK transition pathways has undergone several iterative loops. In the present study, version 1.1 (Foxon et al., 2010) has been evaluated here in terms of their energy and environmental performance. However, earlier studies of the carbon and of low carbon UK energy futures (by, for example, Alderson et al., 2012) suggest that refinements of the technical elaboration or quantification of the pathways are unlikely to make significant differences to their environmental impacts reported in the present study.",
            "Climate change (both to human health and ecosystems)": " There are many 'greenhouse gas' (GHG) emissions, and each has a different potency. Each of a basket of six 'Kyoto' gases were normalised relative to the impact of one unit of carbon dioxide (IPCC, 2007); the main contributor to climate change. They are typically expressed in terms of 'carbon dioxide equivalents', with units of kgCO 2e ; where 'e' denotes equivalents. Methane (CH 4 ), for example, makes up the most significant component of the remaining GHG emissions: 1 kg CH 4 \u00bc25 kg CO 2e . Methane is consequently 25 times more damaging per unit than carbon dioxide in terms of GHG accounting over a nominal 100 year residence time in the atmosphere. It therefore has a so-called 'Global Warming Potential' of 25 (IPCC, 2007). Nevertheless, CO 2 remains the dominant GHG overall (Hammond, 2000;IPCC, 2007). The data presented here uses CO 2e , unless otherwise stated. Analysis of the carbon intensity of electricity grid supply [see Fig. 5] has highlighted the dramatic carbon (GHG) intensity reductions from around 530 g CO 2e /kWh in 2020 to about 160 g CO 2e /kWh in 2035 that would be needed under the MR pathway to be on track to reach the UK Government's legally-binding target of an 80% reduction in its indigenous 'production' GHG emissions from the economy overall by 2050 a 1990 baseline). In turn, this will require concerted action by a range of actors in the decade leading up to 2020 in order that the investments and infrastructure improvements to achieve these reductions can be put in place. Projected 'whole systems' carbon emissions (i.e., operational or 'stack', plus upstream emissions) from the UK ESI (Mt CO 2e ) under all three transition pathways 1990-2050 are shown in Fig. 6. In contrast, the power generator shares of the UK carbon intensity (kg CO 2e /kWh e ) in 2050 under each of the pathways are illustrated in Fig. 7. The coal CCS share of emissions is seen to fall significantly from the MR pathway through CC to its lowest value for TT. Its dominance is largely replaced by CHP generation. Nuclear power plays the more significant role in carbon reductions under the CC pathway. Large-scale renewables have a major influence by 2050 under the CC pathway and, particularly, the TT pathway [see again Fig. 7]. The UK Government established an independent Committee on Climate Change (CCC) in the Climate Change Act, 2008 in order to advise it on progress towards meeting its overall carbon reduction target of 80% 2050 from heating, power and transport fuels against the 1990 baseline. This established a new approach to managing and responding to climate change in the UK, and created a legally binding target for reducing Britain's GHG emissions. A 37% emissions reduction by 2020 (relative to 1990) was proposed under the tightening of second and third CCC carbon budgets. Required reduction in emissions from 2010 until 2030 was set as 46%. But when the CCC applies their calculations to the power sector they account only for operational or stack emissions. The present transition pathways (see, for example, Fig. 6) suggest that, taking account of upstream emissions, there might actually be a fall in carbon emissions from the UK power generation sector of some 34-37% by 2020, 71-79% by 2030, and 77-86% in 2050. The lower figures relate to the MR pathway, whilst the higher ones are associated with the other two pathways. The CCC advocated deep cuts in power sector operational emissions through the 2020s (CCC, 2010), with UK electricity generation largely decarbonised by 2030-2040. In contrast, the present transition pathways (see again Fig. 6) projections indicate that the UK ESI could not be fully decarbonised by 2050 on the 'whole systems' basis employed in the current study (see Section 1.2 and Fig. 1 above). This is because the present estimates take account of upstream emissions, whereas the projections by bodies like the CCC and Department of Energy and Climate Change (DECC) do not. Nevertheless, the transition pathways suggest that the ESI will be able to bear its share of the overall 80% carbon reduction target by 2050. The CCC analysis suggests that their projections would lead to average operational emissions from generation falling to around 50 g CO 2 /kWh e by 2030. In contrast, the present MR pathway (Fig. 5) indicates that 'whole system' emissions from the UK ESI are likely to only fall, accounting for upstream emissions, to $275 g CO 2e /kWh e by 2030 and $ 110 g CO 2e /kWh e by 2050.",
            "Non-renewable energy (NRE)": " Non-renewable energy (NRE) is a measure of the permanent loss of depletable fuel resources: both fossil fuels and nuclear fuels (uranium or mixed oxide fuels and the like). They can be converted into the equivalent quantity of energy on a Lower Heating Value basis (LHV), also known as Net Calorific Value (NCV). The NRE is then expressed in terms of MJ (LHV). Consequently, a lower number for this metric is desirable. The total figure is thus the sum of the fossil \u00fenuclear NRE. NRE associated with fossil fuels (coal and natural gas) will start to dip between the present and 2020 [see Fig. 8] under all three transition pathways. This is due to the assumption of some demand reduction over the period 2016-2020, and consequent falls in coal-fired generation and that from CCGTs. There is then a gradual rise, post 2020. CCS from coal and natural gas power plants are presumed to ramp up during this period. Nuclear output will tend to plateau or slightly decline depending on the transition pathway: MR being relatively high, and TT the lowest.",
            "Human toxicity": " Since the start of the Industrial Revolution the production of heavy metals, such as lead, copper and zinc, has increased tenfold with an associated rise in emissions. The lead contents of ice layers deposited annually in Greenland, for example, show a steady rise in parallel with the mining activities in Europe. They had reached one hundred times the natural level by the mid-1990s (WRI, 1998). More recently exposure to heavy metals has been linked to development retardation, cancers, kidney damage, auto-immunity (which can lead to diseases of the joints, circulatory and central nervous system), and even death. Despite these impacts, exposure to heavy metals has continued. Once heavy metals are emitted they can reside in the environment for hundreds of years. Different heavy metals will have different effects on human health and the environment. Individual human exposure to heavy metals will differ depending on location. Lead levels in children's blood have reduced significantly in the past 30 years in the West, but there is still a need to further reduce the emissions of such heavy metals. 'Disability Adjusted Life Years' (DALY's) is a World Health Organisation metric that can be employed to evaluate both human toxicity and PMF [see Figs. 9 and 10]. It is a time-based measure that combines years of life lost due to premature mortality with years of life lost due to time lived in states of less than full health. The high use of coal (including CCS) appears to be contributing to high human toxicity under the Market Rules pathway [see Fig. 9]. Coal contributes, for example, a significant amount of mercury emissions. The trajectory of the DALY's associated with the three pathways dips around 2020, due to the lower relative output of coal-fired generation, and then 'rebounds' slightly towards 2050. In the case of both the MR and CC pathways, the rebound is predominately due to the large increase in coal CCS in the period 2020-2035, with a minor contribution the increase in CHP renewable fuels. The rebound is due to the moderate increase in coal CCS and the large increase in CHP renewable fuels in the TT pathway. Each of these technologies accounts for just under half of the TT impacts related to human toxicity in 2050.",
            "Particulate matter formation (PMF)": " This essentially gives rise to regional environmental consequences. PM10 may be separated into fine particles, PM2.5, which have an aerodynamic diameter of 0-2.5 mm, and coarse PM, which a diameter of 2.5-10 mm. The combined fraction is known as PM10 (Grantz et al., 2003). The fine PM2.5 particles are considered to be particularly damaging to human health (Goedkoop et al., 2009). Embodied impacts of particulate matter formation are shown to be a significant contributor to overall environmental burdens. These are reflected in the DALY's scores in Fig. 10. Again high coal CCS in 2050 is responsible for high PMF scores under the MR pathway. In contrast, the PMF impact is seen (Fig. 10) to be lower under the CC and TT pathways by 2050. However, the scale of PMF impact (endpoint level) remains smaller than the impact categories of climate change and fossil fuel depletion . The contribution of embodied impacts becomes more pronounced as the total life-cycle PMF impacts fall. Although not displayed here, the weighted results provided by the default ReCiPe weighting sets reveal similar findings to the normalised results depicted in Fig. 10.",
            "Single score LCA indicator": " The 17 separate LCA categories can be weighted against each other. The lower the resulting score the better, although it does not adequately reflect, for example, the impacts associated with nuclear power generation. Nuclear is low carbon, but has a number of other health and environmental impacts associated with the potential release of ionising radiation from nuclear power stations and processing plants. These are generally not accounted for in LCA software tools, because they do not have a basis in ecotoxicology. Statistical weighting of the different LCA categories is normally achieved by the engagement of a panel of experts. It is therefore highly subjective, and this process would not be advisable in many cases. However, it can be a useful complimentary metric. A 'Single Score LCA' metric has been applied in the present study [see Fig. 11] as an indicative measure. Default weightings from the newest, state-of-the-art, LCA interpretation methodology have been utilised (Goedkoop et al., 2009). Fossil fuel depletion and GHG are given strong weightings. The units adopted are known as eco-points (or 'Pts'). They were developed as the Swiss 'Ecological Scarcity Method'. The method is based on a weighted score of each LCA impact category (i.e., climate change, human toxicity, etc.) that enables them to be added into a single score. The base is 100 Pts for the 1990 fuel mix. The Single Score LCA indicator for each transition pathway is indicated in Fig. 11. These represent the results for the total pathway, and not per kWh e . They can be seen to fall over the period 1990-2050, although not as steeply as for carbon emissions [contrast with the GHG emission results displayed in Fig. 6]. Overall there is a 49% reduction against the 1990 baseline under the MR pathway. A 67% reduction is exhibited under the CC pathway, and almost the same reduction in the case of the TT pathway (68%).",
            "Human": " 6.2. The power generating technologies 6.2.1. Upstream GHG emissions associated fuel Upstream environmental burdens are associated with two main GHG burdens: (1) additional energy consumption to 'fuel' upstream activities; and (2) methane leakage. The latter arises from coal mining activities -quite a significant contribution -and leaks from natural gas pipelines (see Table 1). The impact of 'upstream emissions' on the carbon performance of various power generation technologies (such as CHP and CCS) and the three transition pathways distinguish the present findings from those of other analysts, e.g., the UK Committee on Climate Change (CCC) and Department for Energy and Climate Change (DECC). Thus, operational (direct or stack) emissions associated with the combustion of fuels are compared with GHG emission associated with upstream coal and natural gas activities in Table 1. This data indicates the magnitude of the difference between direct combustion and upstream emissions. It implies that the measures advocated by the CCC for decarbonising the UK economy, viewed by some as challenging, are actually likely to be not stringent enough. The upstream carbon emissions referred to above result, for example, from the production and transport of natural gas. The resulting impacts are highly variable depending upon source of gas: whether, for example, they come from UK natural gas fields or are imported into Britain from the Russian Federation. Here that latter is assumed. The gas CCS dataset is the same as the Transition Pathways (v1.1) gas datasets, apart from an assumption of a 90% CO 2 capture rate and a 15% energy penalty. GHG emissions associated with the distribution of Russian gas were found to be 20 times those from the UK sources (Swiss Centre for Life-cycle Inventories, 2009). The latter consequently exhibits very low distribution GHG emissions, compared to Russian gas. The high impact of Russian gas production and distribution is mainly due to their higher gas leakage in piping, together with longer transmission distances. These upstream GHG emissions also have significance in terms of analysing the three transition pathways, because UK indigenous natural gas supplies will run out sooner rather than later. The 'Reserves to Production Ratio' (R/P) of UK natural gas fields is about 5:1, whereas that for the world as a whole is around 63:1 (Hammond, 2011).",
            "GHG emissions from fossil-fuelled power generators": " Carbon capture and storage (CCS) facilities coupled to fossilfuelled plants provide a climate change mitigation strategy that potentially permits the continued use of fossil fuels whilst  reducing the CO 2 emissions. However, the present study has indicated (see Table 2) that coal CCS is about 2/3 lower in terms of GHG emissions in comparison with conventional coal-fired plant (without CCS), i.e., a fall from 1.09 to 0.31 kg CO 2e per kWh. Thus, CCS is likely to deliver only a 70% reduction in carbon emissions on a whole system basis (including both upstream and operational emissions), in contrast to normal presumption of a 90% reduction (Hammond et al., 2011b). [Coal CCS also exhibits a much higher NRE and single score LCA than natural gas-fired plant: see Section 6.1 above.] This brings into question the attractiveness of coal CCS as an environmental proposition. However, it is a relatively cheap fuel, which is readily available (from the UK and elsewhere), and provides flexible generation in contrast to new nuclear power (see, for example, Hammond, 2011). Consequently, there is a broader range of factors to consider when selecting new UK power generation capacity.",
            "Concluding remarks": " Electricity generation contributes a large proportion of the total GHG emissions in the UK, due to the predominant use of fossil fuel (coal and natural gas) combustion for this purpose. Indeed, the various power sector technologies [fossil fuel plants with and without CCS, nuclear power stations, and renewable energy technologies (available on a large and small scale)] all involve differing environmental impacts and other risks (El-Fadel et al., 2010;Hammond and Waldron, 2008). The British Government has set a legally binding target of reducing the nation's CO 2 emissions by 80% between a 1990 baseline and the middle of the 21st Century. It is recognised that in order to achieve this target, the UK Electricity Supply Industry needs to be almost completely decarbonised over this period. Three transition pathways for a more electric future out to 2050 (Foxon et al., 2010) have therefore been evaluated in terms of their life-cycle energy and environmental performance within a broader sustainability framework: 'Market Rules' (MR), 'Central Co-ordination' (CC) and 'Thousand Flowers' (TT). The MR scenario is based on incremental change over time with a continuation of near-term trends in technologies, and energy policy responses to the climate change and energy security challenges. Growth in the take-up of decentralised energy resources (DERs) is assumed to be consumer-led, rather than stimulated by an act of government policy intervention. MR was found to be the highest carbon impact transition pathway amongst the three designated futures. The CC pathway, which envisioned a greater direct governmental involvement in the governance of energy systems, was found to exhibit a very similar energy performance to that under MR (albeit with a lower profile for its carbon emissions). In contrast, the TT pathway implies an extensive penetration of micro-generators in the home to satisfy heat and power also presupposed a network where centralised renewable energy technologies -mainly large-scale onshore and offshore wind turbines -have an important role in the power generation. Demand reduction again plays an important role (in a similar manner to that with the CC scenario), but fossil fuel power generation is effectively eliminated. Both CC and TT achieve similar carbon emissions reductions by 2050, although they get there in different ways. None of the three pathways yield zero GHG emissions by 2050, because of the impact of upstream emissions associated with the 'Energy Transformation System' (see Section 1.2 and Fig. 1 above). They suggest that the UK electricity sector cannot realistically be decarbonised by 2030-2040 as advocated by the Committee on Climate Change (CCC). Despite the fact that many industrialists see that as challenging aspiration, it appears that the real requirement is for even more dramatic ESI carbon reductions. Neither the CCC or DECC currently account for upsteam GHG emissions, or perform their calculations on a 'whole systems' basis of the sort employed here (see Section 1.2 and Fig. 1, as well as Section 6.2.1 and Table 1, above). They only determine the operational or stack emissions. There is a policy debate about this issue, and the related one of whether or not to include so-called 'consumptionbased' GHG emissions into national accounts (Morgan, 2011); some of which will result from trade imports into the UK of, for example, fuel supplies like coal and natural gas. It has been suggested (e.g., by Morgan, 2011) that Britain has met its Kyoto obligations largely by outsourcing production. This implies that it imports consumer products from abroad in order to meet a significant proportion of its consumer demand (e.g., from 'carbon-intensive' China). If the UK is to genuinely meet its stringent carbon reduction targets, then it will therefore be necessary to account for upstream emissions from power generation of the type evaluated here. Otherwise, even if the current UK carbon reduction targets met, there will remain further emissions upstream. An integrated approach was used in the present study in order to assess the impact of such pathways, employing both EA and LCA, applied on a 'whole systems' basis: from 'cradle-to-gate'. Energy analysis required estimates of the energy outputs of the power generators during use, and the energy requirements for their construction and operation. In contrast, the LCA yielded estimates of pollutants or wastes released into the environment as a consequence of the power network (in terms of 17 separate impact indicators, together with a tentative 'single score', aggregate LCA measure). The present study highlights the significance of 'upstream emissions' and their impact on the carbon performance of various low carbon technologies [such as large-scale CHP and CCS] and the three transition pathways. This approach distinguishes the present findings from those of other UK analysts (as indicated above). It suggests, for example, that CCS is likely to deliver only a 70% reduction in carbon emissions on a whole system basis, in contrast to the normal assumption of a 90% reduction (see, for example, Hammond et al., 2011b). Industrial companies have argued that CCS may only be built using gas, because of the cheaper capital cost compared to a supercritical coal plant (especially as the plant is likely to operate at 'mid merit', rather than baseload). Biomass co-firing with CCS may, of course, mitigate upstream emissions on a full life-cycle basis: something that needs careful study in the future. CHP -whether coal or natural gas fired -uses one energy input, but two energy outputs: heat and power. Carbon emissions and LCA impacts therefore need to be allocated or partitioned on some basis between the so-called 'co-products'. In LCA methodology (Udo de Haes and Heijungs, 2007) this can be achieved on the basis of either energy, exergy (Hammond and Stapleton, 2001), or economic value. These different treatments will yield varying results for this technology and the various transition pathways. CHP from natural gas appears in all three (v1.1) pathways in same "
        }
    },
    "10.1016/j.enpol.2015.09.017": {
        "file_name": "27 Power to change",
        "title": "Power to change: Analysis of household participation in a renewable energy and energy efficiency programme in Central Australia",
        "abstract": "The Australian government funded a national Solar City program (2008\u20132013) to support communities to increase adoption of\u00a0energy efficiency measures\u00a0and\u00a0renewable energy technology. One community was Alice Springs, a town with about 9000 households in the geographic centre of Australia. The programme offered a package of support: free energy audits, discounts for the purchase of renewable energy technology and energy efficiency measures, and ongoing information. Households that adopted solar hot water and\u00a0photovoltaic systems\u00a0reduced their electricity usage immediately after adoption by 10% and 34% respectively, and this was maintained in the long term. A small rebound effect of 15% was observed in the\u00a0photovoltaic\u00a0adopters. It was observed that, on average, households that adopted only energy efficiency measures did not have a significant reduction in their electricity usage over the long term. However, consistent with expectations, this study did show that there was a significant correlation between the number of energy efficiency measures adopted and the greatest household reduction in electricity usage. These contrary results indicate that there are additional factors involved. The connection between the effective use of measures, coincident behavioural change or increased energy awareness and greater energy reduction is discussed.",
        "label": "Quantitative",
        "text": {
            "Introduction": " Access to affordable energy is central to maintaining a functioning economy and standard of living. In the five years from 2007 to 2012, the average electricity price to households in Australia increased by 60%, although this trend moderated during the most recent years (Australian Electricity Market Commission, 2014). The cost of energy infrastructure was viewed as the primary reason for price increases in Australia (CSIRO, 2013). Increasing the efficiency of Australia's use of energy and developing sustainable sources of renewable energy are viewed as important strategies for safeguarding energy supplies for households (PM Task Group on Energy Efficiency, 2010). Australia has one of the most carbonintensive economies in the world (PM Task Group on Energy Efficiency, 2010, p. 15); electricity generation alone (mainly from the combustion of coal and natural gas) comprises 33% of Australia's greenhouse gas emissions (Department of Environment, 2014). Therefore, Australian energy prices are highly sensitive to any policy changes to limit or price carbon emissionsboth domestically and internationally. Residential energy efficiency has been a topic of interest since the energy crisis in the 1970s. Despite the technological innovations and education programmes, household energy use continues to rise in developing countries (IEA, 2007). This is in contrast to recent experience in Australia, where a decline in electricity consumption has been observed, a trend which is forecast to continue (or be stable) over the next few years (Australian Electricity Market Commission, 2014). Today the common concern is energy generation, and its contribution to climate change and threats to biodiversity (Gardner and Stern, 2002). Therefore, the use of energy within the household, particularly enhancing energy efficiency, remains an important area of public policy. In light of the importance of energy conservation, the Australian government initiated a major investment in renewable energy and energy efficiency in June 2004, through the national Solar Cities program (Zahedi, 2010). Through national, local and consortium members, this programme generated combined investment of A$280 million into a programme that covered seven cities across Australia, with the objective of supporting communities to rethink the way in which they produce and use energy (Wyld Group, 2011). Alice Springs, a town in the Northern Territory (NT) which is at the geographic centre of Australia, is one such city. In March 2008 the Alice Solar City (ASC) program was launched and based there. The ASC program had funding of A$42 million and operated from March 2008 to June 2013 (Alice Solar City, 2014). ASC received financial support through a funding agreement between Alice Springs Town Council and the Australian Government as part of the national Solar Cities programme, as well as financial and in-kind contributions from a consortium of public and private organisations. ASC was focused on changing energy production and use across three types of buildings: residential, commercial and iconic. The ASC support for residential (household) buildings included three main elements: solar renewable energy (RE) technologies, energy efficiency measures (EEMs) and load management measures. ASC sought to address these elements through a variety of methods, including energy audits, education, financial incentives, rewards for participation and community engagement. In total, A$14m was spent across the RE technologies and EEMs on offer. This was subsidised 35% by the ASC programme. A list of RE technologies and EEMs offered by the programme is listed in Appendix 1. RE technologies formed the major component (87%) of the financial expenditure. The location of this programme, Alice Springs, is a remote town (41400 km from a major city of 4100,000 people) with a population of 25,186 people and 9163 households (ABS, 2011). It has a diverse economy (for example, government support services, mining, tourism) and is a major service town for many small, remote communities and settlements (o1000 people) within a 500 km radius. The climate is reflective of semi-arid conditions with hot summer temperatures: it has a mean daily maximum temperature above 30 \u00b0C for six months of the year (Bureau of Meteorology). Not surprisingly, household electricity consumption is cooling dominated as people rely heavily on air-conditioners to cool indoor temperatures during the extended summer period. There is a sole provider of electricity in Alice Springs, Power and Water Corporation (PWC), and 38% of the total electricity demand for Alice Springs is residential (Alice Solar City, 2013a). This remote community was a good location for a pilot trial exploring residential efficiency and RE technology adoption. This paper explores the programme's effect on electricity usage from the utility provided mains grid. It explores the adoption of RE technologies in detail and also examines the impact of other aspects of the programme (including informational and adoption of EEMs).It examines the impact of adopting RE technology over the short and long term, and the economic parameters involved. The paper also explores the characteristics of households that did not adopt RE technology and the predictors of the greatest change in electricity usage. Residential solar energy has experienced rapid growth in Australia over recent years due to reductions in the costs of technologies and supportive government policies. Like other renewable energy generation, solar energy generation benefits from fiscal and regulatory incentives; including tax credits, feed-in-tariffs, low cost loans and subsidies. The increase in adoption of solar energy technology in Australia is reflected internationally, as the global photovoltaic (PV) capacity increased from 1.4 GW in 2000 to 40 GW in 2010, with an average annual growth rate of around 49% (Timilsina et al., 2012). The growth of solar technologies is attributed to policy support in Germany, Italy, United States, Japan and China (DeVries et al., 2007). Despite the increasing rate of PV adoption, there is often a mix of barriers to its widespread adoption (technical, economic and institutional). Technical limitations include low conversion efficiencies and storage issues (IEA, 2006). Economic barriers relate to initial system costs, financing, uncertainty about ongoing payments for electricity, and potential charges for PV systems to export electricity produced. Institutional barriers refer to existing laws and regulations, metering and billing issues, availability of trained people to install systems, and public misperceptions, knowledge and attitudes (Jacobson and Johnson, 2000;Goldman et al., 2005). Studies have found that reducing these barriers will increase the adoption of RE technologies by more of the population and across demographics (Drury et al., 2012;Faiers and Neame, 2006;Niemeyer, 2010). A key economic consideration is the electricity tariff. The total cost of electricity to the household is an important determining factor in consumer behaviour toward renewable energy and energy efficiency programmes (Bor, 2008;Howarth and Andersson, 1993;IEA, 1997;Scott, 1997). Economic theory suggests that the demand for electricity is related to the total cost of electricity to the householder (Oikonoumou et al., 2009;Poortinga et al., 2003;Sandstad and Howarth, 1994). In simple terms, the total cost of electricity is determined by several factors, including fixed supply and demand related charges together with unit cost (tariff), volume consumed and volume generated by the household. According to conventional economic logic, electricity demand will fall as electricity prices increase if other factors are constant. However, adoption of RE technology can confound consumer behaviour, such as when a rebound effect occurs as households increase electricity usage due to the electricity savings made from adopting RE technologies-which may have been promoted to reduce household electricity consumption (Berkhout et al., 2000). This paper applies the calculation of a direct rebound as described by Berkhout; that is, the percentage of energy saving improvement initiated by the technological improvement that is offset by increased energy consumption. The direct rebound effect is caused by income and substitution effects. Income effects are caused by energy efficiency improvements that lower the household electricity bill, increase the real income of the household and permit increased consumption of all goods and services. The substitution effect examines how households may shift their financial consumption patterns of electricity from other non-energy activities when the relative cost of electricity has decreased, even if their real income is constant. (Oikonomou et al., 2009). Greening and Greene (1998) reviewed 75 studies of the rebound effect. They found consumers adopting EEMs experienced the following rebound effects: space cooling devices, 0-50%; residential lighting, 5-12%; and water heating, 10-40%. This indicates the rebound effect can be quite pronounced. The predictors of adopting renewable energy systems or undertaking EEMs have been extensively studied; however, no definitive predictors have been identified. The literature on residential energy efficiency and renewable energy adoption tends to focus on household behaviour (Abrahamse et al., 2005), economics (Howarth et al., 2000), or policy (Levine et al., 1995;Varone and Aebischer, 2001). Demographic characteristics associated with RE adoption include being younger, more highly educated, and having higher income (Labay and Kinnear 1981;Mills and Schleich, 2012;OECD, 2011). Other studies found home owners, people with higher incomes and homes with a pool were more likely to adopt EEMs and RE technologies (Sidiras and Koukios, 2004;Kaldellis et al., 2005;Mills and Schleich, 2009). However, as the predictive value of these factors vary considerably among studies depending on location, date and government policy a definitive relationship between demographics and adoption has not been established (OECD, 2008). Values, attitudes and economic considerations of households are also factors that predict adoption of RE technologies (Gadenne et al., 2011;Schelly, 2014). Others have reported the type of engagement, goal setting and feedback on performance has an effect on shortterm change in energy use (Harding and Hsiaw, 2012). Providing information alone to households is rarely an effective strategy (Van Houwelingen and Van Raaij, 1989). This study observed no change in energy usage by participating households after programme signup or energy audits. This is similar to a study of Canadian households in the ENEVERSAVE programme, which found that when one group of participants received tailored information and another group received general advice there was no difference in energy usage after two years (McDougall, et al., 1983). Other studies have found that household audits had mixed results, with some households using more energy after the audit (McMakin, et al., 2002), or there being no effect from a programme from the initial sign-up stage (Abrahamse et al., 2005). A combination of policies and investments to encourage adoption of RE technologies and EEMs is one strategy to encourage behavioural changes in households. Studies found that a policy instrument is likely to be adopted if administration exists to help minimise costs of implementation, the policy targets appropriate groups willing to implement changes, and the technology and market structure exist for implementation (Varone and Aebischer, 2001). Energy efficiency programmes with high levels of public engagement tend to provide households with goal setting, information, rewards and feedback (Abrahamse et al., 2005;Harding and Hsiaw, 2012). Households are more likely to engage with energy efficiency programmes if they have identified environmental concerns and 'green living' among their energy goals (Harding and Hsiaw, 2013). Smaller, more educated households are more likely to opt-in to energy efficiency programmes but the key to long-term participation for these households appears to be identifying nonbinding, realistic goals (Abrahamse et al., 2005;Harding and Hsiaw, 2012). So, while household size and income level may be useful guides to spontaneous (unassisted) adoption of energy efficiency practices by households, these factors may become less important if well-designed household engagement strategies are followed and retail energy prices are causing cost-of-living pressure. This paper reports on recent research that explored the adoption of RE technology and EEMs by households participating in an energy efficiency programme in Central Australia, and the impact on household electricity consumption. This paper further examines the impact of tariff increases and any direct rebound effects by households that may occur after adopting an RE technology. The research also explored the predictors of the greatest reduction in electricity usage for households in the programme. From this analysis, this paper seeks to make a contribution to the design of effective renewable energy and energy efficiency programmes targeting residential households.",
            "Methods": "",
            "Background": " ASC required that all residential customers participating in the programme provide access to their electricity usage data. Once this consent was received, PWC provided the utility usage billing data, which was uploaded into the ASC database. This data was provided from 12 to 15 months prior to the date of individual households joining the programme until either the customer withdrew from the ASC or the ASC concluded (the ASC program ended on the 30th of June 2013). Full programme activities continued up to this date for all existing customers, but new customers joining after the 31st of August 2012 were offered a reduced range of activities. Therefore, this study uses the sample of all customers participating in the ASC from the programme's inception to the 31st of August 2012, there being 2016 households in the programme during this period. The programme required that all participants undertake a personalised home energy audit to be eligible for any incentives on offer. The aim of this audit was to identify the most effective EEMs that would reduce household usage, in addition to education and highlighting potential behavioural changes alone that would reduce energy use. Financial incentives were offered on the basis of how effective a particular EEM or RE technology would be for the household, in combination with the likelihood of adoption by the household. The incentives provided a direct reduction in up-front expenditure for adoption of an EEM or RE technology. There were budgetary limits in place for each individual incentive. However, the only incentive that reached its limit was the solar PV incentive, which was capped at 277 households, so the later joiners in the programme were not able to take it up. The ASC program estimates that, if available, up to an additional 50 households may have taken up this incentive. Of the solar RE technology products, solar hot water (SHW) systems and rooftop PV systems are two distinctly expensive, new technology products that are expected to have a large impact on electricity usage post adoption: an estimated 2100 kW h/year and 3100 kW h/year reductions in household energy use respectively. Direct financial incentives for EEMs reduced the cost of 25 products, ranging from replacing perished refrigerator or freezer seals to painting the roof white and installing a variable-speed pool pump. EEMs had a lower cost and lower expected electricity saving than the RE technologies: the average expected electricity saving was 450 kW h/year, ranging from 20 kW h/year to 1200 kW h/year. This paper examines the change in utility electricity usage of a subset of the ASC residential customers relative to utility electricity usage in the Alice Springs control group. It seeks to quantify how involvement in the ASC programme and programme events impacted on the participants' electricity usage. It looks at pre and post event electricity usage and examines the impact of the two largest components of the ASC program; that is, adoption of the two RE technologies, PV and SHW. Additionally, it examines the long-term electricity usage change and the factors that indicate the likelihood of long-term change. By examining this group of customers, some analysis of what caused changes to energy use behaviour and potential policy implications was able to be undertaken.",
            "Data collection": "",
            "Control group": " To control for changes in electricity usage due to other influences, such as price and weather, a control group was used. The NT's dominant power provider -Power and Water Corporation (PWC)provided de-identified monthly utility electricity consumption data for all residential households in Alice Springs, excluding ASC customers (that is, the electricity consumption of approximately households), over the period July 2006 to December 2012. There was some slight adoption of RE technologies in the control group but the numbers are small enough to discount its impact on this study, the adoption of EEMs outside the programme is unknown. The data provided by PWC was the month, number of households, total number of days of electricity usage and total electricity usage. PWC also provided historical tariffs for Alice Springs.",
            "Study sample": " This group was selected based on the following criteria: they had to have been with the ASC program for at least 2 years and they had to have at least 3 years of uninterrupted, error-free electricity usage data. This identified 545 ASC customers. An additional exclusion was applied to this group relating to a problem with faulty adoptions of solar hot water. Toward the end of the programme it was identified that 289 SHW adoptions may have been installed incorrectly: their SHW may have been functioning as an electric water heater and not achieving the energy benefit expected. In our sample of 545 ASC customers, 49 potentially had this problem and therefore were removed from this study. The final study sample contained 496 households. The study sample was representative of the ASC program participants in terms of socio-demographic and household characteristics. Through the compulsory personalised home energy audit a substantial amount of customer information was gathered and recorded. ASC maintained a large database on all its customers. It recorded demographic information; programme participation events; information such as date, quantity, expenditure on any financial incentives taken up (in A$); and electricity usage records. The electricity usage records were recorded in two ways: utility consumption data was recorded with quarterly billing records and PV production data was recorded in half-hour intervals. All customers had their quarterly billing data recorded, from at least 1 year prior to sign-up until termination of involvement in the programme or the end of the programme. Customers that had a PV system installed on their roof had their electricity production data recorded in half-hour intervals. Due to the PV installations being amongst the first in Alice Springs (prior to the programme there was only 1 PV installation) there were some initial data collection issues for PV production. In some cases the collection and storage of the data was delayed. On average, data collection was correctly done within 62 days of PV installation, but in some cases it was delayed by from 6 months to 1 year. This means that the results understated the immediate impact of PV but were corrected for the long-term calculations. The following fields were extracted from the ASC database: sign-up date audit date income electricity usage prior to programme entry number of EEMs adopted during the programme total expenditure by the household on EEMs if installed SHW, date of installation if installed PV, date of installation ADC data for the household over the programme period PV production data post-installation.",
            "Data analyses": "",
            "Control periods": " The monthly electricity consumption data of the control group was converted to average daily consumption (ADC) per month, and a rolling yearly average was calculated. The rolling yearly averages created a series of control periods which were matched to each ASC customer individually. The control periods matched to the individual study samples control for variations that occurred in Alice Springs due to tariff changes or weather conditions.",
            "Change in electricity usage": " This study analyses the percent change in electricity usage from the year prior to sign-up to the programme to the year post each treatment event. This was calculated by calculating each participant's average yearly ADC prior to sign-up. Each participant's average yearly ADC post-each treatment effect was also calculated. The events occurred on different dates for each member of the sample study. Therefore, the matching control period for each member of the sample study was identified for both the pre and post periods. The change in ADC for each individual study sample was then calculated relative to the matched control period ADCs. The short-term treatment effects were: sign-up personalised home energy audit adoption of SHW adoption of PV. The long-term treatment effects examined change in electricity usage from the year prior to programme sign-up to the electricity usage over the calendar year 2012; that is, the average yearly ADC prior to sign-up relative to the average yearly ADC over the calendar year 2012, adjusted by the matched control period ADCs. The long-term treatment effect was calculated for the whole study sample and for different sub-groups of the study; namely, whether a household did or did not adopt SHW or PV. For the households that adopted PV, data for both household utility electricity usage and household generation was available. Therefore, the same analysis on net utility electricity usage of the household was performed. In addition, it was possible to examine the change in gross electricity usage; prior to consumption of electricity produced by the PV system. T-tests were performed to determine the statistical significance of changes in ADC pre and post treatment effect.",
            "Predictors of greatest household electricity reduction": " The households were grouped in quartiles based on the change in long-term electricity usage. The households in the top quartile were compared to remaining programme participants to determine common factors in households that had the greatest reductions in electricity usage. A logistic regression analysis to predict households in the top quartile was performed using SPSS version 22. A comprehensive survey of methods in energy efficiency studies concluded that logistic models were the best approach for constructing a model of predictor values (Klein and Spady, 1993;Scott, 1997;Hannemann and Kanninen, 1996). The dependent variable was defined as the probability that a household was in the top 25% of ASC program participants in terms of long-term change in electricity usage. The dependent variable was then regressed on a vector of predictor variables from the survey data. The predictor variables were selected based upon a review of the literature and also included the most useful variables for policy development, shown in Table 1. Before building the logistic regression model the variables were tested to determine multi-collinearity. There was no correlation between any of the variables. The variables were added to the model using forward stepwise selection.",
            "Results": "",
            "Trends in electricity usage in the Alice Springs control group": " The rolling yearly average ADC for the control group is shown in Fig. 1. Table 2 shows the tariff changes that occurred for Alice Springs households during the life of the ASC program. These results show that the Alice Springs control group had sensitivity to electricity price. Over the period of the ASC program there was a downward trend in electricity usage from 24.71 kW h/day to 23.31 kW h/day, a fall of 5.7%. Over this time there was a total tariff rise of 44%. Notably there was a large fall in electricity usage in July 2009 following the largest incremental tariff increase of 2.79 c/kW h (18%), and similarly following the July 2012 increase of 1 c/kW h (10%).",
            "Study sample description": " A brief description of the study sample groups is shown in Table 3.",
            "Short-term change in electricity usage": " The resultant changes in short-term electricity usage are shown in Table 4. There was no statistically significant impact on electricity usage due to the customer either signing up to the programme or obtaining a personalised home energy audit. On average, audits occurred 65 days after sign-up. There was a short-term, immediately post-adoption, statistically significant impact on electricity usage due to the customer adopting SHW. Likewise, there was a statistically significant impact on net electricity usage the customer adopted PV. On average SHW adoption occurred 360 days after sign-up and PV adoption occurred 228 days after sign-up. Further analysis of the group that adopted SHW showed that there were two types of systems being replaced by the adoption of SHW: either an electric storage hot water system or a faulty electric boost SHW system was replaced in this study sample. 35% of households were replacing an electric storage systemthese households had a control group adjusted fall of 13%, while the others (who replaced faulty SHW systems) had a fall of 6%.",
            "Long-term change in electricity usage": " The long-term results were, on average, 3.5 years later than sign-up, ranging from 2.5 to 4.8 years. The results are shown in Table 5. Overall, there was a statistically significant impact on long-term electricity usage for the entire study group. The group of participants (302 households) who did not adopt SHW or PV did not have a statistically significant fall in electricity usage relative to the control group. This group adopted a total of 483 EEMs, with a gross expenditure of A$339,005 and a net household expenditure of A$207,198 or an average of A$686 per household. SHW adopters' long-term use was analysed, on average, 2.6 years after adoption. The results showed a statistically significant sustained fall in electricity usage ( \u00c0 9%), consistent with the short-term results ( \u00c0 10%). The data for the PV adopters allowed more detailed analysis as we have figures for net electricity usage and electricity generated in the home. PV adopters' long-term use was analysed, on average, 3.1 years after adoption. The PV systems produced 41% of electricity used by households and the results showed a sustained fall in net electricity usage of -35% over this time. Therefore, it is observed that the gross household usage had a statistically significant increase of 6% for the period from adoption to 3.1 years later. Note: the net electricity usage did not exhibit this 6% increase because of increased PV production  figures. As discussed in data collection, there were some limitations in gathering the PV production data immediately post adoption and therefore the short-term PV production data is understated; this is rectified in the longer-term PV production figures and hence explains the increase in PV production. The rebound effect is calculated as 6% of 41%, which gives a rebound effect of 15%.",
            "Long-term predictors of greatest household electricity reduction": " The factors that were significant in predicting greatest household electricity reduction were adoption of PV and the number of EEMs adopted. The other factors (namely, income level, electricity usage prior to programme entry, total A$ expenditure by the household and adoption of SHW) were not predictive. The likelihood of a household being in the top quartile of electricity reduction was modelled using demographic and programme variables. The model fitted well. The Homer and Lemeshow goodness-of-fit test has a significance of.640, meaning the model is a good fit. Nagelkerke's R 2 of.338 indicates a moderate relationship between prediction and grouping. The model was correctly able to classify 81% of the households. The Wald test demonstrated that adoption of PV and the number of EEMs adopted made a significant contribution to prediction. The logistic coefficients are 2.328 for adoption of PV and.114 for the number of EEMs adopted, and the constant is \u00c0 1.820. The average EEMs adopted were 2.6 for the top quartile, compared to 1.8 for the remaining quartiles.",
            "Discussion": " The trend data of electricity usage shown in Fig. 1 illustrates that Alice Springs households are sensitive to the price of electricity. The retail price of electricity charged by PWC during the study period increased by 44%, as PWC moved toward a cost-reflective tariff for provision of electricity with the removal of external funding and cross-subsidies within PWC's overall business. It can be observed that demand is responsive to the larger price changes in July 2009 and July 2012. The demand response of households to an increase in electricity price is consistent with economic theory and suggests that households in Alice Springs may suffer from the rebound effect after making savings on their electricity ASC was a voluntary programme that included a compulsory home energy audit which was conducted soon after sign-up. It could be expected that the households that signed up had an interest in improving their energy efficiency and therefore reducing their electricity usage. Additionally, the compulsory home energy audit provided tailored information to the household and included specific recommendations. A potential advantage of this approach is that households received relevant information rather than an overload of general recommendations. The results show that the act of joining the ASC program, which indicates a likely positive attitude towards electricity conservation in itself, did not result in a reduction in electricity. Likewise, having an energy audit performed did not result in an immediate reduction in electricity usage. Our results showed there was no substantive behavioural change on sign-up or the initial energy audit among participants in the ASC program. This adds to the body of literature that indicates that provision of information alone does not necessarily result in a reduction in electricity usage. The two solar RE technologies available in the ASC program, the SHW and PV systems, were both expected to lead to a significant reduction in overall electricity usage (a 25% (Alice Solar City, 2013a) and a 36% (Alice Solar City, 2013a) reduction respectively). SHW and PV are both large, purpose-built technologies that require no behavioural change for the household to achieve a reduction in electricity usage. Statistically significant reductions in electricity usage were observed immediately post adoption by households in the ASC program for both RE technologies: 10% for SHW and 34% for PV. The reduction of 10% in electricity usage by households that adopted SHW is notably less than expected, while the reduction for PV adopters is in line with expectations. The unexpected result for SHW warrants further investigation. The result in this study sample of 10% electricity saving by households adopting SHW is in line with ASC results conducted on a larger sample of its customers. The ASC results (Alice Solar City, 2013b) indicate an average 13% reduction post adoption of SHW, although this result is not adjusted for the fall in use occurring within the control group and so is expected to a Including 4 households that also adopted SHW.  be higher than this study's result. The reason for the figures observed in the ASC program is that there were two main types of systems being replaced by the adoption of SHW: either an electric storage hot water system or a faulty electric boost SHW system. In our study sample, these groups had a 13% and a 6% fall in electricity usage respectively. Although a faulty system was replaced only if deemed not to be working, this result suggests that some faulty systems were still operating, albeit at a sub-optimal level; hence the savings achieved were reduced. The result is less than was expected by the programme but is broadly in line with an IPART study indicating that a fall of 1400 kW h, or a reduction of approximately 15% of electricity usage, could be expected for replacing an electric storage hot water system (IPART, 2011). The electricity usage savings experienced immediately after the adoption of the RE technology would have had a direct impact in the quarterly bill for these households. The SHW saving was a reduction in electricity usage, which would have had a corresponding reduction in the bill provided the saving was greater than the tariff increases. The PV adoption resulted in electricity generation for which PWC provided an elevated gross feed-in tariff. This resulted in the PV adopters receiving approximately 2.5 times the flat-rate tariff for electricity produced throughout the programme. The gross feed-in tariff increased in line with consumption tariff increases shown in Table 2. The combination of the large production of the PV installations and the elevated gross feed-in tariff meant that these households had greatly reduced electricity bills. The additional income available to the household could therefore be spent on other consumables or they could increase their electricity usage. When the SHW adopters were analysed again 2.6 years after adoption it was observed that there had been no direct rebound effect. When the PV adopters were analysed again 3.1 years after adoption it was observed that there had been a 6% increase in electricity usage within the household, although net consumption remained reduced. This implies a direct rebound effect of 15%. This is at the lower end of the range of rebounds observed in other studies (e.g. Greening and Greene, 1998). The demonstration of price sensitivity in the control group implies that there should be some direct rebound effect following the adoption of RE technology. The solar are the most likely product within the ASC program to be characterised by rebound due to the large impact they would have on total electricity cost and the lack of any behavioural change required to achieve this (Greening et al., 2000). However, it was observed that no rebound occurred in the case of SHW, and only a relatively small rebound was observed for PV. The major differences between these two RE technologies are that SHW adopters had a reduction in cost of producing hot water for the household but the overall cost of electricity usage remained fairly constant due to the tariff increase. The SHW adopters were relatively better off than those that did not adopt SHW, but they did not experience any large reductions in total electricity cost. Our results show that this relative saving did not result in increased electricity usage. The PV adopters experienced a tangible reduction in the cost of electricity to the household. The rebound effect observed in the adopters of PV generated a substitution effect which resulted in more electricity being consumed by the household. The rebound effect could be due to several factors: the large value of investment required; the large volume of energy produced, and consequently large financial savings gained; or the fact that PV actually generated income for the household which was distinct from SHW, which provided only relative savings. These differences could account for the rebound effect occurring for PV adopters rather than SHW adopters. These findings highlight an area of potential future study to better understand the behaviour of RE technology adopters. For example, the distribution of amongst RE technology adopters could be examined and follow up surveys and interviews could identify influences, attitudes and reasons behind change in electricity usage. The ASC program successfully reduced the barriers for RE technology adoption in the remote town of Alice Springs. Prior to the programme there was one PV installation and this programme greatly decreased the technical and institutional barriers experienced in this remote location. The economic barriers were decreased by the specific incentives available for the early adopters of PV. Due to the successful reduction in technical and institutional barriers, later adopters were able to exploit the coincident reduction in PV prices. The ASC program was a valuable initiative to test and refine approaches to promote the adoption of RE technology and EEMs by households in a remote location. Analysis of the popularity of specific technologies and EEMs offered through the ASC program and the subsequent reductions in electricity consumption by households, as presented in this paper, can assist policy makers and programme managers in designing a followup programme. The average electricity usage by the control group fell by 5.7% over the study period. The result for 61% of households in the study sample that did not adopt SHW or PV showed no statistically significant reduction in household electricity usage relative to the control group, even though 483 EEMs were adopted. This is despite an average adoption of 1.6 EEMs and A$686 net expenditure per household. The results are not what was expected and it is difficult to ascertain why there was not a significant reduction in electricity usage in this sample. The adoption of EEMs in isolation should have led to a reduction in electricity usage. The explanation for why this did not occur is: the EEMs were not used or were not used correctly; adoption of similar EEMs or RE technologies was occurring outside this programme; or there was a coincident relative increase in usage of electricity which masked the savings produced by the EEMs. The ASC program had education measures in place to try and mitigate the misuse of EEMs, but possibly a greater focus on follow up and EEM use was required. Furthermore, the ASC program achieved high uptake within the community, engaging 30% of Alice Springs households, and greatly increased the awareness, availability and knowledge of energy efficiency and RE technologies. The relatively small size and isolation of Alice Springs combined with the success of the programme could indicate that householders not participating in the programme were still impacted by it. As can be seen in Fig. 1, the programme also occurred during a period of high increases in electricity cost, which would have impacted both participants and non-participants in the programme. The price signals provided to householders may have led those both within and outside the programme to take measures to reduce their electricity usage. This would indicate that the price signals themselves were stronger than the support offered by the ASC programme as households in both groups reduced their electricity usage similarly. In the ASC program a large range of EEMs were offered and adopted, with a large variation in cost and expected electricity savings. The costs of EEMs was significantly lower than that of the RE technologies, which made the incentive provided by ASC less important in the rising tariff environment. EEM adoption may have increased across the community, but the explicit incentives did not have a statistically significant impact. Future analysis on the costs and savings generated by the ASC program is warranted. Another possible hypothesis is that ASC program participants experienced rebound effect over the period due to the electricity savings made. That could explain the results, although it seems unlikely due to the fact that no rebound effect was observed for the SHW adopters whose energy cost savings were also outweighed by increases in electricity prices. The final results of the study explored who were the greatest reducers of electricity usage. The results showed that income level, electricity usage prior to programme entry, total A$ expenditure by the household and adoption of SHW were not good predictors of being reducers in electricity usage. This programme engaged with households across the demographic spectrum. This is important policy information as it makes clear that energy efficiency programmes should be targeting the broad community, not a particular demographic group. The results found that the two most important predictors of energy use change were adoption of PV and the number of EEMs adopted by householdsthe more EEMs adopted by the household, the more likely they were to have a reduction in electricity usage. This result is as you would expect, however, it is in contrast with the surprising lack of reduction in average long-term electricity usage for the EEM only adopters observed in this study. It is also important to note that the level of investment in the programme was not a predictor of being a larger electricity reducer, rather the actual number of EEMs was. This indicates that there are different responses to the adoption of EEMs. The higher reducers must use the EEMs more, use the EEMs more effectively, or have relative coincidental behavioural change accompanying the adoption of the EEMs. Possibly it requires a combination of these three factors, with an adoption of a greater number of EEMs showing greater commitment, involvement and engagement in the programme; in other words, repeated action, repeated communication with the programme and repeated interventions in the household. This could ensure both greater and more correct use of the adopted EEMs, and may be correlated with behavioural change. An area of interesting further study would be to quantify the impact of the adoption of individual EEMs or particular types of EEMs (such as cooling or refrigeration). The ASC program data did not allow meaningful analysis of the impact of individual EEMS due to the ongoing working nature of the programme and the limited monitoring and evaluation framework possible for this aspect of the programme. There were many different EEMs available which were adopted over a period of 5 years, and in many cases several EEMs were adopted at similar times by different households. The results found here observed that the number of EEMs adopted, as distinct from the total expenditure on EEMs, indicates that there is an engagement component to the reduction in electricity. However, to expand this hypothesis further a greater analysis of the quantitative impact of each EEM would need to be established. Total household energy use is highly dependent on the number of household residents and the proportion of time the house is occupied (Lenzen et al., 2006;Newton and Meyer, 2012). The ASC database recorded these variables only at the point of sign-up to the programme. While this study's dataset excluded houses where there was a change in the individual or family residing at the household, the occupancy rate or number of permanently-residing household members could have either increased or decreased, which would be expected to have a significant impact on electricity usage. Therefore, it is possible that changes in electricity usage were confounded by changes in household occupancy over the life of the programme. However, there is no reason to suggest that there would be a bias toward change in household occupancy for those groups we found to be associated with having a change in their electricity usage.",
            "Conclusion and policy implications": " The results of our study show reductions in electricity usage can be achieved by the adoption of RE technology. These technologies achieved electricity usage reductions in line with expectations but with PV adopters having a rebound effect equivalent to 15% of the power generated by the PV system. While this observed rebound effect is relatively low, it suggests that policies need to be adopted to deter a rebound in energy use when a programme is offering an RE technology which is likely to produce a large reduction in energy cost for the household. The results show that the number of RE technologies and EEMs adopted is predictive of large reductions in household electricity usage; however, the level of household financial investment in the same RE technologies and EEMs was not predictive. That is, the level of financial investment by households in RE technologies and EEMs as part of the ASC program in Central Australia was not a good predictor of eventual reduction in electricity usage by participating households. As such, we believe that this indicates that active engagement of households in energy conservation programmes is more important than attempting to maximise household investment in RE technologies and EEMs. Policy makers should consider methods to maintain the ongoing engagement of households in these programmes. This could include measures such as: requiring repeated programme participation in order to access higher-value financial incentives, staggered access to individual products, or additional support. Our findings suggest these measures could result in greater reduction in electricity usage for a given cost to the programme. Additionally, this would allow the programme to interact with the householder about products previously adopted, ensuring they are being used and are being used correctly. The adoption of RE technologies does not require a change in household behaviour or create a visible change in housing comfort for electricity savings to occur. However, adoption of EEMs often require, or create, a change in household behaviour (e.g. altered lighting, and altered setting for air-conditioners). As such, adoption and sustained use of a relatively high number of EEMs likely to be by households who are highly motivated to achieve substantive reductions in electricity usage. Policy makers should consider low-cost options for supporting households that have adopted a high number of EEMs so that sustained lower energy consumption becomes an entrenched pattern of behaviour, and a core feature of Australia's future households."
        }
    },
    "10.1016/j.enpol.2015.10.002": {
        "file_name": "37 The importance of iteration and deployment in technology development",
        "title": "The importance of iteration and deployment in technology development: A study of the impact on wave and tidal stream energy research, development and innovation",
        "abstract": "The technological trajectory is the pathway through which an innovative technology develops as it matures. In this paper we model the technological trajectory for a number of energy technologies by analysing technological change (characterised by unit-level capacity up-scaling) and diffusion (characterised by growth in cumulative deployed capacity) using sigmoidal 5 Parameter Logistic (5PL) functions, observed and reported as a function of unit deployment. Application of 5PL functions allows inference of technology development milestones, such as initiation of unit-level up-scaling or industry growth, with respect to the number of unit deployments. This paper compares the technological trajectory followed by mature energy technologies to that being attempted by those in the nascent wave and tidal energy sectors, particularly with regards to unit deployment within a formative phase of development. We identify that the wave and tidal energy sectors are attempting to bypass a formative phase of technological development, which is not in line with technological trajectories experienced by historic energy technologies that have successfully diffused into widespread commercial application, suggesting that demand-pull support mechanisms are premature, and a need for technology push focused policy support mechanisms is vital for stimulating economically sustainable development and deployment of wave and tidal stream energy.",
        "label": "Quantitative",
        "text": {
            "Introduction": " Wave and tidal stream energy are, as yet, largely untapped renewable energy resources. Political will and favour towards wave and tidal energy has been strong within the UK, particularly in Scotland (Allan et al., 2011). Historically, the UK has been seen as the leader of the development of wave and tidal stream energy technologies (Ernst and Young 2013). The use of market pull incentive mechanisms such as Renewable Obligation Certificates have been attempting to stimulate technology deployment in the sector and development of a market for ocean energy devices (Allan et al., 2011), supported by a number of grant incentive mechanisms such as the Marine Renewables Proving Fund (MRPF) for pre-commercial prototypes (Jeffrey et al., 2014), and the Marine Energy Array Demonstrator (MEAD) and Marine Renewables Commercialisation Fund (MRCF) providing support for array Contents lists available at ScienceDirect journal homepage: www.elsevier.com/locate/enpol demonstration and technology innovation (Vantoch-Wood, 2012). In total, over d120 million has been allocated to the wave and tidal energy sector in the UK since the year 2000 (Research Councils UK, 2014). Much of the historic funding provided to wave and tidal energy to date has encouraged pre-commercial demonstration in an intense and challenging environment, but with a focus on units that are in the order of one megawatt in capacity (MacGillivray et al., 2013). Whilst utility companies, and end users of electricity generated from the waves and tides, would benefit from the utilisation of large scale technology (which may be considered to directly correlate with larger levels of power production, increased revenue, and lower Levelised Cost Of Energy (LCOE)), the route to successful technology optimisation is not reached through the demonstration of a single unit prototype, or small samples of production. Rather, successful technology is demonstrated through the iterative process of experimentation, in order to understand what works well, and what does not (Thomke, 2003). Prototype costs are invariably significantly more expensive than the end commercial product, but well known cost reduction pathways have been followed within the solar PV and wind energy sectors (Junginger et al., 2010). However, progress down the pathway towards cost reduction is not instantaneous. Learning, a phenomenon well documented in studies and literature, is a function of unit deployment and not a function of time (MacGillivray et al., 2014;Junginger et al., 2010). As a result of a dearth of physical deployment, cost reduction through learning within the wave and tidal energy sectors is therefore restricted to theoretical analysis, making assumptions on future trajectories (MacGillivray et al., 2014;SI Ocean, 2013;Carbon Trust, 2011). The ambition of the wave and tidal energy sectors has been to progress rapidly to medium-sized arrays, with utility and multinational equipment manufacturers heavily involved in technology development and project consenting process. Due to the scale of the financial requirements for these arrays, project finance through company balance sheets, bank loans, and perhaps most prominently public sector grants or loans are essential enablersmuch in the way that more mature wind energy projects would be developed (Winskel et al., 2014). However, many of these early stage wave and tidal energy array projects are struggling to raise sufficient private sector finance in order to allow the projects to successfully engage with contractors and enter construction and operational stages. From a technological development and diffusion perspective, wave and tidal stream energy technologies have not achieved the level of penetration into existing power generation networks that was initially expected, but there is nevertheless a very strong ambition to become an integral part of the future energy mix. These technologies are still considered nascent, and as such, require much development work, supported by strong technologypush policy mechanisms, to enable commercial operation to become a reality in the future.",
            "Logistic growth functions": " The logistic growth function originated as an extension of the exponential growth function, designed to constrain the maximum upper value of a given function or variable where limitless increase is deemed unrealistic (Tsoularis and Wallace, 2002). This limit, the saturation level, provides a numerical upper bound on the growth of the function. The explanation of population statistics within P.F. Verhulst's \"Notice sur la loi que la populations suit dans son accroissement\" in 1838 (Verhulst, 1838) is widely regarded as the first scientific contribution to the understanding of what is now known as the logistic equation. The logistic growth model is able to reflect the changes in growth rate for a particular variable over time: the process follows a sigmoidal (s-shaped) profile where the rate of growth initially accelerates (and can be initially almost exponential in nature), before reaching a point of inflection and eventual deceleration in the rate of growth as a maximum limit is approached, as demonstrated in Fig. 1 below. A number of logistic growth models have been suggested as useful for modelling the growth of biological populations over time, but the application of these functions extends well beyond the fields of biology or social science (Tsoularis and Wallace, 2002). Logistic growth functions have been used as a tool to characterise the diffusion of innovation across a range of processes and technologies. Diffusion of innovation theory emerged during the 1960sbut has since become a popular topic of research within many disciplines, including economics, statistics, marketing, sociology, psychology, and industrial engineering (Rogers, 1995). Logistic growth functions have been applied to technological subjects such as the modelling of market penetration of new telecommunications services (Brewley and Fiebig, 1988), and the evolution of infrastructure in the USApresented as percent of saturation level with respect to year for a number of technologies (Grubler et al., 1999). Within the energy sector, application of logistic functions is utilised for the forecasting of technological change (Sharif and Islam, 1980), global energy usage change together with the senescence and substitution of older technology for more advanced sources of energy (Marchetti and Nakicenovic, 1979), and for the modelling of energy system growth and technology change based on empirical data (Wilson, 2012;Wilson et al., 2012), where the capacity penetration over time and the time-frames associated with development phases for of a number of energy technologies were considered. Forecasts of energy technology industry growth using logistic growth functions have suggested that a methane dominated energy economy could be in place by 2030 (Smil, 2008). Existing research has considered application of 3 Parameter Logistic (3PL) models within energy sector technologies. 3PL functions provide curve-fitting through nonlinear regression models that are defined by three parameters: the maximum asymptote of the curve, the inflection point, and the gradient of the curve at the inflection point. The simplicity of the 3PL growth function can yield useful results when it is deemed an appropriate fit. However, it should be noted that there are some limitations to the use of simple 3PL functions, such as the strict enforcement of symmetry about the point of inflection (Brewley and Fiebig, 1988). Additionally, the diffusion process may occur at varying growth rates over the course of the sample (Brewley and Fiebig, 1988), an attribute that 3PL functions are unable to model accurately. 3PL functions assume that growth initiates from a zero value at the outset, enforcing this as the lower asymptote. In the technologies outlined within this proposed study, these criteria were shown not to consistently be met by the datasets in question to a satisfactory level. Adding a fourth parameter, the minimum asymptote, can enable curve fitting where the process or system being modelled initiates from a non-zero value. Many examples of 4PL logistic growth functions are considered within literature, including the Gompertz function and Weibull distributions (Sharif and Islam, 1980;Tsoularis and Wallace, 2002;Banks, 1994). There are limitations and inflexibilities associated with 3 and 4 parameter logistic growth functions as a result of specific requirements for points of inflection and degrees of asymmetry (Brewley and Fiebig, 1988;Tsoularis and Wallace, 2002). A more flexible logistic growth function has been identified. A five parameter logistic (5PL) non-linear regression model allows for both asymmetry about the point of inflection and a non-zero lower asymptote, thus removing the constraints of 3PL and 4PL functions (Richards, 1959). The 5PL growth model, whose fifth parameter is defined as a shape parameter, which allows asymmetry, is therefore considered a more appropriate tool for representing the development of technology, advancement of stateof-the-art, and diffusion of innovations into commercial application within the energy sector, where non-zero lower asymptotes exist in unit-level deployment, and definitive symmetry about a point of inflection is perhaps plausible, but extremely unlikely.",
            "Application and purpose of the study": " The early stages of the innovation process have been characterised as a \"formative\" stage of development, where specific parameters such as the formation of niche markets and creation of a safe protected environment to carry out early deployments will help to facilitate the learning process and improvement of the price/performance ratio (Jacobsson and Lauber, 2006). This phase can generally be seen to take place comprehensively before a successful technology achieves a greater level of up-scaling and significant market diffusion. The use of empirical data has revealed interesting trends surrounding the formative stages of technology development, and has allowed for the observance of timescales associated with the transition of an invention through formative, up-scaling and growth stages at both unit and industry level (Wilson, 2012). The formative stage can last a number of years, and in most cases, industry growth is preceded by technological consolidation around front-running technology and unit up-scaling. For example, steam turbine technology took over 50 years of development before the technology entered a unit up-scaling phase; a subsequent 20 years of unit-level up-scaling were then seen prior to industry-level growth (Wilson, 2012). Much of the existing literature within the energy sector utilises logistical growth models as functions of time or as functions of cumulative deployed capacity (in GW). When analysing historical trends, time is a metric that can be considered appropriate. However, if those trends are to be used for technology forecasting purposes, time is no longer an appropriate metric. To date, no consideration has been given to the level of deployment that has been carried out within the identified timeframes of a formative phase of development, or the level of deployment prior to the progression from formative phase through up-scaling and on to industry growth. Diffusion is not an instant process, and as such, the element of time is often regarded as an essential factor in the theory of diffusion of innovations (Rogers, 1995). This is accurate, as diffusion of innovations generally requires the transfer of knowledge between different actors in a system, exemplified even from the earliest work in diffusion studies such as the diffusion of hybrid corn seed in rural agricultural communities in the USA (Ryan and Gross, 1943), the acceptance of which naturally takes time to propagate. However, from an engineering perspective, the technological development and innovation in mechanical systems that we seek to evaluate in this study are a more directly a function of deployment and technological evolution through unit deployment. This innovation development by its very nature cannot occur over time alone without physical production and deployment of technology, just as the process of cost reduction through learning is a function of unit deployment and not a function of time (MacGillivray et al., 2014). For example, we cannot expect technological evolution and diffusion of electric vehicles to take place if electric vehicle manufacturers were merely to make one prototype then store it in a garage for a prolonged period of time, inviting marketing experts and photographers to heavily publicise the perceived merits of their innovation for diffusion, as they wait for it to commercialise. Developers of electric vehicles are required to operate, test (often multiple prototypes), and utilise critical feedback in order to allow refined development of future commercial models that meet the needs and requirements of the intended customers. Similarly, for energy technologies, diffusion of innovation cannot be expected to occur through the deployment and operation of single unit prototypes for prolonged periods of time without additional deployment of improved iterations of the technology. Thus we propose herein to use 5PL growth functions to evaluate increases in maximum unit capacity (unit-level growth) and cumulative deployed capacity (industry-level growth) with respect to the number of units deployed. Of course, unit deployments occur over time (and in the case of this study, we catalogued the deployment of technology chronologically prior to carrying out the analysis), and so the requirement of a time-factor within the process is still met, albeit indirectly. Each subsequent unit deployment or iteration takes place at an irregular time interval. The work from this study reveals for the first time an enhanced level of detail, which can identify the level of unit deployment that took place within the given time frame of a formative phase. With the focus of wave and tidal energy firmly geared towards a rapid transition to commercial arrays of large-scale energy converters, this study was an attempt to put into perspective the requirements, in terms of unit iterations and deployments, that have existed in other energy technologies between first unit demonstration and significant unit-level growth (up-scaling) and between the initiation of significant unit level grow and subsequent growth of an industrial sector (cumulative capacity growth). This paper reports the findings of extensive investigation of the technology trajectory, iteration and unit deployment within three technology types: 1. Steam turbines (from thermal coal-fired power plant). 2. Gas turbines.",
            "Wind turbines.": " By highlighting the requirements of the identified technologies in terms of number of unit deployments prior to unit-level upscaling and industry growth (which in many cases had the benefit of developmental input from sectors outside of power generation not considered within this paper), a more realistic approach to the expectations of the wave and tidal energy sector can be considered, together with investigating changes that may need to be made to the research, development and innovation environment and the focus of policy intervention in order to facilitate the emergence of successful wave and tidal energy technologies. The purpose of this study was therefore to identify the number of unit deployments taking place within formative phases of comparable energy technology development, and make evidence-based policy recommendations to support appropriate and economically sustainable wave and tidal stream energy technology development.",
            "Methodology": " Empirical data considering technology deployment was required for this study. Within the technology types, access to data within specific geographic regions directed the core market focus of the technologylimiting each technology analysis to a single country rather than global deployment levels. Whilst this resulted in an inability to capture wider market dynamics, the data did cover principal or core regions of development, so can be considered to be representative of the early or formative stages of technology development in each case. For the steam turbine and gas turbine technology, data was obtained from the US Energy Information Administration's Annual Electric Generator dataset available online (US Energy Information Administration, 2015). In the case of steam turbines, data was supplemented by known early developments in steam turbine design recorded in literature (Baumann, 1912(Baumann, , 1921)). Data for individual steam turbine and gas turbine technology had to be extracted from the source material, which included all power generation sources within the US. For the wind turbine technology, data was taken from the Danish Wind Turbine Master Register, which is updated monthly and is available online (Energi Styrelsen, 2014). For each technology case, the data had to be arranged in order of installation date, forming a chronological catalogue of each deployment of a given technology. Additional data had to be defined for all technologies to record the unit deployment number, and the cumulative installed capacity (in GW) as deployment levels increased. Unit deployment number represents the sequentially increasing number of units that have been collectively deployed, increasing until the final deployment contained within the dataset. Cumulative installed capacity was calculated through summation of the unit capacity of all unit deployments that had taken place at each instance of deployment. Furthermore, the analysis was to consider all units that had been installed, even if they were by then decommissioned. Two specific metrics were of interest within this study: 1. The unit-level capacity growth (unit up-scaling) experienced by the technology, represented by the unit capacity (in MW) with respect to unit deployment number. 2. The cumulative industry growth (industry level up-scaling) experienced within each technology type, represented by the cumulative installed capacity (in GW) with respect to unit deployment number. The 5PL model utilised within this study can be represented by the following equation (Commo and Bot, 2014): \u23a1 \u23a3 \u23a4 \u23a6 y B T B 1 10 b x x s mid = + \u2212 + ( \u2212 ) where: B is the minimum asymptote; T is the maximum asymptote; b is the Hill slope (the gradient of the curve at x mid , dy/dx); x mid is the x-coordinate at the inflection point; s is an asymmetric coefficient. The 5PL function is used herein to supply only an empirical fit to historic datasets, and not to make projections on future trends. Thus the novel approach we suggest is in appropriate considering the intentions of the flexible 5PL function. Each parameter of the function is explained diagrammatically in Fig. 2, with the parameter s reflecting a shift in the asymmetry of the curve. For each technology, two logistic growth functions were envisaged. The first to account for unit-level upscaling, and the second for industry level up-scaling. Logistic curves were fitted for each technology type at both unit and industry level where applicable, allowing comparisons to be made between unit and industry level growth, and in particular the number of unit deployment requirements for growth at a unit level in the historic energy sector. The empirical data used to plot the logistic functions resulted in an s-curve growth function, in which several important parameters emerged for analysis within this study: 1. T (the maximum asymptote denoting the limiting maximum unit capacity (or industry cumulative capacity)). 2. X mid (the x-axis value at the point of maximum growth, taken from the point of inflection of the logistic function). 3. x i (the x value at the point at which the unit or industry level up-scaling exceeded 10% of the difference between the initial deployment capacity and the asymptote, T (or current maximum value if the asymptote has not yet been reached)an indicator of the initiation of the up-scaling process. 4. x f (the point at which the unit capacity reaches 90% of the asymptote, T, if applicable)an indicator that a certain capacity limit was being approached. Several software tools are available for 5 parameter logistical curve fitting and statistical analysis, such as R (R Core Team, 2015), or open-source code for functions within MATLAB (Cardillo, 2012). However, a simplified approach used in this paper utilised the \"Solver\" add in for Microsoft Excel. In this case, a known equation exists, with a known number of variables, B, T, b, x mid and s as defined earlier, for which reasonably accurate initial guesses can be provided based upon observation of the original dataset. A predicted curve can be set up using these initial estimates. The predicted data can then be tested for goodness of fit by comparing with the original data using the least squares method, in which the square of the difference between actual data and predicted data is calculated and then summed across the range of data points to find the Error Sum of Squares (SSE). When using Excel Solver, a target cell is defined, in this case the SSE and the value of the target cell is minimised through iteratively applying perturbations to the five defined variables until convergence upon a solution is reached. Plotting of the solutions for the logistic curve against the input data could provide an immediate sense check of the solutions as, if initial guesses are not adequate, the solver may not reach appropriate solutions. Visual inspection of the plotted logistic function against the real dataset would be adequate to make this judgement. If it was not possible to make confident initial guesses, then use of specific software such as those outlined above would be more appropriate. By calculating the coefficient of determination, R 2 , of the predicted solution, the goodness of fit of the predicted logistic curve could be assessed. Before discussing the results of this analysis, the criteria for use of logistic growth functions should first be outlined. In order for the logistic growth functions to be considered valid for this study, the fit of the logistic growth function had to exceed a goodness of fit R 2 value of 0.94 so that confidence in the results could be justified. For this study it was assumed that if a maximum asymptote value T had not been reached, then the maximum value within the dataset would be taken as the limiting capacity for calculation of x i , even if a point of inflection had not been reached. This scenario would occur if unit-level or industry-level up-scaling was still taking place at an exponential rate. T and x mid were obtained through a satisfactory solution using Excel Solver (as described above), producing an appropriate logistical growth function with a goodness of fit greater than 0.94. The additional points of interest x i and x f could be calculated through re-arranging the 5PL logistic equation and solving for x (the y-value in each case can be calculated as a known function of T and B). The equation then becomes: \u23a1 \u23a3 \u23a2 \u23a4 \u23a6 \u23a5 x x b ln 1 ln 10 mid T B y B s 1 ( ) = \u2212 \u2212 \u00d7 ( ) \u2212 \u2212 The unit level up-scaling considered only the representative technological state-of-the-art, and utilised maximum unit capacities available at a given deployment number, rather than including the entire dataset within the logistic function fit. Deployment of technology below the unit capacity limit continues to take place throughout the up-scaling and growth phases of each technology, but our interest in unit level growth must focus on the maximum unit capacities available at a given deployment. Data points deemed to be outliers to the general trend were removed from the dataset prior to the fitting of the logistic growth functions. These outliers generally represent prototypes with unit-capacities significantly greater than the average deployment trend, and were evident where subsequent deployment of comparable technology unit capacities did not occur in a sustained manner. These outliers can be considered as having been too big, too soon, and did not provide significant contribution in terms of progression through a formative phase. By identifying the factors of interest outlined above, comparisons could be drawn between the historic trajectory of energy technologies and the attempts being made by wave and tidal stream energy technology developers and policy makers to stimulate growth in the nascent ocean energy sector.",
            "Results and discussion": " Within the analysis undertaken for this work, steam turbine and gas turbine technologies were successfully observed to approach a maximum asymptote, therefore logistic growth functions could be used to fully define formative, up-scaling and growth stages at both unit and industry level. Wind turbines, however, are still in a process of unit-level and industry-level up-scalingunit iteration and large scale deployment is still being seen. The data analysed suggested that wind turbine technology may have reached a point of inflection in unit-upscaling, although continued growth from current levels is still expected. However, the industry growth has not reached a similar observed long term reduction in capacity additionsexponential growth at an industry level is perhaps still being experienced. Each technology type will now be considered in turn.",
            "Steam turbines": " Steam turbine unit deployments are shown in Fig. 3, with the calculated logistic fit used for both unit and industry level upscaling. The first steam turbine deployment recorded in the dataset took place in 1909. Analysis of the data revealed that significant unit level up-scaling did not become fully established until after 799 unit deployments had taken place, which was achieved in 1954. The formative period of development therefore lasted 45 years. The rate of increase in unit level up-scaling slowed after 1543 unit deployments (in 1962), reaching a point of inflection at this stage. Subsequent unit growth allowed the maximum capacity to extend beyond 1000 MW, and the analysed data resulted in an asymptote at 1450 MW. At an industry level, the cumulative capacity of steam turbine units reached a growth stage after 1233 unit deployments (in 1958), according to the logistic fit model. There were over 430 unit deployments between the initiation of the unit up-scaling phase, and the initiation of the industry up-scaling phase within the steam turbine technology analysed. These 430 units were deployed in a four-year window between 1954 and 1958.",
            "Gas turbines": " Data for gas turbine technology contained a number of outliers that impacted the fit of the logistic growth functions. Observation of this data suggested that these particular data points did not reflect successful unit level growth when considering the remainder of the industry development and deployment trajectory, as the early large unit sizes did not achieve subsequent deployment of equivalent technology scales until a significantly larger number of unit deployments had taken place. The decision was made therefore to remove any data point from the analysis that consisted of a unit capacity greater than 50 MW prior to the 750th unit deployment. This resulted in the removal of 20 data points within an overall dataset of 3606 units, as shown in Fig. 4. The gas turbine within power generation applications has benefited from development of gas turbine technology within industrial, naval and aerospace applications (Hunt, 1990). The dataset considered did not reflect this external development and we considered only gas turbine applications within thermal power generation plant in the core market region of the US. The first gas turbine deployment recorded in the dataset took place in 1948. Analysis of the data revealed that significant unit level upscaling did not become fully established until after 759 complete unit deployments. The 759th unit was installed in 1971. Observation of the data clearly shows that the formative stage of technology development was dominated by deployment of technology below that of the capacity limit, even before unit-level up-scaling became fully established (see Fig. 4). The rate of increase in unit level up-scaling slowed after 1994 unit deployments (in 1992), the point of inflection, resulting in a clear asymptote at 232 MW. At an industry level, significant up-scaling became fully established after the deployment of 887 units (in 1971), 128 units after the establishment of significant unit-level up-scaling. Industry level growth is still being experienced, and so no upper asymptote was apparent within the dataset.",
            "Wind turbines": " The analysis of the wind energy sector in Denmark presented a number of challenges: at both a unit and an industry level, there has been no definitive inflection in the growth, suggesting that an exponential growth trajectory may still be underway. The latest deployment evidence suggests that this growth may be tapering at industry level, but this was not sufficient to influence a logistic growth function. Thus for wind energy, the initiation of unit-level and industry-level growth is discussed relative to the current maximum values. The first wind turbine deployment recorded in the dataset took place in 1977. In order to establish an optimal logistic growth function that reflected the commercial deployment of wind turbines, the identification and removal of outliers within the dataset was necessary. Several assumptions had to be made that resulted in 16 of 7971 data points being omitted from the study: Turbines of 400 kW or greater within the first 1000 unit de- ployments were removed from the dataset. Turbines of 650 kW or greater within the first 2000 unit de- ployments were removed from the dataset. Turbines of 1 MW or greater within the first 4000 unit de- ployments were removed from the dataset. The data is plotted graphically in Fig. 5. According to the analysis carried out, 3636 unit deployments had taken place prior to the establishment of significant and continued unit-level upscaling. This level of deployment was reached in 1995. Additionally, the analysis suggested that industry-level up-scaling took place after the deployment of 3362 units (which was reached in 1994). Therefore industry-level upscaling became established over 270 units (and one year) prior to the establishment of unitlevel up-scaling, unique within the energy technologies considered within this study. Incremental growth in turbine unit capacity is still occurring, and although wind turbine growth is tapering off from the perspective of onshore designs, the data suggested that a future asymptote value could be approximately 10 MWa unit capacity that could be reached by traditional turbine designs in the future (certain offshore units are already 8 MW in capacity; the largest on-shore wind turbine is the Enercon E-126 7.58 MW unit (Enercon, 2015)).",
            "Wave and tidal stream": " The data points used within the study of wave and tidal stream energy converters utilise technology deployed within UK waters. There is sparsity in data, given the nascent status of the sector. However, the analysis represented the best available given the limited dataset (limited by lack of physical deployment rather than lack of access to data), and is presented as a thought provoking challenge for ocean energy stakeholders. It should be clarified that no data point within the wave or tidal datasets represent longterm installations, and all are pre-commercial prototypes with lifeexpectancy far shorter than the desired 20-year life of commercial products, many of which have already been removed from their initial deployment location. Whilst it is only possible to make a judgement on the likely maximum unit capacity value for a wave or tidal energy converter, it is likely that, in the majority of cases, the maximum capacity of modular ocean energy technologies will be in the region of 0.5-2 MW in scale. Physical constraints that are present within the ocean energy sector characterise these limitations, such as the depth of water columnthe distance between the sea bed and the water surfaceand the physical mass required for structures to survive the intended loading regime as unit capacity (and therefore physical size) increases. Data for wave energy technologies deployed within UK waters, shown in Fig. 6, reveals the rapid shift to large-scale technology. The unit-level growth rapidly increased following the first unit deployment. Several unit deployments in the region of 700-900 kW in scale have been deployed in the very early unit deployments, however subsequent industry growth through deployment of technology at this scale has not been achievedthere has not been utility-scale activity following on from the demonstration of pre-commercial prototypes. Moreover, the data points captured in this study represent a number of different concepts and technological solutions to wave energy conversion, and there is no convergence of design (unlike within the other energy technologies reported). The data clearly shows that the formative phase has not taken place within the UK wave energy sector: data points are widely dispersed, there is no clear unit-level growth trajectory or opportunity for a stable and progressive future unit-level growth, there is a fundamental limitation in the low number of data points, and there is no clear indication of the technology following an appropriate s-curve logistic function profile over a number of unit deployments as seen within successful energy sector technologies. There is a clear early push for \"commercial full-scale\" devices approaching 1 MW in scale. Given that limiting unit capacities are likely to be in the region of those largest devices currently deployed, due to the economics of manufacturing the necessary  structural components (French, 2006), the rapid progression to large scale technology prior to a formative phase of technology proving has led to a lack of established data to benchmark unit growth, and a failure to iterate efficiently and cost-effectively. The levels of unit deployment are very low, but high expectations have been placed on the wave energy sector to date to deliver successful commercial scale power production. This growth pattern differs considerably from the established energy technologies reported. Within the tidal energy sector, some early prototype demonstration did take place using turbines considered to be small-scale (in the order of tens of kW). The small number of data points do, however, reveal a rapid progression to MW-scale technology, as shown in Fig. 7. Data from UK based deployments suggest that unit-level upscaling took place instantly after the first deployment, and rapidly reached an asymptote of 1 MW by the time the 10th unit had been deployed. Although there are a number of deployments that continue to take place at kW scale, there is clear evidence to suggest that, as in wave, the formative phase of technology development has again been omitted; data points are widely dispersed, there is no clear unit-level growth trajectory or opportunity for a stable and progressive future unit-level growth, there is a fundamental limitation in the low number of data points, and there is no clear indication of the technology following an appropriate s-curve logistic function profile over a number of unit deployments as seen within successful energy sector technologies. Both wave and tidal energy technologies are facing similar struggles to achieve commercial scale deployments: there has been little evidence to suggest that the technology can give the required confidence to investors that will justify the level of investment that is needed to sustain continued development at the larger technology scales (MacGillivray et al., 2013). It should also be noted that further UK deployments have been consented, utilising tidal turbine technology with a capacity of 1.5 MW per device (MeyGen, 2015). Tidal turbines to be deployed further afield in France and Canada have rated capacities of 2 MW per device (DCNS Open Hydro, 2015), however, the power output from a single rotor is unlikely to increase beyond this level. For example, the rotor of a tidal turbine will be limited by the depth of the water column due to the desire to avoid the large shear profile at the sea bed, and wave interaction and transport shipping draft close to the surface. Deployment of technology greater than 1 MW represents further unit level up-scaling without significant deployment at earlier technology scalescontinuing to follow the trend of up-scaling prior to successful emergence from a formative phase. Whilst the data for wave and tidal stream energy technologies consists of only a few data points, there is already a clear and stark difference in trend between the ocean energy technologies, and the historic growth pathways followed within other mature and established energy sector technologies.",
            "Summary of data": " The key logistic function parameters for steam turbines, gas turbines, and wind turbines are identified and presented in Table 1 below.",
            "Discussion of findings": " Within each of the historic technologies analysed, it is clear that the initial devices deployed were a small fraction of the capacity of the upper asymptote value (0.0005%, 10%, and 0.2% of T for steam turbines, gas turbines, and wind turbines respectively). At the point in which the establishment of significant growth in the rate of unit-level up-scaling took place, unit capacities still represented only a portion of the asymptote value (13%, 21%, and 6% of T for steam turbines, gas turbines, and wind turbines respectively). Devices deployed between the initial unit and the unit at x i represent the formative phase of the technology. It can be seen that a rapid increase in unit-level up-scaling did not occur instantly in any of the historic cases investigated, but took a number of formative phase deployments spanning decades. Within steam turbine technology, the data suggests the formative phase took place with 799 unit deployments over a period of 45 years. In the case of gas turbine technology, which had the advantage of developmental input from aviation and heavy industry not considered within this study, 759 unit deployments took place within an electrical power generation context over the course of 23 years prior to unit-level upscaling becoming well established. Wind turbines, often considered analogous to the wave and tidal energy technologies due to the modularity of the units, required deployment of 3636 units prior to the establishment of significant unit-level up-scalingand the formative phase took place over an 18 year period. The wind industry did, however, demonstrate that it was possible for industry level up-scaling to take place prior to unit level up-scaling. However, the industry upscaling was able to benefit from a well-developed product in which much evidence of reliable unit operation could be drawn from historic deployment experience. It is clear that the historic development trajectories of existing power generation technologies have followed a gradual unit-level up-scaling process, over the course of many unit iterations and deployments. However, the early wave and tidal energy sector appears to be attempting to bypass this early formative phase altogether, having failed to demonstrate clear consensus on front running technology or successfully emerge through a formative phase of development. Instead technology developers and policy makers alike have set sights on multi-MW array projects as an appropriate development step subsequent to short term single unit prototype testing. Many of the existing deployments within wave and tidal stream energy appear at significantly larger capacity than would be expected for a formative phase of development. If wave and tidal stream energy technology trajectories were to follow similar trajectories to those of the other technologies considered within this study, then it would be expected that a large number of unit deployments at small unit capacity would precede technology upscaling. In the historic energy sector technologies considered within this study, devices that went \"too big, too soon\" were considered to be outliersremoved from the data set as they did not contribute meaningfully to progress through a formative phase. A more appropriate formative phase of technology development in wave and tidal stream energy would perhaps consider the large unit capacities deployed to date within the sector as outliers, and not representative of the necessary development steps in order to successfully progress beyond a formative phase of development.",
            "Conclusion and policy implications": " We offer several conclusions with implications for energy policy, wave and tidal energy technology development, and the process of innovation within the ocean energy sector more generally. This analysis reported that the formative phase of technology development has taken place over hundreds, or even thousands of unit deployments. The lessons learned from earlier iterations and deployment of technology feed into the design of optimised successors, with the up-scaling and build-out of commercial technology taking place after a period of formative development. Without this formative development, there remain substantial technological and economic risks. It would be perhaps foolish to think that the wave and tidal energy sector would be capable of delivering commercially available and large-scale power generation technology in such a small number of deployments, when other industrial technologies required a number of deployments two or three orders of magnitude greater to achieve this goal. Policies and support mechanisms within the wave and tidal energy sector should not incentivise the development of MWscale technologies and multi-MW array projects prior to the emergence of consolidated technology from formative phase development. Policymakers must facilitate a transition in the research, development and innovation environment by focusing on affordable technology development and affordable unit iteration within a formative phase of technology development rather than focusing on achieving early commercial array deployment. Policies should be established that support appropriate levels and scales of technology development within nascent formative stages, rather than attempt to pull a technology that is not yet ready into a market that is under-developed. The objective for policymaking within the ocean energy sector should be to incentivise an appropriate technology trajectory which recognises the need for iteration and optimisation within a formative phase (certainly more than a single unit pre-commercial demonstration prototype will be needed for adequate demonstration of affordability, survivability, availability and performance), and not to incentivise over-aggressive up-scaling and deployment before technology development is complete as has been the case with existing and previous policy and support mechanisms. For technology developers seeking to advance the development of technology to harness tidal stream currents and wave energy, this cost effective unit iteration could be achieved by the development of technology at smaller unit scales, which becomes more affordable to the technology developers and funders responsible for product development, whereby multiple units of smaller scale can be developed for the cost of a single MW-scale prototype. Innovation and minor technical changes within MW-scale technology are likely to be significantly more costly than engineering design changes and innovation within smaller scale units. Additionally, use of the term \"commercial full-scale\" as implying MW-class machines may not be helpful. Technology develops and evolves over time (providing unit deployment is taking place), and the corresponding maximum capacity limit of devices will change over time. In all historic energy technologies investigated within this study, commercial deployment started with units of modest capacity. Similarly, deployment of technology with unit capacity well below that of the capacity limit continued to take place, even as the state-of-the-art in capacity limit increases. A range of technology scales could represent appropriate solutions, and care must be taken to avoid picking unsuitable \"winners\". This research has demonstrated extensively that identification of the number of unit deployments provides a greater level of detail to understanding formative phase development, as it allows the intensity of deployment within a formative phase to be recognised rather than considering only the timescales over which development took place. Time is not the only factor in which observation of change is needed; experience through deployment and iteration can bring about much learning, and the effect of number of deployments on the technological trajectory and the development and diffusion of innovation process is likely to be significant. The political and economic pressure on the wave and tidal energy sector has attempted to bring about delivery of a commercially successful industry, without sufficient formative development. The paradigm shift in thinking must therefore focus on cost efficient unit iteration, recognising the need to secure adequate evidence of technological maturity before precipitating a rush to install multiple-unit multi-MW array deployments. If iteration and deployment is the key to unlocking successful technology development, then many unit deployments are likely to be necessary in order to successfully emerge from a formative phase. At present, neither the technology developers within the wave or tidal energy sectors, nor the governments interested in exploiting the ocean energy resource can afford to iterate extensively at MW-scale. While the technology trajectory followed by wave and tidal energy sectors to date has not yet resulted in successful commercialisation, this study has identified an opportunity for a radical transition in the development pathway. By enabling many instances of technology deployment through a transition to smaller capacity units, progression through a formative phase of development could be carried out in a more economically sustainable and technologically appropriate manner."
        }
    },
    "10.1016/j.enpol.2010.03.044": {
        "file_name": "40 Global technology learning and national policy",
        "title": "Global technology learning and national policy-An incentive scheme for governments to assume the high cost of early deployment exemplified by Norway",
        "abstract": "In this paper it is argued that technology learning may be both a barrier and an incentive for technology change in the national energy system. The possibility to realize an ambitious global emission reduction scenario is enhanced by coordinated action between countries in national policy implementation. An indicator for coordinated action is suggested. Targeted measures to increase deployment of nascent energy technologies and increasing energy efficiency in a small open economy like Norway are examined. The measures are evaluated against a set of baselines with different levels of spillover of technology learning from the global market. It is found that implementation of technology subsidies increase the national contribution to early deployment independent of the level of spillover. In a special case with no spillover for offshore floating wind power and endogenous technology learning substantial subsidy or a learning rate of 20% is required. Combining the high learning rate and a national subsidy increases the contribution to early deployment. Enhanced building code on the other hand may reduce Norway\u2019s contribution to early deployment, and thus the realization of a global emission reduction scenario, unless sufficient electricity export capacity is assured.",
        "label": "Quantitative",
        "text": {
            "Introduction": " The importance of nascent energy technologies to reduce the emissions of greenhouse gases is widely acknowledged. Moreover, a price on carbon, e.g., a CO 2 tax may not be adequate to reduce emissions at a sufficient pace and scale (Stern, 2006). Commitments 1 under the UN Framework Convention on Climate Change (UNFCCC) and the EU renewable energy directive in particular, aim to promote deployment of nascent energy technologies. Development of indicators for monitoring the contribution by Parties to technology development, deployment and transfer under the UNFCCC has only just begun. The EU is applying an indicator 2 to allocate the commitment based on the relative share of renewable energy and energy efficiency in the national energy system (European Commision, 2008). The EU approach may; however, not promote adequate support for the least developed technologies, e.g., offshore floating wind power, because the subsidies required per MW are higher than those needed for the technologies close to commercialisation, e.g., onshore wind power. Moreover, the need for financial support may vary depending on the global scenario and the corresponding spillover of technology learning 3 from the global energy technology market. In this paper the deployment of nascent energy technologies because of two different national measures simulating the implementation of EU-directives: (1) technology specific subsidies and (2) improved building code are analysed. They are evaluated against a set of baselines influenced by the spillover in three global scenarios with different technology development paths. Furthermore, a special case with no spillover for offshore floating wind is also included. The exertion to coordinate national efforts to contribute to technology learning with a portfolio of globally desirable low-carbon technologies adds a new element to scenario analysis, not included in the earlier studies. More specifically, insight is sought regarding the following questions: What is the additional effect, of the national measures derived from EU-directives, on deployment of nascent energy technologies when including spillover of global technology learning? Specifically, do the selected policies and measures provide support to the high cost of early deployment? An indicator for the national contribution to global technology development based on the need for financial support for technology deployment is suggested and used in the analysis. The work presented is part of a study combining spillover of technology learning from the global market and feedbacks from other sectors of the national economy in a national energy systems analysis. First thoughts on the approach were presented, and feedback received, at an IEA workshop (Martinsen and Wene, 2007). In an experiment where net annual export and import of electricity was constrained to zero the need for the new technologies, e.g., wind power and natural gas combined cycle (NGCC) with carbon capture and storage (CCS) appeared only just before 2050. Consequently the contribution to global learning investments was estimated to be small (Martinsen, 2008). In this paper export and import of electricity may take place at today's cable capacity. Below a short discussion of the interdependence between global learning and national deployment is presented followed by a description of learning investments and the indicator for national contribution to global technology development. In Section 3 the method applied to include technology learning and a short summary of the models used are presented. The global scenarios, the Norwegian energy system and national circumstances and the measures investigated are described in Section 4. The main part of the paper is devoted to the national energy system response to the combination of global technology learning and the national measures. A special case, where technology learning for offshore floating wind power (OFW) is endogenous, is also investigated.",
            "Global learning and national deployment": " The influence of global technology learning on the national energy system is briefly discussed in Section 2.1. An argument is provided for why coordinated action between countries in national policy implementation may assist in tackling the challenges of climate change. A description of learning investments and a measure of the national contribution to global technology development is provided in Section 2.2.",
            "Coordinated national policy implementation": " The price of new energy technologies and thus the most cost efficient technology composition of the future energy system of a small open economy like Norway ultimately will be heavily influenced by the selections made in the international energy system and the corresponding development of the international energy technology market. The cost of the energy service from the nascent energy technologies is higher than the existing technologies. Once in production and use; however, experience fosters technology learning and the cost will go down and performance improves (BCG, 1968). The learning system boundary may be assumed to be global given there is -or will be within the early part of the period of analysis -a global market established for the nascent energy technologies, (Junginger et al., 2005). When the nascent energy technologies become competitive they will most likely be included in the future national energy system. This spillover of technology learning from the global energy technology market thus provides a strong incentive for technology change in the national energy system. The incentive will not be technology neutral but be stronger for the technologies experiencing the largest growth in the global energy system. It will thus try to coordinate the development of the national energy technology portfolio with the evolving technology composition of the global energy system. National circumstances may benefit other technologies or even work against the coordination, but are often not as strong. For example, in the early days of the automobile both gasoline and electricity were used as fuel. As the internal combustion engine using gasoline became the dominant technology globally it has been the preferred choice within most national energy systems. In Brazil; however, alcohol is produced nationally at a low cost and has to some extent displaced gasoline. On the other hand, realization of cost reductions through global technology learning depends on national policy implementation. However, early deployment has a high cost. Because of the urgency and large risks the Stern review (2006) calls for policies to support the development and deployment of a portfolio of low-carbon technology options. Technology specific instruments and measures are thus needed to establish strategic niche markets to expedite the introduction of new technologies (IEA, 2003;Kemp et al., 1998), i.e., push the technologies into the energy system. Moreover, efficient strategies to shift the development of the global energy system to a low-CO 2 emission technology path call for international cooperation where local deployment contributes to technology learning on a global scale (IEA, 2000). Technology learning links, in a circular causal chain, the development of energy technology to the development of the energy system, because the technology learning system is structurally coupled to the energy system (Wene, 2008). Coordination of national policies with the desired global technology development scenario is needed to accomplish the global rate of deployment required to achieve emission reduction targets. That is, conceptually to make global and national technology learning to pull together towards a common goal. A jointly implemented CO 2 incentive, e.g., in the form of a CO 2 tax or tradable CO 2 permits already represent a form of coordinated action among governments. However, many new low-CO 2 emitting technologies are still too costly and will therefore require targeted support until they are competitive in the mass markets with the CO 2 incentive. The structural coupling makes path dependency into an inherent feature of technology learning (Mattsson and Wene, 1997;Wene, 2008). This implies that a more stringent global policy goal may exhibit a different technology portfolio (IEA, 2008). 4 A coordination of national policy and global technology learning depends not only on the national policies and measures, but equally on the chosen global scenario and associated global technology path, which set the external conditions for the national analysis. Path dependency therefore prescribes that the global scenario and the technology cost trajectories must be selected together, because different scenarios will exhibit dissimilar technology paths and therefore dissimilar technology cost trajectories. Because the learning system boundary is assumed to be global a global model is required to determine the performance of the energy technologies. The performance, e.g., cost trajectory, is a boundary condition for the national analysis. The global scenarios selected in this paper are those described in the Energy Technology Perspectives (ETP)-Scenarios & Strategies to 2050 (IEA, 2008). There are two reasons for this choice of global scenarios. Firstly, the IEA scenarios outline alternative technology paths to 2050 consistent with the energy scenarios. Secondly, they have been extensively reviewed by a large number of policy analysts and experts from IEA government agencies, industries and research organisations. They constitute the basis for the technology road maps (IEA, 2008) indicating key actions required and time scale to commercialisation. The use of road maps is currently also discussed in UNFCCC in relation to a new protocol subsiding the Kyoto protocol. The IEA road maps will inevitably provide a significant input if the UNFCCC road maps should they materialise. Three benchmark scenarios (REF, ACT and the BLUE) and the road map for wind power are used in this study.",
            "National contribution to global technology development": " Technology learning curves are applied to determine the cost development and performance improvement of the nascent energy technologies in the global model (IEA, 2008). 5 The technology learning curves may also be applied to estimate the corresponding cost of deployment, namely the learning investments (IEA, 2000). Wene (2008) defined the learning investments (LI) as: the resources needed to reduce the cost of the service from the challenging technology (C CH ) until the break-even cost (C BE ) with the incumbent technology, that is, until the challenger is cost efficient in the targeted mass market. The LI at time t needed for one unit, e.g., 1 GW may thus be expressed as LI CH \u00f0t\u00de \u00bc C CH \u00f0t\u00de-C BE \u00f0t\u00de \u00f01\u00de For the electricity generating technologies C BE (t) can be calculated from electricity price, P. The challenging technology then becomes competitive when P CH \u00bcP BE . As the targeted mass market generally is the global market, the break-even cost is a global parameter. It could in principle be estimated from a weighted average of regional electricity prices. For non-fuel using technologies, Eq. ( 1) can be simplified to express learning investments as the difference between actual investments cost for the challenger and the investment cost required making the challenger cost efficient in the targeted mass market. IEA (2008) (see footnote 5) provides Delphi estimates of such target investment costs, C IEA, for the challenger. These target costs may be used as time-independent estimates of break-even costs, C BE (t)\u00bcC IEA . For NGCC with CCS the C IEA for CCS is added to the NGCC cost to estimate a P BE . The cost efficiency of the incumbent technology is measured before the application of any policy measures, e.g., CO 2 incentive or subsidy for specific technologies. Such measures are considered means to persuade the market to provide the necessary learning investments. The learning investments are thus not affected by the global scenario or specific policy, e.g., CO 2 incentive, but the cost when a technology may be viewed by the market actors as commercially viable will be affected. The criterion used in this paper to evaluate national support to global technology development is the investment support (IS). It is a measure of accumulated financial support over and above the effect of a general CO 2 incentive until the technology in question becomes commercially viable in the global market with the global CO 2 incentive. A schematic illustration of the break-even cost in the ETP policy scenarios ACT and BLUE are shown in Fig. 1. The break-even cost is linked to the global parameter P BE . Nationally the break-even cost of a particular technology may be different because of national circumstances, e.g., favourable wind conditions. The general CO 2 incentive may therefore cause a contribution to IS when applied at the national level. I have applied the CO 2 incentives used in the IEA (2008) ACT and the BLUE scenarios at 50 US $ and 200 US $, respectively, for the A-and B-scenarios. Because of varying national circumstances, a direct transfer of global scenario break-even cost to a national system is not meaningful. Instead the national support to a nascent technology is considered to continue until the time period when the global market actors deem the technology commercially viable. The IEA (2008) has, in the technology road maps, provided scenario specific estimates of when the nascent technologies will become competitive in the mass market. In a model with 5-year periods the undiscounted IS is given by IS \u00bc X n \u00bc 1 X k m \u00bc 1 \u00f0C nm \u00c0C nk \u00deD nm\u00f02\u00de where C nm is the national unit cost of technology n in the period m when deployed [NOK/GW]; C nk is the national unit cost in the time period when technology n is deemed commercially viable in global markets [NOK/GW]; D nm is the amount of technology n deployed nationally in period; m \u00bck is the period when technology n has become commercially viable The time period, k, when a technology has become commercially viable with a given CO 2 incentive is provided in the ''technology road maps'' (IEA, 2008)6 and are listed in Table 1. IS captures two important aspects of national support for technology learning. It measures support over and above what is generally required by an agreed international CO 2 -incentive, administrated, e.g., through internationally tradable emission certificates. It also focuses strongly on the high cost of early deployment. As an indicator, it measures the economic contribution rather than based on physical units, e.g., MWh and thus serves as a complement to the EU indicator.",
            "Method": " The analysis of the national measures are done with a bottomup energy systems model of the Norwegian energy system (Markal) with input from a global model (ETP) and a national macroeconomic model (MSG6), see Fig.  Initially, macroeconomic parameters affecting national demand, e.g., economic growth and interest rate in the national models is made consistent with the global scenario. Scenario specific performance of the fossil fuel-and electricity import and export cost/prices are provided by the global model. Moreover, the global energy system model provides scenario specific input from the global energy technology market, e.g., technology cost trajectories reflecting the effect of technology learning. 7 The Markal model handles the energy system including export and import. Demand for energy from the non-energy sectors of the Norwegian economy is provided by the MSG6. The demand for energy differs slightly between the global scenarios because of the changes in the electricity price corresponding to the scenario specific technology cost trajectories and global fossil fuel prices. This influence of spillover on the demand is included for consistency and obtained through a soft-link with MSG6. Feedback on the demand for energy from the national measures discussed in this paper is not deemed significant and thus not included in the analysis. The soft-link is therefore not elaborated further here. The guiding assumption for the analysis is that a small open economy like Norway is a price taker in the global technology markets. From a policy perspective it is also of interest to look at a case where Norway uses its comparative advantages to take the global lead in developing OFW. Norway is well suited to take this lead because relevant knowledge is gained through development of technologies for offshore oil exploration, significant OFW research activity and large wind resources offshore. Moreover, the oil production is expected to go down and offshore wind exploitation may provide a possibility to continue technology development and export energy. Such a case is simulated by considering the Norwegian energy system as a strategic niche market for OFW. The assumption is then that within the chosen time horizon the OFW technology is only deployed in the Norwegian energy system. In this particular case, there is no spillover for OFW and the effect of technology learning on investment cost is determined by an endogenous variable in the optimizing routine. The effect of technology learning on the investment cost of the other technologies is still determined by the global model. The result will thus not only depend on the national circumstances but also on the choice of global scenario. Three global scenarios from the IEA (2008) are applied; the REF, ACT and BLUE scenarios. The national response to these boundary conditions, e.g., technology performance, makes up a set of references representing a potential range in global development. The national measures are subsequently added, and the results compared with the respective ''no additional policy'' scenarios. Existing national policies and measures, including the emission trading system applied to the industry and the CO 2 tax on offshore emission and transport fuels, are replaced by a general national tax incentive of 150 NOK/ton CO 2 . When the global CO 2 incentive is higher it replaces this value.",
            "The models": " The ETP model is a global bottom-up energy systems model with 15 regions. It belongs to the Markal family of models (Fishbone and Abilock, 1981). It represents the global energy economy including primary energy production, e.g., oil, and conversion to final energy carriers, e.g., gasoline and electricity. The model applies 5-year intervals and optimizes the global energy system up to 2050 (IEA, 2005). 8 The cost development of the nascent energy technologies are affected by technology learning (Gielen et al., 2004). The cost trajectories are determined on the basis of the accumulated global deployment and technology specific learning rates (IEA, 2008). 9 For large plant like technologies with very long lifetime, e.g., NGCC with CCS several vintages with declining cost are used rather than a technology learning curve approach. The ETP model framework includes an oil price module estimating the market prices of fossil fuel endogenously (IEA, 2005). 10  The Markal (Fishbone and Abilock, 1981) Norway model applies a system boundary for the Norwegian energy system following the national boundary, but including the offshore oil producing installations. The current electricity export/import capacity may be exchanged across the system boundary. The option to add additional export capacity is not included in this study. macroeconomic the Norwegian economy is a computable general equilibrium-multi-sector growth model version 6. It has a detailed description of the structures of economic policy, production and consumption sectors in the Norwegian economy. The model has 41 private and 8 governmental production activities (Heide et al., 2004).",
            "The global scenarios and national measures": " This section initially gives a brief description of the Norwegian energy system. Subsequently, the global and national scenarios are described.",
            "The Norwegian energy system": " The Norwegian energy system is embedded in a technological regime with hydroelectric power, and where electricity is dominating as energy carrier outside the transport and oil producing sectors. The main technology for electricity generation in Norway will continue to be large scale hydropower. Hydroelectric power generate about 118 TWh11 and supply almost all domestic electricity today, equal to about 65% of total energy consumption. The demand for energy service from buildings is about 23% of stationary energy service demand without electricity specific uses for appliances. While the demand for electricity across the scenarios is projected to increase 35% to about 160 TWh by 2050, its share of stationary energy use remains at the same level. The future potential for electricity production in large hydroelectric plants is limited. The only existing gas power plant was completed in 2006 but has not been in regular operation until very recently; however, because of the high price of natural gas. Coal and nuclear power plants are currently ruled out because of political decisions and not included in this study. Potential future conversion technologies include NGCC with CCS, small-, mini-and micro-hydropower, wind power onshore and offshore, salt wedge power and wave and tidal power. Norway has a relatively large wind power potential both onshore and offshore. There are substantial research programmes investigating two different OFW concepts and the first prototype was deployed in the summer 2009. The government has declared ambitious intentions to develop the CCS technology. Moreover, Norway has pioneered the technology for storage of carbon dioxide under the seabed in the North Sea. The Norwegian energy system is physically coupled to the Nordic and the European energy system through export/import cables. Electricity prices in Norway, though traded on the Nordic electricity exchange (Nor-Pool), are affected by the limitations in transmission capacity and thus lower on the annual average than the price in Sweden and Denmark. The price of electricity to consumers has historically been low. The export/import cable capacity, together with the establishment of a fully competitive market for electricity, has increased the ''import'' of European electricity prices. Still, the electricity price in the national market is sensitive to the spillover of technology learning from the global technology market.",
            "The global scenarios": " Among the global scenarios in the ETP study, the REF, the ACT Map and the BLUE Map are selected. They are stabilising the CO 2 emissions at today's level and reducing the CO 2 emissions 50% by 2050 respectively and represent a relatively optimistic view with respect to technology development. They include a disaggregated representation of both of the technologies most interesting for Norway, wind power and NGCC with CCS. Up to 2030 the REF scenario is calibrated to the World Energy Outlook 2007 (IEA, 2007). Increasing energy efficiency is identified as a key element in all the ETP scenarios (IEA, 2006(IEA, , 2008)). 12 In the global scenarios with increased CO 2 incentives the market price of oil is expected to reach a maximum around 2035 and then fall slightly up to 2050 (Gielen, 2006;IEA, 2008) ",
            "The national measures": " The national climate change-and energy security policy are, in addition to international commitments, influenced by EU-directives. There are two EU-directives of particular importance for this paper: the Energy Performance of Buildings Directive (EPBD) and the Promotion of the Use of Energy from Renewable Sources directive (ERSD). EU-directives are to a large extent descriptive and thus leave a great deal of freedom for each member state to adapt the implementation to national circumstances. The impact on energy use and the build environment will be highly variable as exemplified by a study of the implementation in the United Kingdom (Ekins and Lees, 2008). The EU 20/20/20 target aiming at increasing new renewable energy, reducing energy demand through energy efficiency and reducing CO 2 emissions all by 2020 are concrete, though the extrinsic national targets vary. The national policies applied here are made to illustrate the potential of the directives to push member states to contribute to technology deployment and identify potential conflicts between different national goals. Two different policy measures are included in this study: (1) subsidies for new renewable energy conversion technologies, renewable district heat generation (DH) and carbon capture and storage and (2) improved building code to reduce energy demand. The national policies are further described below. A nomenclature of the national scenarios is given in Table 2.",
            "Technology subsidies": " The technology subsidies are applied to wind mills, NGCC with CCS and DH using renewable energy carriers such as wood and waste. There are two levels, a low and a high level of subsidies. All the subsidized technologies receive a feed-in tariff applied to the energy carrier generated. Various initiatives to stimulate wind power development have been launched since the early 1980s, and in 2002 a national target of 3 TWh wind power by 2010 was established. An electricity feed-in subsidy of 50 NOK/MWh was introduced in 1998. Later, the subsidy was rather provided as a contribution to the initial investment (Buen, 2006). The level of subsidy chosen here is consistent with the levels of contribution suggested in Norway. The feed-in tariffs for the CCS technologies are consistent with an investment subsidy of 10% and 25%, respectively, of the cost of plant with CCS in the high and the low policy scenario. The high CCS subsidy level is about equivalent with the total cost of the CCS. This may seem high; however, the feed-in tariffs are of the same order of magnitude as for wind power. The wind power subsidy ends in 2025 and the CCS subsidy is applied up to the end of the period of analysis in 2050 because some of the CCS technologies are not available before 2030.",
            "National strategic niche market for offshore floating wind": " Using the ETP assumptions, 9% LR and high starting capacity, OFW is not selected in any of the scenarios. A subsidy targeting both wind power and NGCC with CCS increases the use of NGCC with CCS and reduce the use of other renewable energy technologies, e.g., near shore wind power. Providing the subsidy to wind power only with 9% LR, near shore wind and wave still dominates the nascent electricity generation technologies. The high subsidy ending in 2025 is thus still not sufficient to push OFW into the national energy system. The sensitivity of this result to extending the wind power subsidy period and increasing LR is investigated further. A shift the dominant nascent technology to OFW is observed when the high subsidy is extended until 2035. The OFW technology may thus still become competitive within the national strategic niche market with sufficient subsidies. On the other hand, assuming that OFW is a new technology, where 20% LR and 0.3 GW starting capacity is appropriate, OFW is deployed both and the AE-H scenarios. OFW is then barely deployed in 2015 followed by 3 GW in the next 5-year period.",
            "Improved building code": " This measure may be viewed as a national implementation of the EPBD directive. It is implemented as an efficiency improvement forced upon commercial and residential buildings. It is applied to new building construction and major refurbishments  (Wigenstad and Tyholdt, 2005).",
            "Effect of the national policies with technology learning": " The effect of the national policies on deployment, and thus indirectly on the system cost, 14 CO 2 emissions and level of electricity generation, is evaluated against a set of scenarios labelled ''no additional policy'' corresponding to each of the global scenarios. These scenarios include only the influence of technology learning. Subsequently, the effect of each of the measures is described. Finally, the result from the special case with ETL and no spillover for OFW is provided. An overview of the national scenario results in 2050 with spillover from global technology learning is listed in Table 3. The impact of global technology learning is substantial. In the R-scenario the CO 2 emissions are increasing from about 44 Mton in 2005 to about 60 Mton in 2050. New electricity generation capacity is then obtained from NGCC. The choice of new electricity generation technology in the ''no additional policy''-A-and B-scenarios, new electricity generating capacity is dominated by OFW as shown in the small graph inset in Fig. 3. The cost of OFW is heavily influenced by global technology learning. In the scenarios A and B, spillover of global technology learning facilitates both reduced national CO 2 emissions and lower system cost because utilizing the full electricity export capacity generates significant revenue. Both targeted national measures increase the system cost, though marginally. The influence of the measures on total annual CO 2 emissions is only significant in the R-scenario though still very small. The impact of the measures on total electricity generation is also small exempt from the building code.",
            "Subsidies for wind power and CCS": " In the R-L scenario the amount of onshore wind increases displacing gas power. In the R-H scenario onshore wind increases further and a small amount of OFW is introduced by 2020. By 2050; however, NGCC with CCS displaces about half of the wind power and reduces the share of small new hydropower, see Fig. 2. The subsidies thus significantly influence the technology composition, initially increasing deployment wind power and later shifting deployment to gas power with CCS because the subsidy for CCS is retained longer than for wind power. At first post combustion CCS is selected, while oxy fuel is added in 2045. Gas power with CCS then generates about12.5 TWh electricity by 2050. The A-L scenario exhibit similar behaviour except NGCC with CCS is introduced already in 2020 rather than part of the onshore wind power and OFW. With high subsidy, in the A-H scenario, onshore wind and significant OFW is introduced by 2020 displacing NGCC with CCS. Some new hydro is also displaced. Towards 2050 the subsidy for CCS in both the A-L and A-H scenarios displaces some of the OFW, but also the small amount of NGCC without CCS in the ''no additional policy'' scenario. In the B-L scenario wind power is increased in 2020. This outcome is accentuated in the B-H scenario where both onshore and OFW increases displacing more new hydro compared to the A-H scenario. The long term effect of the subsidies is modest. In 2050 a very small amount of NGCC with CCS is pushed into the energy system and then only in the B-H scenario, see Fig. 3. Across the national policy scenarios the subsidies alter the technology composition. They increase deployment of wind power in the early periods, displace NGCC and introduce NGCC with CCS particularly in the late periods. This is less pronounced in the B-scenarios because of the small remaining CO 2 emission becoming expensive with the high CO 2 incentive.",
            "Building code": " The building code has limited effect by 2020. In the A-B scenario the demand is significantly reduces demand for final energy in the long term. Because the export is constrained the electricity generation in 2050 is also reduced, see Table 3. This is predominantly through significantly reduced deployment of OFW. Both NGCC without CCS and with CCS is also reduced, but as these are small in the A scenario they are of minor significance, see Fig. 3. Together, total electricity generation in the A-B scenario is increasingly less than the A-scenario, at TWh in 2020 and 26 TWh less in 2050. The CO 2 emissions are also reduced in the R-B scenario because additional NGCC capacity is eliminated from the energy system. In the A-B and B-B scenarios, the effect of a more stringent building code on electricity generation is more pronounced as electricity increasingly is used as energy carrier for heating. The increase in system cost; however, is then about 100 billion NOK, equivalent to about 2% of total system cost up to 2050. The uncertainty in the cost of this measure should be investigated further. In particular, the potential impact from technology learning on a regional implementation of a ''passive house'' standard.",
            "National contribution to global technology learning": " This section analyses the national contribution to global technology development and thus responds to the second research question posed in the introduction. The special case, where a strategic national niche market simulates no spillover for OFW is also discussed.",
            "With spillover from global technology development": " All the national scenarios include the electricity generating technologies deployed in the corresponding global scenarios and thus contribute to global technology development. Nevertheless, there are differences in the technology composition of the future national energy system reflecting the national policies and thus affecting the national contribution to technology development. There are also large differences in the IS depending on the global scenario. Using IS as measure of the national contribution to global technology development is illustrated for the R, A, A-H, AE and AE-H scenarios below. In the R-scenario the national CO 2 incentive of 150 NOK/ton may initiate an IS. The IS is very small; however, because NGCC are selected to meet the increased electricity demand. The national subsidy, in the R-H scenario, shifts the investments to NGCC with CCS. Because it does not become commercially viable within the analysis period all of these investments contribute to IS. This increases the IS substantially, see Fig. 4. In the A scenario, with a CO 2 tax at the level of the global CO 2 incentive only, significant IS is provided. This may seem inconsistent with the definition of IS. Firstly, the decision to provide IS is internal to the optimizing routine and thus determined by the system cost for the whole analysis period. important are probably the favourable conditions for wind power in Norway compared to the global average. In 2015-2020 the IS is directed to onshore wind power. From 2025 when spillover of global technology learning reduces the investment cost, IS is directed to OFW. The large contribution to IS in 2025 compared to 2035 is because the difference between C nm and C nk is much greater in 2025. Introducing the subsidy, in the A-H scenario, the IS starts one period earlier. Moreover, the fraction of IS in 2015 is more than three times higher than without the subsidy. Likewise, the support provided for OFW also starts earlier. The contraction of IS for OFW to 2020 is because the model maximizes the benefit of the subsidy ending in 2025. The phase in of NGCC with CCS observed in the A-H scenario hardly influence the IS because it occurs after it becomes commercially viable in 2035. While the early contribution to IS is of particular interest, we may also note the fraction for the different technologies as well as the value of IS. The support for OFW is slightly less in the A-H scenario because of the export constraint. The fraction of IS for onshore wind power; however, is substantially higher. The IS in the A-H scenario is therefore higher than the A scenario. A similar pattern is also observed for the B-H scenario but with even more support for OFW by 2020. Because of the export constraint other electricity generation is intermittently displaced in 2020, mostly large hydro, see Fig. 3. Because large hydro is already commercially viable, displacing it by OFW increases the IS. The subsidy thus both increases the national contribution to early learning investments and it is provided earlier than in the A scenario with the CO 2 tax only. The building code reduces the national energy demand, particularly beyond 2020. The electricity generation from nascent energy technologies follows because of the export constraint. The building code may thus reduce the IS, particularly in the A scenario. In the B scenario electricity displaces to some extent other energy carriers and thus reduces the influence of the export constraint. Onshore wind deployment is delayed by 10 years in the A scenario. In the B scenario the introduction of OFW is delayed by 15 years until 2035. OFW has then moved beyond the global deployment phase and become competitive in the global energy technology market, see Table 1. Norway would then no longer contribute with IS. The national contribution to LI is also estimated for comparison, see inset table in Fig. 4. They are an order of magnitude larger than the IS. There are two reasons for this difference between IS and LI. Firstly, IS measures the national investment support relative to the break-even in markets with the general CO 2 incentive while LI measures total additional support relative to a break-even cost in the Baseline without any general CO 2 incentive, see Fig. 1. Secondly, LI covers a longer time period than IS because it will take longer time for the technology to reach the Baseline. In some cases the technologies may not reach the baseline break-even cost (C BE ) within the analysis period. Moreover, NGCC with CCS may only reach the C BE based on a fossil plant without CCS if integrated in a manner such that externalities make it more cost efficient. The difference between the LI and IS increases when there is a more ambitious global CO 2 reduction target resulting in a higher CO 2 incentive, i.e., the A and B scenario. This is because the IS only credit early deployment and because increased deployment globally makes the technologies become competitive earlier. The building code also reduce the national contribution to LI, see inset in Fig. 3. This is predominantly because the deployment of OFW is significantly reduced as demand is lower and the export is constrained. In the R-scenario the national contribution to LI is increased substantially by national policy, while in the A-scenario it is merely affected. This is because the national energy system aligns itself with the global technology path in the A scenario as a result of the pull from spillover of global technology learning.",
            "National strategic niche market": " Finally, it may be of interest to investigate the IS if Norwegian market actors believe they can obtain a LR of 20% for OFW and moves ahead alone. Because no others deploy this technology there is thus is no spillover. National deployment is now a prerequisite to obtain the cost reduction for OFW. The decision to provide LI for OFW is internal to the optimizing routine. As described in 5.3, only with a LR of 20% the technology is deployed. The case investigated here is the AE and AE-H scenarios with 20% LR for OFW and spillover of technology learning for the other technologies. We may then no longer use the road map (IEA, 2008) to determine the time period (k) when the technology becomes commercially viable in the global market. While the global breakeven electricity price P BE may not change very much because the total global deployment of OFW is relatively small, the time period (k) when OFW becomes competitive may be delayed because of less deployment. However, with the higher LR less deployment is required to reduce the cost and thus for the technology to become competitive. From inspection of the unit cost curves in Fig. 5 applying the cost in 2030 for C nk seems to be a reasonable assumption.   In the AE-H scenario, the effect of the subsidy is similar to the response with spillover of global technology learning. The early investment, in OFW in particular, increases, see Fig. 5. The level of IS is more than double than with spillover because the early deployment costs for OFW is higher and total national deployment has increased slightly. A A-H R A A-H R A A-H R A A-H R A A-H R A A-H R A A-H R A A-H2010 In the AE and AE-H scenario, the installed capacity of OFW by 2050 is 15-18 GW. The building code combined with the electricity export constraint again causes learning investments to be insufficient to make OFW cost efficient and it is thus not deployed within the analysis period. The early cost reductions exhibited for OFW without the building code, combined with delayed introduction of the building code may; however, initiate other strategic niche markets. While investigating this is beyond the scope of this paper, further studies with two or more strategic niche markets interacting is recommended.",
            "Conclusion": " Introducing a targeted national subsidy for the nascent energy technologies onshore-, near shore-and floating offshore wind power and NGCC with CCS has only marginal influence on the Norwegian CO 2 emissions by 2050. Norway's contribution to early deployment of the nascent energy technologies; however, increases significantly. Both onshore wind power and offshore floating wind power is, under the global Energy Technology Perspectives scenarios ACT and BLUE, deployed earlier with the subsidy than with spillover of global technology learning only. Moreover, the suggested indicator for national contribution to global technology development, investment support, IS, increases with the subsidy. The indicator measures the contribution of national policies to early deployment, over and above the effect of a globally agreed CO 2 incentive and spillover of technology learning from the global market. Realization of the cost reductions in the Energy Technology Perspectives scenarios, through technology learning, depends on national deployment. The indicator, measuring the national contribution to global technology development in monetary unit, facilitates crediting the high cost of early learning investments. It may complement the indicator in energy units used by the EU to monitor the member states compliance with, e.g., the 20/20/20 target. The value of IS depends both on the global scenario and the targeted national measures. A special case with no spillover of technology learning is analysed for offshore floating wind. Substantial subsidy, or a learning rate of 20%, is then required to make deployment of this technology cost efficient for the analysis period 2005-2050. Applying the 20% learning rate, the investment support more than doubles compared to the case with spillover. Adding a national subsidy further increase the investment support and shifts it to an earlier time period. Overall, the investment support exhibits the same behaviour with, and without, spillover. Coordinated action facilitates spillover of technology learning and reduces the need for national investment support and the risks connected to the obtainable technology learning rate. The special case with no spillover for offshore floating wind may also exhibit the situation where a country who is the first to deploy the technology. The contribution by a country who takes on the role of ''first mover'' may then be acknowledged through crediting the high value of the national investment compared to the case with spillover. Implementation of an improved building code reduces demand for energy and may reduce Norway's contribution to global technology development unless sufficient electricity export capacity is assured. Without spillover the combined effect of the electricity export constraint and the building code prevents offshore floating wind from becoming commercially viable within the analysis period."
        }
    },
    "10.1016/j.enpol.2008.04.025": {
        "file_name": "43 Refueling availability for alternative fuel vehicle markets",
        "title": "Refueling availability for alternative fuel vehicle markets: Sufficient urban station coverage",
        "abstract": "Alternative fuel vehicles can play an important role in addressing the challenges of climate change, energy security, urban air pollution and the continued growth in demand for transportation services. The successful commercialization of alternative fuels for vehicles is contingent upon a number of factors, including vehicle cost and performance. Among fuel infrastructure issues, adequate refueling availability is one of the most fundamental to successful commercialization. A commonly cited source reports 164,300 refueling stations in operation nationwide. However, from the perspective of refueling availability, this nationwide count tends to overstate the number of stations required to support the widespread deployment of alternative fuel vehicles. In terms of spatial distribution, the existing gasoline station networks in many urban areas are more than sufficient. We characterize a sufficient level of urban coverage based upon a subset of cities served by relatively low-density station networks, and estimate that some 51,000 urban stations would be required to provide this sufficient level of coverage to all major urban areas, 33 percent less than our estimate of total urban stations. This improved characterization will be useful for engineering, economic and policy analyses.",
        "label": "Quantitative",
        "text": {
            "Introduction": " Transportation energy systems face a number of long-term challenges, including climate change, urban air pollution, energy security, limited inexpensive oil resources and continued growth in demand for transportation services. In the light-duty vehicle sector, vehicle fuel economy improvements are an effective means of addressing each of these challenges (DeCicco et al., 2001;Greene et al., 2005;NAS, 2002). However, the benefits of efficiency improvements will prove limited in the long term if future demand projections are realized (EIA, 2006). Mode shifting and smart growth can reduce automobile dependency, but may have limited potential in countries such as the United States where personal vehicles are strongly entrenched. Given these limitations and future demand projections, alternative fuels such as liquid biofuels, synfuels, hydrogen and electricity must play a fundamental role in achieving future social, environmental and economic goals (Birky et al., 2001;Greene and Schafer, 2003;WBCSD, 2001). The lack of retail stations is one of the major barriers to the adoption of alternative fuel vehicles (AFVs), especially dedicated AFVs that operate on a single fuel. The present analysis improves our understanding of this barrier by estimating how many alternative fuel stations would be needed to satisfy the refueling needs of the general population living in urban areas. Analysis of sufficient rural coverage is more challenging, and is not addressed directly in this study. Adequate refueling availability is fundamental to the commercialization of AFVs. Owners of flex-fuel or bi-fuel vehicles are more likely to use alternative fuels if retail stations are prevalent. 1  And the adoption of dedicated AFVs, which rely exclusively on an alternative fuel, is wholly contingent on refueling availability-consumers will not purchase vehicles that they cannot refuel, regardless of the cost or performance of vehicle technology. Moreover, refueling availability may be an important cost factor for some fuels. For liquid fuels with energy densities similar to gasoline, retail costs will likely comprise a relatively small fraction of the total fuel cost. For lower energy density fuels, and for hydrogen in particular, retail costs may be a significant fraction of total fuel costs due to the higher capital costs of storage and handling equipment, as well as production costs for stations that produce hydrogen onsite (H2A, 2005;NAS, 2004). An improved characterization of refueling availability can contribute to ongoing and future efforts to commercialize AFVs. The existing network of gasoline stations may offer some insights into the refueling availability requirements of future AFVs. Unfortunately, reliable, detailed and consistent nationwide data on the coverage provided by this network does not exist. National and regional perspectives on the issue of refueling availability therefore remain obscure, though some micro-scale studies have offered important insights (Greene, 1998;Nicholas et al., 2004). Comprehensive nationwide data are reported on a state basis through the annual survey conducted by National Petroleum News (NPN) (NPN, 2006). However, as discussed in Section 3, these data are inconsistent among states, do not distinguish between urban and rural stations, and are best interpreted as an overestimate of the actual number of public gasoline stations. The present analysis makes two contributions to our understanding of refueling availability. First, we build on existing data sources to estimate how many gasoline stations serve urban areas and how many serve rural areas. Second, we demonstrate that the existing station network provides more than adequate coverage in many urban areas, and we propose a sufficient level of coverage that meets the refueling needs of the general population living in urban areas. This sufficient level of station coverage is based upon a subset of cities served by relatively low density station networks, and is expressed as a function of urban area population density, with higher density cities requiring a higher density of alternative fuel stations. Moreover, this characterization provides a context for interpreting previous studies that estimate a necessary level of coverage to support early AFV markets-the relatively sparse coverage that would satisfy the refueling needs of AFV early adopters. Of the approximately 175,000 gasoline stations reported by NPN in 2000, we estimate that some 75,800 were located in urban areas, and that 51,000 of these stations (67 percent) would provide a sufficient level of urban refueling availability while maintaining some degree of retail competition. This characterization of urban and rural refueling station networks will prove useful for engineering, economic and policy analyses of future efforts to introduce AFVs. This paper is presented in six sections. Following this introduction, Section 2 reviews the issue of refueling availability with respect to AFVs. Section 3 reviews the 100-year history of gasoline retailing and offers a perspective on future trends. Section 4 describes our estimate of the total number of urban and rural refueling stations, and presents various comparisons to verify that our parametric representations of stations are consistent with related transportation and demographic trends. Section 5 expands on this analysis by proposing a sufficient level of refueling availability in urban areas, and Section 6 provides a brief summary.",
            "Refueling availability": " Many attempts have been made to promote alternative fuels, but success stories, such as Brazil and Argentina (Fracchia, 2000;Goldemberg et al., 2004), tend to be exceptions among a longer list of failures. Public support for refueling stations alone does not assure success, as has been demonstrated with compressed natural gas vehicles in New Zealand and Canada, and methanol vehicles in California (Flynn, 2002;MacDonald, 2005;Yeh, 2007). Several studies (Leiby and Rubin, 2004;Melaina, 2002;Sperling, 1988) have discussed the chicken-and-egg problem associated with dedicated AFVs, which involves a bind between three major stakeholders: consumers reluctant to purchase vehicles that cannot be refueled, vehicle manufacturers reluctant to produce vehicles that will not be purchased, and fuel providers reluctant to provide fuels for vehicles that do not exist. Given the stasis and market failures reinforced by this three-way bind, and considering the public benefits of many alternative fuels, government agencies have a justifiable role as a fourth critical stakeholder. Government support for the adoption of alternative fuels may involve a wide range of options, including financial incentives, mandates, information dissemination, development of codes and standards, labeling and certification, and stakeholder coordination. Support for early alternative fuel stations is often discussed in terms of strategic niche management, in which AFVs are first introduced into controlled and centrally refueled fleets, such as government, utility or commercial fleets (Kemp et al., 1998). This strategy is a component of AFV support provided through the 1992 Energy Policy Act and the 1990 Clean Air Act, and it underlies the structure of the Clean Cities program (DOE, 2007). Though these efforts are ongoing, the fleet approach has met with limited success with light-duty vehicles in the United States, and the strategy may prove to be limited due to a variety of factors (GAO, 2000;McNutt and Rogers, 2004;Nesbitt and Sperling, 1998). For example, refueling facilities serving centrally fueled fleets are often not available to the public and many centrally refueled fleet vehicles also rely on public refueling stations. Though niche market programs can result in technological learning and improved stakeholder communication and coordination, they are not sufficient to bring about the widespread commercialization of AFVs. A more ambitious strategy will be required to move beyond niche markets and overcome the chicken-and-egg challenge. At some point in time, a necessary level of station coverage must be established to satisfy the refueling needs of a large fraction of potential AFV early adopters. As a response to the chicken-andegg problem, this strategy is ambitious due to the timing and scale of the endeavor: a large number of stations will be needed, they must be dispersed across relatively large geographic regions and they must be operational before AFVs are successfully massproduced and sold. The coupled relationship between the automobile manufacturing and transportation fuels industries is explicitly recognized by this strategy: the extent of the refueling coverage achieved must enable demand for vehicles proportional to the economies of scale needed to reduce AFV production costs. In the case of hydrogen vehicles and infrastructure, this ''initiation'' strategy has been examined by researchers (Melaina, 2005;Melaina and Ross, 2000;Wurster, 2002), advocated by industry (Gross et al., 2007;McCormick, 2003), and adopted (at least in part, and conceptually) by government agencies (CEPA, 2005;FDEP, 2007;HyNor, 2007). The capital costs and investment risks associated with this strategy would be large. However, the risks faced by fuel providers would be smaller in scale than the financial and technological risks faced by auto makers in deploying large volumes and multiple models of advanced AFVs, such as hydrogen fuel cell vehicles. As discussed elsewhere, fuel costs are a relatively small component of total vehicle lifecycle costs (Ogden et al., 2004). Establishing a necessary level of refueling availability is one of the many inputs required to support the AFV technology innovation process (Norberg-Bohm, 2002;PCAST, 1999;Popper and Wagner, 2002). The financial risks associated with installing early alternative fuel station networks will be proportional to the level of refueling availability needed to support early AFV markets. This necessary level of availability cannot be quantified precisely, but it can be estimated. Some studies have characterized a necessary level of refueling availability in terms of the percentage of existing gasoline stations in a given area. In a study of consumer behavior and expectations, Kurani surveyed vehicle owners during the introduction of diesel vehicles in California and natural gas vehicles in New Zealand (Kurani, 1992;Sperling and Kurani, 1987). Analysis of initial survey results suggested that concerns over refueling availability diminished rapidly after approximately 15 percent of existing stations provided the alternative fuel, and subsequent analysis suggested that the level was closer to 10 percent (Nicholas et al., 2004). A consumer survey by Greene (1998) was relatively consistent with this result, concluding that the cost of inconvenience to consumers would decrease rapidly if approximately 10-25 percent of existing stations provided an alternative fuel. An inherent shortcoming of these types of percentage estimates is that the total number of gasoline stations varies between cities and regions. As discussed in Section 4, station densities (i.e., stations per square mile) may vary by a factor of two between urban areas of similar size and population density. Due to the risks of stranding capital in early refueling station networks, a more robust methodology for estimating necessary coverage levels is desirable. Estimates of a necessary level of refueling availability have also been made on an absolute basis. Melaina (2003) developed two simple estimation approaches for urban areas based on land area and miles of major roads, concluding that coverage at 18-25 square miles per station would require approximately 1600-4500 stations, and major urban road lengths of 10-20 miles per station would require approximately 3100-6200 stations. The first land area approach treats all urban areas similarly, while the second approach accounts for road network structure and may therefore provide a better representation of required coverage. A more recent and detailed study by Melendez and Milbrandt (2006) found similar results. Nicholas et al. ( 2004) employed a traffic model to optimize station locations by minimizing the average consumer travel time to the nearest station. Their analysis suggests that an average driving time of 3 min would be achieved if 48 stations in the Sacramento region (roughly 16 percent of existing stations) provided an alternative fuel. In subsequent analyses of multiple urban areas, equivalent levels of convenience were achieved at different percentages of stations: higher population density cities required a lower percentage of stations to ensure the same average driving time (Nicholas and Ogden, 2006). Reports from E4Tech and LBST estimate that less than 5000 stations could provide adequate coverage for early markets in Europe (E4Tech, 2005;Wurster, 2002). Refinements to these types of necessary coverage estimates will allow for more effective policy support for AFVs, and will clarify the market opportunities and investment risks faced by businesses pursuing AFV technologies. However, the broader issue of refueling availability remains poorly understood, partly due to ambiguity surrounding the coverage being provided by the existing network of gasoline stations. The following section provides a historical review of gasoline retailing, which serves as a context for the improved characterizations of the existing network presented in Sections 4 and 5.",
            "A brief history of gasoline retailing": " The history of gasoline retailing can provide a context for estimates of future levels of refueling availability. Fig. 1 presents various metrics spanning the 100-year history of gasoline retailing, including various types of station counts, total registered light-duty vehicles, and total gasoline consumption. As indicated, in 1929, some 20 years after the introduction of the Ford Model T, the number of registered vehicles had reached 24.5 million. This corresponded to one car for every five persons, compared to roughly four cars for every five persons today. Fig. 1 also indicates fuel consumption by motor vehicles, primarily gasoline, which increased in step with the number of registered vehicles until the first energy crisis in 1973. Several subsequent price spikes resulted in fluctuations in gasoline consumption, but both registered vehicles and gasoline consumption have followed an upward trend since WWII. Projections from the Energy Information Administration suggest that this growth will continue, though fuel economy improvements from the Energy Independence and Security Act of 2007 will temporarily dampen the growth rate of fuel consumed by light-duty vehicles (EIA, 2008). Fig. 1 also indicates various estimates of the total number of refueling locations between 1900 and 2006. Station growth trends have not followed registered vehicle or fuel use trends. On the contrary, they have had a nearly inverse relationship over most of the last century, and especially since the early 1970s. Data points for this period of time are taken from a variety of sources, some of which are inconsistent in scope and over time, but each being a nationwide estimate of the total number of establishments providing motor vehicle fuels. Two types of gasoline refueling establishments are indicated before 1950: stations and outlets. In general, ''station'' data are taken from relatively consistent census records and represent establishments that primarily provide gasoline to vehicles but may also provide some additional services. By comparison, ''outlet'' data are taken from a broader collection of sources and represent any establishment or location providing gasoline, perhaps as just one of multiple services. Data adhering to this definition of outlets could not be found after 1946 (though NPN data from some states may comply with this definition, as discussed below). The outlet numbers, which are inclusive of the census station data, provide insight into the degree of refueling availability provided for early vehicle markets: approximately 100,000 refueling locations had been established by the early 1920s and more than 300,000 were in operation by the early 1930s. As discussed elsewhere (Melaina, 2007), these early outlets proliferated rapidly and included a variety of gasoline refueling methods, including cans sold in general stores, barrels located at repair garages, handcarts operated by roaming vendors, and curb pumps located alongside urban streets and in front of rural general stores. These innovative ''non-station'' refueling methods ensured a sufficient level of refueling availability for early adopters of gasoline vehicles. Over time they were replaced by high-volume refueling stations. According to census records, station numbers grew slowly but steadily between the end of WWII and the first energy crisis in 1973. As indicated in Fig. 1, the number of census stations peaked at approximately 226,000 stations in 1972, dropped rapidly between 1973 and 1982, and have continued to decline at a slower rate up to the present. This atrophy occurred despite continued growth in registered vehicles and fuel consumption. This trend probably applies to all gasoline stations, but the census station counts reported after WWII are underestimates of the total number of gasoline stations due to the census definition of establishments that qualify as gasoline stations. The definition has varied over time, but recent counts only include establishments that attain more than 50 percent of total revenue from gasoline sales. This census criteria tends to exclude busy convenience stores and does not capture the recent rise in stations co-located with big box stores (EIA, 2001).",
            "Urban and rural fueling stations": " The distinction between urban and rural refueling availability is pertinent for the deployment of AFVs that will likely be first introduced in large volumes in urban markets. Concentrating AFV deployment in urban areas would reduce the infrastructure capital needed to provide necessary refueling availability, and the limited range of some early vehicle models may make them less appealing in rural markets (e.g., hydrogen or electric vehicles). Refueling availability between major urban areas can be achieved by installing stations along interstates and other major arterial corridors (Melaina, 2003;Melendez and Milbrandt, 2005). After vehicle markets have been established in urban areas, and increased inter-urban travel justifies greater refueling coverage between urban areas, rural populations near interstates may begin to adopt more AFVs. Estimates of investments required to establish early station networks can therefore benefit from a more detailed characterization of stations in urban and rural areas. There are various sources of data on US gasoline station counts, but none provide an accurate distinction between urban and rural station networks. Census records report station numbers within Metropolitan Statistical Areas (MSA), but these counts are underestimates, as discussed above, and MSA boundaries are based upon county boundaries that often include rural areas, especially in the west. Surveys of particular urban markets are available from various market research organizations, such as MPSI, OPIS, and the Lundberg Survey (Lundberg, 2007;MPSI, 2007;OPIS, 2007). However, these sources typically focus on a subset of competitive urban markets and rarely survey rural markets. The volunteerbased Gas Price Watch has accrued an impressive listing of both urban and rural stations, providing price data on 128,500 stations in March of 2008, 22 percent less than the 2007 NPN survey result. By comparison, the 2002 Economic Census reported 120,902 stations, 30 percent less than the NPN survey result for the same year. Unlike more detailed surveys, the NPN survey reports aggregate station counts by state, making no distinction between urban and rural stations. In the present analysis, urban area survey results acquired from MPSI are used to estimate the number of stations in all major US urban areas. The resulting urban station counts are then subtracted from NPN state counts to provide an estimate of rural stations by state. Given this approach, our estimates of rural station counts are overestimates to the same extent to which NPN survey results are overestimates of state-level station counts. Despite this tendency, and the inevitable incongruence associated with combining two distinct data sources, the resulting rural station estimates are reasonably consistent when compared with various state metrics. A unique definition of urban area has been developed to accommodate the MPSI survey boundaries and to provide a consistent representation of urban and rural areas. On a conceptual level, refueling availability can be discussed in terms of a unified urban area served by a continuous network of fueling stations. Unified urban areas are identified here as urban basins, suggesting a boundary within which there is a high density of refueling activity and outside of which refueling activity diminishes significantly. Urban basins are defined with respect to population density and on a census tract basis. Urban basins include contiguous census tracts with population densities greater than 250 persons per square mile (ppsm), resulting in 438 urban basins in the lower 48 states, all containing at least 30,000 persons. These urban basins are comparable to the 447 Urban Areas in the lower 48 states identified by the year 2000 census as contiguous densely populated areas containing at least 50,000 persons (US Census Bureau, 2002). The discrepancy between the number of urban basins and census Urban Areas is due to two factors: (1) a reduction resulting from adjacent Urban Areas being combined into single urban basins, and (2) an increase resulting from additional urban basins meeting the 250 ppsm criteria and falling within the MPSI survey boundaries (as discussed below). The net effect is a reduction in total urban areas, with nine fewer urban basins than census Urban Areas. Urban basins tend to have total populations similar to corresponding Urban Areas but are more inclusive in terms of land area. In Table 1 urban basin characteristics are compared with census Metropolitan Statistical Areas and census Urban Areas, as defined by the 2000 census. The criteria used to characterize urban basins are relatively consistent with the spatial distribution of the MPSI data. The MPSI survey results include the latitude and longitude coordinates for all gasoline stations located within the boundaries specific to each survey. Of the 438 urban basins discussed above, 103 are located within the MPSI boundaries of various surveys conducted between 1998 and 2002. These 103 urban basins are referred to as specified basins. These basins are a subset of the total number of urban basins, and MPSI survey results indicate the total number of stations located in each of the 103 specified basins. Gasoline stations reported by the MPSI surveys but not located within specified basins (i.e., rural stations) are excluded from the analysis. The 103 specified basins are representative of large US urban areas in that they include a range of urban area sizes and population densities and are located in multiple geographic regions. Fig. 2 demonstrates that specified basins are well distributed across the range of urban basin populations and population densities. Table 2 demonstrates the geographic distribution of specified basins, indicating the percent of urban basins and urban basin populations within five regions: Pacific, Mountain, Midwest, South, and Northeast.2 Specified basins account for 16-37 percent of all urban basins in each region, and 50-79 percent of the total urban population in each region. In total, specified basins include 24 percent of all urban basins and 62 percent of the total US urban population. Fig. 3 shows the number of stations in each of the 103 specified urban basins as a function of population. 3 The dotted line is a linear fit to all specified urban basins and is shown for reference. In general, there tend to be fewer stations in Pacific cities than in other cities with similar populations, and there tend to be more stations in Southern cities than in other cities with similar populations. The number of stations in cities within the Mountain, Midwest, and Northeast regions are closer to the linear fit to all cities. Likely explanations for this variation include the higher population density of cities in the Pacific versus the South, higher market entry barriers due to stricter regulations, and perhaps the more recent development of urban areas in the Pacific region. Additional analysis would be required to determine the influence of these and other factors. If we assume that the correlations between station numbers and specific urban basin populations are representative of all major urban areas in each region, we can estimate the number of stations contained within unspecified urban basins. The following power function has been fit to specified basin data for each region: N \u00bc aP b where the number of stations (N) is a function of the total population in a given urban area (P). The a and b parameters and R 2 values shown in Table 2 represent the correlation between station numbers and specified basin populations within each region. Using these parameters, we estimate the number of  stations contained in unspecified basins within each of the five regions. The number of urban stations is then subtracted from the total number of stations reported for each state in the year 2000 NPN survey, resulting in an estimate of rural stations by state. Our estimates of rural stations therefore tend to be overestimates to the same degree that NPN state data are overestimates, while the urban are derived from more consistent and precise data from MPSI. Additional details regarding the urban basin data analysis are provided in Melaina and Bremson (2008).",
            "Sufficient urban station coverage": " From the perspective of spatial coverage, the number of gasoline stations serving many urban areas is more than sufficient. The density of stations in a particular urban network is dependent upon a number of factors, such as market entry barriers, profit margins, codes and standards, traffic patterns and local retail competition dynamics. These issues have been discussed in economic studies (e.g., Barron et al., 2004;Shepard, 1993) and industry profiles (EIA, 2001). There are consumer advantages to a high density of fueling stations, including greater convenience and price reductions due to increased competition, but these advantages will not necessarily push emerging alternative fuel station densities as high as the gasoline station densities observed today. Examples of factors that may hold alternative fuel station networks at lower densities include higher market entry barriers due to high capital costs (especially for hydrogen stations), increased real estate costs, the trend toward larger stations, urban sprawl and reduced searching times due to onboard vehicle navigation systems. Factors that may require higher station densities include limited vehicle range and any redundancy needed to compensate for more frequent station maintenance or equipment failures. Estimating stable levels of future gasoline or alternative fuel station densities is beyond the scope of this paper. However, the present analysis can be drawn upon to characterize an existing level of sufficient refueling availability by examining variations in urban station densities. A sufficient level of coverage can be quantified based upon a subset of specified basins with relatively sparse networks of gasoline stations. Fig. 5 shows specified basin station densities and population densities, and indicates six population categories (in millions). Most specified basins have population densities between 1000 and 3000 ppsm and station densities between 0.5 and 1.0 stations per square mile (spsm). Station densities tend to increase with population density and vary significantly among specified basins with similar population densities. In Fig. 5, the solid line represents a fit to all specified basins and the dashed line is the proposed lower bound for a sufficient level of refueling availability. The lower bound is a fit to a selected number of specified basins with relatively low station densities. Most of these specified basins are located in the Pacific region, as suggested by Fig. 3, but several major urban areas outside the Pacific region also have densities near the lower bound, including Chicago, IL, Washington, DC, Rochester, NY, and the New York-Newark urban area. This station density equation represents the number of alternative fuel stations needed to provide a sufficient level of refueling availability for the general population in a given urban area, while still allowing for some degree of retail competition. Providing this level of refueling availability to all urban basins would require about 51,000 urban stations, 33 percent less than the total number of urban stations estimated above and indicated in Table 3. With projected urban population growth (and sprawl), a greater number of stations may be required to provide the same level of coverage to future urban areas. With regard to the level of refueling availability required to support the widespread commercialization of AFVs, this sufficient level of coverage is a more consistent and appropriate basis than the total number of existing urban gasoline stations. These results can also be interpreted in terms of consumer travel distance or driving time. stations per square mile would be required to satisfy the sufficient station coverage indicated in Fig. 5. With this level of coverage, an urban driver would never be further than 1.4 miles from a pair of refueling stations, and would usually be about 1.1 miles from a pair of stations. Traveling an average of 25 mph, and assuming travel through a grid, this is a maximum driving time of about 4 min and a typical driving time of about 3.3 min. This level of convenience exceeds the consumer preferences suggested for early markets in previous studies (Greene, 1998;Nicholas et al., 2004;Welch, 2007) and allows for some degree of station clustering or retail competition. It may be argued that existing station networks represent a spatially efficient distribution of stations due to the highly competitive nature of retail station markets. However, Fig. 5 demonstrates that spatially efficient coverage is not a consistent outcome of retail market dynamics. Existing gasoline and diesel stations, and especially stations that are also convenience stores, or ''c-stores'', compete in markets for a variety of products and services, not just convenient refueling availability. Many c-stores receive substantial support from non-fuel product sales, including sales of snacks, beverages, and cigarettes (NACS, 2003). In addition, some urban areas may experience larger than normal seasonal fluctuations in fuel demand due to driving between cities. Existing station densities may be an economically efficient response to these broader markets, but in many urban areas they are excessive with regard to geographic coverage. The subset of urban areas with station densities near the sufficient coverage threshold indicated in Fig. 5 involve some degree of retail competition, but they do so with a more spatially efficient distribution of stations. In theory, urban networks monopolized by a single firm and selling only motor fuel could remain profitable with even lower station densities. The degree to which competitive dynamics within future alternative fuel retail markets may encourage or suppress investment in higher density networks remains to be seen, and will depend in part upon the business models supporting future station networks.",
            "Summary": " A lack of refueling availability at the retail level is a fundamental barrier to the adoption of alternative fuel vehicles (AFVs). This problem is more pronounced for dedicated vehicles that operate exclusively on a single fuel, such as hydrogen or electric vehicles, but it is also important for flex-fuel and bi-fuel vehicles that can operate on more than one fuel. A commonly cited source, NPN, reports that there are currently approximately 164,300 refueling stations in operation in the United States. However, our analysis of station counts on a city-by-city basis suggests that this aggregate value is a poor frame of reference for understanding the issue of refueling availability with respect to the commercialization of AFVs. This study offers an improved characterization of the refueling availability provided by existing gasoline station networks. Previous studies have examined refueling availability on the city scale, and have focused on a necessary level of coverage needed to support early AFV markets. In contrast, this study outlines an improved national and regional perspective by estimating the following: (1) the number of gasoline stations serving urban areas and the number serving rural areas, and (2) a sufficient level of station coverage that meets the refueling needs of the general population in urban areas, while still allowing for some degree of retail competition. Station counts have declined over the past 30 years of gasoline retailing, and recent trends towards fewer and larger stations suggest that today's network may be more spatially efficient than previous networks. Forecasting future station counts or coverage is challenging due to a general lack of detailed data, and the variety of factors influencing market entry and exit dynamics. This analysis therefore focuses on station counts and coverage provided in the year 2000. Survey data from a market analysis company, MPSI, are analyzed for 103 representative urban areas. These data are relied upon to estimate the number of stations in 335 additional urban areas, with all urban areas summing to 191 million persons, or 68 percent of the total population in 2000. These urban area station counts are then subtracted from NPN state-level data to estimate the number of rural stations by state. Of the approximately 175,000 gasoline stations reported by NPN in 2000, we estimate that 75,800 stations (43 percent) served urban areas and 99,200 stations (57 percent) served rural areas. This distinction is relevant for AFVs that are likely to be first introduced in urban markets. An examination of station coverage on a city-by-city basis reveals that some cities are being provided with more than sufficient refueling availability-station densities (stations per square mile) can vary by a factor of two between cities of similar size and population density. This suggests that station markets do not consistently result in spatially efficient coverage, though they may be an economically efficient response to broader markets such as non-fuel products and services provided by convenience stores. Given this observation, we propose a sufficient level of urban station coverage based upon a subset of urban areas served by relatively sparse station networks. This sufficient coverage is expressed in terms of station density and as a function of urban area population density. We conclude that some 51,000 stations could provide a sufficient level of refueling availability for the general public in urban areas, while still allowing for some degree of retail competition. This sufficient coverage estimate for urban areas offers an improved representation of refueling availability needs for AFVs. It can serve as a conceptual upper bound that alternative fuel station networks will evolve towards as AFVs are commercialized, and can therefore contribute to engineering, economic, and policy analyses of alternative fuels. These results improve on the aggregate nationwide station counts that typically serve as a frame of reference for discussions of adequate refueling availability for AFVs."
        }
    },
    "10.1016/j.enpol.2012.01.049": {
        "file_name": "50 The driving forces of change in energy-related CO2 emissions in Ireland",
        "title": "The driving forces of change in energy-related CO 2 emissions in Ireland: A multi-sectoral decomposition from 1990 to 2007",
        "abstract": "Ireland recorded significant growth in energy-related carbon emissions from 1990 to 2007 as the country underwent rapid economic development. Using the LMDI decomposition analysis method, this paper aims to identify and analyse the driving forces of CO2\u00a0emissions in eleven final energy consuming sectors. This multi-sectoral analysis is based on four economic sectors, the residential sector and gives a detailed representation of transport in keeping with UNFCCC recommendations. Scale, structure and intensity effects are explored and substantial heterogeneity in sectoral performance is observed. Scale growth in economic and transport activity was considerable. Some improvements in energy intensity were recorded in the economic sectors. In transport, increases in intensity contributed to a significant increase in emissions, while energy intensity decreased in the residential sector. The declining emissions coefficient of electricity was important in limiting emissions but renewable energy has been slow to penetrate the demand side. The results have relevance in considering development paths and can aid in identifying policy measures required to address the key driving forces of emissions in the sectors. The rapid increase in transport emissions in particular raises concerns of future lock-in to a higher emissions trajectory.",
        "label": "Quantitative",
        "text": {
            "Introduction": " Energy and CO 2 emissions are integral to issues of development in all nations and have become a significant policy challenge in the Republic of Ireland. Through the Kyoto Protocol and the European Union (EU) Burden Sharing Agreement (Council Decision 2002/358/EC) the target agreed for Ireland was to limit the increase in greenhouse gas (GHG) emissions to \u00fe13% of 1990 levels by 2008-2012. This coincided with a period of rapid economic development, during which infrastructure was expanded, lifestyles changed and energy demand and CO 2 emissions increased substantially. In 2007, total GHG emissions in Ireland were 25% higher than the 1990 level (McGettigan et al., 2009). Energy-related CO 2 emissions increased by 49.4% and accounted for two-thirds of all GHG emissions. Understanding driving forces of CO 2 emissions is essential to formulating climate change mitigation policy and the fulfilment of applicable targets. Decomposition analysis of change in emissions provides a robust means of achieving this objective. At the United Nations Framework Convention on Climate Change (UNFCCC) Dublin Workshop on Fourth National Communications from Annex I Parties (UNFCCC, 2004), index decomposition analysis (IDA) was recommended to quantify key drivers of emissions and separate effects such as energy efficiency and GDP growth. In the literature, applications of IDA have undergone substantial changes since the late 1970s. Recently, IDA methods particularly the logarithmic mean divisia index (LMDI) technique have been widely applied to track economywide energy efficiency trends by different countries/organisations (Ang et al., 2010). Sectoral analysis has been expanding from energy demand and CO 2 emissions in industry and manufacturing sub-sectors to analysis such as UK road freight in Sorrell et al. (2009). Insight into the driving forces underlying change in CO 2 emissions in Irish sectors has been limited to the decomposition analysis of manufacturing. Given the large increase in emissions, particularly from the under-investigated transport sectors, the absence of appropriate enquiry could have consequences for policy. In the in-depth review (IDR) of Ireland's third national communication to the UNFCCC, Rolle et al. (2005) highlighted this gap in knowledge. The reviewers recommended that changes in GHG emissions of Irish transport be linked to changes in modal split and changes in physical activity by passenger kilometres (p-km) and tonne kilometres (t-km). The objectives of this study were to identify and analyse trends in the historical driving forces of CO 2 in all of the energy end-use sectors from 1990-2007. It also forms the first response to these UNFCCC recommendations. The sectors are analysed separately but inter-sectoral shifts in the shares of activity in the economic sectors and the transport modes are also analysed. Rather than develop policy recommendations per se, this study contributes to the discussion of appropriate mitigation measures by engaging with gaps in knowledge of trends and driving forces in the end-use sectors. The results obtained are not only relevant to Irish policymaking but may provide useful insights for other countries experiencing a development transition. The analysis of the historical progression of key indicators, particularly energy intensity, also functioned as the first step in the development of scenarios of future CO 2 emissions in O' Mahony et al. (submitted). Similar to Wu et al. (2005) who analysed driving forces in China, the originality of this study lies in the use of a framework that gives a disaggregated multi-sectoral decomposition. Multi-sectoral decompositions in previous studies often deal with three or four sectors (Diakoulaki et al., 2006;Lise, 2006;Tuncet al., 2009) whereas this study disaggregates eleven final consumption sectors. Whereas the EU-ODEX has been used to track energy efficiency in some sectors (Dennehy et al., 2009), this is the first comprehensive index decomposition analysis of the Republic of Ireland, including of the non-manufacturing economic sectors, the residential sector and of particular importance, the transport modes. While this study decomposes all final consumption sectors, particular focus is accorded to the disaggregation of transport recognising both that it is under-investigated and also its importance in total emissions. This is as opposed to Oh et al. (2010) a multi-sectoral decomposition of South Korea, which concentrated on disaggregated manufacturing but aggregated transport. This multi-sectoral analysis may provide deeper insights than the macro level approach recommended by the UNFCCC (2004). The rest of this paper is organised as follows. Section 2 presents sectoral emissions from 1990-2007 and the classification of the sectors in Ireland that leads to the decomposition scheme. Section 3 introduces our decomposition framework and Section 4 describes data sources. In Section 5, we present the decomposition analysis results from each sector and an aggregate analysis. Section 6 concludes this study.",
            "Sectoral CO 2 emissions in Ireland": " Fig. 1 shows the evolution of the sectoral contribution to total energy CO 2 emissions in Ireland from 1990 to 2007. The classification of final energy end-use sectors was established in the Ireland's energy balance sheets communicated to the European Commission and the International Energy Agency. It can be observed from Fig. 1 that there was an increasing trend in the total CO 2 emissions and a concentration of growth occurred from 1993-2001. The residential and industry sectors are the major contributors but their shares have declined over time. All transport modes experienced substantial growth in emissions with the exception of rail. 1The decomposition framework used in this study is based on the sectoral classification previously described. This sectoral disaggregation is similar to that used in Agnolucci et al. (2009), Oh et al. (2010) and to a lesser degree that of Wu et al. (2005). Full coverage of the main final consumption sectors is achieved using data by sector and fuel type. The four economic sectors include agriculture, industry, commercial services and public services, but does not separate construction as disaggregated was unavailable. Agnolucci et al. (2009) split industry into energy intensive/ extensive branches but gross value added (GVA) data in Ireland is not disaggregated along these lines pre-1995.2 Industry remains aggregated to facilitate a full analysis from 1990 to 2007. Agriculture and public services are given their own characterisation as agriculture is unique in its use of energy and public services are unique in the instruments necessary to reduce CO 2 emissions due to state control. In our analysis, a methodological challenge arises in attempting to understand the increase in emissions from transport since 1990. A response is required to the recommendations of Rolle et al. (2005), that changes in emissions be linked to changes in modal split and activity by p-km and t-km. Ang and Zhang (2000) specifically suggested the use of LMDI I to measure the physical efficiency of transport. As discussed by Timilsina and Shrestha (2009) given a lack of data, a common approach in energy literature is to measure modal shift by changes in modal fuel consumption in total transport fuels (EIA, 2007;IEA, 2004). This proxy method assumes the same intensity across the different modes and weakens results. The approach adopted in this study retains the physical measure of modal shift and also intensity. As shown in Fig. 1, transport in the decomposition framework is split into six sub-sectors or modes corresponding to energy and CO 2 data. This reflects the considerable modal differences in the provision of transport services while responding to the recommendations of Rolle et al. (2005). International aviation and maritime transport are not considered as both are memo items in national inventories and excluded from national totals and quantitative targets (IPCC, 1999). It should be pointed out that a similar limitation to Agnolucci et al. (2009) arose in the case of rail since the data on energy use by passenger and freight components cannot be separated. As such, we aggregate the total activities performed by rail passenger transport and rail freight using the approach suggested by Diakoulaki et al. (2006). Since the ratio of rail p-km to t-km was not stable, the results of aggregate intensity for rail are interpreted with this in mind. The road public passenger sector is also an aggregation of bus and taxi transport modes. It is worth noting that the approach of Timilsina and Shrestha (2009) aggregates road transport and also aggregates rail transport. The activity of the unspecified and fuel tourism sectors cannot be measured. These sectors are aggregated to complete the analysis but effects are not measured. In keeping with Ekins and Barker (2001) it is recognised that energy demand is more related to energy services (heat, light, power, mobility, etc.) than for energy itself per se. This has implications for the drivers that lead to change in energy CO 2 emissions, but it is difficult to accommodate given the huge variety of energy services required in each sector. In order to overcome this, energy services are represented by either monetary or physical indicators based on the characteristics of different sectors. Usually, the use of physical indicators is considered to be more accurate but this may only be applicable for particular sectors such as transport (Diakoulaki et al., 2006;Freeman et al., 1997). In the case of the economic sectors, both physical and monetary indicators of output can be used, but both present with potential limitations. Physical indicators can create difficulties in aggregating disparate physical outputs across different products, commodities or service groups, while monetary indicators can mislead due to changes in unit prices. Similar multi-sectoral studies have used monetary indicators of economic output (Wu et al., 2005;Oh et al., 2010;Lise, 2006;Diakoulaki et al., 2006). In this study, using the monetary indicator GVA facilitates a commonality in the method of analysis across the sectors and also the analysis of structural shifts. For the residential sector, the number of households is taken as the activity indicator. Transport activity is represented by mobility rather than vehicle distance as mobility is the primary energy service sought (Ekins and Barker, 2001). Therefore, p-km and t-km are, respectively, taken as the activity indicators for passenger and freight transport modes.",
            "Methodology": " Index decomposition analysis (IDA) has been widely accepted as an analytical tool for supporting policymaking on national energy and environmental issues (Ang, 2004b). The decomposition of the change in an aggregate indicator into a pre-defined set of factors helps to understand the progression of driving forces, the impact of major processes occurring and policy dimensions tied to these processes (Steenhof et al., 2006). The results of an IDA application study have direct policy implications such as evaluation of energy conservation programs (Ang, 2004b;Ang and Liu, 2007). They may also provide a basis for forecasting (Ang, 2004a) or scenario analysis of future evolution. The results of this study are used as the basis for scenarios presented in O' Mahony et al. (submitted). A range of techniques have been established under the umbrella of IDA, among which the LMDI I technique has been identified as the preferred approach by Ang (2004b). The mathematical properties of the technique suggest its suitability for this study including: perfect decomposition, consistency in aggregation and ability to handle zero values. In the methodological literature (Ang, 2004b) recommends the multiplicative and additive LMDI I methods for their theoretical foundation, adaptability, ease of use and ease of result interpretation. LMDI I has both additive and multiplicative forms. In this study, it is applied in multiplicative form chain-linked annually accommodating separate decomposition of the sectors and subsequent aggregation to total change. The basic mathematical formulae for IDA and LMDI I can be found in Ang (2004b) developed from work by Ang and Liu (2001). The work of Ang and Liu (2001) was extended by Wu et al. (2005) as a three-level decomposition for China disaggregated by sector and province. In contrast, this study applies a two-level decomposition for Ireland without provincial disaggregation but for a greater number of sectors. The approach used facilitates the elaboration of sectorspecific insights. The decomposition schemes applied to each of the sectors are detailed in Eqs. ( 1)-(3) where index i\u00bc1, 2,y,6 respectively denote coal, oil, peat, gas, renewables and electricity and index t the year from 0 (base year) to t (target year). Eq. ( 1) is applied to each of the economic sectors for j\u00bc 1,2,3,4 denoting industry, commercial services, public services and agriculture: Cecon j,t Cecon j,0 \u00bc X 6 i \u00bc 1 C tij FF tij FF tij FF tj FF tj E tj E tj Y tj Y tj Y t Y t\u00f01\u00de In Eq. ( 2) applied to each of the transport sectors, j indexes sector, for j \u00bc5,6,y,10 for private car transport, road public passenger transport (bus and taxi), road freight transport, rail transport (passenger and freight), domestic aviation and aggregated unspecified and fuel tourism: Ctrans j,t Ctrans j,0 \u00bc X 6 i \u00bc 1 C tij FF tij FF tij FF tj FF tj E tj E tj TD tj TD tj TTD t TTD t\u00f02\u00de Eq. (3) applies to j\u00bc11 the residential sector: Cres j,t Cres j,0 \u00bc X 6 i \u00bc 1 C tij FF tij FF tij FF tj FF tj E tj E tj THN t THN t\u00f03\u00de The meanings of the variables in Eqs. (1)-( 3) are described in Table 1. Assume that CE tij \u00bc C tij /FF tij is the carbon emissions coefficient for fuel i in sector j for year t; FS tij \u00bcFF tij /FF tj is the ratio of fossil fuel i to total fossil fuels in sector j for year t; RE tj \u00bcFF tj /E tj is the share of total fossil fuels in total energy consumption in sector j for year t; EIE tj \u00bc E tj /Y tj is the energy intensity of economic sector j ( j\u00bc1,2,3,4) for year t; EIT tj \u00bcE tj /TD tj is the energy intensity of each transport sector (mode) j ( j\u00bc5,6,7,8,9,10) for year t; EIR tj \u00bcE tj /HN tj is the energy intensity of the residential sector for j \u00bc11 for year t; ES tj \u00bcY tj /Y t is the share of economic output in sector j (j \u00bc1,2,3,4) in total economic output for year t; ET t \u00bcY t /Y 0 is the change in total economic output for year t; TS tj \u00bcTD tj /TTD t is the share of transport distance in sector (mode) j in total transport distance (j \u00bc5,6,7,8,9,10) for year t; TT t \u00bc TTD t /TTD 0 is the change in total transport distance for year t; HN t \u00bcTHN t /THN 0 is the change in the total number of households for year t; where 0 is the base year  Cres j,t Cres j,0 \u00bc X 6 i \u00bc 1 CE tij FS tij RE tj EIR tj HN t\u00f06\u00de The steps required to develop Eqs. ( 4)-( 6) as LMDI I are detailed in Ang and Liu (2001). The detailed decomposition formulae applied in this study are presented in the Appendix. These give the determinant effects in each of the sectors described in Table 2 along with the nomenclature used for results. These effects can be categorised into three groups: the intensity effects C emc , C inte , C intt and C intr , the structure effects C ffse , C repe , C es and C ts , and the scale effects C et , C tt and C hn . The C emc is the ratio of CO 2 per unit of energy for each fuel type in each sector. It analyses fuel quality and the installation of abatement technologies. As electricity is included as a fuel type in the consuming sectors, this effect also shows the change in the CO 2 coefficient of electricity due to fuel switching and renewables in power generation. The C inte , C intt , C intr effects measure the change in CO 2 from the change in the intensity of energy use in each sector and can represent the push and pull of both technological efficiency and socio-economic behaviour. They can also subsume intra-sectoral structural changes and energy price effects. In the economic sectors C inte measures change based on the energy consumption per unit of GVA. C intt measures change in CO 2 based on the energy consumption per unit of travel activity (p-km and t-km), while C intr measures change through the energy consumption per household unit. C ffse is a structural effect that represents the ratio of each fuel type in total fossil fuels. This effect measures the substitution of fossil fuels within each sector but not in electricity as this is a demand side analysis. C repe shows the penetration of renewable energy into total final consumption under demand side control in each sector and not that in power generation. C es measures the change in the structure of the economy, and C ts measures change in the structure of transport modes. The scale effects C et , C tt and C hn measure the changes in CO 2 emissions due to the changes in total economic output of the economic sectors, total transport work performed and total number of households respectively. C tot indicates the aggregated change of all effects over time in each sector. While each of the sectors have been decomposed annually from 1990-2007, results are presented as three distinct development periods to aid discussion, see Section 5.",
            "Data": " The data on energy, CO 2 emissions and activity indicators from 1990-2007 were collected from various sources. For energy, total final consumption (TFC) data reported by sector and fuel type are collected from the energy balance sheets compiled by Sustainable Energy Ireland (SEI, 2008). While the Irish Environmental Protection Agency (EPA) publish a national inventory report (NIR) of Irish greenhouse gas (GHG) emissions annually for reporting to the UNFCCC and the EU, the reporting format is not appropriate for this study. 3 Therefore in the case of CO 2 emissions, the data used in this study is also taken from SEI energy balance sheets. The EPA dataset treats electricity as a separate sector and does not allocate it to the consuming sectors. For the SEI dataset, the total CO 2 emissions from electricity generation, including its transmission and distribution, are allocated to the final consuming sectors in proportion to their final energy consumption. Both datasets use the IPCC sectoral methodology (IPCC, 1997), SEI energy balance sheets and the same national emission factors. In contrast to the top-down approach used by SEI, the EPA used a bottom-up methodology through reporting of individual installations under the emissions trading scheme (ETS). This leads to a slight deviation of reported energy CO 2 where the EPA data is 1.49% greater in 2007. Output in the economic sectors is measured by real growth in GVA in h million (CSO, 2008a). A number of data gaps for the activity of Irish transport were overcome by estimations made in this study. For the transport sectors, to complete a dataset of rail activity including all p-km and t-km, data from CSO (2008b) was completed using additional Dublin tram 'LUAS' passenger data from the Rail Procurement Agency (RPA, 2005). Road freight data in t-km was obtained from CSO (2008bCSO ( , 2009b)). Data on private car p-km is problematic in Ireland and is not currently compiled nationally. While data on v-km has been improved, occupancy assumptions are not available to extend this data to p-km. The revised Irish p-km estimate of the European Commission (DGTREN, 2009) was used but required modification. This data aggregates p-km of private car and 'Small Public Service Vehicles' (SPSVs) or taxis and hackneys and the SPSV p-km data was subtracted from the DGTREN estimate to allow the separate decomposition of private car. Given the importance of private car CO 2 in both growth and absolute terms (Fig. 1), this is an important development in the analysis of Irish emissions. For the road public passenger mode, data on p-km is also not available nationally and estimated bus and coach p-km from DGTREN (2009) was combined with an analyst estimate for SPSV. 4 Separate decomposition of bus and SPSV would be desirable, but this approach is necessary as energy/CO 2 data is aggregated. Another data gap for Irish transport activity is domestic aviation p-km. An analyst estimate was produced combining passengers handled data with the national average distance travelled per domestic flight. 5,6 For the residential  1990-2003. As this data registers a passenger twice in both departing and arriving location passengers handled was divided by two to arrive at the number of passenger journeys. The theoretical average distance of all domestic aviation journeys is 125 nautical miles (231.5 km), as used by Irish authorities in calculating the NIR. 6 The passengers handled data also includes journeys to or from the smaller airports in Ireland including Kerry, Knock and Galway. As journeys originating in these airports only register once the division by two results in a minor under-accounting. sector total household numbers from 1990-2007 are derived as the number of private households measured by census and interpolated for intercensal years (Cavanagh, 2009, personal communication). Unspecified and fuel tourism activity have no relevant activity measure. The unspecified category includes data errors and consumption by motorcycles, service vehicles, construction vehicles and domestic water activities. Fuel tourism is a category that accounts for fuel purchased in the Republic of Ireland and consumed in another territory. This includes both petrol and diesel purchased by motorists and hauliers from Northern Ireland arising due to a price differential between the two territories. To characterise data quality, in keeping with Lyons et al. (2008), data on energy and CO 2 emissions in Ireland can be assumed of high quality. Data on GVA and household numbers are assumed to be of high quality since they are well reported and well understood. Data for transport activity is of mixed quality given the combination of reported data and estimates inferred to overcome gaps. Data for rail (CSO, 2008b) is reported from annual survey. 7 Data for road freight (CSO, 2008b;CSO, 2009a) is compiled annually by survey and measured for variability. The key issue for private car p-km data from DGTREN (2009) after the removal of SPSVs is what appears to be a low occupancy assumption adopted by DGTREN reducing from 1.4 in 1990 to 1.25 in 2007. 8 Due to the absence of comparable estimates of p-km, bus and coach and taxi and hackney activity data are difficult to validate. Domestic aviation includes a minor underestimation of p-km from the smaller airports of Kerry, Knock and Galway. 9 Potential limitations are considered in the interpretation of results. Rather than just a discussion of trends, to improve robustness, observed changes and underlying factors are discussed in the context of existing analysis available in the literature. In the case of the energy intensity effects, this study analyses the general trends in each of the eleven sectors and does not attempt a finer disaggregation. A finer disaggregation is theoretically more desirable to further quantify underlying factors in energy intensity change but limits on data availability and quality must be considered (Ang et al., 2010). Further development of Irish data sources in response to the limitations highlighted above would benefit the analysis of energy and emissions.",
            "Results and discussion": " We perform decomposition analysis using the LMDI I method and present our decomposition results in this section. For ease of interpretation, the analysis of each sector is presented separately. The results are discussed over the entire analysis period from 1990 to 2007. Despite the annual analysis employed in this study to monitor evolving effects on a yearly basis, three distinctly different development periods emerged. Results have therefore been presented for ease of interpretation as the periods from 1990-1993 before the economic boom in the Republic of Ireland, from 1993-2001 as emissions increased rapidly along with economic development and 2001-2007 as emissions growth moderated.",
            "Economic sectors": " Fig. 2 shows the decomposition results for the industry sector. It can be seen from Fig. 2 that the change in industry CO 2 is predominantly explained by growth of the overall economy (C et \u00bc 2.7678). This is attributable to Ireland's pursuit of economic growth through industrial development policy and is illustrated by an increased structural share of industry in the economy (C es \u00bc1.3378) with particular prominence from 1993-2001. Energy intensity (C inte ) is the major factor in reducing industry emissions in all sub-periods and over the entire time series (0.4215). Improving energy intensity can be attributed either to technical efficiency or to structural change. A more detailed subsectoral disaggregation could provide a better understanding, but this was limited due to the lack of disaggregated data over the full time period. However, previous studies have shown that the significant achievement in energy intensity of Irish industry is more attributable to structural change (Cahill and O \u00b4Gallachoir, 2009;Diakoulaki and Mandaraka, 2007;Dennehy et al., 2009). 10Development concentrated on high-value, energy extensive branches such as chemicals, petrochemicals and ICT and changes to industrial structure also included the cessation of steel production in 2001 and fertiliser production in 2002. This shift can be linked to national industrial development policy and global economic influences and Diakoulaki and Mandaraka (2007) consider Ireland a pioneer in integrating the sustainability concept into the development strategy. Considering these assertions, we conclude that structural change was the dominant contributor to energy intensity improvement. Following the increase in earlier years, from 2001-2007 CO 2 emissions dropped and the emissions coefficient effect (C emc \u00bc 0.8282) became important. This arose from the decarbonisation of electricity supply, fuel switching and the use of renewables in power generation, and an increase in the ratio of electricity in the industrial fuel mix. Although progress in industry fuel substitution (C ffse \u00bc0.9938), renewable energy (C repe \u00bc0.9879) and energy intensity (C inte \u00bc0.7829) were made, a significant proportion of the achievement in manufacturing industry from 2001-2007 is consequently attributable to power generation. Fig. 3 presents the results for commercial services where scale growth in the economy also dominated the increase in emissions (C et \u00bc 2.7624) with a significant increase in emissions predominantly from 1993 to 2001 and stabilising from 2001 to 2007. A reduction in the energy intensity of commercial services (footnote continued) These airports contributed 9.01% of total passengers handled in 2006 and 12.45% in 2008 suggesting an underestimate of passenger journeys (and hence p-km) of 4.5% and 6.23% in the years where comparison is possible using CSO (2009b). 7 The aggregation of rail must be considered in the analysis as the energy intensity indicator can measure both technical efficiency and structural change through the reduction of rail freight in total rail activity. 8 Using private car p-km data incorporating a low occupancy assumption could underestimate the increase in energy intensity. 9 See footnote 6. (C inte \u00bc 0.7203) acted to limit growth in emissions. Despite output growth, the sectoral share of services slightly diminished over the entire period (C es \u00bc 0.9740) and a structural transition to services was not evident. Fossil fuel substitution increased notably (C ffse \u00bc1.2283), particularly since 1993. Despite a reduction in the effect of oil, there is an increase in the effect of electricity on CO 2 , as absolute electricity consumption expanded through office use of ICT and air-conditioning, despite reductions in the emissions coefficient of electricity supply in general. Little progress in reducing emissions was achieved through renewable energy in the fuel mix which registered from 2004-2005 onwards. The effects acting to reduce emissions in commercial services were energy intensity and the emissions coefficient. From 2001-2007, improvements in intensity (C inte \u00bc0.8530) were exceeded by improvements in the emissions coefficient (C emc \u00bc0.7603) due to reduction in the carbon intensity of power generation. It is more difficult to form conclusions about the energy intensity of services as energy data is calculated as a residual and information on branches is unavailable 11 (Howley et al., 2008). The sector is the most heterogeneous in the economy, from high value added/ lower energy intensive offices, research and development, to lower value added/higher energy intensive restaurants, bars and catering. Output growth in services was dominated by officebased branches such as financial intermediation, real estate and business activities and also in retail. 12 The shares of fuel types are also heterogeneous by sub-branch ranging from those with higher space heating requirements consuming a higher proportion of oil and gas to higher electricity consumption correlated with office employees. This sector along with residential and public services sectors would tend to be the most climate dependent due to space heating requirements but historically this has not been a significant factor. Previous studies have shown climate correction has had a negligible impact on results (O' Leary et al., 2005;Howley et al., 2009) due to Ireland's relatively benign climate. Despite a reduction in the economic share of public services (C es \u00bc0.4744) scale growth in the economy again dominates in Fig. 4. The C ffse effect (1.2629) increased despite declines in oil and peat as gas increased and electricity use increased significantly. Although renewable energy penetration begins to take effect in the 2001-2007 period (C repe \u00bc 0.9961) it has relatively little effect over the entire period. The intensity effect fluctuated annually and is relatively stable over the entire period with no improvement (C inte \u00bc 1.0013). Within public services the dominant negative effects are the loss in economic share occurring since 1990 and the reducing emissions coefficient attributed to electricity. The agriculture sector in Fig. 5 was also dominated by overall economic growth (C et \u00bc2.7696) but only marginally increased emissions over the full period (C tot \u00bc1.0328). Industry and services were the strategic economic development priorities as Ireland further moved away from its agrarian past. Increases in emissions arising in the first two periods were countered by a reduction from 2001-2007 (C tot \u00bc0.8182). The structural effect of economic share declines in all sub-periods and over the entire period as the other sectors grew. The fuel switching (C ffse \u00bc1.0238) and renewable energy penetration (C repe \u00bc0.9995) effects were relatively static. While energy intensity increased over the entire period (C inte \u00bc1.0496), it reduced emissions from 2001-2007 (C inte \u00bc0.8621) as growth in output exceeded that of energy consumption. The emissions coefficient effect also reduces emissions (C emc \u00bc0.8458) but electricity is a smaller component of the fuel mix in agriculture.",
            "Transport modes": " Over the entire period and in all sub periods, private car presents a significant increase in emissions. It is of significant concern to climate mitigation policy in Ireland due to its share of total emissions and the rate of increase since 1990 (Fig. 1). The dominant driver is the scale effect of overall growth in transport (C tt \u00bc2.2563). Although its share of total transport declines (C ts \u00bc0.8795) this may mislead due to the considerable growth  11 Data on floor area is unavailable and the necessary branch energy data to analyse structural shifts is unavailable. Per employee, fuel consumption decreased by 46% from 1990 to 2007 and electricity consumption increased 41% signalling the effect of ICT and air-conditioning (Howley et al., 2008 'Gallachoir et al., 2009). 17 Considering this evidence, we conclude that the net effect of reducing occupancy and increasing engine size led to an increase in intensity per p-km. Private car transport is an energy intensive form of passenger mobility. In Ireland with reducing occupancy and larger engine size it became less defined by efficient mobility and more as a lifestyle choice. However, it is not inevitable that enhanced incomes will lead to these trends and also to increased v-km and motorisation of mobility choices in addition. The manifestation of this consumption pattern in Ireland was aided by cultural development towards individualisation and a range of government policy choices. Dispersed pattern settlement, urban sprawl and the prioritisation of private over public transport in policy and investment 18 contributed both to the increasing requirement for the private car as a modal choice and increased vehicle distances. The impact of biofuels on emissions through renewable energy penetration presented a small reduction from 2004-2007 (C repe \u00bc0.9902) (Fig. 6). Road freight increased more than any other sector as industry required increased freight movement due to economic growth. The scale effect (C tt \u00bc2.2563) was accompanied by an increase in the structural share (C ts \u00bc1.6162). Increases in freight activity were handled by road rather than rail and in later years a modal shift actually occurred away from rail to road. Road freight share growth was particularly high during the boom years of 1993-2001 (C ts \u00bc1.5178), but was still increasing from 2001-2007 (C ts \u00bc 1.1445) despite increases in fuel price over the period. Of considerable importance to this pattern is the failure to introduce policies leading to a reduction effect. Neither fuel substitution (C ffse \u00bc1.0000) nor renewable energy (C repe \u00bc 1.0000) made progress. The energy intensity effect improves marginally from 1993 to 2001 (C intt \u00bc 0.9842), but over the entire period (C intt \u00bc1.0538) and in the most recent period from 2001 to 2007 (C intt \u00bc1.0231) this indicator increases. The increase in intensity occurred despite a surge in diesel fuel prices by 47.2% from 1997 to 2007 (CSO, 2008b) and contrary to the decreasing intensity observed internationally including in South Korea and the United Kingdom (Oh et al., 2010;Sorrell et al., 2009). Previous studies of Ireland based on the ODEX method (Dennehy et al., 2009;Howley et al., 2007) have recorded a marginal reduction and an increase in energy intensity respectively. This was attributed to the growth in lowvalue heavy transport for construction as intensity was measured with respect to economic activity. Heavier loads should reduce intensity measured with respect to t-km consequently the increase in intensity is attributable to physical and logistical factors. Studies such as Kamakate \u00b4and Schipper (2009) and Leonardi and Baumgartner (2004) identified factors influencing intensity as not only the fuel economy of vehicles but also logistics and driving, load factor, empty running and matching of truck capacity to load (Fig. 7). Road public passenger emissions also increased significantly over the analysis period. Scale growth was a considerable factor (C tt \u00bc2.2563) as transport demand increased with affluence. The key result in this mode is the large increase in intensity (C intt \u00bc1.4613), particularly in the 2001-2007 period (C intt \u00bc 1.4360). Owing to data limitations this category includes not only buses and coaches, but also SPSVs. 19 The number of SPSVs and their use has increased Fig. 6. Private car decomposition by sub-period. 13 This study adopted the private car p-km data of DGTREN (2009) which assumed a drop in occupancy of 10.71% from 1.4 in 1990 to 1.25 in 2007. 14 Data on private car occupancy in Ireland is poorly reported. NRA (2003) suggests a possible value of between 1.13-1.92 for transport modelling based on flow group. These assumptions do not establish a temporal pattern. In the Urban Environment Project, Casey (2009) (EEA, 2003;EEA, 2005) have shown falling occupancy for each of the ten states with a multi-annual time series. Average occupancy for the United Kingdom, Germany and the Netherlands drops from 1.62 in 1990 to 1.46 in 2002, or 1.8-1.5 from 1990-1998 for the UK alone. This is not the same in absolute terms, but is similar in pattern to the occupancy assumption adopted for Ireland by DGTREN (2009). The pattern in Europe has been attributed by the EEA to increased individualisation in society including higher car ownership and smaller household size. These trends have been more pronounced in Ireland as it followed a path of rapid development catch -up, therefore it could reasonably be assumed that the occupancy assumptions should be higher and also the fall more significant. This increases confidence in the conclusion that intensity per p-km has increased and that falling occupancy is primarily responsible. 17 According to O \u00b4 'Gallachoir et al., (2009), the increase in engine sizes led to an increase in the specific fuel consumption of new Irish petrol cars by 1.6% from 2000 to 2005 from 6.91 l/100 km to 7.02 l/100 km. This fell slightly in 2006 to 6.74 l/100 km. The equivalent for diesel cars was an increase of 1.78% from 6.19 l/100 km in 2000 to 6.30 l/100 km in 2005 followed by a drop in 2006 to 6.18 l/100 km. 18 Ireland's bias of investment and policy focus towards roads over public transport has been criticised (McDonagh, 2006). In recent decades, investment in transport in Ireland has favoured roads over public transport. From 2000 to 2005, (footnote continued) investment in roads was h6.62 billion and in public transport was h2.5 billion (DTTAS, 2005). 19 As discussed in Section 4 data, the Road Public Passenger mode is an aggregation of bus and coach and taxi and hackney (SPSVs), as separate energy and CO 2 data for these modes are unavailable. dramatically in Ireland with the liberalisation of taxis and hackneys from 2000 and co-occurred with the increasing intensity from 2001 to 2007. 20 Bottom-up analysis by Howley et al. (2007) shows that fuel consumption of SPSVs has increased significantly since 1990 and consumed more fuel than the bus and coach category by 2003. 21 As p-km completed by SPSVs are more energy intensive than that by bus and coach this led to increasing intensity in this mode (Fig. 8). 22 ,23   The growth in rail CO 2 over the analysis period (C tot \u00bc1.1189) was smaller than the other modes and incidentally is within the Ireland's Kyoto benchmark of \u00fe13% on 1990. This sector was subject to considerable scale growth in all periods (C tt \u00bc2.2051). Its structural share declined (C ts \u00bc0.7721) over the entire period but increased from 2001 to 2007 period as passenger numbers increased and the LUAS electrified tram scheme was commissioned in Dublin. The substitution effect acted to increase CO 2 emissions in all periods due to absolute increases in electricity consumption (C ffse \u00bc1.0980). Considerable improvement in the energy intensity of rail transport was achieved in the entire period (C intt \u00bc0.6248) and in all sub-periods. This is mainly due to modernisation of the rail system to upgrade locomotives and the rail network. This modernisation delivered increasing passenger kilometres24 and improved intensity. It is likely that the opening of the LUAS tram system also contributed to decreasing intensity. 25 The decline in rail freight activity contributes to the decrease in rail intensity but this does not appear to be significant. 26,27 A minor improvement in the emissions coefficient is measured due to electricity (C emc \u00bc0.9580) (Fig. 9). Considerable growth in CO 2 from domestic aviation was recorded scale growth in activity (C tt \u00bc2.2563) predominantly responsible. This sector experienced both increasing activity and increasing energy intensity (C intt \u00bc1.3631). Increasing intensity was considerable from 1990 to 1993 (C intt \u00bc1.2745) and slowed from 2001 to 2007 (C intt \u00bc1.0044). In domestic aviation the growth in aircraft movements exceeded the growth in passengers handled. 28 Improvement in technical efficiency through replacement of aircraft was consequently insufficient to counter the resulting increase in intensity per p-km. Domestic aviation is in receipt of a subsidy in Ireland with the objective of facilitating regional development. 29 The domestic aviation mode accounted for just 1.12% of transport CO 2 in 2007 but has a higher energy intensity per p-km and competes with other less energy intense modes. The analysis also excludes the other aviation GHGs and sources of radiative forcing described in IPCC (1999) (Fig. 10). The unspecified and fuel tourism categories have been aggregated and included in the decomposition to complete sectoral coverage at the final consumption level but do not have effect measurements as such. Absolute growth of these aggregated categories was considerable (C tot \u00bc3.6342).   to 2005, the first full year of LUAS operation. From 2004 to 2005 rail freight activity also declined \u00c0 24.01%, but later years appear to show that reducing rail freight does not have a significant impact on decreasing intensity. Large reductions in rail freight activity occurred from 2005 to 2006 ( \u00c0 31.81%) and 2006-2007 (\u00c0 37.65%) while overall rail intensity (C intt \u00bc0.9855) and (C intt \u00bc 0.9903) did not decline significantly during these years. This suggests that rail freight is not a significant factor in decreasing intensity. 26  (PSO) air services were established for connections from Sligo, Donegal, Knock, Kerry, Galway and Derry with Dublin. This PSO was established on the policy assumption that these services were considered vital for the economic development of their regions, and that services would not otherwise be provided on a commercial basis.",
            "Residential sector": " In the residential sector, progress was made in limiting the increase in CO 2 . Emissions increased slightly over the entire period (C tot \u00bc1.0396) but decreased from 1990 to 1993 (C tot \u00bc0.9607) and from 2001 to 2007 (C tot \u00bc0.9305) despite a significant increase in house numbers (C \u00bc1.4910). The most significant factor in reducing emissions was energy intensity (C intr \u00bc0.8658). Energy is consumed in the residential sector for a diverse range of energy services from space and water heating to the use of appliances. Increased affluence contributed to investment in the building stock to improve thermal performance (C int ) and other forms of technological replacement (C ffse ) and (C repe ). As discussed in DBERR ( 2007) and Oh et al. (2010) energy consumption in households can vary with climate, house size and type, lifestyle, energy prices and energy efficiency. With respect to space heating, energy intensity has improved due to tightening thermal standards 30 ; a high proportion of newly built dwellings 31 ; changes in heating equipment 32 and increases in heating fuel prices. 33 The impact of change in heating degree days on energy consumption was negligible. 34 Despite these positive trends and the decreasing intensity per household, some negative trends have also arisen. Increased affluence facilitated a preference for larger floor areas in detached houses 35 and also higher residential electricity demand due to increased penetration and use of electrical appliances 36 (Howley et al., 2008;Dennehy et al., 2009), although legislative change has encouraged energy efficiency of domestic appliances. 37  The emissions coefficient effect (C emc \u00bc0.8153) reduced in all periods attributable upstream to changes in power generation. The substitution effect reduced emissions (C ffse \u00bc0.9767) as coal and peat was replaced by oil, gas and electricity. Renewable energy reduced as a share of the fuel mix over the entire period (C repe \u00bc1.0113), but had begun to reduce emissions again from 2004 onwards. The improvement in the residential sector as typified by energy intensity should be placed in context. International comparison suggests substantial further mitigation potential to reduce both energy and carbon emissions particularly given Ireland's relatively benign climate. According to O' Leary et al. (2008), the average Irish dwelling in 2005 emitted 47% more CO 2 than the average UK dwelling and 104% more than the average for the EU-27 (Fig. 11).",
            "Synthesis and aggregated change": " For the economic sectors development followed a lower emissions trajectory achieved through development policy to restructure the economy coined as ''the Irish way'' by Kaivo-oja and Luukkanen (2004). While emissions did increase, economic restructuring favoured a lower emissions trajectory but technical efficiency appears to have been less successful. Economic growth does not necessarily lead to linear increases in emissions as it can potentially facilitate reducing energy intensity and it is the nature of growth that is critical in determining outcomes. The economy and society relationship with energy and emissions is more complex than a simple linear interpretation can provide and can be elucidated by a analysis. In the residential sector affluence led to demand increases for energy, e.g. appliance use increasing electricity consumption, but also facilitated technological change to reduce energy intensity, deliver fuel substitution and renewable energy penetration through legislative and policy change. In transport, increases in GVA drove higher freight demand and increasing personal affluence drove higher personal mobility demand. Demand evolved towards more energy intensive modes of transport and increased intensity within mode. This illustrates where governance and societal choices evolved towards a weaker pattern of sustainability and resulted in poor ''delinking''. In the context of sustainability, the economic and societal development that occurs with a growing economy can potentially be directed to delinking emissions from growth   et al., 2008). 35 The average floor area of new households has increased by 24% for new houses and 27% for new flats and apartments from 1990 to 2007 (Howley et al., 2008). 36 Electricity consumption per dwelling has increased by 31% since 1990 which has been attributed partly to increasing use of appliances (Howley et al., 2008). 37 Legislative change in the EU to encourage the energy efficiency of appliances includes the energy labelling of domestic appliances directive (2003/ 66/EC). through immaterialisation, dematerialisation and decarbonisation (Tapio et al., 2007). The aggregation of transport activity in the C ts and C tt effects of the decomposition framework allowed the consideration of transport as an integrated whole. While aggregation may not be correct from a strictly mathematical point of view due to aggregation of p-km and t-km, it gives two potential advantages in the context of data constraints: (i) the use of physical indicators which in general give more robust measures of transport intensity and (ii) proximate insights into modal shift can be identified that may not otherwise have been possible due to the lack of disaggregated energy/CO 2 data for rail. In transport, growth in private car activity has been particularly problematic, as was growth in SPSVs and growth in road freight. The increasing intensity indicated in these modes is a significant concern for policy. Ireland's third In Depth Review (Rolle et al., 2005) noted the importance of limiting growth in emissions from transport and that no single measure could address this problem sufficiently. The various results for intensity illustrate the diversity of the dynamics in the sectors that cannot be measured without sectoral disaggregation. In Fig. 12, aggregated changes in CO 2 emissions for the sectors are presented; the C emc , C ffse and C repe effects aggregated across all sectors, the intensity effects C int are aggregated for the economic and transport sectors as C intec and C intt , respectively, and C intres represents the energy intensity of the residential sector separately. This allows comparison of the relative importance of changes in the driving forces of the sectors to total emissions. The C intec effect (0.6123) reflects a substantial decrease in energy intensity of the economic sectors predominantly from economic restructuring as discussed. The C intt effect (1.3589) illustrates the intensity increase of aggregated transport as a whole and the C intres effect shows the decrease in intensity of the residential sector (0.8658). The scale effects C et (2.7669), C tt (2.2545) and C hn (1.4910) are reflective of not only the magnitude of the impact of economic growth and affluence on the system but of its nature. Production and consumption expanded to increase the size of the economy in C et . With C tt transport scale expanded to reflect increased economic demand for freight and increased passenger mobility demand. The increase in C hn is consistent with both growth in affluence and population leading to increasing house numbers. The significance of the economic growth and affluence that evolved is not just in the historical increase in driving forces of carbon emissions that was observed. As short and medium term decisions have long-term consequences (Fisher et al., 2007), when a period of economic growth occurs future lock-in to a higher emissions trajectory can result unless the development path is directed into forms that do not increase emissions. Given the pattern of the historic results across the energy system, the 'carbon lock-in' phenomenon 38 (Unruh, 2000;Unruh, 2002) provides some insight into potential future evolution in Ireland and the challenges that national mitigation policy will face. It may also provide lessons for other countries experiencing a development transition. In general, given the evidence of causation in the transport sectors, confidence can be expressed in the conclusion of increasing intensity of private car, road public passenger, road freight and domestic aviation and also the decreasing intensity of rail. However, further analysis of Irish emissions from the sectors would benefit from development of activity data in the transport sectors and also disaggregation of energy and CO 2 data for rail and the road public passenger category.",
            "Concluding remarks": " This paper applied the LMDI I method in a multi-sectoral framework to decompose Ireland's energy-related CO 2 emissions from 1990 to 2007. The study is not only the first multi-sectoral decomposition of Ireland, but also the first decomposition of many of its sectors, which may be particularly valuable for the under-investigated transport modes as recommended by the UNFCCC. As a demand-side analysis, the results generated aid the understanding of historical driving forces of sectoral emissions and can consequently contribute to the discourse on mitigation policy. The patterns of sectoral development that emerged through the analysis may also contain lessons for other countries in development transition. Ireland has had a relatively unique recent history given its economic growth path. In addition to monitoring historical progression, the results were necessary for the development of scenarios of future sectoral emissions in O' Mahony et al. (submitted). Results have shown three different periods of distinct differences in the national development path while overall a considerable increase in emissions was recorded. As expected, scale growth in the economy played a significant role in the increase in emissions from the economic sectors. This economic driving force may also be related to the increase in emissions from the transport sectors. Greater affluence resulted in expanding mobility requirements but also more energy intensive mobility choices characterised development. The sectoral results illustrate a diversity of dynamics in driving forces. Scale effects predominate in acting to increase emissions in the economic and transport sectors. Improvements in energy intensity are notable in the economic sectors and in the residential sector. Overall, transport experienced a significant growth in CO 2 emissions due not only to scale growth in activity but also crucially due to increasing energy intensity. Despite the moderation of growth in emissions from 2001-2007, due to the pattern of development Ireland may experience significant challenges in Fig. 12. Radar of aggregated sectoral decomposition 1990-2007. 38 The concept of 'carbon lock-in' described by Unruh (2000Unruh ( , 2002) ) exists in the Techno-Institutional Complex (TIC) across the energy system arising through technological, organisational, social and institutional co-evolution and due to the self-referential nature of this process, escape conditions are unlikely to be generated internally. This is closely linked to the concept of inertia in capital stock discussed in Barker et al., (2007) where the timescale for replacement of appliances such as cars may be fast but of infrastructure such as roads may be very long. Notwithstanding the potential for lock-in in other elements of the energy system in Ireland, given the increase in road infrastructure, car ownership, societal preference for motorised transport and embedding of particular policy and investment approaches in institutions, the amelioration and prevention of further lock-in in transport is of much concern with respect to reducing emissions. overcoming future potential path dependency and the concept of 'carbon lock-in' is increasingly relevant (Unruh, 2000(Unruh, , 2002)). It is widely acknowledged that long-term emission reductions will depend on development paths 39 in general in addition to energy and mitigation policies (Sathaye et al., 2007). While mitigation requires sectoral policies in Ireland, particularly in transport, to prevent increasing long term lock-in to a higher emissions trajectory, the sustainability of the development path in general requires consideration.",
            "Appendix": " Applying the decomposition schemes detailed in Eqs. ( 4)-( 6) as a multiplicative LMDI I requires development through a number of steps detailed in Ang and Liu (2001). In this study, following these steps yields the decomposition formula in Eq. ( 7) for each of the economic sectors, in Eq. ( 8) for each of the transport sectors and in Eq. ( 9) for the residential sector: Cecon j,t Cecon j,0 exp X 6 i \u00bc 1 $ ij \u00f0tn\u00deln CE ij,t CE ij,0 \" # \u00c2 exp X 6 i \u00bc 1 $ ij \u00f0tn\u00deln FS ij,t FS ij,0 \" # \u00c2exp X 6 i \u00bc 1 $ ij \u00f0tn\u00deln RE j,t RE j,0 \" # \u00c2 exp X 6 i \u00bc 1 $ ij \u00f0tn\u00deln EIE j,t EIE j,0 \" # \u00c2exp X 6 i \u00bc 1 $ ij \u00f0tn\u00deln ES j,t ES j,0 \" # \u00c2 exp X 6 i \u00bc 1 $ ij \u00f0tn\u00deln ET t ET 0 \" #\u00f07\u00de Ctrans j,t Ctrans j,0 exp X 6 i \u00bc 1 $ ij \u00f0tn\u00deln CE ij,t CE ij,0 \" # \u00c2 exp X 6 i \u00bc 1 $ ij \u00f0tn\u00deln FS ij,t FS ij,0 \" # \u00c2exp X 6 i \u00bc 1 $ ij \u00f0tn\u00deln RE j,t RE j,0 \" # \u00c2 exp X 6 i \u00bc 1 $ ij \u00f0tn\u00deln EIT j,t EIT j,0 \" # \u00c2exp X 6 i \u00bc 1 $ ij \u00f0tn\u00deln TS j,t TS j,0 \" # \u00c2 exp X 6 i \u00bc 1 $ ij \u00f0tn\u00deln TT t TT 0 \" #\u00f08\u00de Cres j,t Cres j,0 exp X 6 i \u00bc 1 $ ij \u00f0tn\u00deln CE ij,t CE ij,0 \" # \u00c2 exp X 6 i \u00bc 1 $ ij \u00f0tn\u00deln FS ij,t FS ij,0 \" # \u00c2exp X 6 i \u00bc 1 $ ij \u00f0tn\u00deln RE j,t RE j,0 \" # \u00c2 exp X 6 i \u00bc 1 $ ij \u00f0tn\u00deln EIR j,t EIR j,0 \" # \u00c2exp X 6 i \u00bc 1 $ ij \u00f0tn\u00deln HN t HN 0 \" #\u00f09\u00de Using the nomenclature for the determinant effects detailed in Table 2, for each of the economic sectors for j \u00bc1,2y,4, Eq. ( 7) can then be re-written as C tot \u00bc C emc C f f se C repe C inte C es C et\u00f010\u00de Further to this, for each of the transport sectors for j \u00bc5,6,y,10, Eq. ( 8) can then be re-written as C tot \u00bc C emc C f f se C repe C intt C ts C tt\u00f011\u00de For the residential sector for j\u00bc 11, Eq. ( 9) can then be rewritten as C tot \u00bc C emc C f f se C repe C intr C hn\u00f012\u00de In order to further aggregate the indices of change in C tot for each of the individual sectors for j \u00bc1,2,3,y,11 to total change in all sectors, the consistency of aggregation provided for by LMDI I must be respected. As per Ang (2004b), change within each sector is aggregated using the following general IDA identity: V \u00bc X i V i \u00bc X i x 1 , i x 2 , i , :::,x n,i\u00f013\u00de The decomposition framework applied in this study provides a link between the individually decomposed sectors in the case of the economic and transport activity share effects. However, as each sector is decomposed separately, aggregation to total change in emissions in all sectors for year t must be achieved by weighting the index of change (C tot ) for each individual sector, by the sectors' share of total emissions in 1990. In Eq. ( 14), the left hand-side represents the index of change in total CO 2 emissions from all sectors, (C tij ) indicates the aggregation of the determinant effects in each individual sector, year t \u00c0 1 is the base year for analysis, year t is the target year and 0 is the reference year (1990) for sector j\u00bc1, 2, y, 11: C t C t\u00c01 \u00bc X 11 j \u00bc 1 X 6 i \u00bc 1 C tij C j,0 C 0\u00f014\u00de"
        }
    },
    "10.1016/j.enpol.2014.06.031": {
        "file_name": "52 Is Germany\u05f3s energy transition a case of successful green industrial policy",
        "title": "Is Germany's energy transition a case of successful green industrial policy? Contrasting wind and solar PV",
        "abstract": "In this paper, we address the challenge of Germany\u05f3s energy transition (Energiewende) as the centrepiece of the country\u05f3In this paper, we address the challenge of Germany\u05f3s energy transition (Energiewende) as the centrepiece of the country\u05f3s green industrial policy. In addition to contributing to global climate change objectives, the Energiewende is intended to create a leading position for German industry in renewable energy technologies, boost innovative capabilities and create employment opportunities in future growth markets at the least possible cost. The success in reaching these aims, and indeed the future of the entire concept, is hotly debated.The paper aims to provide an up-to-date assessment of what has become a fierce controversy by comparing solar photovoltaic (PV) and wind energy along five policy objectives: (1) competitiveness, (2) innovation, (3) job creation, (4) climate change mitigation, and (5) cost. We find mixed evidence that Germany reaches its green industrial policy aims at reasonable costs. Wind energy seems to perform better against all policy objectives, while the solar PV sector has come under intense pressure from international competition. However, this is only a snapshot of current performance, and the long term and systemic perspective required for the energy sector transformation suggests a need for a balanced mix of a variety of clean energy sources.",
        "label": "Quantitative",
        "text": {
            "Introduction": " Green industrial policy, that is, government intervention to hasten the restructuring of the economy towards environmental sustainability (Pegels, 2014), is a particularly suitable instrument to achieve the radical and long-term transition required to maintain acceptable living conditions for ourselves and our descendants. Governments must intervene, because market mechanisms such as prices alone are failing to bring about the drastic and fast changes to the very fabric of our economies required for the protection of our planet (Hallegatte et al., 2013). Linking environmental protection to such traditional aims of industrial policy as competitiveness, job creation and innovation as 'co-benefits' may help it to win supporters. Environmental sustainability on its own has failed to become a driver of structural change in most countries. However, the multiplicity of aims also renders green industrial policy making and the assessment of policy success more complex. This paper analyses one of the most far-reaching attempts globally to initiate a policy-driven transformation of an entire economy through green industrial policy: the German 'Energiewende'. We compare wind and solar PV electricity promotion along five central green industrial policy aims: fostering competitiveness, inducing innovation, creating jobs, mitigating climate change and minimising cost to consumers. These policy aims are not always in harmony, and even when they are, vested interests may prevent the required shift from polluting to clean economic activities. The energy sector is a prime example for these challenges. Energy literally powers economic development. Hence, energy policy must be considered as a cornerstone of any industrial policy, regardless of the latter's specific objectives, approach and implementation. Through its impact on energy availability in general, and through more specific measures targeting the promotion of different energy sources and their relative prices, energy policy has a strong influence on an economy's competitiveness, employment, sectoral diversification patterns, trade position and long-term technological trajectory. As a result, energy policy is invariably designed and applied within a veritable minefield of stakeholders, interests, conflicts and alliances. It requires a long-term planning perspective and a holistic look at political, social, economic and technological challenges and scenarios. Above all, energy policy fundamentally determines a country's future basic infrastructure for decades ahead and thus creates strong lock-in effects and path dependency (Lecocq and Shalizi, 2014;Unruh, 2000). It is a field of economic policy that does not lend itself to frequent shifts and reorientations unless huge investments are to be turned into stranded and wasted assets (Rozenberg et al., 2014). The above applies in particular in the context of the German case. The country is amidst a fundamental energy transition (Energiewende), which involves a complete phase-out of nuclear energy and a deliberate policy of reliance on renewable energy sources. This necessitates a basic consensus on societal preferences, resulting energy policy aims and the way ahead. In a somewhat stylized perspective, German society has generally been characterized by a strong technological risk aversion; more specifically, the nuclear exit policy commands broad political and popular support and such technological options as carbon capture and storage or hydraulic fracturing meet with strong public opposition. Also, climate change considerations figure high on the agenda of societal concerns. The issue of energy prices currently somewhat dominates the debate around energy policy, both for industrial and household consumption, and this has become one of the essential yardsticks for assessing the progress and prospects of the ongoing energy transition towards renewables. The swift transition to various renewable energy sources primarily for electricity generation (but also increasingly for heat generation and fuels) constitutes the centrepiece of German energy policy. For the purpose of this paper, an exclusive focus on electricity generation is adopted. Based on own calculations and a review of existing literature, the paper aims to provide an up-to-date assessment of what has become a fierce controversy. We compare solar photovoltaic (PV) and wind energy along five dimensions: (1) competitiveness, (2) innovation, (3) job creation, (4) climate change mitigation, and (5) cost. These aims are derived from policy statements on the objectives of the energy transition presented in Section 2, along with the methods used to assess the costs and benefits of the policy measures applied. This assessment is a complex undertaking fraught with diverse methodological challenges. Political positions and lobbying often guide seemingly technical calculations. An attempt is thus made to rely to the extent possible on quantitative assessments and clearly spell out the underlying assumptions. We use revealed competitive advantages as indicators for competitiveness, relative patent shares for innovation, gross number of jobs for job creation, and tons of CO 2 avoided for climate change mitigation. We contrast those with the differential cost of the feed in tariffs for wind and solar PV, respectively. Section 3 presents and discusses the results of the assessment for both technologies separately and in direct comparison. We find that wind energy performs better in all dimensions, but argue in the concluding Section 4 that this does not result in the imperative to concentrate exclusively on wind energy support. The assessment at hand is a snapshot of current performance, while the necessary systemic and long-term perspective for transforming the energy sector suggests the need for a balanced mix of a variety of clean energy sources.",
            "Methods": "",
            "The German energy transition: objectives and measures": " A national priority project of the highest order, such as the energy transition, is invariably governed by a complex set of objectives. To some extent, these have been officially pronounced and codified in legal documents. In addition, they can be derived from ministerial policy statements and publications. With the Renewable Energy Sources Act (EEG) being the most important green energy policy law, its expressed policy objectives deserve prime consideration (Renewable Energy Sources Act -EEG 2012). In its Article 1 on the purpose of the law, the following objectives are listed: \"Sustainable development of energy supply.\" \"Protecting our climate and the environment.\" \"Reducing the costs of energy supply to the national economy.\" \"Further development of technologies for the generation of electricity from renewable energy sources.\" In various publications, statements and speeches by the relevant Government entities (Ministry of Environment, Nature and Nuclear Safety; Ministry of the Economy and Technology, as well as the Chancellor herself), the energy transition is portrayed as contributing to: Strengthening Germany's leading global market position for climate-friendly technologies. Ensuring reliable and affordable energy supply to maintain competitiveness. Boosting innovative capabilities of industry. Creating employment opportunities from renewable energy development.",
            "Mitigating climate change.": " Saving scarce resources and reducing import dependency from fossil fuels. In general, renewable electricity promotion policies in Germany are built around the concept of feed-in tariffs (FiT), whose core elements were established as part of the EEG in 2000. They are complemented by dedicated renewables loan programmes, as well as various types of support to research and development activities (R&D) (direct funding, demonstration projects, innovation alliances etc.) as part of science and innovation policies. Neither local content policies nor government procurement or renewables purchase obligations (outside the EEG-FiT, which constitutes a de facto unlimited purchasing commitment) are in place at either the federal or the state level. The German renewables policy scenario can thus best be characterized as being a combination of a robust legal and policy framework, sustained funding of a diversified set of research institutions and an emphasis on price-based rather than quota-based investment incentives. Presently (early 2014), a fierce debate is raging in Germany on the impact and further adjustment needs of the EEG (see, for example, Diekmann et al., 2012a;EFI, 2014;Fraunhofer ISE, 2014). One trigger is the massive and unanticipated expansion of solar PV installations under EEG provisions. With PV panel prices down by more than 60 per cent over the last six years, the expansion of capacity has exceeded government targets by a factor of two. Against this backdrop, political negotiations are ongoing in the new coalition government on a proposal to rein in future capacity expansion. Specifically, the proposal envisages the introduction of ceilings for future capacity growth, strong reductions of future FiT rates and an ambitious degression scale. In the following sections, we aim to contribute to a rational basis for decision making on the future of the German EEG, and the system of FiTs in particular, by contrasting cost estimates with quantitative indicators for benefits of solar PV and wind energy support.",
            "Methodological approach": "",
            "Cost assessment": " The German feed-in tariff (FiT) approach has become an \"export success story\" in itself, and, to date, has been replicated in essence (with variations in detail) in more than 50 countries worldwide. It continues to be widely recognized as a benchmark for effective policy design in support of renewable energy expansion. Therefore-and also in view of limited annualized data availability for the volume and terms of renewable energy loans, as well as R&D expenditures-this paper will focus entirely on seeking to assess the cost-effectiveness of this policy instrument. To this aim, we present estimates on the differential cost of the FiT, that is, the difference between FiT rates and the electricity market price. It is important to note that this estimate includes distributional effects, and is thus higher than the macroeconomic cost of wind and solar PV energy production induced by the FiT. This differentiation is essential, although not always made explicit in the literature. The additional macroeconomic costs themselves arise from the fact that electricity production from most renewable sources is still more expensive than from conventional sources. These costs can be measured as the difference between the levelized cost of electricity (LCoE) generated from renewable sources and the LCoE of non-renewable sources. 1 If a FiT is to induce investments in renewable energy, it needs to cover these costs and a reasonable markup as compensation for the added risks of such investments (for example, resource and technology risks, or social acceptance risks, see Waissbein et al., 2013). The markup, however, does not add to macroeconomic costs. It is rather a redistribution of funds from electricity consumers to producers of renewable energy. In the case of Germany, this is reinforced by the exemptions granted to energy intensive enterprises, which raise the burden on the remaining consumer groups. Since the burden on consumers features prominently in the public debate, we chose to use the differential costs, including the distributive markup component, instead of actual macroeconomic costs as an indicator for the cost dimension. The shares of the FiT-related differential costs attributable to wind and solar PV are calculated based on the average annual FiT paid (in \u20acct/kWh) between 2005 and 2013. For each energy source and the volume of electricity fed into the grid, the total amount of paid-out FiT is calculated and compared with the prevailing electricity market prices, thus arriving at the differential costs (BDEW, 2013). 2",
            "Benefits assessment": " After assessing the cost, we proceed to identifying the positive impact of support policies. What have been the benefits generated in terms of building up new competitive industries, fostering innovation, creating employment, and contributing to fighting climate change? Only after having assessed both the costs and benefits of policy interventions in favour of renewables will it be possible to meaningfully assess the question of cost-effectiveness. We rely on two indicators to assess the development of Germany's competitiveness in wind and solar PV: world market share, defined as the share a country has in world exports for a given product, and revealed competitive advantage (RCA). 3 The RCA is one of the most commonly used competitiveness indicators. It compares the export-import ratio of one product to that of all products for the same country. The values of RCA can vary hugely and theoretically reach infinity. In order to be able to present the values better in graphs, we use the ln (logarithmic) function, \"normalize\" the values using the tanh function (tangens hyperbolicus), and multiply by 100: tanh(ln(RCA))n100 (see also Eichhammer andWalz, 2009, with data coverage up to 2008). In this approach, positive numbers indicate a competitive advantage. In terms of data sources, we rely on the United Nations Commodity Trade Statistics Database (UNCOMTRADE, 2013). 4  The product nomenclature used originates from the Harmonized System (HS, 1996), which is available at the 6-digit level. Specifically, for wind energy and solar PV, it offers the following two product groups: 850231: \"Other generating sets-wind powered\" (referred to below as wind converters). 854140: \"Photosensitive semiconductor devices, including photovoltaic cells whether or not assembled in modules or made up into panels; light emitting diodes\" (referred to below as solar PV). Two caveats are in order: First, it needs to be understood that the RCA approach of measuring competitiveness cannot discriminate between specialization patterns rooted in structural economic determinants (factor endowments, productivity etc.) and those caused by trade policy interventions. For instance, a country's temporary recourse to import restrictions or export dumping practices would translate immediately into an improved RCA value. Second, in a few cases annual fluctuations of country-specific export and import data are of such an immense magnitude that doubts arise as to their accuracy. However, UNCOMTRADE data cannot be verified here and must be assumed as being correct. The measurement of innovation dynamics is notoriously difficult. In the absence of sufficient company-level data on R&D investments, international patent data can be a useful proxy indicator. However, evidence needs to be treated with care. Results will differ in accordance with the database applied, the country in which a patent has been filed, the reliance on either patent applications or patents granted as well as the inventor's or applicant's home country. Also, the significant time required for processing a patent registration and the incidence of cross-sectoral patent use (e.g., electronics patents applied in solar PV; machinery and automotive patents applied for wind turbine gearboxes) would ideally need to be considered. Lastly, patents can only indicate those aspects of the innovation process which are based 1 Levelized Cost of Electricity (LCoE) is calculated on the basis of the total expenses (investment, operation, maintenance, replacement, insurance etc.) of a project over its entire life span. These are discounted to the same reference point and divided by the present values of the electricity output. For a critique of various concepts of LCOE and grid parity see (Bazilian et al., 2013). 2 While the average electricity price per household rose from 19 to 29 ct/kWh between 2005 and 2013, the FiT for onshore wind remained constant at about 9 ct/ kWh whereas the FiT for solar PV fell from 53 to about 30 ct/kWh. 3 Following Eichhammer and Walz (2009), our calculation of the RCA differs from Balassa's (1965) original concept, which is solely based on export performance. 4 Available at: http://comtrade.un.org. on patented knowledge (Fraunhofer ISE, 2014). They thus provide only part of the picture. The results presented in Figs. 7 and 8 are based on the OECD Patent Database (as updated in January 2013 with data up to 2010, OECD, 2013). They cover patent applications (not patents granted), which are generally considered to be a better indicator for innovation dynamics. The relative patent shares (RPS) have been calculated by using the same methodology as applied earlier for calculating revealed competitive advantages. RPS thus compares, for a given country, the world share for a patent of one specific technology with the world patent share across all technologies. The solar and wind technology sectors have grown into significant providers of employment in the German economy. While no data are available on the number of net jobs created, there are reliable data on gross employment creation both directly through capacity investment and indirectly through maintenance, operation and other support activities. To assess the environmental benefits of the FiT, we rely on directly avoided carbon dioxide (CO 2 ) emissions for which consistent time series data are available. Data in Table 3 are based on applying specific substitution factors for wind energy and solar PV, respectively. This is relevant in view of the fact that the emission intensities of coal, lignite and natural gas differ substantially. More specifically, the following substitution patterns are assumed: For wind energy: coal 80 per cent, natural gas 17 per cent and lignite 3 per cent, For solar PV: coal 75 per cent, natural gas 22 per cent and lignite 3 per cent.",
            "Costs and benefits": "",
            "Costing the feed-in tariff": " Figs. 1 and 2 present the shares of the FiT-related differential costs attributable to wind and solar PV, respectively. From Fig. 1, it can be seen that the combined projected differential costs for wind energy and solar PV promotion amount to close to \u20ac12 billion in 2013-almost double the amount of 2010. Moreover, Fig. 1 clearly shows a pattern of a relative increase in the weight of solar PV: between 2005 and 2013, the ratio of total solar PV subsidies to total onshore wind subsidies (in \u20ac million) rose from 0.4 to 3.0, i.e., from less than half to three times as much. This coincided with a narrowing of the same ratio in terms of \u20acct/kWh, as shown in Fig. 2: in 2005, the average feed-in differential tariff for solar PV was 9.4 times higher than for onshore wind; in 2013 this factor was down to 4.8-the obvious explanation being the FiT reductions triggered by the phenomenal cost decreases and subsequent growth of solar PV electricity generation. While the latter grew by a factor of 27, wind-generated electricity just doubled in volume from 2005 to 2013. However, a holistic look at the composition of electricity prices is necessary with a view to putting the EEG-surcharge in perspective. Electricity prices basically result from the costs of generation, transmission and distribution; various state taxes and levies; and finally the EEG-surcharge. In 2013, the latter accounted for 22 per cent of electricity prices for households and 35 per cent for industrial consumers. In 2005, the shares were 5 per cent and 7 per cent, respectively. Thus, while contributing between one fifth and one third to total prices, the EEG surcharge has increased rapidly in recent years to become a pronounced cost factor. In the context of this growing relative weight, the distributional impact of the EEG-surcharge has become a controversial subject. In 2013, the EEG apportionment for electricity consumers, i.e., the rise in their electricity price attributable to the FiT, amounted to 5.3 \u20acct/kWh. Private households (with an electricity consumption share of roughly one quarter) have to bear 35 per cent of the surcharge while the industrial sector (with a consumption share of almost 50 per cent) accounts for only 30 per cent of the surcharge -largely a result of exemptions for energy-intensive industries. However, the financial burden to be borne by households is easily overestimated. A recent study concludes that in a scenario of a further 1.3 \u20acct/kWh increase of the electricity surcharge by 2015, additional expenditures would amount to just 0.1 per cent of the average disposable household income, although with a slightly regressive effect (Lehr and Drosdowski, 2013). Furthermore, the total subsidy costs of the FiT are not higher than the subsidies paid for electricity generated from coal and nuclear power. In a recent study, Forum \u00d6kologisch-Soziale Marktwirtschaft (2012) estimates a subsidy for fossil and nuclear energy of 10.2 \u20acct/kWh in 2012, amounting to a total subsidy sum of \u20ac40.3 billion. In essence, a visibility bias is at work here. While the subsidies for renewables appear explicitly as electricity surcharge on the power bill of end consumers, subsidies for conventional energy sources are embedded in state budgets. This applies not only to direct subsidies and tax incentives, but more importantly, to external costs such as environmental damage, the costly search and management process of nuclear waste disposal sites, and the risk of nuclear incidents.  ",
            "Assessing the benefits of the energy transition": "",
            "Competitiveness": " The notion of competitiveness is one of the most fundamental concepts in economics. However, exactly how to define and measure competitiveness and how to delineate its meaningful remit has remained highly controversial, in particular when moving up from competing firms to competing locations, sectors or entire economies and, for that matter, nations. Famously, Krugman (1994) went as far as branding competitiveness as a \"dangerous obsession\" of policy-makers. This may indeed apply to much of the popular debate and its oversimplifications, yet it does remain a valid concern-economically and politically-to ascertain how goods produced in a country can stand the test of international market acceptance and how they fare in relation to the same goods produced elsewhere. This section therefore reviews the competitiveness of the German wind energy and solar PV industries. The pioneering FiT introduction had created such a strong domestic market pull that early export efforts were effectively stifled. A similar pattern can be observed for the revealed competitive advantage: its values increased sharply in 2005 and kept growing in the period up to 2012. In terms of comparator countries, the recent growth in China's and Spain's market shares is to be noted, as is the rapid and consistent loss of market shares by Denmark. Beyond the aggregate data presented in the charts, industry analysts underline the particularly strong competitive position of German companies when it comes to offshore turbines (and offshore wind parks in general), as well as large-scale onshore turbines above 5 MW capacity. A particular driver of competitive strength originates from a classical technology cluster constellation in the four Northern states of Lower Saxony, Schleswig-Holstein, Bremen and Hamburg.5 This so-called North Western Region Wind Power Cluster has grown into a densely interconnected web of more than 300 partners-comprising globally leading turbine manufacturers, specialized component suppliers, wind park operators, local governments and cutting-edge research institutions. The cluster boasts some of the industry's major innovations (e.g., the development of the 5 MW offshore turbine and the offshore test site Alpha Ventus). At the same time, the wind cluster also owes some of its success to the long-standing track record of Germany's engineering, machinery and power sectors in general. Without the foundation of highly advanced manufacturing capabilities and skills across a whole range of industries, the German wind energy sector would not have been able to achieve global technological leadership. 3.2.1.2. Solar PV competitiveness. The global solar PV market, even more so than other renewable energy markets, is a highly political  market shaped by trade subject to significant government interventions. The recent EU-China trade dispute around subsidized solar panel exports and alleged dumping practices bears testimony to this feature. Hence, analysing revealed competitive advantages must be seen with this caveat in mind. Figs. 5 and 6 clearly demonstrate a relatively lower international competitiveness of the German solar PV industry compared to the German wind energy industry. A temporary increase in the world market share up to 2008 (15 per cent) could not be sustained: in 2012, this share fell back to its pre-2005 level of below 10 per cent. Background data show that German exports of solar PV were almost cut in half between 2010 (US$8.1 million) and 2012 (US$4.5 million). Similarly, we can witness a consistent revealed competitive disadvantage over the entire period from 2000 to 2012. In terms of comparator countries, the spectacular rise of China stands out. By 2010, the country was in the leading position in both indicators presented here. Other than the German wind industry, which is under pressure but not endangered by China (Lema et al., 2013), the German solar PV industry has lost its competitive edge. Beyond the aggregate data presented in the charts, the strong competitive position of German PV system component manufacturers and equipment suppliers must be emphasized. Data for 2011 show that the share held by German firms in the global market for specialized PV equipment was as high as 50 per cent, while the market share of PV inverters (converting the direct PV cell current into alternating grid current) stood at 35 per cent (GTAI, 2013, fact sheets).",
            "Technological innovation": " A positive value in Figs. 7 and 8 indicates that the technology under consideration has a superior patent (innovation) position compared to the entire technology portfolio of a country. It emerges that in the case of Germany, wind energy-after a trend reversal in 2005-has consistently achieved a positive RPS (value of \u00fe26 in 2010), while the opposite applies for solar PV. From a moderately positive RPS up to 2006, the trend has been downwards resulting in negative RPS as of 2009 (with a value of \u00c0 13 in 2010). Background data show that between 2005 and 2010, the absolute number of German wind energy patents more than tripled; the number of solar PV patents increased by one quarter. These results are corroborated by a similar analysis undertaken for 2009 based on European Patent Office (EPO) data (Bointner, 2012) in which the gap between a positive RPS value for wind technology and a negative RPS value for solar PV technology is even more pronounced. They are further substantiated by a recent broader cross-country analysis of green technology patents based  on World Intellectual Property Organization's (WIPO) classification (Bierenbaum et al., 2012), which led to the following results (for the 1990-2010 period): While trailing behind the U.S. and Japan in terms of the absolute number of \"green\" patents 6 granted, Germany exhibits the highest per capita green patent intensity of all countries worldwide. In wind energy technology, Germany is comparatively stronger as an innovator (measured as share of cumulative global wind patents) than as an adopter (share of installed global wind power capacity) although the difference, with 21 per cent and 14 per cent respectively, is relatively small. In solar PV technology, Germany is comparatively stronger as an adopter than as an innovator, with a 44 per cent share of installed global capacity and only 12 per cent share of global cumulative patents. In general, there seems to be a closer alignment between innovation and deployment trends in the case of wind energy, while for solar PV, innovation and deployment hubs may be decoupled as PV technology is more easily transposable to countries with the most conducive incentives structure for large-scale deployment (Lee et al., 2009). From the same study, it emerges that several German wind energy companies are among the top 20 patent holders (Enercon 7 indeed is number 1, followed by Siemens at number 7) whereas in the case of solar PV patents only Siemens figures at number 20.",
            "Employment creation": " Of the almost 380,000 total jobs created by renewable energies in 2012 (for the first time, down from the previous year), more than half (54 per cent) were accounted for by solar PV (23 per cent) and wind energy (31 cent) alone (Table 1). Based on the two sources below Table 1, the following structural features stand out: While the majority of jobs stem from investments into solar and wind installations, the share of jobs related to maintenance and operation services is growing. This applies in particular to onshore wind, where the share of maintenance and operations jobs is as high as 16 per cent. For solar PV, the same share stands at 10 per cent. Despite the 2012 slump in new solar installations, maintenance and operation jobs kept growing. Export markets play an essential role in employment creation. For all renewables, in 2012 the domestic market generated 59 per cent of investment-related jobs, with export markets accounting for 41 per cent. In view of the above-average export ratio of electricity-generating technologies, exportdriven employment must be even higher for wind energy and solar PV. The regional distribution of employment is more dispersed than often assumed. While there is a basic pattern of more wind installations in the Northern and Eastern coastal regions and a higher solar PV intensity in Southern federal states, component-driven employment is often located in the traditional industrial centres. At the same time, an important inequality-reducing impact is noticeable: In those Eastern federal states suffering from the highest unemployment ratios nationwide (with the exception of city states), the relative importance of solar and wind employment is most pronounced. Specifically, this applies to Mecklenburg-Western Pomerania, Saxony-Anhalt and Brandenburg with unemployment rates (June 2013) of 10.8 per cent, 10.7 per cent and 9.5 per cent, respectively. In terms of the skill profile of the labour force (see Table 2), employment in both the solar PV and wind energy industry is very much in line with the comparative advantage of a sophisticated labour market in a high-tech economy like Germany's. While there is a negligible share of unskilled labour, in both the wind and particularly the solar PV industry the share of university-degree staff is around three times as high as the national industry average.",
            "Environmental benefits from avoided emissions": " As emphasized in Section 2, from the outset one of main drivers of renewable energy promotion in Germany has been the political commitment to achieving ambitious goals of reducing greenhouse gas emissions in the fight against climate change, as well as reaching environmental objectives in terms of reducing various pollutants. Hence, the question of exactly what level of avoided emissions can be attributed to the growing deployment of wind energy and solar PV is of particular importance. In Table 3, we take a look at directly avoided carbon dioxide (CO 2 ) emissions for which consistent time series data are available. It emerges that between 2005 and 2012 the amount of avoided CO 2 emissions has more than doubled from 23.8 million tonnes to 56.5 million tonnes. The contribution of wind energy and solar PV to reducing Germany's carbon footprint thus is of significance at the broader national level: In 2012, both sectors combined avoided a Includes also jobs created by fuel supply activities (biogas, biomass, biofuel), as well as related jobs in public institutions (R&D, administration). 6 According to WIPO's Green Inventory, \"green patents\" cover alternative energy production patents in 13 sectors: solar, wind, geothermal, biofuel, biomass, fuel cell, hydro, synthetic gas, integrated gasification combined cycle, man-made waste, mechanical power from muscle energy, natural heat and waste heat. 7 Enercon patents are registered under the name of Aloys Wobben, who founded the company in 1984 and has remained its owner to date. CO 2 emissions amounting to 6.9 per cent of total CO 2 emissions, or 17.8 per cent of CO 2 emissions caused by electricity generation. When considering the entire 2005 to 2012 period, more than one tenth (11.3 per cent) of electricity-related CO 2 emissions could be prevented. Numerous life cycle assessments of the ecological balance sheet of alternative energy sources have been undertaken in recent years. The overall result of a comparatively much smaller carbon and ecological footprint of wind energy and solar PV than, for example, coal-based electricity, is unequivocal (IPCC, 2011). Relevant data for Germany lead to the conclusion that in terms of CO 2 , coal-based electricity generates around 100 times more emissions per unit than wind energy and 10-20 times more than solar PV (Krewitt and Schlomann, 2006, p.35). In assessing the ecological impact of the FiT, it must be noted that greenhouse gas emissions in the European context are traded under the European Emissions Trading Scheme. Any FiT-induced lowering of CO 2 emissions reduces demand for certificates, cuts their price, and thus discourages investments in emission reductions elsewhere (B\u00f6hringer andRosendahl, 2010, 2011). On the other hand, the lower price of certificates opens political space for tighter ETS caps without threatening the competitiveness of companies. Without such tighter caps, however, the parallel operation of FiT and ETS will crowd out the former's emission reduction benefits-at least for those emissions traded under the ETS. Nonetheless, literature finds many arguments for operating both systems in parallel, such as the long term aspect of developing technologies for carbon neutrality (Vogt-Schilb and Hallegatte, 2014), political economy arguments (Jenkins, 2014;Rozenberg et al., 2014), investment certainty for low carbon investments (Lecuyer and Quirion, 2013) and cost reductions through learning and spillover effects (Fischer and Preonas, 2010).",
            "Contrasting wind and solar PV": " In Fig. 9, a stylized summary of the main quantitative results of Section 3 is presented, complemented by the EEG differential costs as proxy for the additional cost of wind and solar. While not amounting to an objective assessment of each sector, the comparison between wind energy and solar PV would indicate that the wind energy sector is leading in all performance dimensions: employment creation, competitiveness, technological innovation and avoided CO 2 emissions-and does so with lower subsidy levels. Also in terms of medium-term projections of the LCoE for wind energy and solar PV in Germany (Fraunhofer ISE, 2012), onshore wind plants are considered to remain the most cost-effective renewable energy technology. Currently at 8 \u20acct/kWh (at 2000 full-load hours per year), the LCoE for onshore wind energy is forecast to marginally decrease further to 7 \u20acct/kWh in 2030. While solar PV systems are expected to remain more costly, they are coupled with much faster cost decreases due to a steeper technological learning curve. Overall, this would lead to onshore wind plants becoming cost-competitive with a conventional (fossil plus nuclear) electricity mix by 2017, while the same would apply for ground-mounted solar PV systems by 2022. The above stylized comparison of solar PV and wind energy has a number of broader industrial policy implications, which will be discussed in Section 4.",
            "Conclusions and policy implications": " While green industrial policy in Germany targets many sectors (for example resource-efficient environmental technologies, waste management, biofuels production or electro-mobility), the energy transition (Energiewende), with its focus on renewable energy sources is certainly the most prominent national project. It places Germany among the most ambitious countries worldwide in the promotion of a transition to sustainable energy. However, public debate in Germany about the Energiewende in general and its different features in particular is highly politicized, and often driven by ideology or vested interests. This paper has sought to Source: Based on Tables 1 and 3, and Figs. 2, 4, and 6-8 in this paper. provide a balanced assessment drawing on the best available evidence and quantifying explicitly what costs and benefits are excluded or included. Germany has a variety of policies in place to support the Energiewende. Among them are mechanisms targeting all stages of renewable energy technology development from basic research to deployment. The system of feed-in tariffs (FiT) is the core element of Germany's policy package, and as such deserves closer analysis. In the energy policy community, there is widespread agreement that the FiT mechanism in general, and its application in Germany in particular, has proven to be an exceedingly effective policy instrument for pushing renewable energies into the market (Haas et al., 2011;Held et al., 2006;Matschoss, 2013). Its efficiency, however, hinges on the appropriate determination of tariff levels. Based on a comparative assessment of renewable energy support policies in its member states, the European Commission concludes that \"well-adapted feed-in tariff regimes are generally the most efficient and effective support schemes for promoting renewable electricity\" (EC, 2008, p.3). Experiences in the emerging countries have shown that competitive bidding may be a suitable approach to identify the actual levels of such well-adapted feed-in tariffs (Becker andFischer, 2013, Pegels, 2014), and Germany could be well advised to 're-import' some such elements when reforming its own support scheme. 8The German FiT scheme is characterized by a long contract period (20 years), guaranteed grid priority, technology-specific tariffs on a degressive scale and recently, provisions for tariff evolution in response to deployment trends (flexible ceiling). These design elements have created a stable investment environment and hence a strong readiness of capital markets to finance renewable energy projects at relatively low interest rates. Furthermore, the technology specificity-with differing FiT subsidy bands for each source of renewable energy-has had the advantage of encouraging the early deployment and upscaling of a wide spectrum of technologies. On the downside, it has not allowed for a focus on the most cost-efficient decarbonization technologies. A premium was thus placed deliberately on creating a broad foundation for various renewable energy technologies to develop and become commercially viable. However, this premium seems to have led to a bubble in the German solar PV manufacturing industry. Obviously, the critical challenge is to identify a sufficiently high subsidy level for investments to be triggered without creating excessively high policy rents (Pegels, 2014). This presupposes correct assumptions about future technological learning curves and price trends as a basis for taking well-informed decisions about an optimal tariff degression scale. The assumptions in the case of solar PV did not correspond to the considerable cost reductions of PV installations since 2009. Fig. 9 seemingly presents an unequivocal outcome of the comparison between wind and solar support, showing the superior performance of wind energy for all indicators. However, the policy implications these empirical findings are less clear-cut than they may appear at first glance. Should all eggs be put into the wind basket? In the direct comparison of wind and solar energy, the answer could be \"yes,\" on grounds of cost-efficiency and broader benefits. Yet just like in the case of financial investments, there are advantages to be had from diversification. Hence, Fig. 9 needs to be interpreted dynamically and from a systemic perspective. While wind energy currently performs better, the data presented is only a It may be wise to also support solar PV and, for that matter, a variety of other sources of renewable energy. The technology learning curve of solar PV may still promise strong cost reductions, while wind energy is already mature (Diekmann et al., 2012b). The solar resource and thus deployment potential in other world regions may further support these reductions. Once a particular energy source achieves grid parity, deployment may increase steeply and give other performance indicators a boost as well. Technologies in their earlier stages may also hold a higher potential for innovation than their mature counterparts. This includes solar PV, but also such other early stage renewables as offshore wind or tidal and wave energy. Innovation as an aim of green industrial policy could thus benefit from the diversified support of renewable energy technologies. However, diversification as such does not guarantee success in fostering innovation and competitiveness. Has the policyinduced creation of a lead market led to a first-mover advantage Is it more a question of the early bird catching the worm or the second mouse getting the cheese? On the one hand, Germany has succeeded in building up world-class renewable energy technologies and has captured large segments of the world market. If well exploited, this lead position can secure competitiveness, employment and positive innovation dynamics for years to come. On the other hand, there are strong elements at play here of other countries appropriating part of the benefits of Germany's lead market role. This may be seen as a \"successful internationalization of the photovoltaic strategy (and)\u2026 a tribute to Germany's contribution to meeting global energy and climate challenges\" (Diekmann et al., 2012a, p. 3). Alternatively and in a more pointed manner, the verdict may be that \"German households have, through the renewable subsidies they pay, made the world a gift of solar technology which China has now been happy to exploit\" (Buchan, 2012, p.4). It is hard to escape the conclusion that the deployment of solar PV in particular has in recent years been out of line both with its long-term expansion potential and its reasonable relative weight within the renewable energy mix-in a country with less-thanideal climatic conditions for heavy reliance on solar energy. Also, in the harsh judgment of Eicke Weber, Director of Fraunhofer ISE, \"Germany's energy policy has created a market for photovoltaicsnot an industry\" (Paris Tech Review, 2012, p.5). This indicates that deployment under the soft conditions of heavy subsidies was given priority, without sufficient attention to forming an innovative industry pushing the technological frontier. In a nutshell: expansion was put above upgrading. However, at the broader level of the energy system and within a supply scenario increasingly based on renewable energy, a variety of different intermittent sources in the electricity grid are required to support overall grid stability-the sun may shine when the wind does not blow. This contributes to security of supply, in particular if investments in transmission lines keep pace and connect geographically dispersed locations of renewable electricity generation. Unfortunately, German investments in grid expansion and solutions for electricity storage lag behind requirements. The systemic perspective cannot, however, be restricted to renewables: the energy sector must be seen in its entirety. The pace of German renewable energy deployment has taken many actors by surprise. This has led to unintended effects on energy planning, which in turn affect the overall aims of green industrial policy, in particular its environmental dimension. To safeguard energy security, Germany currently operates two energy systems in parallel: a base-load focused, centralized and fossil fuel-based system; and an intermittent, decentralized and renewable system. These systems increasingly interact. To compensate for the phasing out of nuclear power, the German government has decided to support highly efficient new coal and gas fired power stations, financing this support out of the Energy and Climate Fund (Deutsche Bundesregierung, 2012). Together with the unexpectedly high generation from renewable sources, Germany currently produces much more electricity than it consumes. In 2012, electricity exports exceeded imports by a record level of 22.8 terawatt hours (TWh), up from 6 TWh in 2011 and 17.6 TWh in 2010 (Statistisches Bundesamt, 2013). This oversupply, combined with low input prices and the low price of carbon emission certificates traded under the European Emissions Trading Scheme, reduces electricity prices to the extent where at times only the cheapest sources are still competitive, that is, hard coal and, in particular, lignite in the case of Germany. Lignite, however, is exceedingly damaging to the environment and human health. As a result, total German carbon dioxide emissions have been stagnating in the past four years, and even rising in 2012 (Umweltbundesamt, 2013b). Paradoxically, the rapid deployment of renewables thus does not currently lead to decreasing total greenhouse gas emissions. At the same time, the low electricity prices at the stock exchange do not improve the competitive position of small and medium enterprises. Including 99 per cent of German enterprises and providing more than 60 per cent of jobs (May-Strobl and Haunschild, 2013;2012), the Mittelstand is widely considered as the backbone of Germany's economy. However, their electricity prices are among the highest in Europe-at least partly due to the added cost of renewables (DIHK, 2012). The blow to the competitiveness of the largest electricity consuming companies is softened by exemptions from the electricity surcharge. These, however, call the equity of the current support system into question, since they raise the burden on households and small and medium enterprises. To reach the broader aims of green industrial policy and manage the energy transition effectively, Germany will need to address the systemic challenges outlined above. Special emphasis is to be put on three broader dimensions: institutional fragmentation, interacting policy schemes and transformational alliances.",
            "Institutional fragmentation": " As discussed by Zelli (2011) and Zelli and van Asselt (2013) in the context of climate governance, institutional fragmentation may have negative implications for effectiveness, legitimacy and fairness of policies. Since the promotion of wind energy and solar PV in Germany is part of a much more fundamental agenda of transitioning to a decarbonized development trajectory, issues of institutional fragmentation and distributed responsibilities are particularly relevant. The contribution of renewables to electricity generation has reached proportions that call for simultaneous policy attention to capacity expansion, competitiveness, technological innovation, grid management and storage capacities, i.e., a systemic perspective. However-and this may be surprising for a country often portrayed as a poster child of institutional effectiveness-the current institutional setup leaves a lot to be desired. Several federal ministries have important roles to play, and specialized subsidiary agencies are proliferating. There is thus a strong case for pooling the political responsibilities. This could be all the more important given that in the typical German scenario of a coalition government, there is a high likelihood of interlinked functions being spread across political party lines.",
            "Interacting policy schemes": " The FiT policy tool as the cornerstone of Germany's energy policy is not operating in complete isolation. In fact, it runs parallel to the European Emissions Trading System (ETS). The interactions between both policy spaces thus need to be analysed. On the one hand, it can be argued that any FiT-induced lowering of CO 2 emissions would lead to the availability of additional certificates, which, once sold, would generate corresponding emissions elsewhere. On the other hand, the political decision of where exactly to fix a cap for emissions may itself be partly influenced by anticipating trends of future renewables capacity (Lechtenb\u00f6hmer and Samadi, 2011, p. 10). In essence, the parallel operation of FiT and ETS will crowd out most of the former's emission reduction benefits-not, however, the other benefits it creates. A second dimension of policy interaction is related to transcending national boundaries. Quite obviously, the multiplicity of national FiT schemes, for example in the European Union, is an ineffective response to the potential of a unified European energy policy. A unified European, or even trans-Mediterranean, grid could largely balance out inherent grid instability caused by intermittent renewable energy sources. At the same time, there is a danger of a conceivable common approach being designed as the lowest common denominator of conflicting country interests. As a result, the more ambitious energy policy of Germany as a lead market for renewables may be severely compromised.",
            "Transformative alliances": " Rightly or wrongly, green industrial policies in Germany are almost equated today with the energy transition. We are dealing with a national project of the first order. There are winners and losers, proponents and adversaries. In this economically and politically highly charged setting, the formation of transformative alliances and the definition of a compelling narrative are key (Schmitz et al., 2013). Such alliances may see unlikely bedfellows. Just as parts of the business establishment are embracing the transition and investing into the energy technologies of the future, heavy resistance is coming from parts of the traditional green movement. Alliances will thus have to go beyond conventional boundaries. Having created the largest lead market for upscaling deployment and having brought down prices of renewables is not going to be a winning argument in the public discourse. The German FiTdriven renewables revolution may have been \"arguably the most successful development cooperation programme ever in this field\" (Hombach, 2013), making off-grid renewable electricity affordable in remote areas of developing countries. However, this is not the yardstick used by the German public at large when assessing costs and benefits. In Germany, any transformative alliance can only succeed if it builds on a platform of employment, competitiveness and innovationa platform that is currently endangered both by the emotionally charged debate around imports of solar PV panels from China (Schmitz, 2013, p. 9) and the debate around electricity price hikes. Furthermore, the creation of decentralized energy systems and hence strengthened regional and economic structures (above all in economically weak regions) should be highlighted more than hitherto."
        }
    },
    "10.1016/j.enpol.2013.06.004": {
        "file_name": "7 CO2 emissions and economic activity",
        "title": "CO 2 emissions and economic activity: Short-and long-run economic determinants of scale, energy intensity and carbon intensity",
        "abstract": "We analyze the short-term and the long-term determinants of energy intensity, carbon intensity and scale effects for eight developed economies and two emerging economies from 1973 to 2007. Our results show that there is a difference between the short-term and the long-term results and that climate policy are more likely to affect emission over the long-term than over the short-term. Climate policies should therefore be aimed at a time horizon of at least 8 years and year-on-year changes in emissions contains little information about the trend path of emissions. In the long-run capital accumulation is the main driver of emissions. Productivity growth reduces the energy intensity while the real oil price reduces both the energy intensity and the carbon intensity. The real oil price effect suggests that a global carbon tax is an important policy tool to reduce emissions, but our results also suggest that a carbon tax is likely to be insufficient decouple emission from economic growth. Such a decoupling is likely to require a structural transformation of the economy. The key policy challenge is thus to build new economic structures where investments in green technologies are more profitable.",
        "label": "Quantitative",
        "text": {
            "Introduction": " The European Union member states have agreed on five headline targets for 2020. Two of these targets are high employment and reducing greenhouse gas emissions by at least 20% compared to the level of carbon dioxide (CO 2 ) emitted in 1990 (European Commission, 2010). Similarly, Australia has recently introduced a carbon tax, which will be replaced by an emissions trading scheme in 2015 (Australian Government, 2011). While there is strong consensus in scientific communities that rising global temperatures must be combated, there is also a concern that implementing emissions reductions too quickly will limit economic growth. Without rapid development of low-carbon technologies, reducing greenhouse gas emissions will conflict with other socioeconomic targets such as low unemployment and sustained economic growth (e.g., Anderson and Karpestam, 2012;Karpestam and Andersson, 2011;Wang et al., 2011;Narayan and Smyth, 2008). Firms have an obviously important role to play in developing and deploying new green technologies (see e.g. Bode, 2006;Chimeli and Braden, 2009;Honma and Hu, 2009). But the policy maker also has a central role in building a carbon free economy. The policy maker can with the right incentives and the right level of support increase the level of investments in and the speed of diffusion of new green technologies (see e.g. Weber and Mathews, 2007;Weber, 2009). Understanding the links between economic activity and CO 2 emissions is consequently essential to designing an efficient climate policies and economic policies that reduce emissions while allowing the economy to expand. The empirical literature on the effects of economic growth on CO 2 emissions is often separated into two parts (Tol et al., 2009;Ang and Zhang, 2000): empirical evaluations of the environmental Kuznets curve (EKC) and the decomposition literature. The EKC Contents lists available at ScienceDirect journal homepage: www.elsevier.com/locate/enpol Energy Policy hypothesis (e.g., Grossman and Krueger, 1995;Selden and Song, 1994) postulates an inverted U-relationship between national income and environmental degradation that emanates from the assumption that countries will use more green technology, decrease their goods production and increase their service production as they experience economic growth. However, empirical research finds little support for an existing EKC for CO 2 emissions (e.g., Dinda, 2004;Wang et al., 2011;Jie and Rickard, 2010;Tol et al., 2009), although exceptions exist (e.g., Hsiao-Tien and Chung-Ming, 2010;Guo et al., 2010). The decomposition literature complements the EKC literature by providing additional insights into the poor empirical support for a CO 2 EKC (e.g., Grossman and Kreuger, 1991;Zhang and Ang, 2001;Sun, 1998). The decomposition literature decomposes the relationship between CO 2 emissions and economic activity into three separate channels: scale, energy intensity and carbon intensity. Scale represents changes in energy demand caused by greater use of production resources, energy intensity represents changes in the amount energy used to produce one unit of output, and carbon intensity represents changes in the amount of carbon emitted per unit of energy (Lise, 2006;Tol et al., 2009;Tol, 2007). A general finding is that both energy intensity and carbon intensity have declined in developed countries, but these reductions are insufficient to compensate for the increase in CO 2 emissions caused by the scale effect (e.g., Hamilton and Turton, 2002;Lindmark, 2004;Tol et al., 2009). Countries have, in other words, not yet reached the turning point when the declines in energy intensity and carbon intensity dominate the scale effect, which explains the poor empirical support for the EKC hypothesis. Building on the decomposition approach, we take the analysis one step further and analyze the economic determinants of the three channels for eight developed economies and two emerging economies1 from 1973 to 2007. Based on our empirical results, we discuss policy challenges and potential policies that can be used to decouple economic growth from rising emissions. From our results we draw three main conclusions. First, there is a difference between the short-term and long-term determinants of emissions. In the short term, most changes in emissions are caused by the scale effect, and over average business cycles, fluctuations in emissions of between 74% per year are expected. During more severe recessions, such as the \"great recession\" following the financial crisis of 2008, even larger temporary reductions in emissions may occur. Year-on-year reductions in emissions are therefore not an indication that any reduction targets are being met, especially not during an economic recession. Moreover, these short-term fluctuations in the economy are a normal part of the economic process and have no long-term impact on emissions. Our results also show that there is little scope for policies to affect these short-term fluctuations and that emissions should be allowed to fluctuate in the short term to avoid harming the real economy. Second, policies potentially have more effect on emissions in the long term. The real oil price, for example, affects both energy intensity and carbon intensity, which suggest that a global price for carbon could be used to reduce CO 2 emissions. However, the effect of the real oil price is limited. Third, statistical tests show that the parameters in our regression models are stable for the entire analyzed period. This implies that decoupling economic growth from emissions growth will be difficult within the present economic structures. Changing these economic structures (such that the relationships in the economy changes) should therefore be a key policy target. Changing economic structures is not easy or automatic and involves a complex process of social, political and technical experimentation and innovation (Geels and Schot, 2007;Perez, 2013). A successful climate policy is therefore likely to involve political innovations in terms of institutions, regulations and economic incentives to encourage changes both on the production side and consumption side of the economy, and government investments in key infrastructures and support for emerging technologies and markets. The remainder of the paper is organized as follows: Section 2 presents the model; Section 3 presents empirical results and discusses policies; and Section 4 concludes the paper.",
            "The model": "",
            "Long-and short-term analysis": " Economic theory distinguishes between the causes of shortterm business cycles and the causes of long-term economic growth. Business cycles are caused by unexpected events (shocks) and frictions in the economy. Frictions such as sticky wages and prices prevent the economy from adjusting to shocks immediately and thus cause the economy to temporarily deviate from its longterm trajectory. Long-term developments, on the other hand, are mostly outcomes of supply-side factors, i.e., productivity improvements, capital accumulation and employment growth (e.g., Samuelson, 1955;Goodfriend and King, 1997;Woodford, 2007), as well as macroeconomic structural changes such as changes in institutions (von Tunzelman, 2003) and radical innovations (Mokyr, 1994). In econometric modeling, it is important to distinguish between the two time horizons because regression results may otherwise lead to erroneous conclusions regarding key relationships in the economy and consequently to bad policy decisions (e.g., Ramsey and Lampart, 1998). Therefore, to capture the different operational modes of the economy over different time horizons, we decompose all variables into short-term and long-term components using a maximal overlap discrete wavelet transform (e.g., Crowley, 2007;Percival and Walden, 2006), and estimate a band spectrum regression (see Engle, 1974;Andersson, 2011) that distinguishes between the short term and the long term. Following Englund et al. (1992) and Cover and Pecorino (2005), we define the short term (business cycle) as being up to 8 years and the long term as being more than 8 years. The wavelet transform is a band-pass filter that can be used to analyze the variation of time series at different frequencies. Because we can interpret high frequencies as the short term and the low frequencies as the long term, by separating frequencies, we can identify the short-term and long-term components of our variables. Having identified the short-term and long-term components, we can then use a traditional regression model to obtain short-term and long-term parameter estimates. Several different filters can be used to distinguish between high-frequency and low-frequency fluctuations, but a particular strength of the wavelet transform is that it combines both time and frequency resolution. The combination of time and frequency resolution makes it possible to use the transform to distinguish among different frequencies when the time series data contain structural breaks, outliers and other non-recurring events, without having to prewhiten the data (Percival and Walden, 2006).2 ",
            "CO 2 emissions model": " Building on the decomposition literature (Lise, 2006;Tol et al., 2009;Tol, 2007), we model CO 2 emissions as a function of scale (S), energy intensity (EI) and carbon intensity (CI): \u00f0CO 2 \u00de jt \u00bc S jt \u00c2 EI jt \u00c2 CI jt \u00bc \u00f0S SRjt \u00fe S LRjt \u00de \u00c2 \u00f0EI SRjt \u00fe EI LRjt \u00de \u00c2 \u00f0CI SRjt \u00fe CI LRjt \u00de \u00bc \u00f0S SRjt \u00c2 E SRjt \u00c2 CI SRjt \u00de \u00fe \u00f0S LRjt \u00c2 EI LRjt \u00c2 CI LRjt \u00de \u00f01\u00de where CO 2 is the total emissions of carbon dioxide in tons, j denotes the country, and t denotes the time. SR and LR denote the short-term and long-term components of each variable, respectively. By construction, S jt \u00bc S SRjt \u00fe S LRjt , EI jt \u00bc EI SRjt \u00fe EI LRjt and CI jt \u00bc CI SRjt \u00feCI LRjt . Taking the natural logarithm and first difference of (1) yields the following expression for annual CO 2 emissions growth: \u0394ln\u00f0\u00f0CO 2 \u00de jt \u00de \u00bc \u00f0\u0394lnS SRjt \u00fe \u0394lnEI SRjt \u00fe \u0394lnCI SRjt \u00de \u00fe\u00f0\u0394lnS LRjt \u00fe \u0394lnE LRjt \u00fe \u0394lnCI LRjt \u00de \u00f02\u00de Carbon intensity is defined as \u00f0CO 2 =Energy Consumption\u00de. Data on carbon intensity are generally available from World Development Indicators,3 and we can therefore model changes in carbon intensity directly. Scale is often approximated using GDP, and it follows that energy intensity can be expressed as \u00f0Energy Consumption=GDP\u00de. In theory, the scale effect is intended to capture a growing energy demand from greater use of production resources. GDP growth is a combination of both extensive (increased use of resources) and intensive (increased productivity) growth. An increase in GDP due to more intensive use of available resources does not increase the demand for energy but rather reduces the required amount of energy needed to produce one unit of output (i.e., energy intensity). GDP is therefore an inappropriate proxy for scale. Instead, scale should be modeled using capital and labor, while productivity should be used to model changes in energy intensity. Consequently, the short-term scale component is modeled as follows: \u0394lnS SRjt \u00bc \u03b3 1 \u0394ln\u00f0c SRjt \u00de \u00fe \u03b3 2 \u0394ln\u00f0l SRjt \u00de \u00f03\u00de and the long-term scale component is modeled as follows: \u0394lnS LRjt \u00bc \u03b3 3 \u00fe \u03b3 4 \u0394ln\u00f0c LRjt \u00de \u00fe \u03b3 5 \u0394ln\u00f0l LRjt \u00de \u00f04\u00de where c is capital and l is labor. Using (4) and ( 5), the short-term energy intensity is defined as \u00f0energy consumption SRjt =S SRjt \u00de, and the long-term energy intensity is defined as \u00f0energy consumption LRjt =S LRjt \u00de. Without the parameters in (4) and ( 5), we cannot model scale and energy intensity separately. However, by estimating the following regression model, we estimate these parameters jointly with the parameters from the energy intensity model: \u0394ln\u00f0\u00f0CO 2 \u00de jt \u00de\u2212\u0394lnCI jt \u00bc \u03b2 j1 \u00fe \u03b2 2 \u0394X SRjt \u00fe \u03b2 3 \u0394X LRjt \u00fe \u03b2 4 \u0394Z SRjt \u00fe\u03b2 4 \u0394Z LRjt \u00fe \u03b5 jt\u00f05\u00de where \u0394X is a vector containing the two scale variables, capital growth (\u0394capital)4 and employment growth (\u0394labor), and \u03b2 2 contains the parameters from (3) and (4).The variables used to model the energy intensity are contained in \u0394Z. Energy intensity is modeled using seven variables: Total factor productivity growth (\u0394TFP)5 : TFP captures changes in GDP caused by all other factors except capital and labor. Consequently TFP captures, among other things, the effect on output due to less waste, new technology and more human capital, all which should reduce the energy intensity. Changes in the share of goods production (\u0394goods): The goodsproducing sector is, in general, more energy intensive than the service sector, and a larger goods-producing sector should increase energy intensity. Change in share of the population living in urban areas (\u0394urban): The urban population in most developed countries is between 70% and 80%, while in developing countries, it is usually below half that level (World Development Indicators). To sustain an urban population, more energy-intensive production methods are necessary, and a larger urban population is also associated with greater energy demand through greater transport demand (Jones, 1991), both which are related to higher energy intensity. Changes in the real oil price (\u0394oil): We use the real oil price as a proxy for the price of fossil fuels and expected it to have a negative effect on energy intensity, as higher oil prices cause firms to readjust their production processes to reduce waste and switch to alternative, less energy-demanding production technologies. Freight transport growth (\u0394TKM): Trade has increased over the last few decades as a result of globalization (Krugman and Venables, 1995). One effect of globalization and trade is a greater geographical concentration of industries. Specialization increases productivity and thus GDP but also results in greater transport demand (e.g., Rodrigue (2006)). This link between TFP and TKM increases the energy input in the average unit of output. Increases in TKM are thus expected to increase energy intensity. To capture this link between TFP and TKM, we also include an interaction variable: \u0394TFP \u00c2 \u0394TKM. The final variable is an interaction variable (\u0394Capital \u00c2 \u0394Goods): Different outputs are produced by different types of capital (Stern, 2011). The service sector commonly employs less energydemanding capital than the goods-producing sector. For example, the service sector employs a relatively larger share of information and communications capital (ICT) than the goods-producing sector and the goods sector in turn employs more machinery capital that requires more energy (EUKLEMS). The service sector has expanded in most countries since the 1970s, and to capture the effect of a reallocation from capital employed in goods production to capital employed in service production, we include the interaction variable, which is expected to have a negative effect on energy intensity. The carbon intensity is modeled as follows: \u0394ln CI it \u00bc \u03b4 j1 \u00fe \u03b4 2 Y SRjt \u00fe \u03b4 3 Y LRjt \u00fe \u03c1 jt ;\u00f06\u00de where Y is a vector containing the explanatory variables. As with eq. ( 5), we distinguish between short-and long-term effects. We use the following explanatory variables: \u0394oil: higher oil prices increase incentives to switch from oil to other energy sources. \u0394TKM: the freight transport sector is more highly dependent on fossil fuels than the average sector. Globalization has increased TKM, which may thus have increased carbon intensity. \u0394Goods: the choice of energy source is related to the production technology, which in turn is related to the nature of the output. More goods production is possibly related to a greater dependency on fossil fuels. Change in the share of electricity generated by nuclear power (\u0394Nuclear). Several countries invested in nuclear power following the first oil price shock. However, because not all countries chose to invest in nuclear power, this is effect is not captured by the \u0394oil variable, so we include nuclear power as an additional explanatory variable.",
            "Empirical results": " The empirical results section consists of two parts: first, we present the results of the estimation of our two models. Second, we analyze the determinants' contributions to changes in emissions and discuss future policies that may decouple growth from emissions.",
            "Data": " We estimate our models using data from eight developed economies and two emerging economies for the period 1973-2007. The choice of countries and time is dictated by data availability. 6 Rather than estimating one model for each country, we pool the countries in a fixed effects panel data model with dummies for country and time. The use of a panel data model is motivated by the separation between short-and long-term effects. With 35 yearly observations for each country, the number of longterm observations for each country is too small to estimate the models country by country. By pooling countries in a panel data model, we can improve the precision of the parameter estimates. 7CO 2 emissions data are collected from the Carbon Dioxide Analysis Center (CDIAC)8 and measure emissions generated through the burning of fossil fuels. Carbon intensity data are collected from World Development Indicators. A detailed description of the explanatory variables and data sources is available in Table A.1 in Appendix A. The average yearly growth rates and standard deviations of the respective variables for each country are shown in Table 1. Three patterns are visible in Table 1. First, there is a difference between the developed economies and the two emerging economies. The average growth in emissions is higher for the emerging economies than for the developed economies. Carbon intensity declined in all developed countries but increased in the emerging economies. Growth in TKM, urbanization and capital accumulation has also been higher in the emerging economies than in the developed economies. Second, countries with the largest decreases in carbon intensity also had the largest expansion in nuclear power (e.g., France and Sweden). Third, countries with higher rates of capital accumulation, such as Spain and the United States, had higher rates of emissions growth.",
            "Scale effect and energy intensity": " The estimation results of the scale and energy intensity model are presented in Table 2. Diagnostics tests are presented at the end of the table. Because we reject the hypothesis of homoskedastic residuals, we apply Arrelano's (1987) robust standard errors. Based on the results of a Chow test, we reject the hypothesis that the short-term and long-term parameters are equal and that the separation of the two time horizons is justified by the data.",
            "Short-term determinants of scale and the energy intensity": " In the short term, employment growth has a positive and significant effect on energy demand (the elasticity is 0.964), but the effect of capital growth is insignificant. This result suggests that in the short term, firms respond to variations in aggregate demand by adjusting employment rather than capital stock. This is supported by economic theory, which hypothesizes that adjusting the capital stock in the short term is expensive and that employers respond, to a great extent, to fluctuations in demand by hiring and firing employees instead (see e.g., Massey et al., 1993). Short-term TFP growth has a positive rather than the expected negative effect on energy intensity, which can be explained as productivity improvement being a long-term process and short-term TFP growth most likely capturing business cycle fluctuations (i.e., excess demand) (e.g., Woodford, 2007). There is usually some spare capacity in the economy, even during boom times, that allows firms to increase production before they employ more capital and labor. In the short term, spare capacity allows firms to increase production when demand temporarily increases. During recessions, when demand decreases, firms sometimes wait until demand picks up again and do not necessarily reduce labor and capital instantly. It is therefore possible to interpret TFP as excess demand in the short term, as opposed to total factor productivity (i.e., business cycle component), which explains the positive effect. Combining the employment effect and the TFP effect, our results show that average business cycles generate fluctuations in emissions of 7 4% around the trend. For a more severe recession such as the \"great recession\" following the financial crises in 2008, short-term fluctuations in emissions can be even larger. Although these short-term fluctuations cancel out in the long run, it is important that they are taken into account in policy making. For example, the third phase in the European Union Emissions Trading Scheme (ETS) lasts eight years (2013-2020), during which the effect of a business cycle normally would be zero over the entire period. However, in a given year, it is normal to expect temporary deviations of 74% from the trend due business cycles (e.g., changing weather conditions). As discussed by Karpestam and Andersson (2011) and Andersson (2010), large short-term fluctuations in the demand for emission rights will result in high fluctuations in the market price of carbon as well, if the supply is fixed in advance and is not adjusted in response to changes in demand. The supply of emission allowances in European Union's Emissions Trading System (EU ETS), for example, is reduced by 1.74% per year. To prevent large price fluctuation in the price of allowances banking has been introduced, but banking has not prevented price to fluctuate with the business cycle. For example, the price of one emission allowance on the secondary market rose with the business cycle in 2005-2006 but then fell during the \"great recession\" (www.eex.com). Such price fluctuations in emission allowances increase the risk associated with investments in cleaner technologies and thus reduce firms' propensity to invest in such technologies. Setting a fixed price on emission rights or adjusting the supply of emissions based on demand would alleviate the negative effects of such price changes (see e.g., Weitzman, 1974;Hepburn, 2006;Andersson and Karpestam, 2011).",
            "Long-term determinants of scale and energy intensity": " With respect to the scale variables, the long-term results are the opposite of the short-term results. Capital growth has a significant effect (as indicated by an elasticity of 0.738). But, this effect of capital growth is reduced if at the same time there is a reallocation of capital from the goods-producing sector to the service-producing sector. Labor growth has no significant effect. Most of the employment growth over the last few decades has been in the service sector, where energy intensity is lower than in the goods-producing sector, which may explain the insignificance of labor growth. For example, employment in the manufacturing sector in the United States decreased by 6 million people between 1973 and 2007, while employment in retail and wholesale trade increased by 5 million people. In the United Kingdom, employment in manufacturing decreased by 4 million people, and employment in wholesale and retail trade increased by 1.6 million people during the same period (EUKLEMS). TFP has a negative effect on energy intensity, with an elasticity of \u22121.268. The different effects of the GDP growth sources on emissions reinforce the view that it is not GDP growth that matters for emissions growth but rather the source from which the growth stems. It could be argued that continued GDP growth is possible without increasing emissions if growth is caused by productivity improvements (and service sector employment growth) and not capital accumulation. However, it should be remembered that TFP growth increases the marginal productivity of capital and thereby creates incentives for firms to invest (see Solow, 1957;Lucas, 1988). It is therefore questionable whether TFP growth without capital growth is a viable growth path for the future. The negative effect of TFP on energy intensity is moderated by the effect of the \u0394TFP \u00c2 \u0394TKM interaction variable. Although increased TFP reduces emissions, if that growth is associated with a greater volume of freight transport, the energy intensity decreases by less than if the TFP is not associated with greater TKM demand. On the one hand, globalization has a negative effect on emissions for developed countries in that it increases TKM. On the other hand, globalization has also caused a decline in the goods sector and a rise in the service sector in most developed economies (Gemmell, 1982;Saeger, 1997), which, through the reallocation of capital to the service sector, reduces energy intensity. A greater urban population also increases energy intensity. For every percentage point that the urban population increases, emissions increase by 1.142%. The populations of most developed economies are already 70-90% urban, but countries such as China and India have urban populations of 44% and 30%, respectively, which suggests that emissions from these countries are likely to increase as they continue to develop. Increases in the levels of urbanization in China and India to the same levels as in the developed countries would suggest 40-50% increases in the emissions of China and India due to this factor alone. Real oil price reduce energy intensity, but the effect is moderate: a long-term increase of 10% in the real oil price reduces emissions by less than 1%. This result suggests that increasing the real price of oil or a price on carbon in general is a policy tool that can be used to reduce future CO 2 emissions. However, the effect of the real oil price is relatively small, and it is questionable whether a carbon price is sufficient to achieve the necessary reductions in emissions unless the economic relationships in the economy changes.",
            "Short-and long-term determinants of carbon intensity": " The regression results for carbon intensity are presented in Table 3. The results of three regression models are presented: Model 1 is the benchmark model, and Model 2 and Model 3 consider nonlinearity9 in the effects of the real oil price. In Model 2, we have included the square of the real oil price ((\u0394Oil) 2 ), and in Model 3, instead of using the square of the real oil price, we have used an interaction between the real oil price and a dummy variable that takes the value 1 if the long-term real oil price increase exceeds 10%. 10 Both Models 2 and 3 have better fit, according to the information criteria, than Model 1, and we can conclude that there is a nonlinear relationship between real oil prices and carbon intensity. Furthermore, Model 3 best captures this nonlinear affect, according to the information criterion, and we consequently proceed to analyze this model. In the short term, only freight transport has a significant effect on carbon intensity and then only at the 10% level, while a change in nuclear power is significant at the 5% level and, as expected, has a negative effect on carbon intensity. Over the long term, however, increases in oil prices cause changes in energy sources, which reduce carbon intensity. There is a threshold effect, and beyond a yearly long-term 10% increase in the real oil price, the effect disappears. In other words, for increases up to 10% in oil prices, the oil price does have an effect on carbon intensity, but increases beyond that level do not cause additional reductions in carbon intensity. Increasing the real oil price increases the economic incentives to switch to alternative sources of energy. For some firms, switching energy sources is relatively easy and occurs in response to small changes in the real oil price. For some other firms, the choice of energy sources is limited by the existing production technology, existing energy infrastructure and the nature of their output (Gr\u00fcbler and Nakicenovic, 1996). Even if the real oil price increases, changing energy sources is not a viable alternative for these firms. The variable that explains most of the changes in carbon intensity is the expansion of nuclear power in both the short term and the long term. An increase of one percentage point in the share of energy produced through nuclear power reduces carbon intensity in the long term by 0.617%.",
            "The relative contribution of the long-term determinants of CO 2 emissions and the path forward": " Based on the regression results presented in Sections 3.2 and 3.3, we analyze the average contribution of each determinant of emissions during the period considered. Only determinants that were significant in our regression models are included in these calculations. We also limit the analysis to the long-term results because the short-term fluctuations in the economy do not affect the long-term averages. Based on these calculations, we then discuss policy challenges and potential future policies that can decouple growth from emissions. The results are presented in Table 4 and show the annual average effect for each country. The column to the far right shows the observed average change in emissions. Columns 1-8 show the effects of the significant determinants. Column 9 shows the average change in emissions that we cannot explain by our two models. The first rows show the results for each country, and the final two rows show the results averaged for all countries considered and for all developed countries considered, respectively. Capital accumulation (the scale effect) is the main driver of emissions. On average, capital growth increases the demand for energy by 2.91% per year. This growth has been moderated by the reallocation of capital to the service sector, which has reduced energy intensity by 0.55% per year, on average. The most rapid increase in energy demand from capital has been in China, where capital growth has caused an increase in energy demand of 7.29% per year. However, other developed countries, such as Spain, have also experienced relatively large increases in energy demand. The residuals are heteroscedastic, and we have therefore corrected the standard errors using Arrelano's (1987) robust standard errors. 10 We also tested for threshold levels at which the real oil price change is negative, but none of these variables were significant in the regressions, and thus they were excluded from the analysis. TFP explains most of the increases in energy intensity: the average effect is \u22121.59% per year. However, in countries where part of the increase in productivity is associated with greater TKM, this positive effect of TFP is reduced. Again, this is especially a problem for emerging economies such as China, where the establishment of a modern economy generates greater transport demand. For developed countries where the transport system and trading patterns are already established, the effect of growth in TKM is smaller. Urbanization has increased energy intensity, mostly in China, where between 1984 and 2007, the urban population doubled from 20% to 40% of the population. The real oil price has reduced energy intensity by 0.81% per year, on average. The oil price also has a negative effect on carbon intensity, but the threshold level of 10% ensures that the average effect of the oil price changes is close to zero (0.05%). That is, the change in the real oil price over the period considered has not caused a systematic change fossil fuels to non-fossil fuels. The price of oil is likely to have influenced policies to develop nuclear power in countries such as France, Sweden and the United States, but there is no evidence of changes in real oil prices causing automatic changes in the energy infrastructure and an overall shift away from fossil fuels in all countries. On average our model explains most of the change in emissions. The unexplained emission component is \u22120.03% for developed economies and 3.22% for emerging economies. Based on these results, four policy challenges and opportunities can be observed. First, China and India have been catching up economically with developed economies over the last few decades. If this catching up continues, it will have substantial global consequences for emissions. Sustained development of these economies following a path similar to that of the last 20 years implies that emissions will increase not just through capital accumulation but also through urbanization and development of the transport infrastructure. Emissions may grow by up to 50% over the next few decades simply from continued urbanization alone and by another 40% due to growth in transport demand, which follows as a part of building a more efficient economy. Investing in existing technology from developed countries will be insufficient to increase energy intensity sufficiently to avoid these large increases in emissions. Major investments in new technology and non-fossil fuels are essential to combat emissions globally. However, adapting cleaner existing technologies from developed countries is insufficient to accommodate a larger urban population, and new, even cleaner technologies are necessary to avoid large increases in emissions. Second, long-term TFP growth has declined in recent years among developed countries close to or at the technological frontier. The relative expansion of the service sector as a share of GDP has also slowed down. For example, from the late 1990s until 2007, TFP growth declined by between 0.3 percentage points (France) and 1.3 percentage points (Italy). This deceleration of TFP growth follows acceleration of TFP growth during the 1980s and 1990s. Long-term capital growth has, on the other hand, either remained stable or increased slightly among developed countries. The relative shift in the GDP growth sources from intensive growth (TFP) to extensive growth (capital) implies that the long-term trajectory for emissions has increased relative to the late 1990s, which makes it more difficult to reach future carbon reduction targets. Empirically, decreases in emissions can be observed for some countries after 2007, which contradicts this long-term observation (EDGAR).11 However, as our estimation results show, these decreases can be explained by the \"great recession,\" which is likely to temporarily reduce the rate of growth in emissions. However, as the recession ends, emissions may be harder to reduce than before the crisis. Historically, TFP growth and capital growth have fluctuated cyclically (e.g., Haustein and Neuwirth, 1982;Mokyr, 1994;Gore, 2010) and the relative importance of the three long-term GDP growth sources have consequently varied over time. This variation implies that the relationship between GDP growth and emissions also varies over time. Long-term cycles in TFP growth are caused by the development and diffusion of new radical innovations, possibly of the general-purpose type (Jovanovic and Rousseau, 2006) or the development block type (Sch\u00f6n, 2006). If we expect a pattern of growth in the future similar to that since the first industrial revolution, TFP growth may pick up again in the future, as it has after previous slumps. From a policy perspective, longterm cycles in the GDP growth sources imply that reducing emissions will be easier during some decades than other decades. CO 2 reduction targets that are set for 2050 should therefore be broken down into 10-to 15-year targets, with the targets for some periods being more ambitious and the targets for other periods being less ambitious, based on the TFP cycles and the economy's ability to reduce emissions through productivity growth. Breaking down the long-term targets into 10-15 year sub-targets will not jeopardize the long-term emission targets. Third, a price for set at the global level will reduce both energy intensity and carbon intensity. To maximize the effect of the carbon price, the price should increase yearly by a fixed percentage to give firms the ability to reduce the risk involved in making investment decisions. According to our results, an optimal yearly increase in the carbon price is 10%, but our model results are only based on changes in the real oil price, not all fossil fuels, and only involve global changes in the real oil price. The optimal price therefore cannot be estimated precisely. Moreover, the results are also brought into question if not all countries participate in putting a price on carbon, as countries that do not participate may attract more energy-intensive production and limit the global effect of the carbon price on emissions. Nonetheless, our results show that a price on carbon can have a measurable effect on the economy. However, even if the effect is significant, within existing economic structures, the effect that can be achieved by a carbon price is limited relative to the growing energy demand that results from capital accumulation. The effect of a carbon price may increase in the future as the world moves far beyond the peak oil point at which the scarcity of oil creates a need for non-oil energy sources. However, there is no evidence in our empirical results that such a change has already occurred. The effect of a price for carbon on the economy depends, among other things, on the production technology, the output mix and the existing energy infrastructure (Ayres and Kneese, 1969;Gr\u00fcbler and Nakicenovic, 1996). To increase the effect of a carbon price policy, measures that affect these three variables are necessary. Fourth, breaking the capital-emissions link is likely to be important because capital is the main driver of emissions. As long as capital requires energy to operate, a greater capital stock will lead to greater energy demand, and breaking the link between the two directly will be difficult. However, the effect of capital on emissions can be neutralized by either reducing energy intensity (i.e., by making each unit of capital more energy efficient) or reducing carbon intensity (i.e., by changing energy sources). A reduction in energy intensity can come about in three ways: the capital stock can be renewed with new and more energy-efficient capital, energy waste in production can be reduced, and the output mix can change to new and less energy-intensive products. The effect of renewal of the capital stock is captured by TFP in our model. The effect of changes in the output mix is captured by the interaction variable between goods production and capital growth in our model. As Table 4 shows, these two effects have been small relative to the effect of capital growth and insufficient to neutralize the effect of greater energy demand. If capital continues to be accumulated at the same pace as in the past and if economic growth is to be combined with large reductions in emissions, additional efforts to develop and deploy new cleaner technology and products are essential. As our results indicate, a price for carbon is insufficient to increase profitability sufficiently to achieve the necessary investments. A key policy challenge is thus to increase the speed of the improvements in the energy intensity and the carbon intensity. All economic activities takes place within certain macroeconomic structures, which Perez (2007) calls the techno-economic paradigm. The paradigm defines the guidelines for innovations and competiveness and affect what is produced and which technology is used to produce it (Perez, 2007). What and how much firms produce, as well as how much they invest in new technology and in which new technologies they invest, are thus influenced by the paradigm. Statistical tests12 show that the parameters in our models are stable over time. This result can be interpreted as the economic structures defined by the paradigm have been stationary since at least the 1970s. Moreover, the development and deployment of cleaner technology and products are not profitable enough for firms and entrepreneurs to invest in these to neutralize the effect of capital accumulation. A new techno-economic paradigm that increases profitability for firms that increase their investment in R&D and deployment of cleaner technology and products is most likely necessary for the future. Each paradigm is the outcome of complex interactions among social, political and technical innovations (Geels and Schot, 2007;Perez, 2013). Political decisions alone cannot change the paradigm, but policies can have a role in shaping a new paradigm, together with the market forces (von Tunzelman, 2003). For example, the development process of new technologies and productions is nonlinear, and the economic and environmental benefits of new technologies may not emerge immediately. Supporting new technologies at the early stages of deployment and diffusion, before they reach the threshold at which they are economically selfsupporting, can increase both the economic and environmental benefits for society over the long term (Anderson and Karpestam, 2012). This support can include investments in research and development in both new technologies and new products that are less energy intensive and supporting and protecting markets for new emerging technologies and productions that are not yet fully viable economically but which will be economically viable in the future (Foxon, 2013;Perez, 2013). Such support involves risk, and not all investments will yield profits. However, without such risk-taking by governments, growing economies and reducing emissions will be difficult (see e.g., Anderson and Karpestam, 2012). A passive government that does not try to change the macroeconomic structures in favor of cleaner technology and products using a wider set of policy tools also takes a risk that either emissions will not decline sufficiently to combat global warming or that the economy will not be able to expand according to our results. The deployment of new techno-economic paradigms has historically been linked to changes in primary energy sources through changes in the energy demand brought about through new technologies (Piatier, Gr\u00fcbler and Nakicenovic, 1996;Enflo et al., 2009). In the transition to new energy sources, government investments in essential core energy infrastructures have often allowed the diffusion of new technologies and more radical transformations of economies. Such active government involvement is likely to be necessary in the future as well. In conclusion, reductions in energy and carbon intensity are essential to combining economic growth with emission reductions. If reductions in energy intensity and carbon intensity are to be sufficient to counter the effect of capital growth, radical changes to countries' economies are necessary, and policy makers will play a central role in generating such changes (Perez, 2007(Perez, , 2013;;Anderson and Karpestam, 2012).",
            "Conclusions": " In this paper, we analyze the economic determinants of scale, energy intensity and carbon intensity from short-term and longterm perspectives. Our results show that there are differences between the short-term and the long-term determinants of scale, energy intensity and carbon intensity. Short-term fluctuations in emissions are caused by temporary external shocks and business cycle fluctuations. The ability of policy makers to combat emissions growth in the short term is thus limited. Furthermore, emission policies should allow for short-term fluctuations in emission to avoid causing problems in the real economy. long-term, emissions grow due to capital growth (the scale effect), but productivity growth, changes in the composition of the capital stock and the real oil price reduce energy intensity. Changes in carbon intensity are partly an effect of the real oil price, although changes in excess 10% per year have no additional effect on carbon intensity. Most of the changes in carbon intensity in our model are explained by expansion of nuclear power. From a policy perspective, these long-term results suggest both policy opportunities and challenges that need to be addressed to decouple economic activity from emissions. First, a price for carbon could be part of a policy package to improve energy intensity, but the effect on carbon intensity is likely to be small without additional investments in the energy infrastructure, even if the tax is global and includes all countries. Second, if China and India continue to catch up economically with the developed world, emissions in these countries will increase substantially. Third, decoupling economic growth and emissions growth is unlikely to be achievable given the present techno-economic structure. A technical revolution combined with changes in institutions, the legal framework, the transport infrastructure and the energy infrastructure are likely to be necessary. Techno-economic paradigms evolve slowly over time. Policy makers do not directly determine the paradigms but can use policies to influence the direction and the content of the paradigms. For policy makers to successfully change a paradigm, a wider development perspective is required (see e.g., Perez, 2007Perez, , 2013;;Anderson and Karpestam, 2012)."
        }
    },
    "10.1016/j.enpol.2012.12.078": {
        "file_name": "76 Scenario-based modelling of future residential electricity demands and assessing their impact on distribution grids",
        "title": "Scenario-based modelling of future residential electricity demands and assessing their impact on distribution grids",
        "abstract": "New developments towards a more sustainable energy delivery system require electricity distribution grids that support distributed generation and a potential increase in electricity demand. In this article, the impact of changes in future residential use on the electricity distribution grids is assessed by using a scenario-based methodology to model residential loads. It illustrates that scenarios resulting from varied economic and demographic developments, but also driven by the focus of energy policies, can have considerable consequences on the loading and the resulting required network capacities of electricity distribution grids. A strategy for network operators to cope with these changes and optimise the utilisation of their grids is to use the possibilities to control flexible loads to reduce peak loads and shift demands. This article shows that if these loads can be managed in such way, the electricity profiles can be flattened significantly. For the case of the Netherlands, the peak demands in residential areas can be reduced with 35\u201367% in various scenarios. Load-flow analyses of medium voltage networks show that a load management strategy to reduce peak demands can realise a reduction of 21\u201340% for required capacity of cables and transformers. This makes a reduction 45\u201372% in investment costs possible.",
        "label": "Quantitative",
        "text": {
            "Introduction": " Electric power delivery systems are subject to many external influences. One of the major changes influencing the development of these systems is caused by a transition to a more sustainable energy system which will cause fundamental changes in the supply and demand of electrical energy. On the one hand, the share of renewably generated energy is increasing. In contradiction to conventional power plants, renewable energy generation technologies are by nature quite suitable for small-scale, distributed implementation, and must be integrated in the local delivery system, i.e., the electricity distribution grid (Pecas Lopes et al., 2007). In addition to the changes on the supply side, the demand side also changes in response to the energy transition. Consumers are starting to produce electrical energy themselves, and thus need less electricity from the grids. However, if they use e.g., photovoltaic panels and are temporarily not provided with solar energy, they may still need to be fully supplied by the grid at peak moments. This means that the net load profiles of the consumers will be less predictable and vary more. Other developments on the demand side include the application of heat pumps and electric vehicles. These electric appliances are often cited as efficient technologies that can reduce the overall use of energy (Cockroft and Kelly, 2006;European Climate Foundation, 2010;Veldman et al., 2011a), but they will lead to a substantial additional demand for electricity. The electricity distribution grids have to deal with these changing net load profiles and the potential additional load with its specific characteristics. However, how the demand at the consumer side will develop is surrounded with much uncertainty. The outlooks that have been developed are still very diverse on issues like the emerging new technologies that will be successful at local level, the timing and the penetration grades of these technologies. Another aspect of future residential loads is the degree in which the loads are controllable. Future electricity demand may be more flexible than it is currently. A large part of the future residential load might, for example, be the result of electricity demand of electric vehicles. Because cars do on average stand idle for at least 90% of the time, these loads are less timecritical than most other types of loads. This gives the supplier and/or distribution network operator (DNO) the opportunity to manage the charging of electrical cars. The development towards so-called smart grids, that use information and communication technology to intelligently integrate the actions of the users connected to the electricity distribution grid, makes such demand response possible (Veldman et al, 2010). Preparing infrastructure for future electricity demand involves large investments. However, the investment and replacement strategies which have been successfully deployed to the distribution grids so far no longer hold because they do not fulfil future requirements and cannot handle uncertainties in the right way. Especially in a future energy system as described before, peak loadings in electricity distribution grids can increase significantly and without any smart functionality to reduce these peaks, this can potentially lead to a considerable increase in network investments (Blokhuis et al., 2011). The ability of smart grid functionalities to reduce the peak loadings and use grid capacity efficiently is recognised as one of the main benefits of smart grids (see e.g., International Energy Agency (IEA), 2011a;McDonald, 2008). To realise the potential savings in network investments through smart grids, which eventually will flow back to the end consumers, it is of utmost importance to make sound decisions related to the expected required capacity of the electricity grids. However, because of the long life-time of the assets, planning of electricity grids is a challenge keeping in mind the uncertainty about future electricity demand. It is therefore essential to perform analyses of future electric demands in various scenarios that take the effect of certain developments and policy choices on the electricity use into regard, and subsequently assess the impact on the distribution grids in which smart grid strategies to reduce peak demands may be applied. A first step, is to define various scenarios that may have very different impact on the distribution networks by identifying the main drivers that initialise changes on the local demand and supply of electricity. The impact of these scenarios can then be explored after modelling the resulting demands for the scenarios with and without load control to reduce peak demands. This is done by applying a novel procedure for a profile-driven determination of the peak load value and peak moments, which can differ per scenario. We use this method which, unlike other methods, makes it possible to differentiate between residential areas by defining different shares of new technologies that contribute to the electricity demand. The resulting peak loads are used for load-flow calculations of medium voltage distribution networks. This reveals differences in the impact of various scenarios on the loading of the distribution network and makes it possible to quantify the effect of flexible loads on the required capacity and the resulting investment costs of the distribution grid infrastructure. This supports the assessment of the (societal) benefits of smart grids. In this article, this approach is applied to distribution networks in the Netherlands. First, based on an extensive review of several scenario studies the main drivers and policy measures that may lead to variations in the local (residential) electricity demand and supply are identified and three realistic scenarios that may have very different impact on the distribution networks are defined. Section 3 describes how current developments affect the residential electricity use and the possibility of controlling flexible loads at residential areas in future smart grids is discussed. In Section 4 the applied methodology to estimate future residential electricity demands that takes these issues into account is described. After the future residential net load profiles are constructed for three different scenarios, the impacts of various future scenarios and the effects of applying smart grids strategies to reduce peak demands in electricity distribution networks are assessed. Section 5 examines the impact of these profiles on the loading of the network components and treats the financial consequences of reduced capacity requirements. Finally, the last section reflects on the results drawing conclusions and pointing towards issues for further research.",
            "Future scenarios and effects on electricity delivery": " Although the need for a transition towards a more sustainable energy system is generally accepted, recent publications reveal that the pace in which the transition develops at the moment is not fast enough to achieve energy-related policy goals to e.g., reduce greenhouse gas emissions and increase the share of renewable energy production. One of the examples is the World Energy Outlook that emphasises that without a bold change of policy direction, the world will lock itself into an insecure, inefficient and high-carbon energy system (International Energy Agency (IEA), 2011b). This is no different in the Netherlands, where the transition towards a low-emission energy supply is still in an early phase and can develop in many directions (Rotmans et al., 2001;Verbong and Geels, 2007). To investigate how various directions in which the transition can develop affect the distribution networks, three extreme, but realistic future scenarios that have a very different impact on the distribution networks are created. First, recent scenario studies are reviewed to identify the main drivers that lead to various energy scenarios. After that, the three scenarios are created based on these drivers and the features relevant for the electricity delivery system are described.",
            "Scenario drivers": " The European Commission has published several energy scenarios over the years. These are based on energy policies implemented on European level and in Member States, and updated every two years with the latest economic developments, energy prices, and new policies and measures (Directorate-General for Energy, 2010). More specific for the Netherlands is the scenario study performed by the Netherlands Environmental Assessment Agency (Janssen et al., 2006;Van Drunen et al., 2011). In this very extensive scenario study the long-term effects of current policy on various themes are assessed for 2040; one of these themes is energy. The main uncertainties that are foreseen and explored in these scenarios are the uncertainties regarding the economic and demographic developments and different directions regarding international politics: governance (international co-operation or national sovereignty) and international trade (with a focus on public or private responsibility). In the various scenarios the effects of current policies till 2020 are investigated, but after that there is more variation in the scenarios following different story lines, since the political landscape can change. It can be concluded that mainly the economic development and the climate policy in the various scenarios are related to the expected electricity demand. For instance, policies regarding climate goals can be effective via two ways: through strong international co-operation with a focus on international climate goals or in a scenario where the overall electricity demand growth is limited through low economic growth. In these scenarios greenhouse gas emissions are reduced significantly and the share of distributed electricity generation is relatively high. Also relevant for our research is the Reference Projection study from the PBL Netherlands Environmental Assessment Agency (Verdonk and Wetzels, 2012). This study examines the future development of Dutch energy use, based on assumptions regarding economic, structural, technological and policy developments. Especially the effects of the current policy programme for energy and climate are assessed. Though the view of this study only reaches to 2020, it also concludes that the if the climate policy measures to reduce greenhouse gas emissions and to increase the share of renewable energy production are continued, this will lead to a limited growth of electricity demand and to more decentralised electricity generation. After exploring these scenario studies the drivers that lead to variations in the future electricity supply and demand, can be identified: a more national or international focussed policy, a more economic or environmental oriented society and the economic growth. Differentiations in these drivers will lead to very different, but all realistic, future energy scenarios.",
            "Three scenarios for the Netherlands": " Three scenarios based on divergent choices concerning the underlying drivers are defined here. Besides the amount of electricity produced and consumed, the effect of various scenarios on the location where the loads and generators are connected to the grid, are important for the development of the electricity delivery system. The following combinations between economic development and policy directions can lead to large differentiations on the impact on the distribution grids: A situation with low economic growth in combination with an effective (national) climate policy. In this scenario the electricity demand growth will be low. Distributed generation will more or less be on the same level as nowadays, because the investments in new technologies are low and because a large growth of renewable energy production is not necessary to reach climate goals as a consequence of the low energy demand growth. A situation with high economic growth in combination with a less effective climate policy. Through strong international cooperation the economy flourishes, climate goals are however not reached. This scenario leads to high electricity demand and generation on central locations. A situation with moderate to high economic growth in combination with an effective international climate policy. Through a focus on the environment, much is invested in sustainable energy technologies and the share of distributed electricity generation grows. Through the focus on the environment, the economic growth is a bit restrained. That, in combination with measures leading to energy savings, limits energy demand growth. In Table 1 the three scenarios are summarised and it is indicated what it means for the electricity system, in terms of the expected demand growth of electricity, the voltage level to which generators are connected and developments of new technologies that are applied at the residential level. These scenarios are further used for our research.",
            "Electricity demand and generation in residential areas": " In this article we look in particular at the impact of changes at the residential level on the electricity distribution grids. In this section, we will take a closer look at the developments of electricity use in residential areas.",
            "Changing electricity flows": " Due to several developments the future electricity demand of residential consumers will change. Besides an anticipated demand growth for domestic appliances, new technologies will certainly influence the future demand at the household level and households may start to generate electricity (International Energy Agency (IEA), 2011a; US DOE (Department of Energy), 2009). Differences may exist between individual consumers connected to the grid, e.g., one household may choose for a micro combined heat and power (m-CHP) system and the other for a heat pump in combination with solar panels. This means that the net load profiles of individual household consumers will differ more and will be less predictable than nowadays. Looking at a larger scale, the differences between residential areas may diverge. A newly developed residential area in a city, for example, may have a very different profile than an existing group of houses in the countryside. The introduction of local generation and new types of demands such as electric vehicles and heat pumps will alter the current patterns of electricity demand and generation. Technologies like m-CHP systems, heat pumps, photovoltaic panels and electric vehicles all have different characteristics in terms of size and time when they produce or consume electricity. The variability and flexibility of their electricity production or consumption differ considerably over day (see Fig. 1). Significantly changing patterns of energy production and usage implies a change in the use and development of the networks (Shaw et al., 2010). When analysing future (peak) loading of the networks due to these new technologies, a significant source of uncertainty is the introduction and penetration degree of new technologies (Blokhuis et al., 2011). Therefore, the impact of new technologies should be investigated in such analyses by looking at different scenarios with various penetration grades of these technologies as indicated in the previous section.",
            "Characteristics of residential areas in various scenarios": " In this research, different types of residential areas in the Netherlands are defined based on population density. In the Netherlands a lot of data is available for residential areas classified by five degrees of population density (Government of the Netherlands, 2009). The residential areas are classified by this degree of population. Also, for all five types of areas with a certain population density a distinction has been made between already existing and newly developed neighbourhoods. This results in ten typical residential areas. Some numbers about the main technologies that will emerge in the scenarios A, B, and C were already presented in Table 1. These numbers are now further specified for each of the ten residential areas and presented in Table 2. These numbers are based on data from Government of the Netherlands (2009) and Ministry of Infrastructure and the Environment (2009) in combination with some additional numbers about the number and growth of houses and vehicles that are defined for each scenario (see Table 3). The amount of installed capacity of solar panels in each scenario is translated in the average size of the solar panels per house, based on the availability of well-oriented roof area. A global economy dominates. The economic growth is high, which leads to a high demand for energy. To be able to cope with the increase in energy needs of the population, there is a focus on overall energy savings. The demand for electricity for heating and mobility grows fast. The applied energy policies have a local and environmental focus. Many investments are made in new technologies, leading to an increasing application of new technologies and growth of generation on decentralised level. Economic growth is high, but the effect on the energy demand is average.",
            "Effect on the supply of electricity": " There is mainly centralised generation (connected to the high voltage level). The share of distributed generation stays on the same level as in 2011. There are not many solar panels and m-CHPs: the installed capacity of solar panels in residential areas is 0.34 GW and each year 50,000 m-CHPs are installed in existing houses. There is a growth of generation on all levels. Due to a high electricity price the amount of gas-fired distributed generation grows, but the share of centralised production connected to the high voltage level grows even more. The share of solar panels and m-CHPs is limited: the installed capacity of solar panels in residential areas is 0.34 GW and each year 50,000 m-CHPs are installed in existing houses. There is a large increase of distributed generation connected to the low and medium voltage level. The amount of solar panels and m-CHPs grows substantial. The total installed capacity of solar panels is 20 GW, of which half is installed in residential areas and half is installed on more central locations. Each year 250,000 m-CHPs are installed in existing houses. Effect on the demand of electricity Demand growth of the normal residential electricity use is 0%. The market share of electric vehicles will not grow fast: in 2040 40% of the vehicles will be electric. Heat pumps are mainly installed in newly developed areas. In existing houses 20,000 air source heat pumps are installed each year. In 50% of the houses that are built in 2040, a ground source heat pump is installed. Because of an increase in the usage of electric appliances, the demand of the normal residential electricity demand grows with 1.5%. The demand for the normal residential electricity decreases with 1.0%. There are many heat pumps and electric vehicles. In 2040 75% of vehicles will be electric, which is consistent with the goal of the Dutch government to have 1 million electric vehicles in 2025. In existing houses 300,000 air source heat pumps are installed each year. And in 80% of the houses that are built in 2040, a ground source heat pump is installed. The market share of electric vehicles is also large: in 2040 75% of the vehicles will be electric. There are many electric vehicles and heat pumps, although the air source heat pumps have to compete with m-CHPs in existing houses. Each year 150,000 air source heat pumps are installed. In 80% of the new houses that are built in 2040, a ground source heat pump is installed. 75% of the vehicles will be electric.   New houses can be made fit for solar panels; therefore, the share of solar panels is higher in newly built areas. Furthermore, in more densely populated areas houses are smaller, so less roof area is available for solar panels and the electricity use as well as the heat demands are less. People also drive on average less in these areas. The penetration degrees for heat pumps and m-CHPs are in accordance with the numbers as presented in Table 1. In case of ground source heat pumps, which are expected to be mainly applied in newly built areas, an additional electric heating element is present. m-CHPs are only expected to be installed in already existing houses, because they are especially attractive in houses with a large heat demand and thus less suitable for newly built, well-insulated houses. This is also the reason more m-CHPs are applied in houses with larger heat demand. Differentiation in heat demand in newly built houses in the various scenarios is caused by the fact that the requirements for insulation are highest in scenario B and lowest in scenario A. In all scenarios insulation reduces the heat demand in existing houses, compared to the current heat demand in these houses.",
            "Flexible electricity demand": " Developments in the electricity demand of residential consumers may include smarter household appliances, such as a washing machine that may start running when the electricity prices are low. Also, flexible demands as heat pumps and electric vehicles are introduced. These new, energy intensive loads have the characteristic that the exact moment by which the demand is met is less important than for normal loads. For example, a house has the capacity to hold the thermal energy within its walls for some time, and cars may be charged during night. Their demand for electricity is less time-critical than most other types of loads and this gives the supplier and/or DNO the opportunity to manage the power demand in time while meeting the total energy constraint. The flexibility in these demands brings with them the opportunity to shift demand in time and apply load control without any discomfort for the consumer. There can be various reasons to use this flexibility. Until now, electricity distribution grids are designed to handle peak demands. This is inevitable due to the fact that until recently storage for the application for energy management in distribution grids has been technically and economically infeasible (Dunn et al., 2011). Current developments in electricity storage, brings the application of storage technologies for this goal rapidly closer. However, shifting a part of the electricity demand by for instance control of flexible loads makes it possible to leverage the loads without expensive storage technologies or increasing grid capacity to the level of high peak loads. Another advantage of shifting the use of electricity in time can be found in the fact that more and more local resources are connected to the distribution grids. These local resources are often intermittent, which makes it difficult to match the available electricity to local electricity demand. To use the intermittent distributed generation optimally, it might be attractive to shift demand for electricity in time or, more precisely, to shift the transport of electricity in time. In this way, the electricity grids can be used more efficiently, energy loss due to the transportation of electricity is reduced and the integration of distributed renewable energy sources into the electrical power system can be supported without requiring major grid reinforcements. From the broader perspective of the energy supply sector and the transmission system operator (TSO), a third advantage of shifting energy in time would be to support the operation of an energy portfolio and maintaining the power balance in the system. The fulfilment of this overall, system-wide requirement can be achieved by large-scale storage technologies, such as pumped hydro or compressed air energy storage, but also by distributed electricity storage or load control. An example of applying load management for this goal will be demonstrated at the island of Bornholm in Denmark. This island has more than 50% electricity consumption from renewable energy production and approximately 2000 residential consumers are involved (EcoGrid, 2012). One should realise that, in a liberalised electricity sector, the aforementioned objectives for load management are in the interest of different parties. Maintaining the balance between demand and supply of electricity is primarily the responsibility of transmission system operators and commercial energy suppliers. However, the optimal use of electricity grids is the responsibility of network operators. These different objectives can be conflicting, which might result in a non-optimal shifting of electricity demands. Therefore, assessing the impact of various control strategies on the grids is regarded to be an important step towards the development of smart grids in which the systemwide benefits of load management in the distribution system can be obtained.",
            "Modelling future electricity use in residential areas": " Assessing the capacity needs of the distribution grids with respect to future demand, including distributed generation of electricity in residential areas, requires an estimation of the aggregated (peak) demand for groups of households. Accurate modelling of future (new) loads and generators is therefore essential, but should also take into account uncertainties that these future demands bring with them. First, we will look how we can model residential loads and generators for various future scenarios. Then, we will introduce demand response of the flexible part of the loads to reduce the peak loads and model the loads accordingly.  ",
            "Modelling individual load and generation profiles": " The approach we apply provides the possibility to analyse the impact of various new technologies and penetration degrees. It takes into account the load (and generation) profiles of the different future residential technologies in aggregated net load profiles of tens to hundreds of houses. In this approach the profiles of the different future residential technologies that consume or produce electricity are first considered separately.",
            "Normal residential electricity use": " For the aggregated load of the normal electricity use (for small household appliances, lighting, etc.) of residential electricity consumers, normalised curves are used. With these normalised curves the average demand curves of a number of households can be defined if the annual energy demand is known. For instance in the Netherlands, normalised daily curves based on data of 400 households are available for all days of the year. In Fig. 2 the average load curves for a residential customer with an annual electricity demand of 3400 kW h (this equals the average electricity demand in the Netherlands) are shown for four different days of the year. For large numbers of customers individual peak demands are leveled out in the combined demand through random customer behaviour and the ratio between the sum of the individual peak demands and the maximum peak demand of the combined loads remains constant. Examples based on historical data of normal domestic electricity demand in Kersting (2007) and Van Oirsouw (2011) show that this is the case from 50 customers and up. This justifies working with these aggregated profiles for domestic loads representing 50 customers or more. ",
            "Photovoltaic panels": " For a group of houses with solar panels the total area of the panels can be summed up and the efficiencies of the solar cells can be averaged. These factors can subsequently be applied to the irradiance pattern to create an aggregated generation profile of the total of solar panels in a residential area with the following formula: P PV \u00f0t\u00de \u00bc A \u00c2 Z \u00c2 I b \u00f0t\u00de \u00f01\u00de In (1) A is the area of the panels, Z the efficiency of the panels and I b (t) the irradiance with an inclination angle b to the horizontal plane. The maximum and minimum irradiance of the sun in the Netherlands in the months July, having the longest days, and December, having the shortest days, are shown in Fig. 3.",
            "Electric vehicles": " Mobility Research Netherlands is an initiative that conducts a yearly survey under 50,000 participants and collects a large dataset with driving distances, home arrival and departure times from which driving patterns can be obtained (Lampropoulos et al., 2010;Ministry of Infrastructure and the Environment, 2009;Verzijlbergh et al., 2011). Based on this dataset, the penetration degree of electric vehicles in an area, and the energy need of a single car which depends on the daily distance driven (an EV efficiency of 5 km/kW h is assumed), aggregated profiles are constructed. The charge profile also depends on the charge rate. A detailed description of how the profiles are constructed, taking into regard simultaneous demand of groups of EVs, can be found in Verzijlbergh et al. (2011).",
            "Combining the individual load and generation profiles": " After careful modelling of the profiles of all elements, the individual profiles can be combined, which results in aggregated net load profiles for groups of households.1 For each of the scenarios, this is done for the ten residential areas with the characteristics as presented in the previous sections. This results in realistic aggregated profiles of the residential areas in the year 2040. For the electricity distribution grids the worst case situation is of most interest, this is the situation in which there is maximum generation or maximum demand. This can be a situation in summer when there is much generation by solar panels and very low demand or a situation in winter on a cloudy day when heat demand is large and there is no generation by solar panels. In Scenario C, the share of photovoltaic generation in residential areas is the largest. In Fig. 4a the profile of the residential area with the largest share of solar panels in summer time is presented. In Fig. 4b, the profile of the same area in winter time is presented. The individual profiles of new technologies as they are expected in this area as well as the total aggregated profile of the group of households are depicted. It can be seen that the peak load in winter is higher than the maximum generation when generation peaks in summer and that even with this large share of photovoltaic generation the highest peak will occur in winter. This applies to all residential areas. The variation in the maximum electricity demand in the residential areas in the three scenarios is presented in Fig. 5. For each scenario the winter profiles of two residential areas, the area with the lowest and the area with the highest demand, are presented. Also, the profile of an average household with a current annual electricity demand of 3400 kW h and assuming an demand growth of 1% per year, is presented.",
            "Incorporating flexible loads": " This research assesses the impact of future scenarios on the distribution grids. For grid operators, especially the potential of optimising network utilisation can be a major benefit of future, smart grids. Therefore, in this research the impacts of future loads to which a control strategy is applied that is focussed on reducing the peak demands at residential areas is assessed, besides the impacts of future demands without load control. The applied control strategy is based on the following assumptions: Electric vehicles are connected to the grid when people are at home and the cars must be charged before leaving. It is expected that in the future smart grid 10% of the normal residential electricity use for household appliances can be shifted to other times in day through load management. This percentage is based on an extensive European research on the potential of load shifting by domestic appliances (Stamminger, 2009). It concludes that in a region that represents Germany and Austria and that can be compared to the situation in the Netherlands, the evening peak is for almost 50% caused by dish washing, and laundry washing and drying. It also concludes that by managing the power on the grid 10-30% of the power demand of these appliances may be shifted to other times in day. The electricity demand for the compressor of welldimensioned heat pumps cannot be shifted on (very) cold days, because the compressors that are used to provide basic heat demand are continuously functioning during these days. Especially on a very cold winter day with maximum demand for which the grid must be dimensioned, this will be the case. In case of ground source heat pumps that are expected to be mainly applied in newly built areas, where no gas networks are present, a resistive heating element is present for additional heating on very cold days. Measurements show that this Scenario A, new area with <500 households/square meter Scenario A, existing area with >2500 households/square meter Scenario B, new area with <500 households/square meter Scenario B, existing area with >2500 households/square meter Scenario C, new area with <500 households/square meter Scenario C, existing area with >2500 households/square meter 1% demand growth of normal residential electricity use element is only used for short periods and that its use depends on the buffer capacity of the house (Veldman et al., 2011b). In Westerga et al. (2011) the thermal capacities of various housing types are determined. It is shown that under extreme Dutch winter conditions it takes more than an hour for the indoor temperature to decrease with 1 K in existing houses that are not well-insulated and that under normal Dutch winter conditions in well-insulated newly built houses this takes at least 6 hours. In our case of well-insulated newly built houses, under extreme winter conditions, the temperature loss in the houses will be somewhere in between these two values. This makes it a valid assumption to state that these houses have enough buffer capacity to store the heat for some time and makes it possible to shift the additional heating and thus the electrical demand of the resistive heating element to an earlier point in time. With these assumptions the profiles are again constructed. First, the flexible parts of the individual load profiles are determined, i.e., the demand for electric vehicles, 10% of the residential demand, and the demand for the resistive heating elements of the heat pumps. Then the flexible parts of the load profiles are added to the profiles of the inflexible demand. This is done by applying a function f(t) to the flexible parts of the electricity demand to spread the flexible load from the peak to other times in day: f t \u00f0 \u00de \u00bc C\u00c0 P total \u00f0t\u00de P max, total\u00f02\u00de In this formula P total (t) is the total load at time t without the load of the flexible demand which is controlled. C is a constant that determines how much of the flexible demand can be served during the peak moment. In principle, if C\u00bc1, the peak of the new total load is never higher than the peak of the total inflexible load (under the condition that all flexible load might be served during off-peak hours). To study the effect of e.g., a group of electric vehicles on a distribution feeder, it seems more realistic to assume that not all connected vehicles can be controlled perfectly. Therefore, a value of C \u00bc1.1 is chosen. This means that 10% of the peak can also be used by the flexible loads. This function is used to determine the charge rate of electric vehicles determined by the available charge time between home arrival and departure and the car's energy need. See Verzijlbergh et al. (2011) for a detailed description of constructing the profiles for controlled charging. The power demands for the resistive heating elements as well as for the residential demand to which demand response is applied are fixed. The function is in these cases only used to shift the times when these demands are fulfilled. Applying this control strategy to the flexible parts of the demand leads to more flattened net load profiles. The resulting total aggregated net load profiles for the same areas as which were presented in Fig. 5 are presented in Fig. 6, but now with load control of flexible loads. The changes in the peak demand and in the contributions of the individual elements during the peak moment are summarized in Table 4 for the ten types of residential areas. Through smart control the total (aggregated) peak demand can be reduced with 35-67% in the various areas. This would require much less network capacity. The largest contribution to the reduction of the peak demand is caused by smart charging of electric vehicles.",
            "Impact on the distribution grids": " The impact of various future scenarios on the loading of electricity distribution grids is assessed by using the net load profiles as input for load-flow calculations of an extensive set of medium voltage networks in the Netherlands. As in most countries in northwest Europe, the Dutch electrical power system was introduced at the start of the 20th century and, after its initial introduction, increased in scale and developed into the extensive electricity delivery system that we have today. Specific for the Netherlands is the fact that during its development nearly all connections in the distribution grids up to 20 kV have been replaced by cables; this resulted in a high reliability compared to other European countries. The uncertainties in future electricity demand and the opportunities provided by smart grids are nonetheless not different from other developed countries.",
            "Topology and operation of medium voltage networks": " The typical topology of medium voltage (MV) networks in the Netherlands is depicted in Fig. 7. An MV-network is fed by a (regional) transmission network through a high to medium voltage (HV/MV) transformer. Typical primary voltages of HV/MV-transformers in the Netherlands are 220 kV, 150 kV, 110 kV and 50 kV; typical secondary voltages are 25 kV, 20 kV and 10 kV. MV- Scenario A, new area with <500 households/square meter Scenario A, existing area with >2500 households/square meter Scenario B, new area with <500 households/square meter Scenario B, existing area with >2500 households/square meter Scenario C, new area with <500 households/square meter Scenario C, existing area with >2500 households/square meter 1% demand growth of normal residential electricity use Fig. 6. Aggregated residential net load profiles in 2040 for three different scenarios with control of flexible loads (scaled back to one household). transmission can be carried out either at the same voltage as MVdistribution, in which case no MV/MV-transformer is necessary in the MV/MV-station, or at a higher voltage (e.g., MV-transmission at 20 kV or 10 kV and MV-distribution at 10 kV or 3 kV, respectively). MV-distribution feeders are generally constructed as two half rings which are disconnected from each other. In Fig. 7 MV-networks with and without MV-transmission are depicted schematically in their most straightforward form. More complex variations frequently occur, in which for instance a MV/ MV-substation is connected to several other MV/MV-substations. Besides, many MV-installations at HV/MV-substations feed both MV-transmission networks and MV-distribution feeders and not all distribution feeders feature the pure ring shape. MVtransmission networks normally meet the (n \u00c01) criterion, which means that when all (parallel) cable bundle circuits are in operation, any cable circuit in the bundle can be lost without causing an overload of any other cable and without any interruption of supply. Meeting the (n \u00c0 1) criterion also facilitates maintenance, as one circuit can be taken out of service for carrying out maintenance.",
            "Load-flow calculations of medium voltage networks": " The selected grids for the analysis cover networks from the 150 kV till 0.4 kV voltage level. The assets included in these networks are the HV/MV-transformers, the 10 kV transmission and distribution cables and the medium to low (MV/LV) transformers. The number of assets under consideration in this research can be found in Table 5. These numbers are related to 48 MV-networks that serve in total 920,000 residential customers. In order to identify the impact of future residential demands on the MV-networks, the loadings of these four types of assets are assessed with load-flow calculations. The values of voltages and power flows of systems in normal steady-state operation are calculated. For this research, the loadflow calculations are performed with the commercial package Vision (Vision Network Analysis, 2011), which uses the Newton-Raphson method to solve the load-flow equations. It is assumed that the high voltage side of the HV/MV-transformer functions as a slack bus. Loads are modelled as constant impedances to ensure better convergence of the load-flow algorithm. The networks under consideration are all represented in files suitable for this package and these Vision network files include recent measurements of cable and transformer loadings as well as various coincidence factors based on these measurements. These coincidence factors compensate for the fact that maximum power at the beginning of the MV-distribution cables is not equal to the sum of the individual peak power of the connected loads. The coincidence factors are connected to each node of the MVdistribution cable with a load (i.e., a MV/LV-transformer). Also,  coincidence factors are applied between MV-distribution and MVtransmission cables. The coincidence of peak demands of individual households may change due to for example a simultaneous demand for heat pumps on a cold day. This is integrated in the aggregated net load profiles at the MV/LV-substations. The coincidence factors at the MV-cables have not been altered for the load-flows with future residential demands. The peaks of the profiles are used in the load-flows to calculate the peak loadings in the networks. Further details can be found in Grond (2011). For the three scenarios load-flow calculations are performed to calculate the component loadings in 2040 by altering the existing residential demands in the network to future conditions. This procedure is presented by the block diagram in Fig. 8. The loads of the transformer substations that supply residential areas are adapted by connecting the aggregated day profiles of the future residential loads of the ten types of residential areas as introduced in Section 4. The transformer substations in these networks supply on average 72 households. For all three scenarios the situation without control and the situation with load control to reduce peak demands are investigated.",
            "Component peak loadings": " Load-flow calculations yield the peak loadings of the four types of assets in 2040 as presented in Table 5. These peak loadings occur on a very cold winter day when there is maximum demand and minimum generation. The spread of the peak loadings of the assets of the 48 MV-networks that have been analysed, are depicted in Fig. 9 and the average peak loadings are presented in Table 6. Also, the expected loading in 2040 following the conventional network planning method of the DNO that takes into account a yearly demand growth of 1% for all connected loads is presented. Though the assets should be replaced in time to prevent them from overloading, these results give a good representation of the relative differences of the peak loading of the assets between the different cases and enables a comparison between the various scenarios and the situation with and without load management to reduce peak demand. When comparing the results, large differences can be observed between the three scenarios. In most cases the expected loading is higher than the loading that the conventional network planning method takes into account. This is especially the case for scenarios B with and without load control and scenario C without load control; for these situations the component peak loadings are at least 24% higher than the situation that only takes into account a 1% load growth of the normal residential electricity use and no additional loads for new technologies. If we focus on the results of the peak loadings of the scenarios in which load control of flexible residential demand is applied to reduce peak demand, we can see significant reductions of the loading for all types of assets: in all scenarios, the loadings of the assets are reduced with 21-40%. Furthermore, it can be noted that the assets on a higher level in the network are higher loaded than the assets close to the end users. This is caused by the fact that assets operating on a higher voltage level are more expensive and HV/MV-transformers are therefore placed with relatively less redundant capacity than MV/ LV-transformers. That MV-distribution cables have more redundant capacity available for future growth than MV-transmission cables was also demonstrated in Veldman et al. (2011a).",
            "Financial impact": " To give an impression on what these reductions in required capacities have on network investments, we will calculate the indicative financial consequences for the 48 MV-networks including the assets that were presented in Table 5 and compare these with the expected investments costs of the conventional scenario.  Based on current investment costs, taking no discounts rates or price rises of material and labour costs into account, we calculated the investment costs that are needed for upgrading the capacities of the existing assets, by replacing every overloaded asset with a new one. The overload criteria for the assets are given in Table 7. For the scenarios without load control, the overload criteria follow the guidelines of the DNO involved in this research. The overload criteria of the scenarios with control are more stringent, because a more continuous loading of the assets reduces the room to utilise the heat capacity of the assets and hence the potential for exploiting thermal dynamics (Slootweg et al., 2007). The replacement prices vary depending on the capacity of the specific asset that is replaced and the size of the replacement project. To give an indication, the average replacement costs lie around h12,000 for a MV/LV-transformer, around h2,400,000 for a HV/MV-transformer, and between h225,000 and 350,000 per km MV-cable. The number of replacements and outcomes for the 48 MV-networks can be found in Fig. 10 and Tables 8 and 9. The relative cost savings that can be realised by applying load control to reduce peak demand, are the highest in Scenarios A and C. Due to the fact that in scenario B the growth of the electric energy demand is much higher, the total investments needed will be much higher, regardless of any load control. Therefore, the cost savings that can be obtained by load control relative to the investment costs if no control is applied, will be less compared to scenarios A and C. But, because the total investments costs will be much higher in Scenario B, the absolute cost savings will be higher. These numbers give an impression of the possible costs savings that can be realised by applying smart grid functions that involve reducing peak demands at residential areas. In a country like the Netherlands it is expected that in the period towards 2050 h5-19 billion needs to be invested in the medium voltage a Because of the (n \u00c0 1) criterion the MV-transmission cables must be able to take over the load of parallel cables during an interruption. To fulfil the (n \u00c0 1)criterion in case of HV/MV-transformers spare capacity is present by additional transformers that are not in operation; this does not affect the overload criterion of the individual transformers. Note that when the transformers need to be upgraded the save capacity that includes the capacity of the additional transformers is taken into consideration.  5 for the scenarios A-C with and without load control to reduce peak demand; the boxplots present the minimum and maximum values and the 25th, 50th and 75th percentiles. grids (Netbeheer Nederland, 2011), the possible cost savings are thus substantial. These numbers are, however, only indicative, and for a good financial analysis one should also include costs for energy losses and maintenance, because a higher utilisation degree of electric assets will induce higher energy losses and maintenance and thus increase operational expenditures. On the other hand, possible savings on the low voltage networks can be expected as well, these savings are not included in this study. To realise the costs savings, a smart distribution grid must be in place. A smart grid requires investments in information and communication technology (ICT), and also investments in electronic devices, software and marketing to get the customer indeed involved. The investments in the distribution networks that are needed for smart grids require sensing, monitoring and control equipment in the low and medium voltage networks. Measurement on the LV-side of the MV/LV-substations can be done relatively easily and with low investments. The MV side is more complicated, but in the recent past there have been some interesting developments (Slootweg et al., 2011a). Though the market for equipment for sensing, monitoring and control in MV and LV networks is relatively new and prices are still high, DNO's start to roll out on a large scale distribution automation as one of the key elements of a smart grid (Morren et al., 2011). The best solution for getting the LV-consumers involved is to use smart meters (Slootweg et al., 2011b). The roll-out of these smart meters, another component of smart grids, is already well underway in many EU member states to realise various kinds of operational benefits, like elimination of meter reading costs and minimising power theft (Faruqui et al., 2010). Taking into regard the various goals of using smart grid functionalities and the investments that are already (being) made for the various components of smart grids, it can be concluded that the potential costs savings in investments by reducing peak demands through smart grids are very likely to offset additional costs that are needed to realise these. Besides this, there may be other additional benefits of smart grids than cost savings in investments that make an even more positive case for smart grids. The most important building block of smart grids to realise the positive overall (or societal) business case and grasp the financial gains, is to unlock the flexibility in residential electricity  demand by the introduction of dynamic tariffs (CE Delft and KEMA, 2012;Faruqui et al., 2010). Therefore, further research regarding possible dynamic tariffs is highly recommended. Besides that, it is important to test these new arrangements and designs of the smart grid in the real world to gain a better understanding of the opportunities and risks in pilot projects with actual consumers and prosumers. It is important that these smart grid projects not only demonstrate the technology which will be implemented in the long term, but also focus on new institutional arrangements and the social and economic aspects of the concept of smart grids.",
            "Conclusions and discussion": "",
            "Conclusions": " New developments towards a more sustainable energy delivery system require electricity distribution grids that support distributed generation and a potential increase in electricity demand. With activation of flexible demand through smart grids, grid utilisation can be optimised. Our research has given more insight in what applying smart grid strategies to reduce residential peak demands means for the required capacity of the distribution grids by using a scenario-based methodology to model future residential demands. Because future technologies are separately modelled with this approach, it is possible to model aggregated residential demands for various future scenarios. In future residential areas of the Netherlands an (average) peak demand of 0.89-1.30 kW per household can be expected in 2040 if, following the conventional network planning method, a 1% load growth of the normal residential electricity use is taken into account. It is shown that for various scenarios considered in this research, the peak demands for electricity in future residential areas towards 2040 will be higher compared to this situation. These demands can, however, differ significantly per scenario; an average peak load of 0.89-2.03 kW per household is expected in a scenario with a small economic growth and mainly centralised production (scenario A) compared to 1.96-3.60 kW in a scenario with high economic growth that leads to higher energy demand and many new technologies in residential areas (scenario B). Furthermore, the scenarios lead to different daily net load profiles. A strategy for network operators to cope with these changes and to optimise the utilisation of their grids is to use the possibilities to control flexible loads to shift demands and reduce peak demands. This includes charging cars during night hours, spreading the electrical demand for heat pumps by buffering heat and having smart appliances like smart washing machines running when demand is low. In this article it is shown that if these demands can be managed in such way, the electricity profiles during winter can be flattened significantly and the peak load in residential areas is reduced with 35-67%. The largest part of flexibility in future residential electricity demands is the process for charging electric vehicles. The resulting aggregated residential loads for various future scenarios are used for load-flow analyses of typical medium voltage distribution networks in the Netherlands which are built up of cables and radially operated. It showed that a load management strategy to reduce peak demands can realise a reduction of 21-40% for required capacity of cables and transformers. This makes a reduction of 45-72% in investment costs possible in all scenarios, with regard to required capacities for medium to low voltage transformers that supply residential areas, medium voltage cables and medium to high voltage transformers. Of course, there are also investments needed to realise these costs savings, but taking into regard the various goals of smart grids functionalities and the investments that are already (being) made for the various components of smart grids, it can be concluded that the potential costs savings are very likely to offset additional costs that are needed to realise these.",
            "Discussion": " By examining electricity networks in the Netherlands, we have shown that the approach as applied in this article gives insight in the impacts of uncertainties in future electricity demands. The results illustrated that scenarios resulting from varied economic and demographic developments, but also driven by energyrelated policy choices to e.g., reduce greenhouse gas emissions and increase the share of renewable energy production, can have considerable consequences on the loading and the resulting required network capacities of electricity distribution grids. To be able to respond to the developments on time, on the one hand it is essential for DNOs to be flexible in network planning itself and on the other hand, making use of the flexibility in future demands can be a way to reduce (rapidly growing) peak loads and optimise grid utilisation. Further, local as well as national governmental bodies can contribute to minimising uncertainty by formulating clear visions on the future energy system and making clear choices regarding their energy policies. The results of the case study covered in this article showed that various scenarios have impacts on different network levels. This shows how choices towards a more centralised or a more decentralised energy system have implications on different levels of the entire energy delivery system. Policy makers should therefore be aware how policy choices affect all chains in the overall system and take this into account when making these choices. Furthermore, they should communicate their policies and tune their strategies to stimulate distributed generation and new enduse technologies with network operators to be able to make sound choices and avoid excessive investments in network capacity on the one hand or capacity shortages on the other. A last point of discussion is the impact of demand response on the loading of the distribution networks. In the case as treated in this article, the possible gains of load management of residential loads with regard to network capacity were quantified. However, many other objectives for load management can be thought of. To assess the system-wide benefits of load management in the electricity delivery system it is important to further quantify the impacts of various control strategies that may serve different goals and different parties on the grids. Developing these insights helps to obtain the overall benefits of demand response in smart grids and will make it possible to combine the different goals for different parties in such way that the benefits for the overall system and for society are optimised. The question in which way the residential electricity consumption can be managed in practice to achieve the results presented here is beyond the scope of this article, but requires further research. The potential gains presented in this article are relevant input for this discussion."
        }
    },
    "10.1016/j.respol.2012.10.004": {
        "file_name": "128 Niches and networks",
        "title": "Niches and networks: Explaining network evolution through niche formation processes",
        "abstract": "This paper uses the evolutionary perspective of Strategic Niche Management to investigate and explain the network dynamics of a collaborative innovation network. Building upon the theories of socio-technical transitions, we link macro-level network dynamics to the micro-level niche processes of vision building and experimentation. The paper describes a method to construct longitudinal two-mode affiliation networks and this method is illustrated with an analysis of the network properties of an agricultural niche in the Netherlands over a period of 15 years. Results show how a successful niche grows more connected, even when it grows in size. We found three distinct phases during which the network composition is more or less stable. Powerful actors are able to shape the composition of the network, either through providing the financial resources or through creating \u201clegislative space\u201d for the network to grow.",
        "label": "Mixed",
        "text": {
            "Introduction": " The fundamental question of how innovations can contribute to sustainable development is important for both researchers and practitioners. It calls for an understanding of how new technological practices are developed and spread and how these processes can be managed effectively. Sustainable technologies go beyond simple technological fixes, but instead require a reordering of societal structures and social change. The study of these large systemic innovations has been taken up in the relatively new fields of Strategic Niche Management and Transition Management (Kemp et al., 2001;Loorbach and Rotmans, 2006;Rip and Kemp, 1998;Schot and Geels, 2008). These transition theories hold an evolutionary perspective of technological development that focuses on the socio-technological niche as the place where new technologies emerge (Schot and Geels, 2007). New and divergent technologies are allowed to survive in small protected spaces where the mainstream pressure from the market or other regulatory forces is lower. Historical case studies have shown how many successful innovations started out in a technological niche and how they gradually became more important before they eventually took over the existing dominant socio-technological regime (Geels, 2002(Geels, , 2006;;Geels and Schot, 2007). The lessons from these historical case studies have inspired practitioners to purposefully create and manage socio-technical niches that allow for experimentation in order to further promising novelties. It is increasingly acknowledged that network structures play an important role in explaining the potential of emerging technologies to spread (Spielman et al., 2010;Van der Valk et al., 2011). An interesting approach to assess a niche is to look at its network. Cani\u00ebls and Romijn (2008) were among the first to systematically investigate the network of a niche using Social Network Analysis (SNA) and more recently Lopolito et al. (2011) have used SNA to define several development stages of a niche. This paper aims to take these approaches one step further by studying the characteristics of the network of a niche as it evolves over time. The central questions this paper poses are: (1) how does the network of a socio-technical niche evolve over time and (2) how can these changes in network structure be explained by the internal niche formation processes? Our analysis of these two questions provides both theoretical and methodological contributions to the study of niches and their roles in socio-technical transitions. The theoretical contribution of this paper lies in its introduction of a perspective of 0048-7333/$ -see front matter \u00a9 2012 Elsevier B.V. All rights reserved. http://dx.doi.org/10.1016/j.respol.2012.10.004 network evolution in the study of niche developments. Studies on the evolution of social networks show how changes in the macrolevel network structure can be explained by micro-level processes (Stokman and Doreian, 1997) and in this paper we will review how the niche internal processes of convergence of expectations and learning and testing drives the network structure of the niche. The methodological contribution of the paper lies in the application of Social Network Analysis on a dynamic network. Descriptions of longitudinal networks are still relatively rare. So rare in fact that Knoben et al. (2006) speak of a \"longitudinal gap\" that exists in the study of collaborative networks. In this paper we will apply an innovative method that helps in mapping the network characteristics of a network over time in a relatively straightforward manner. We will illustrate this approach by investigating the changes in the network of a Dutch agricultural niche over a period of 15 years. The implications for Strategic Niche Management, the study of transitions in general and the possibilities this approach has for further research are presented in Sections 5 and 6.",
            "Niches and networks": " A socio-technical niche can be defined as a protected space where promising new technologies are developed. As such a niche forms the micro level of technological and social change where actors are trying out new ideas in a series of dedicated experimental projects (Kemp et al., 1998;Raven et al., 2010). Raven (2005) identified three internal processes that are important for the development of a niche: (1) the articulation and subsequent convergence of visions, (2) learning and experimentation and (3) the building of social networks. The convergence of actors' visions refers to the degree to which their strategies, expectations, beliefs and practices go in the same direction. A shared vision between collaborating actors is important in order for the different actors to agree on the actions they will undertake (Beers et al., 2010). The actors in a niche are prepared to accept the initial low performance and higher costs of a new technology and are willing to invest their time and resources to improve it. Niche innovations are therefore often carried and developed by small groups of pioneers: dedicated \"outsiders\" that are marginal to the existing networks of the socio-technical regime and do not share some of the rules with respect to technical development (Van de Poel, 2000). When initial expectations of the innovation are confirmed through positive results of projects and experiments, new actors and organisations are more likely to invest new resources in further developing the technology. This shared expectation provides direction to the projects and experiments done in the niche. Within a socio-technical niche, learning and experimentation function therefore as a way to test the vision, and to gain experience with a new practice or technology. In many SNM projects there is often a strong focus on social learning and knowledge co-creation. This form of organisational learning takes place in multi-disciplinary collaborative projects that create an opportunity for people to interact, share their ideas and verify their own mental frameworks in discussion with others. During processes of social learning, peoples' perceptions change and they move from typical first loop learning to second loop learning. Their individual mental models are aligned into a shared group model enhancing trust between participants along the way (Argyris and Sch\u00f6n, 1978;Leeuwis and Pyburn, 2002;Pahl-Wostl et al., 2007). Social learning processes thus result in outputs, the practical plans, policies or technical novelties that were produced, and some intangible outcomes: improved relations and trust between actors (Burgess and Chilvers, 2006;Hermans et al., 2011). Finally there is the composition of the niche and its network. Complex innovations require different partners with different resources and knowledge in order to perform different roles and tasks within the niche (Hermans et al., in press). Research shows that a niche with a limited network in terms of diversity is likely to fail and that niches with broader networks provoke more secondorder learning (Schot and Geels, 2008). Other network studies that look at the performance of individuals and corporations as a function of their personal network characteristics show how certain network characteristics can be advantageous for innovative performance, while other are not (Ahuja, 2000;Burt, 2005). Based on the three niche internal processes of Raven, Lopolito et al. (2011) derived a taxonomy of the potential stages a niche can find itself in, see Table 1. A linear development process is defined in which first a shared vision has to be present, the right actors are to be involved and finally the experimentation and learning can start. It is clear that the internal niche processes are closely linked to each other and form an iterative cycle of activities in the niche (Loorbach and Rotmans, 2006). Through testing and experimentation the vision will be adapted in a continuous process: promises and practices in a niche develop simultaneously (Stuiver and Wiskerke, 2004). The results of successful experimental projects will make it easier to enrol new actors and expand the network. Negative results, or results that are below the initial expectations, do they opposite: they reduce the faith in the new technology leading to a shrinking network and less resources made available for further testing (Geels and Raven, 2006). Our first goal is to move from the rather static, linear description of development stages portrayed above to a more dynamic approach that takes into account the changes in the niche network over time. This means that we will look at the network structure of a niche and we will explain the changes in the structural characteristics of the network by referring to the two underlying processes of vision convergence (shared purpose) and learning and experimentation. Following Lopolito et al. we formulate our first proposition: Proposition 1. Technological niches have different development phases in which the purpose of the actors involved, their learning and experimentation define the network properties of the niche. According to Head (2008), the character of cooperation within networks change over time with the establishment of trust. In the early stages of the collaborative network, its projects often can be characterised as forms of cooperation in which the work is task-focused, generally short term and participants maintain their organisational identities as they strive to obtain the goals and objectives of their own organisation. As trust between participants develops, successful co-operations may lead to more complex and ambitious projects being organised that require more coordination among the network participant and the installation of a central coordinating organisation. Joint planning or the implementation of an agreed joint working programme for the medium term can be established. The network stabilizes and a central coordinating organisation is created that can take the form of a special platform or a consortium that coordinates interactions in the network and stimulate its further expansion. Since technological niches are not yet ready to function as a market niche, the coordinating role within these kind of networks is often reserved for the government (Raven, 2005). Proposition 2. The network structure of a niche becomes increasingly centralised as trust builds up between actors and organisations and they move from cooperation to more coordinated forms of collaboration. However, there is also a competing force at work. As the network of the niche grows, more and more people will be involved and they are less likely to know all the other actors involved in the network. A growing network can easily suffer from a decline of trust between the people involved. This line of reasoning follows Coleman (1988) and Granovetter (1985Granovetter ( , 1992) ) who have argued that closed networks facilitate the effective enforcement of sanctions as all the actors are connected and therefore know each other's actions: a denser network will therefore induce more trust (Buskens, 1998). After the network has reached a certain size actors lose the overview of the whole network and the trust between its members is likely to go down. Proposition 3. A growing network will become less cohesive which will lead to a loss of trust between partners. It is important to note that the potential of a niche to be successful depends not only on the internal characteristics of the niche, but also on its relationship with the incumbent technological regime and the broader environment, the socio-technological landscape both the niche and the regime are embedded in, conceptualised in the multi-level perspective of transitions (Geels, 2002(Geels, , 2005;;Geels and Schot, 2007). The multi-level perspective (or MLP for short) brings the elements of learning, bottom-up innovations and processes of social change in a single research framework. Although the multi-level perspective has become a very popular framework to study transformative innovations within society, it is not completely undisputed. For example, the analytical distinctions between the different levels of the MLP sometimes seem to be somewhat arbitrary. The differences in structuration of different levels are of a gradual nature in which one level blends into the next. The core concepts of niches, regimes and landscape therefore differ from study to study, leading to a wide range of definitions being in use (Markard and Truffer, 2008;Raven et al., 2010). Boundaries between niches and regimes sometimes become blurred or even disappear altogether (Elzen et al., 2008;Smith, 2006Smith, , 2007)). This has led some authors to call for more methodological rigour in the application of the MLP (Genus and Coles, 2008;Smith et al., 2010). An additional goal of this paper is therefore to investigate whether the application of Social Network Analysis can provide such a more formal approach to link the relationships of the actors in the niche to the actors outside the niche.",
            "Method": "",
            "Case: the environmental cooperatives of the Northern Frisian Woodlands": " The case of the Northern Frisian Woodlands (NFW) is an example of a socio-technical niche operating in the agricultural sector. In the niche two related ideas were championed that challenged the prevailing Dutch agricultural regime regarding dairy farming and manure application. The establishment and history of the NFW has been described by various authors in terms of Strategic Niche Management, see for instance: Roep et al. (2003), Wiskerke and Van Der Ploeg (2004) and Stuiver (2008). We will draw on these descriptions for our historical overview described below. The Northern Frisian Woodlands is an area of about 60,000 ha located in the north of the Netherlands dominated by dairy farming. It consists of small-scale, closed landscapes on high sandy soils, alternated by relatively open areas on lower peat-clay soils. The small-scale landscapes are formed by hedges and belts of alder trees surrounding the plots of land, resulting in a unique mosaic of parcels (Van Apeldoorn et al., 2011). In the 1990s, national regulations were drafted that imposed stringent measures to reduce the environmental impact of agricultural activities. These national regulations were tailored to the existing socio-technical regime in dairy farming: prescribing the use of large manure injectors to pump the sludge directly into the soil of the grassland thus reducing direct ammonia emissions. The new law did not allow any other form of manure application anymore and forced all farmers to work with these manure injectors. However, these manure injectors consisted of very large and heavy machinery that conflicted with local field conditions and threatened the operations of local dairy farms within their small-scale landscape. As a response to this threat, regional environmental farmer cooperatives were established with the aim to move towards viable and environmental friendly agro-systems attuned to the local landscape. VEL (Vereniging Eastermars Lansdouwe, landscape association of Eastermar) and Vanla (Vereniging Agrarisch Natuur en Landschapsbeheer Achtkarspelen, Agrarian Nature and Landscape Association of Achtkarspelen), were the first two environmental farmers cooperatives in the Netherlands (Renting and Van Der Ploeg, 2001). After its foundation in 1992, a subsidy of the Ministry of Housing, Spatial Planning and the Environment (VROM in Dutch) created the financial room for VEL to work out its ideas for landscape management and nutrient reduction into a consistent pilot plan. Based on this plan, VEL and Vanla joined forces with three other new Dutch environmental cooperatives and successfully lobbied the Ministry of Agriculture to let them implement their vision and explore and develop their own means of combating nutrient losses on their farms. In 1996 the Minister, overruling his own civil servants, granted the environmental cooperatives a formal exemption for the national manure regulations and allowed them to start experimenting with locally developed alternative measures. With this formal exemption the environmental cooperatives got their niche status as a protected space ( Van der Ploeg et al., 2004). The exemption from the national legislation for this region has been extended ever since in order for the cooperatives to develop new knowledge and experiment with other forms of nutrient management in close cooperation with scientists (Eshuis and Stuiver, 2005;Stuiver et al., 2003;Stuiver and Wiskerke, 2004). In 1998, VEL and Vanla and three other regional environmental cooperatives merged into a new regional environmental cooperative, The Northern Frisian Woodlands (NFW). At almost the same time two large research projects commenced. The first project is the Nutrient Management Project, a follow-up project of the grassland experiments of 1996, to evaluate the new approach in a more scientific manner. Additionally, an extensive scientific research project (AGRINOVIM) is also approved in this phase by the Netherlands Organisation for Scientific Research (NWO) and these additional financial resources make it possible to involve even more scientists in the region. A scientific council is created that brings representatives of the farmers and the scientific community together and starts to coordinate the research activities in the region. In the year 2000, the landscape management programme is formally institutionalised with a national subsidy program that allows for farmers to manage the landscape in return for financial compensation. Over 400 farmers belonging to the NFW enrolled in the programme and  in 2003 the whole region is given the protected status of National Landscape (Eshuis, 2006). The manure and nutrient management project do not fare so well. In 2001, the group of involved scientists split internally over the interpretation of the manure application experiments. The spark that ignited this controversy was the publication of the book \"Good manure does not smell\" (Eshuis et al., 2001) by a group affiliated mainly with the rural sociology department of Wageningen University claiming the success of the early grassland experiments. The second group of scientists, mainly affiliated with the animal sciences department of the same university, contested the claims that were made on statistical grounds. See Stuiver (2008) for an in-depth description of this conflict. In the end, a compromise was reached that more research was necessary into the link between grassland quality, manure application and soil quality. In 2004, a new national subsidy programme is set up with the specific aim to trigger transitions to a more sustainable agricultural sector. The programme, entitled TransForum, derived its inspiration from transition management and SNM (Veldkamp et al., 2009) and after some lobbying two projects related to the NFW emerged. The first project was a scientific project that places environmental monitoring in a more participatory regional context: instead of monitoring on environmental pollution at the farm level it investigates the possibilities to shift this monitoring to the regional level. The soil scientist who had taken up a more or less neutral position in the earlier conflict came to the forefront to lead this new scientific project. The other project that was started was a practical project aimed at investigating the possibilities and requirements of a regional contract as a new form of rural governance. One of the requirements of TransForum for funding the NFW was to broaden the regional network and start making work of regional development that also included other sectors, apart from the agricultural dairy sector. In 2005 this regional covenant is signed by the five municipalities, water board, province of Friesland, and the farmers. Fig. 1 gives a timeline for the most important events in the history of these two environmental cooperatives. This initial overview provides some preliminary support for some of our propositions in a qualitative manner. Firstly, the conflict between the scientists involved that followed upon the publication of the book \"Good manure does not smell\" is indicative for a loss of trust between participants. Secondly, the governance structure of the niche did change over the years with more coordination of the network activities in the form of two research councils and the regional contract. With the start of the Regional Contract in 2005, this new governance structure was also formalised. Thirdly, the development of the shared vision started with landscape management, and then further evolved into nutrient management and broadened to regional development and this would indicate a shift in the need for different partners with different knowledge regarding these new goals and practices, resulting in a change in the composition of the network. All in all, this case contains all the ingredients necessary to test our propositions regarding network development on. In the next section we will describe our methodology to construct the different networks over time in some more detail.",
            "Sources of data and data selection": " We collected data from the various experimental projects from the foundation of VEL and Vanla in 1992 until the end of 2008 using scientific descriptions of the projects, as well as archival information such as project proposals, final reports, minutes of various meetings, and an extended collection of over 220 newspaper clippings detailing the founding of the VEL-Vanla cooperatives between 1990 and the 2000. These newspaper clippings were further extended with a Lexis-Nexis search between the years: 2000-2010 on the topics of \"NFW\" and \"VEL AND Vanla\". Information was structured using the timeline for the Northern Frisian Woodlands given by Van der Ploeg et al. (2007). The year 2008 functioned as a cut-off date for data gathering. New projects may have commenced, but these were not included in the data set. We limited the selection of the projects included in the data set to only those where members of VEL and Vanla participated, either through actively contributing or more passively by an advisory role or providing data for further analysis. Interdepartmental working groups consisting of civil servants alone were not incorporated in the data set. Similarly, PhD research projects were not included. Selected projects were checked by two long-time participants in the VEL-Vanla network for accuracy. Table 2 gives an overview of the 21 different projects we identified. We made a distinction between four types of projects, based on their main purpose: nutrient management, landscape management, governance and research. Nutrient management projects focussed on the reduction of nutrient losses on farms through the use of additives to the manure, combined with a systems perspective of dairy farming that linked the feeds, cows, milk, manure and grasslands in an overarching analytical framework. The landscape projects focussed on the opportunities landscape management could provide for additional income of farmers. The governance projects focussed on the development of alternatives away from the top-down environmental legislation towards self-governance and a broader agenda of regional development. Research projects were process oriented, either actively coordinating research activities in the region, or evaluating the success of the collaborative projects of farmers and researchers in terms of innovative capacity.  ",
            "Mapping of networks": " Details of the projects, such as the persons and organisations associated with them, their starting and end dates were recorded in a database. Start dates and end dates were rounded to the nearest quarter as sometimes either the start point or end point was not exactly clear. The network of the niche at any point in time is constructed through the aggregation of all projects that run on a specific point in time, cf. Rosenkopf and Tushman (1998) and Soh and Roberts (2003). Each network consists of a unique combination of projects and the people and their organisations that are affiliated with them. As a new project starts, new organisations and people enter the network and once a project stops they leave again. We can regard each of these network structures as snapshots of the project network of the niche at any given time. This way we constructed 29 different two-mode affiliation networks4 that represent a unique configuration of different projects (see Figure 2). Playing these images quickly behind each other will eventually give a dynamic movie of the networks development over time (Moody et al., 2005). This method to construct the networks holds two assumptions. The first assumption has to do with the information transfer between people. Actors can exchange information in various ways, both in person and by other means (Berends et al., 2006). In our analysis we focus on the information that is shared between persons within a project. The projects provide the formal opportunity for people to meet each other in person and share their ideas. We have therefore assumed that all the people in a project know each other and communicate. We have applied the same reasoning for the organisations people are officially affiliated with. Large organisations (universities and government ministries for instance) were divided into their smaller subdepartments or chair groups where people can be expected to know each other and communicate. The second assumption has to do with the membership over time of the projects. We assumed them to be constant: no people leave or enter a project once it has started. It might be possible that a particular person of one organisation is replaced by another person as this does not fundamentally change the network structure.",
            "Analysis procedure: Social Network Analysis": " Social Network Analysis has been used as a tool to investigate the properties of social networks and the positions of actors in those networks in a semi-quantitative manner (Degenne and Fors\u00e9, 1999;Knoke and Yang, 2008;Wasserman and Faust, 1994). In Table 3 an overview is provided of some of the fundamental concepts of network analysis that are applied in our analysis. One of the core problems in longitudinal network studies is how to compare different sized networks with each other. Network size, density and centralisation are correlated, for which we have to control when interpreting the results. To circumvent this problem the mean degree of the nodes in the network was selected as a measure for network density: that is the average amount of ties each of the nodes possesses in the network. This measure has the advantage that it is independent of network size (Anderson et al., 1999;Stokman, 2001). However this is not possible for the degree centralisation and we have used the conditional uniform graph hypothesis test proposed by Anderson et al. (1999) to estimate the effects of this possible interference. Network composition was measured using the organisational diversity within the network. Organisations connected to the projects were categorised according to their institutional role: government, non-governmental, political or commercial. Table 4 gives an overview of the categories used in the analysis of the organisational level.",
            "Software": " Network properties were analysed using \"R\" the statistical software programme (version 2.8.0) (R Development Core Team, 2008) and more specifically its statnet-package (version 2.1) (Handcock et al., 2003). Visualisation was done using Pajek (version 1.26) (Batagelj and Mrvar;De Nooy et al., 2005) and SoNIA -Social Network Image Animator (Bender-DeMoll and McFarland, 2006).",
            "Results": " We constructed 29 different networks based on the combination of collaborative projects running at the same time. Space does not permit a full representation of all 29 networks, however the complete set of networks has been visualised in a short movie that shows the growth of the network over time as well as the change in structure. This movie can be downloaded as additional information to this paper. Table 5 gives an overview of the various measures for size, mean degree per node and the centralisation degrees for each of the 29 networks at different points in time. Fig. 3 depicts networks 1 and 16 as an example of two of these 29 networks. The first network shows the first project that was organised and how it brings ten persons from nine different organisations together. The other network, number 16, shows how six projects run during this period and how these projects are mutually linked through the persons that are member of the same projects. Fig. 4 gives an overview of the organisational composition of the network over time. Some drastic shifts in the network composition can be observed from one phase to the other, however in between these shifts the network composition remains relatively stable. Based on this figure we can thus distinguish between three different phases that existed over time. The first phase (comprised of networks 1-9) starts in 1993 and lasted until 1997. During this phase different agencies related to the provincial government take up an important part of the network. The second phase (networks 10-24) started in 1998 with the commencement of a number of research projects and lasted until early 2005. For most of this period the research groups made up for more than 50% of the network composition. The third phase (networks 25-29) started in the second quarter of 2005 and was still on-going at the point where we stopped the analysis at the end of 2008. In this last phase the network composition changes again into a more balanced distribution of sectors present: green-NGOs dealing with aspects of environment and landscape conservation become more involved, as well as local municipalities. Fig. 5 gives an overview of the development of the total number of organisations and persons in the network, measured as the total amount of nodes in the network, the connectedness of the network, measured as the mean degree: the average number of ties per node and the centralisation of the network. Our second proposition that the network will become more centralised after a number of successful projects and trust is established between the project partners, is not supported by the data on network structure. The network centralisation builds up before the year 2000 and decreases after that period but with a Pearson's product moment correlation of 0.23 there is only a weak correlation between mean degree and centralisation. This does not mean no coordination took place. After all, the governance structure of the niche did change over the years with more coordination of the network activities in the form of two research councils and the regional contract that was signed in 2005. Yet, these coordinating activities did not have any effect on the any centralisation of the affiliation network. Both research councils probably acted more as a portal to the niches network: new (research) projects first had to be approved by the research council, giving the members of the council the control over the influx of new people in the network, especially researchers. The network size and connectedness (mean degree) do show a significant correlation with a Pearson's product moment correlation of 0.60. This means that as the niche's network grows the network becomes cohesive at the same time: the average number of bonds between its members increases, making the network more connected. The opposite also holds: a declining number of members in the network corresponds with a less connected network. These results run contrary to our third proposition that the network would grow more disconnected as more and more people and organisations become involved in the niche. Fig. 5 shows how the mean degree steadily declined after the year 2001 and only started to grow again after 2005. This coincides with the period when the scientific controversy between the researchers of the rural sociology department and animal sciences group played out in the network of the Northern Frisian Woodlands. The controversy made it more difficult to interest new partners in the network as the visions within the niche did not converge anymore. The results show that the amount of trust between participants determines the growth and connectedness of the niche. A successful niche will grow more connected, even when it expands. Fig. 6 shows the boxplots for the network centralisation and the mean degree. A one-way between-groups analysis of variance (ANOVA) confirmed a statistically significant difference (at the p < 0.05 level) in the mean degree between the phases, but the networks centralisation scores between the phases did not show a significant difference. Post hoc comparison using Bonferroni's test showed that the average network degree of the second phase differs significantly with the other two phases. Phase 1 and phase 3 did not show a statistically significant difference. Our results thus show that the different phases in the niche can not only be viewed from the composition of the network, but they are reflected in the connectedness in each phase as well.",
            "Discussion": " The results show three phases in which the composition, the connectedness (mean degree) and goals of the niche remained  relatively constant. Table 6 summarizes the most important niche internal processes within each of the different phases. The environmental cooperatives were the result of farmers uniting themselves against the threat of a top-down implementation of national environmental legislation unsuitable to their way of farming in a small-scale landscape. This initial pre-niche phase thus was characterised by the self-organisation of farmers into the two environmental cooperatives. In phase 1 the vision converges as the farmers work out an alternative vision on landscape management and nutrient management on dairy farms. To spread their local vision, farmers actively lobbied the national authorities resulting in an exemption from the environmental legislation. It gave them the possibility to put their alternative manure and landscape management practices to the test during a series of field experiments that were conducted under the supervision of a number of researchers from different departments of Wageningen University. Half way during this phase (phase 2) the researchers developed a major conflict on the statistical interpretation of the experiments and the vision in the niche became fragmented. This conflict lingered on in the network leading to a decrease in the size of the niches network. Unable to prove beyond dispute the positive results of their experiments, the NFW farmers were forced to broaden their initial goals to include new goals of regional sustainable development. The network was broadened and the farmers were one of the partners, but not the most important ones. The composition of the niches network depends on the projects that it undertakes as part of the learning and experimentation process. The composition thus remains fairly constant within each phase. At first the niche had two main goals: landscape management and nutrient management. Although the landscape management initially faced strong opposition, the experiments with landscape management by farmers were successful and in the year 2000 it became official government policy. After this year no new landscape management projects were initiated anymore and this is a sign of success. The nutrient management projects were far more controversial and the experiments only raised new questions instead of answering them. The experiments done in the niche depended on exemptions from existing environmental legislation and each new project therefore had to obtain a new exemption for further testing and experimentation. So far the NFW has been able to secure the political backing but it has to be expected that this situation will not last if the nutrient management approach remains scientifically controversial. This brings us to the question the relationships of the local niche and supporting organisations such as government institutions and research funds that are not necessarily part of the project networks. Table 6 also shows the influence of some of these actors within the different phases. Funding from the Ministry of Housing, the Environment and Spatial Planning provided the necessary financial means that sustained the network in the first phase. The second phase of the niche started when the Minister approved the exemption of national environmental legislation under the condition that the field experiments would be conducted under the supervision of a number of scientists. Additional funds from the Dutch organisation for scientific research made it possible to include even more researchers in the experiments. In the last phase, the network composition was strongly influenced by the requirements of TransForum. The shifts from one phase to another can be attributed to these powerful organisations that influenced the niche through the conditions they set on the collaborating partners in return for their financial or legislative support. The network expands and decreases in time along with the finances provided various governmental subsidies that sustain it. Further research in the evolution of collaborative networks should focus on quantifying this effect, not only in SNM cases where government is very influential, but also in more commercial cases where the collaborating partners themselves or banks or venture capital provide the funds and resources necessary for the network to expand. A limitation of our study is the fact that we have only investigated the ties as expressed through the official membership of a multidisciplinary project. This has the disadvantage that it does not look at the role of weak ties in the development of the network. The decision who to invite for collaboration in the niche usually starts with some informal contacts between possible partners (Ahuja, 2000). However, the choice of our data gathering method based on archival information limited the possibilities of exploring these important mechanisms. For instance, after the Minister of agriculture gives the exemption for the national environmental legislation at the end of 1996, it still takes another year before the cooperatives bring in new partners and the new projects commence (in 1998). Similarly it also takes a while to set up the new projects funded by TransForum and it is at the end of the different phases that these informal contacts are likely to play an important role that currently remains hidden in the analysis. Further research should therefore focus on the partnering process in niches in more detail by incorporating also other types of relationship ties. This might also be helpful to further investigate the centralisation process in the niches network. Using affiliations did not reveal any significant centralisation process in the niche (proposition 2). However, applying another measure for network ties (like money flows or formal authority ties between actors) might still shed more information on the centralisation process. With regard to general transition theory, application of SNA complements the multi-level perspective that is commonly in use when studying socio-technological transitions. More research in this area is necessary but the network evolution perspective we present in this paper has the potential to allow for more detail in the study of the relation between niche and regime actors than is currently possible with the multi-level perspective alone. By reframing the interactions between competing niches and between niches and regimes in network terms it becomes possible to study the networks that are formed around different ideas and practices and analyse the different positions organisations and actors have within these network and their relationship towards the niche in more detail. Applying this perspective reframes the development and spread of socio-technical innovations as the result of a process in which many different actors and organisations are linked together by the different projects that they cooperate, fund or provide legislative space for. On a practical level the results show the importance of the recognition of the different possible phases in a niches development for policy makers. Institutional actors have been shown to be very influential in determining both the composition and the goals of the niche. For instance, the requirement of the Ministry of Agriculture to involve scientists led to a network dominated by researchers, while the requirement of TransForum to move on to regional development saw the inclusion of new actors and the adoption of a new discourse focussing on regional development within the network. Whether intentional or not, funding criteria shape the room for a niche to develop in. Government policies aiming to support a niche's growth and development should therefore not only cover a range of policy instruments (from shielding, to nurturing to empowerment, see Smith and Raven, 2012) but more importantly implement these instruments according to the kind of phase the niche is in.",
            "Conclusions": " In this paper we have used a simple and elegant method to map the various network configurations in a niche over time by focusing on the flow of (multidisciplinary) innovation projects that are undertaken by a changing group of people and their organisations. As projects start or end the network configuration changes accordingly. We have applied this method on the case of the Northern Frisian Woodlands and we have shown that we can distinguish between three different phases in which the vision in the niche and subsequently also the projects and experiments done in the niche differed. We have shown how the structural characteristics of the network of a niche evolve over time and how its size and density are related to the building of trust as a result of successful experimentation. Successful experiments will not only increase the size of the network but will also increase its connectedness at the same time. However, not all experiments lead to consensus and a fragmentation of visions between niche partners triggers the opposite: it leads to the erosion of trust within the network and a shrinking and a more disconnected network. The composition of the network and its mean degree remain (relatively) constant within each phase, but differ significantly between the phases. The shifts from one phase to another can therefore be attributed to these powerful organisations that are not necessarily part of the niche, but influence it through the conditions they set on the collaborating partners in return for their financial or legislative support. The network expands and decreases in time along with the finances provided by various governmental subsidies that sustain it."
        }
    },
    "10.1016/j.enpol.2006.07.008": {
        "file_name": "14 Biofuels for transport in Europe",
        "title": "Biofuels for transport in Europe: Lessons from Germany and the UK",
        "abstract": "The utilisation of biofuels is attracting growing support from the European Union and member states as a strategy to tackle climate change, enhance energy security, and contribute to regional development. This paper describes, compares, and analyses the markets for biofuels in Germany and the UK. The introduction of biofuels for transport in these member states provides contrasting pictures, and the success or failure of biofuels here is pertinent to the development and diffusion of biofuels across Europe. This paper concentrates on the socio-political context for the biofuels industry in Germany and the UK, discusses the lessons learned from the German and British experiences, and presents general conclusions for policy-makers that are predominantly relevant for the early stages of a biofuels industry.",
        "label": "Mixed",
        "text": {
            "Introduction": " Biofuels or liquid fuels for transport produced from biomass are attracting considerable attention in Europe as a strategy to tackle climate change by decreasing greenhouse gas emissions from transport, to enhance energy security and respond to rising oil prices by substituting or blending petrol and diesel with biofuels, and to contribute to regional development by increasing employment opportunities and diversifying activities for farmers through energy crops. The objective of this paper is to describe, compare and analyse the development and diffusion of biodiesel and bioethanol, and the socio-political context for the biofuels industry, in Germany and the UK. There are many insights for policy-makers in the European Union (EU) and member states from the German and British experiences. This paper comprises several sections. Section 2 deals with the context for biofuels in Europe, including the types of fuels and vehicles on the market, advantages and disadvantages of biofuels, and the many policies, directives, standards and norms affecting the biofuels industry. Section 3 explains the methodology applied to develop the country studies on Germany and the UK. Section 4 provides a description and analysis of the biofuels industry in Germany and the UK, which divides the country studies into markets, institutions (regulatory frameworks and stakeholder views), and actors and networks. Section 5 comprises a comparison and discussion of the lessons learned from Germany and the UK, including the formation and evolution of technological systems, critical factors (drivers and barriers) for biofuels, and general conclusions for policy-makers.",
            "Context": " In this paper, biofuels are considered liquid fuels for transport produced from biomass. There are a range of biofuels with different feedstocks and conversion processes (see Fig. 1). Currently, the only biofuels that can be supplied in considerable amounts are the first generation biofuels of bioethanol (from sugar and starch) and biodiesel (see Fig. 2). Bioethanol and biodiesel have some important advantages over many alternative fuels in that they can be used in conventional vehicles. Biodiesel consists of fatty acid methyl esters (FAME) and it is agreed that it can be used in pure form or any blends in conventional diesel vehicles with only minor engine alterations (International Energy Agency (AEA), 2004). For bioethanol, it is generally accepted that all recently produced conventional petrol vehicles are compatible with blends up to 10% bioethanol and 90% petrol or E10 (International Energy Agency (AEA), 2004). Flexi-fuel vehicles can use both bioethanol and petrol. They are often designed for blends of 85% bioethanol or E85. In flexi-fuel vehicles there is a sensor system that detects the bioethanol and petrol blending currently used and it automatically adjusts the engine (International Energy Agency (AEA), 2004). The ability of consumers to switch between bioethanol and petrol in flexi-fuel vehicles allows the diffusion of E85 across a network of service stations. Furthermore, it is feasible for bioethanol and biodiesel to use the distribution infrastructure designed for petrol and diesel with no major changes. Biodiesel can use the transport, storage and retail systems of diesel. Bioethanol faces a few difficulties. To avoid some problems it can be converted to ethyl tertiary butyl ether (ETBE) and then blended with petrol (Biofuels Research Advisory Council (BIOFRAC), 2006).  A disadvantage associated with biofuels is a lower energy density than diesel and petrol. More than a litre of biodiesel or bioethanol is necessary to substitute a litre of diesel or petrol. However, both biofuels are also reported to have higher combustion efficiency, which partially makes up for the lower energy density (International Energy Agency (IEA), 2004). Furthermore, there is considerable attention on the environmental impacts from biofuels. In terms of tailpipe emissions, both biodiesel and bioethanol are generally considered to be less polluting than petrol and diesel (Biofuels Research Advisory Council (BIOFRAC), 2006). The well to wheels (WTW) greenhouse gas balance of biofuels is also attracting interest. A range of studies indicate that it depends on the way feedstocks are produced, processed into biofuels, and distributed (International Energy Agency (IEA), 2004). The use of fossil fuels and fertilisers to produce biofuels can result in less than impressive greenhouse gas savings. However, in Brazil there are estimates of 90% greenhouse gas savings when sugarcane is utilised to produce biofuels (Alckmin and Goldemberg, 2004).",
             "Methodology": " This paper is based on country studies of Germany and the UK (Yin, 2003;Stake, 1995). The research focused on biodiesel and bioethanol in these member states because the success or failure of biofuels here is pertinent to the development and diffusion of biofuels in Europe. These member states are also interesting to compare because of contrasting national contexts. The German Government has supported the biofuels industry since the early 1990s. In the UK the biofuels industry is only recently emerging and the British Government has provided ambiguous signals on biofuels. It is important to recognise that the biofuels industry in both Germany and the UK are evolving rapidly, so it is challenging to present an up-to-date paper. The research for this paper involved a combination of different methods and triangulation (Bloor, 1997;Morrow  and Brown, 1994). First, key stakeholders were identified and then contacted to participate in interviews. The key stakeholders encompassed government officials, research experts, and representatives from biofuels producers and suppliers, trade associations, oil companies and automobile manufacturers. Second, a range of documents related to biofuels were reviewed, including legal documents, press releases, position papers, policy documents, technical standards and research reports. Third, a novel technique for investigating the content of articles in the media was tested, which involved searching the internet for articles on biofuels published in the German and British media in 2005. The articles were then classified as positive, mainly positive, neutral, mainly negative and negative. The technique provided insights into the debate on biofuels in the German and British media and how biofuels are presented to the general public.",
            "Description and analysis": " Germany and the UK provide contrasting pictures of biofuels in Europe in terms of markets, institutions (regulatory frameworks and stakeholder views), and actors and networks in the biofuels industry. There are many regulatory frameworks related to the development and diffusion of biofuels, including capital grants for biofuels plants, support for research, development and demonstration, information activities and public relations, public procurement of biofuels and flexi-fuel vehicles, fuel standards, emission standards, and alcohol legislation. This paper concentrates on the transport biofuels or fuels strategy and excise duty exemptions or reductions in Germany and the UK. In terms of stakeholder views, the National Government (and political parties), environment groups, and the general public are important to an emerging biofuels industry. The general public are both citizens and consumers who are able to influence the public sector and the private sector. However, it appears that in both Germany and the UK the general public is not playing any role at present in either supporting or blocking biofuels. The main actors and networks in the biofuels industry include the biofuels producers and suppliers who construct and operate biofuels plants, trade associations, oil companies and automobile manufacturers. This paper outlines the different roles played by the main actors and networks.",
            "Biofuels in Germany": "",
            "Markets": " Production and consumption of biodiesel in the UK only started in 2002. Most of the biodiesel is produced domestically from waste vegetable oil (WVO), which is the cheapest feedstock. Biodiesel is mostly available in lowlevel blends, such as B5 (British Government, 2004a). Bioethanol was not used for transport until 2005. Consumption has quickly expanded and bioethanol is now more important than biodiesel in the UK. Bioethanol is only utilised in low-level blends, such as E5. No bioethanol is produced in the UK with imports predominantly from Brazil (British Government, 2005). To meet the indicative target of 5.75% by 2010 the consumption of biofuels in the UK needs to expand by a factor of 300 (see Table 2).",
            "Institutions": " The main regulatory frameworks in the UK related to biofuels are the transport biofuels strategy and excise duty reduction. The National Government places biofuels in the context of creating a low carbon economy. It is therefore concerned about the limited role biofuels is able to play in a low carbon economy in the UK because of land availability and environmental impacts (British Government, 2003). Biodiesel has received a reduction but not exemption in excise duty since 2002, which was extended to bioethanol in 2005 (British Government, 2005). It applies to biofuels in pure form and blends. On a volume basis, biodiesel and bioethanol are price competitive with diesel and petrol. However, on an energy basis, only biodiesel from some feedstocks, such as WVO and to some extent palm oil, are price competitive (see Figs. 6 and 7).",
            "Actors and networks": " The number of biofuels producers and suppliers is growing in the UK. However, biodiesel production only started in 2002. There is no market for B100 in the UK and all biodiesel is utilised for blending (British Government, 2004b). Capacity is about to expand with several biodiesel plants under construction. By 2006, the capacity is expected to exceed 450,000 t/y (British Government, 2005). No bioethanol is produced in the UK, and most is imported from Brazil. There are several proposals to build bioethanol plants utilising wheat and sugar beet. However, many entrepreneurs with proposals appear to be waiting on policies and actions from policy-makers before investing into biofuels. There are only a few trade associations in the UK for the biofuels industry, which include the Allied Biodiesel Industries (ABI), the British Association for Biofuels and Oils (BABFO), the Environmental Industries Commission (EIC) and the Renewable Energy Association (REA). BABFO has dissolved recently, so the REA is now the leading trade association. The REA employs staff, maintains an up-to-date website and conducts lobbying. There is some cooperation between the trade associations, oil companies and car manufacturers, mostly through the National Government sponsored low carbon vehicles partnership, which aims to shift away from high carbon transport systems (Low Carbon Vehicle Partnership (LCVP), 2005). The trade associations remain relatively weak, however there are signals that the biofuels industry is becoming more organised. The UK Petroleum Industry Association (UKPIA, 2005) demand clear direction from the National Government on whether the objective of biofuels is for climate mitigation, energy security or to support British farmers. UKPIA state that biomass production in the UK is limited so if the objective is climate mitigation then heat and power  generation is superior to biofuels for transport. There is a petrol surplus and diesel shortage in the UK, so oil companies want support for biodiesel rather than bioethanol. Furthermore, many oil companies view bioethanol (and biodiesel) as short-term products in contrast to second generation biofuels, which are perceived as long-term products (UK Petroleum Industry Association (UKPIA), 2005). The Society of Motor Manufacturers and Traders (SMMT, 2004) accept both E5 and B5 because of the compatibility with existing vehicles and distribution systems. SMMT suggests that if B100 becomes available on the market then many vehicles with EU warranties will also be covered in the UK. Some automobile manufacturers want to introduce flexi-fuel vehicles for E85. However, more support is required to create a network of E85 refuelling stations across the UK, which is necessary to stimulate the diffusion of flexi-fuel vehicles (Society of Motor Manufacturers and Traders (SMMT), 2004).",
            "Biofuels in the UK": "",
            "Comparison and discussion": " The formation and evolution of the biofuels industry in Germany and the UK is influenced by the dominant technological system for transport based on oil. Any discussion on the identification of drivers and barriers for the biofuels industry in Europe therefore demands an understanding of technological systems, and the process of shifting to a new technological system. Unfortunately, there is no step-by-step guide on how to promote biofuels. However, the assessment of the German and British experiences generates a range of general conclusions for policy-makers, which are particularly relevant for the early stages of a biofuels industry.",
            "Technological systems": " Once a technology has become the standard in society it becomes increasingly difficult to replace by competing technologies (Hughes, 1989;Arthur, 1989;Utterback, 1994). When a technology is the standard, the phenomenon of increasing returns to scale is often observed, which entails that the more the technology is applied, the more it improves, becomes less expensive and expands its market (Organisation for Economic Cooperation and Development (OECD) and International Energy Agency (IEA), 2003). Once the process has gained momentum, a society may 'lock-in' to a technology and may therefore 'lock-out' competing technologies (Tsoutsos and Stamboulis, 2005). Currently, the dominant technological system for transport is based on oil. Biofuels are part of a new technological system, which is embedded in the dominant technological system. What is attractive about biofuels to many actors is that low-level blends, such as E5 and B5, are able to utilise the existing distribution systems of the oil industry. Furthermore, many types of conventional vehicles are compatible with low-level blends. So the transition to low-level blending of biofuels with petrol and diesel is almost unrecognised by vehicle users. The dominant technological system in which oil companies and automobile manufacturers operate is therefore able to adapt to the introduction of biofuels with few difficulties. It is only high-level blending that requires more adaptations for oil companies, automobile manufactures, and vehicles users. There is more to the process by which a technology becomes dominant than the phenomenon of increasing returns to scale. Society becomes adapted to the technology through changes in its formal and informal institutions (North, 1990). The institutional infrastructure creates systems of incentives and disincentives for individuals and organisations (Ornetzeder and Rohracher, 2006). Proponents of a technology try to influence the evolution of the institutional infrastructure, so that it accommodates the technology. If a technology achieves supremacy and establishes a dominant technological system, institutions in society become aligned with it, supporting its development and obstructing that of competing technologies (Jacobsson and Bergek, 2004). The emerging biofuels industry in Germany and the UK is engaged in transforming the institutional infrastructure as well as the physical infrastructure. Dominant technological systems comprise a multitude of artefacts and physical infrastructure (Hughes, 1989). If a new technological system were to become dominant, then the established artefacts are at risk of becoming obsolete. Actors that have invested in a dominant technological system therefore have a vested interest in it and often oppose any competing technologies. Important actors for a new technological system are prime movers or system builders, which are technically, financially and politically able to defend and build a new technological system (Jacobsson and Bergek, 2004). The experience in Germany demonstrates that creating conditions for prime movers or systems builders through the excise duty exemption and the transport fuels strategy was critical to the development of the biofuels industry. Under some conditions actors embedded within the dominant technological system embrace a new technological system and promote its development. In terms of biofuels, it appears that oil companies in both Germany and the UK are more supportive of biodiesel than bioethanol. In Europe, the demand for diesel is growing while demand for petrol is stagnating (see Fig. 8). The expanding demand for diesel makes biodiesel interesting to oil companies as it allows a 'stretching' of diesel through blending. In contrast, the 'shrinking' market for petrol is resulting in some resistance from oil companies to bioethanol. Furthermore, the appearance of biodiesel has attracted the attention of bus fleets, truck operators, and agricultural vehicles because it is price competitive and reliable in conventional vehicles. New technological systems often require supportive economic policies. However, there are always debates about if subsidies should have sunset clauses and whether tax breaks are necessary (Organisation for Economic Cooperation and Development (OECD) and International Energy Agency (IEA), 2003). For biofuels there are two justifications for supportive economic policies. First, biofuels often have lower environmental impacts and greenhouse gas emissions compared to fossil fuels. Second, biofuels may be competitive with fossil fuels in the longterm but require assistance in the short-to medium-term to establish a new technological system. The second argument weakens as the biofuels industry grows and strengthens. Supportive economic policies, such as subsidies, should therefore be temporary and involve sunset clauses. However, permanent tax breaks in relation to fossil fuels are justified because of the first argument on lower environmental impacts and greenhouse gas emissions. There are many discussions in Germany and the UK regarding cost/price developments for biofuels. The technologies and systems for first generation biofuels are relatively mature (Biofuels Research Advisory Council (BIOFRAC), 2006). There are possibilities for incremental improvements through scale economies and learning effects. However, the main production cost is the price for the feedstocks, which are often agricultural crops. For the costs/prices to go down significantly on first generation biofuels, the cost/prices for agricultural crops will have to go down. A strategy to achieve cost/price developments is to focus production in favourable climates, which for Europe translates to imports from places, such as Brazil. Many member states have adopted policies that restrict imports of biofuels from favourable climates (International Energy Agency (IEA), 2004). So to achieve reductions in costs/prices, member states and the EU will have to invest in technologies and systems for second generation biofuels. It is second generation biofuels that promise to extend the range of feedstocks beyond valuable agricultural crops, thereby significantly altering the conditions for the main production cost of biofuels (Biofuels Research Advisory Council (BIOFRAC), 2006). However, it is important to recognise that cost/price developments for biofuels in relation to fossil fuels depend on oil prices, which are far more volatile than improvements in biofuels.",
            "Critical factors": " The main driver for biofuels in Germany has been the excise duty exemption, at the beginning for B100 and since 2004 also for low-level blends of biodiesel and bioethanol. Automobile manufacturers allowing B100 in their conventional vehicles and service stations supplying B100 have also been critical for the development and diffusion of biofuels. The main barriers that biofuels face in Germany are their higher production costs; the uncertainty if the National Government will continue to support biofuels; the reluctance of oil companies to utilise bioethanol for blending in petrol; and the declining number of conventional vehicles with warranties for blends higher than B5. Since biodiesel was not addressed by the mineral oil tax in Germany until 2004, it was therefore exempt from the mineral oil tax, if utilised as B100. The rise in oil prices helped biofuels producers and suppliers to provide biodiesel that was more or less price competitive with diesel. Furthermore, many automobile manufacturers responded by allowing B100 in conventional vehicles designed for diesel. The appearance of biodiesel has attracted truck operators, bus fleets and agricultural vehicles because they are sensitive to changes in oil prices. They can purchase conventional vehicles at the same price and with the same performance, and they can then switch between diesel and biodiesel depending on availability and price. Establishing the distribution systems for B100 and E85 is difficult because it requires dedicated pumps across a network of service stations. However, in 1996 petrol with lead was prohibited in Germany by the National Government and more than 1000 pumps at service stations required replacements. The market for biodiesel in Germany was at that moment able to seize the opportunity. Until 1996, the use of biodiesel was predominantly in niche markets. The shift away from petrol with lead resulted in many service stations adopting biodiesel as an attractive option and over 600 pumps were converted to provide B100. This transition in distribution systems transformed the biofuels industry in Germany. In Germany, the National Government has played an active role in the development of a market for biofuels and a domestic industry. The National Government has sponsored research on bioethanol and biodiesel, and invested in demonstrations of flexi-fuel vehicles and B100 in agricultural vehicles. The trade associations have also been important for supporting the domestic industry. The critical attitude of some leading environmental groups in Germany appears so far not to have hindered the development of the domestic industry. For most consumers the price of biofuels is clearly more important than environmental considerations regarding biofuels. Furthermore, in the UK the general public has not been prepared to purchase biofuels, which are marketed at a price premium.",
            "General conclusions": " The introduction of biofuels in Germany and the UK provide contrasting pictures and many insights into the drivers and barriers that can shape markets for biofuels in Europe. This paper has derived a range of general conclusions from the assessment of the German and British experiences with biodiesel and bioethanol that are particularly relevant for the early stages of a biofuels industry. As suggested, the dominant technological system for transport based on oil has established a formidable institutional infrastructure. Biofuels are part of a new technological system that requires support to establish prime movers or system builders. Consumers purchase cheap rather than green: The experience in Germany and the UK shows that most consumers only purchase bioethanol and biodiesel if they are price competitive with petrol and diesel. In Germany, the availability and price of biodiesel has allowed B100 to establish a market and biodiesel sales continue to grow. In the UK, the experience indicates that only few consumers are prepared to purchase B5 at a price premium. The environmental reasons for purchasing biofuels are simply overshadowed by price and availability. Excise duty exemptions or reductions are instrumental for stimulating investments in biofuels: Excise duty exemptions or reductions can ensure biofuels are price competitive. In Germany, the excise duty exemption has been instrumental in stimulating the domestic industry for both biodiesel and bioethanol. In the UK, the excise duty reduction has triggered the sales and production of biofuels. However, it is only sufficient for biodiesel production from some feedstocks, such as WVO and palm oil, which limits the developing market for biofuels. National Government commitment is the foundation for a biofuels industry: To achieve the 2010 targets for biofuels in Europe, it is important for National Governments in member states to provide clear signals. In Germany, the consistent backing of biofuels by the National Government and most political parties has encouraged investments in the biofuels industry, the oil industry to implement blending, and automobile manufacturers to provide warranties on conventional vehicles. In the UK, the National Government support of biofuels has been ambiguous, resulting in many oil companies adopting a wait-and-see strategy. Low-level blending is the easiest and cheapest way for marketing biofuels but not sufficient to meet targets: The distribution of B5 and E5 requires negligible investments in distribution systems and no different pumps or labels. Most oil companies are therefore prepared to support lowlevel blends more than B100 or E85, which require more investments. However, B5 and E5 are not sufficient to meet the 2010 targets for biofuels. There are two options to respond to this dilemma. First, promote the diffusion of high-level blends, which in many instances requires the production and marketing of flexi-fuel vehicles, and distribution of biofuels at service stations. Second, alter the fuel standards for petrol and diesel to allow blending of E10 and B10, which is an effective way to meet the targets and expand the market for biofuels. Niche markets are an opportunity for bioethanol and biodiesel: Rather than only produce low-level blends for conventional vehicles, a parallel strategy for bioethanol and biodiesel is to address niche markets, such as bus fleets for public transport, truck operators, and agricultural vehicles. Niche markets are able to utilise high-level blends or pure forms of biofuels; switch to flexi-fuel vehicles or vehicles for only biofuels; and establish dedicated refuelling stations. It is important to place biofuels in the context of shifting to sustainable modes of transport. If biofuels are used in bus fleets for public transport then not only are the fuels more sustainable but so are the modes of transport. Oil companies are more supportive of biodiesel than bioethanol: Oil companies in Europe face an oversupply of petrol and a shortage of diesel. In both the UK and Germany, oil companies are more critical of bioethanol than biodiesel. If policy-makers want to diffuse bioethanol on the market, they have to exert more pressure on oil companies and provide clear direction. Furthermore, policy-makers need to engage with automobile manufacturers to provide warranties for conventional vehicles and to produce flexi-fuel vehicles in parallel with service stations offering high-level blends, such as E85. Environmental impacts and carbon balances of biofuels vary: The environmental impacts and carbon balances of biofuels depend on feedstocks and the way they are farmed, processed and distributed. Clearly, environmental impacts associated with energy crops require sustained investigation. Biodiesel and bioethanol in the EU has been calculated to result in 15-70% greenhouse gas savings when compared to fossil fuels (Hass et al., 2003), while bioethanol from Brazil results in over 90% greenhouse gas savings (Alckmin and Goldemberg, 2004). However, it is clear that both biodiesel and bioethanol are expensive options for climate mitigation as compared to biomass for heat and power generation. Sustainability certification scheme for biofuels is necessary: Presently, all biofuels are treated equally irrespective of greenhouse gas balances or environmental impacts. The introduction of the RTFO in the UK appears to encompass reporting on greenhouse gas balances for biofuels and any environmental impacts associated with the production of biofuels. The ambition is therefore to reward the more sustainable biofuels and punish the less sustainable biofuels. A consistent and transparent sustainability certification scheme for biofuels in the EU is necessary to maintain confidence in the performance of biofuels from environmental and social perspectives. Support for bioethanol and biodiesel is not expected to 'lock-in' or 'lock-out' any technologies: As first generation biofuels, both biodiesel and bioethanol can be blended with petrol and diesel with no major changes in distribution systems and can be used in conventional vehicles. Second generation biofuels can also be supplied in the distribution systems and used in conventional vehicles with only minor adaptations. It is important to provide sufficient support for second generation biofuels so as to expand the range of feedstocks for the production of biofuels, and to promote technologies with the most flexibility and best performance."
        }
    },
    "10.1016/j.techfore.2011.08.014": {
        "file_name": "140 Patterns of expectations for emerging sustainable technologies",
        "title": "Patterns of expectations for emerging sustainable technologies",
        "abstract": "Innovation is characterized by uncertainties, high risks, large investments and late returns on investment which make it a complex process. This is particularly true for sustainable innovation where market forces alone cannot be relied upon to realize the desired transitions. Insight in the dynamics of such innovation processes is necessary in order to influence technological change toward a more sustainable direction. However, few instruments and indicators are available to assess the performance of emerging technological innovation systems. In this phase competition often takes place based on expectations rather than on technological performance. This paper therefore focuses on the expectation patterns of technological innovation systems in the exploratory phase through the analysis of the expectation dynamics of three emerging technologies in the field of sustainable mobility within the Netherlands: biofuels, hydrogen as a transport fuel and natural gas as a transport fuel. These technologies do not only compete with the current fossil-fuel based system but also with each other. We have collected over 5000 expectation events regarding these technologies for the period 2000\u20132008 and discuss the insights generated by the comparison of the observed expectation dynamics to theoretical patterns.",
        "label": "Mixed",
        "text": {
            "Introduction": " Innovation is characterized by uncertainties, high risks and late returns on investment which make it a complex process. This is particularly true in the case of innovations for sustainability where market forces alone are not sufficient to come to a more sustainable socio-technological regime [1][2][3]. The large scale diffusion of energy-efficient and more sustainable energy and mobility technologies is necessary to realize such a transition. It is however difficult to predict which technological options have the most potential to become part of a future more sustainable socio-technological regime. The development of sustainable energy-and mobility technologies is characterized by long development times, large required investments and the involvement of many actors. These actors include the entrepreneurial firms that bring new technological options to the market, the government actors that stimulate and support the development and market introduction of innovations through protective measures or public procurement, as well as consumers and NGOs. The speed and direction of technological change thus depend on the nature of the technological (innovation) system [4]: \"a dynamic network of agents interacting in a specific economic/industrial area under a particular institutional infrastructure and involved in the generation, diffusion, and utilization of technology\". In the case of innovations for sustainability, technology generation, diffusion and utilization may be hampered by a \"double externality\" problem [5]: In addition to R&D related market failures, there also exist positive externalities related to the adoption and diffusion of environmentally friendly technologies (e.g., clean air). Because of these externalities entrepreneurial firms may not be able to appropriate all the benefits of their innovation. Other factors that complicate the diffusion process are the involvement of a heterogeneous set of actors with different preferences and the competition between innovations for sustainability and other new and existing technologies-both on traditional performance characteristics and on sustainability characteristics [6]. In several countries policies are therefore in place in order to stimulate the emergence and development of technological innovation systems for more sustainable energy and mobility technologies i.e., [7,8]. Expectation based methods such as foresight exercises and scenario studies are an important input for policy makers in this area. However, few instruments and indicators are available to assess the potential performance of emerging technological innovation systems as performance criteria are still unclear in the early stages of development [9][10][11][12]. Therefore competition between alternative technological options often takes place based on the expectations about future technological performance rather than on current technological performance [13][14][15][16][17]. Expectations influence the development path of a technology and several authors indicate that expectations are therefore the subject of strategic behavior by entrepreneurs and other stakeholders [18]. Aldrich and Ruef [19] for example stress the importance of legitimisation strategies in addition to technology development (learning) strategies for entrepreneurs. In the early stages of the technology life cycle entrepreneurs create legitimacy for the new technology through the management of expectations and by providing information [20]. These guidance activities are a way for stakeholders to influence the technological innovation system toward a favorable direction. When market driven technological innovations are concerned this behavior has been studied in the context of product preannouncements [21]. However, in the case of sustainable technologies, such as biofuels, the entrepreneurial firm is just one of the actors trying to influence the expectations about a technological option. Other stakeholders within the innovation system such as, for example, the environmental lobby and the government may also attempt to influence the direction of technological change. This complex environment makes the task of expectations management difficult and this paper addresses the need to better understand the expectation patterns for sustainable technologies [22,23]. A theoretical framework that acknowledges the important role of expectations for emerging technologies is the functions of innovation systems approach which describes the basic functions that need to be facilitated in technological innovation systems in order to build up and function well [24,2,25]. Of particular importance in the early stages of development of a new technology is the so-called \"guidance of the search function\" [26,27]. This function involves activities that provide direction to the development of the emerging technology. Activities that provide this guidance are for example the implementation of policy measures, standard setting, and the expression of promises and expectations regarding technological development and performance. Several case studies using the functions of innovations approach have emphasized the important role of expectations and have described the patterns of expectations observed in these individual cases [28,29]. In this paper we seek to link the expectations identified in case studies of sustainable mobility technologies to the general literature on expectation dynamics [30]. This allows us to investigate whether sustainable innovations show similar expectation patterns and it contributes to a more empirical description of the guidance of the search function in the technological innovation systems literature. In summary, the influence of expectations on policies for sustainable development, the importance of expectations in emerging innovation systems for sustainable technologies, and the influence of the expectations of multiple heterogeneous actors on technology development raise the need for more insights in the expectation patterns of emerging sustainable technologies. An expectation pattern is the temporal pattern of expressed expectations about a technology. Our focus is on the expression of expectations by actors, by expressing expectations these actors influence the technological innovation system and current and future technological trajectories [9,31]. More specifically, this paper considers three emerging technologies in the field of sustainable mobility within the Netherlands: biofuels, hydrogen and natural gas as fuels for the automotive sector. These three technologies can potentially provide an alternative for the current fossil-fuel based mobility system. There is thus both competition between the incumbent fossil fuelbased technology on the one hand and the three alternative technological options on the other hand and between the three alternative technological options. While it is not necessary the case that this competition results in a single dominant technology (a coexistence of different options may also be possible), these technologies do currently compete for subsidies. Furthermore, all three technologies require substantial investments in infrastructure increasing the chances of lock-in in a single technology [32,33]. The three technologies differ with respect to their stage of development and their compatibility with the current infrastructure. A switch to hydrogen might therefore be considered as a more radical innovation than a switch to biofuels or natural gas as the main transport fuel. However, large scale deployment of each option requires infrastructure investments as well as adaptations to the vehicle and can thus be considered disruptive to the existing fossil-fuel based regime [34]. In order to better understand the role of expectations in these three technological trajectories the paper proceeds as follows: First, Section 2 elaborates on the role of expectations in innovation processes as described in the literature [14,35,23]. Section 3 describes the methodology of event-history analysis [36] that was used to collect data on the expectations about the three technologies during the period 2000-2008. Section 4 gives a short overview of the case study data and presents the observed expectations in the three case studies. Finally a discussion and concluding remarks are given in Section 5.",
            "The role of expectations in innovation systems": " We follow Borup et al. [22] in describing technological expectations as \"real time representations of future technological situations and capabilities\". Expectations play an important role in determining the direction of technological change and the rate at which innovations are adopted [35,22,18,14,37,38]. First, expectations function as a coordination mechanism for actors and activities [39]. Positive expectations help to attract actors to emerging innovation systems and to align the interests and activities of these actors [40]. Second, through these processes of alignment and coordination expectations can also create legitimacy for the new technology [23,19]. Very strong positive expectations can even help create a protective niche around a technology, within such a niche the technology is more likely to be positively evaluated [39,41]. Third, expectations play an important role in mobilizing resources for the new technology. Geels and Smit [18] even indicate that expectations and visions about the future as such are an important resource in the creation of protected niches for the new technology. Finally, (shared) expectations can reduce the uncertainty perceived by technology developers and thereby guide the process of technological change. Expectations thus play a pivotal role in attracting actors to the technological innovation system and to stimulate the fulfillment of other key processes in technological innovation systems such as the mobilization of resources. This role of expectations is strongest in the earliest phases of the life cycle of a technology which is characterized by uncertainty regarding future performance and possible applications [42]. It is this early phase of development that is the focus of this paper. The importance of expectations for technology development creates incentives for actors to express and influence technological expectations. Several authors have identified such strategic elements in expectation formation processes [18,41,43,19,44]. Berkhout [35] even suggests that expectations can be considered: \"as bids about what the future might be like, that are offered by agents in the context of other expectation bids\". This implies that agents make these bids strategically, i.e., with the knowledge that other actors will 'counter' and respond with alternative bids. An important strategy for stakeholders at this stage of technological development is to try and improve the reputation of their preferred technology through the management of expectations and by providing information [20,45], this is an example of a proactive expectations management strategy. Proactive expectations management strategies have an important role in creating legitimacy for new technologies [19,18]. A more reactive form of expectations management occurs when actors react to negative expectations expressed by other actors. Reactive expectations strategies occur, for example, when biofuel stakeholders respond to the critical statements about the (un)sustainability of biofuels. In this paper we consider the pattern of expectations expressed by a certain actor as an expectations management strategy. Expectations can be considered as more successful once they are shared by a larger number of influential stakeholders [46] and the effectiveness of an expectations management strategy depends on several aspects. First, the content of the expectation is important. Berkhout [35] indicates that the validity and attractiveness of expectations are important in determining which expectations become dominant over time, i.e., become shared by a large number of people. Proponents of a certain technology often make an effort to frame the discussion about competing technologies in such a way that the strengths of their preferred technology become important performance criteria in the process of technology selection [47,48]. An example of this is stressing the potential of a technology on the long term when current performance is not yet competitive. Expectations can be specific, addressing the performance of the new technology, or more general concerning the ability of the innovation to contribute to solving societal problems. An example of a general expectation is \"Hydrogen as a freedom fuel\" whereas a specific expectation also indicates future technology performance such as \"Hydrogen cars will be cost-competitive in 2015\". In addition to the specificity of an expectation one can also distinguish expectations that relate to the short term from those that relate to the long term. Low performance expectations on the short term can sometimes be compensated by high expectations about technology performance on the long term. Furthermore, Expectations can be positive, highlighting the expected benefits of the technology, or negative, expressing for example the potential risk associated with the new technology. It is important to distinguish between these different types of expectations as they can have different effects on innovation processes [43]. Expectations concerning a specific technology are of course influenced by expectations concerning competing (existing and new) technologies. Rosenberg [14] for example states that \"Expectations of continued improvement in a new technology may therefore lead to postponement of an innovation, to a slowing down in the rate of its diffusion or to an adoption in a modified form to permit greater future flexibility\". High expectations regarding a new technology may for example lead to an increase in R&D and marketing efforts for the existing technology and cause a sailing ship effect. Second, in addition to the content, the actor or actor group expressing the expectation influences the impact of the expectation [35]. An important actor group consists of the entrepreneurial firms that are willing to invest in the new technology. These entrepreneurial firms can be both new entrants and incumbents. Other stakeholder groups are for example the incumbent firms that are threatened by the new technology [49], governments that see a role for the new technology in achieving policy goals and stakeholder groups such as NGOs and lobby organizations. Expectations can bring together a particular stakeholder group and the size and power of the group influences the effectiveness of the expectations management strategy used by the (group) members, that is, expectations become stronger when there is alignment between different stakeholder groups. Expectations expressed by some actors (such as the government) potentially have a greater impact on the emerging technological innovation system than expectations from other actors. However for these influential actors the reputational costs that arise when high expectations cannot be fulfilled may negatively influence future credibility and diffusion of the technology [39]. Expectation dynamics often show a typical pattern over time with alternating cycles of hype and disappointment [43,20,50]. A hype cycle occurs when there is a sudden rise in positive expectations regarding a technology followed by a sharp decline in positive expectations or a rise in negative expectations. These ups and downs can have a strong impact on innovation processes [43]. The disappointment that arises when the initial high expectations cannot be met, can lead to large costs for the emerging innovation system in terms of both resources and reputation [20]. As sustainable technologies are often dependent on substantial (public and private) funding, we expect that there is an incentive for stakeholders to overstate the potential of their technologies possibly leading to hype and disappointment cycles. Another pattern described in the literature, refers to the changes in the nature of the expectations of a technology over time. For example high and diffuse initial expectations are replaced by more specific expectations as a technology develops [15]. For example abstract representations of 'the car of the future' are replaced by expectations based on actual prototypes [51]. With this progression the distance between the actual performance of the technology and the expectation decreases, thereby reducing the level of uncertainty associated with the technology.",
            "Data and methodology": " Traditional methods for the analysis of innovation processes such as patents, R&D investments and other firm level data do provide insights in innovation system functioning in more mature stages of development but are less suitable for emerging systems [52]. In this paper we therefore build on the recent functions of innovation systems approach. This approach describes the basic functions that need to be addressed in emerging technological innovation systems in order to build up and function well [2,25]. The performance of a technological innovation system can then be studied by analyzing how these functions are facilitated by the system. This approach recognizes the importance of expectations which are classified as contributing to the guidance of the search function of technological innovation systems. This system function describes the process of selection and alignment that is necessary for further system development, involving, for example, policy targets, outcomes of technical or economic studies and expectations regarding technological development and performance. A systematic, methodology to analyze the realization of system functions is event history analysis, as developed in the context of organisation studies [36,53]. Event history analysis studies sequences of events as a way to analyze processes of change and thus offers the possibility of operationalising and measuring system functions by relating these functions to events. Within the context of a technological innovation systems analysis, an event can be defined as an instance of change with respect to actors, institutions and/or technology which is the work of one or more actors and which carries some public importance with respect to the system under investigation. Examples of events that contribute to the guidance of the search function are standard setting, expressions of positive or negative expectations about the technology as well as promises or targets expressed by actors with the power to change institutions. In the event history analysis of the emerging Dutch biofuels innovation system by Suurs [29] empirical support for the importance of the guidance of the search function was given by the fact that over 40% of the events that were collected related to this innovation system were classified as guidance of the search. The current paper focuses on the expectation events within this broader guidance of the search category. As a source for our event history analysis we used Dutch newspapers and professional journals 1 in the period 2000-2008. We thus focused on those events in which expectations were expressed regarding the use of biofuels, hydrogen and natural gas as transport fuels. This was done by reading through the literature and separating, throughout each text, the events reported. The construction of the event sequences was done as 'objectively' as possible based on empirical sources. To minimise personal bias the identification and classification of events was performed independently by three researchers after which differences in interpretation where discussed and resolved. This method resulted in a number of 3811 expectation events for biofuels, 989 events for hydrogen as a transport fuel and 943 events for natural gas as a transport fuel. For each case we then constructed a database containing the events in chronological order. Note that all events were counted irrespective of their importance. However, events that provide important guidance to the system are covered in more articles than less important events and are thus more prominent in the database. This is for instance the case with a statement about the hydrogen economy by former US president Bush (Hydrogen as freedom fuel). The resulting database provides an overview of events and the time of their occurrence. Subsequently we determined the following characteristics of each event: 1. Positive/negative content: Does the content of the expectations event express positive or negative future technology performance? 2. General/specific content: Does the event concern general guidance or expectations specific to the technology? Expectations can be specific, addressing performance of the new technology, or more general concerning the ability of the innovation to contribute to solving societal problems. 3. Short term/long term content: Does the expectation relate to the near future (b10 years) or the distant future? 4. Actor type: Entrepreneur, government, knowledge institute, NGO, other. 5. Furthermore, within the biofuels database we also distinguish between first and second generation technology. 2   While we acknowledge that the content of an expectation plays an important role in determining the guiding capacity of that expectation we focus mainly on the patterns of expectations for each case study in order to enable a comparison between case studies and with the more general literature. For each actor type we now consider the pattern of expectations expressed over time by actors of this type. Not all events can however be attributed to a specific actor type, these events are classified as \"other\". This category mainly contains editorial comments, articles written by journalists and important events that happened abroad (e.g., technological breakthroughs). While there may be a strategic element to those events as well we have focused on expectations expressed by stakeholders in the Dutch technological innovation systems, that is explicit expectations management events. The events in the \"other\" category are taken into account when assessing the overall expectations regarding a specific technology.",
            "Observed expectation patterns": " In addition to the theoretical patterns described in Section 2 this section elaborates on the expectation patterns of the three case studies. Table 1 gives an overview of the number of expectation events that were generated by the different actor groups. Table 1 indicates that entrepreneurial firms play a prominent role in the discourse about the technology for the three technological innovation systems we have investigated. This is consistent with patterns described in the broader literature as described in Section 2. However, we also observe an important role for the government in the biofuels and natural gas technological innovation systems. With regard to content, many of the expectations expressed by the government are related to standards and regulations concerning the use of transport fuels. Below we consider the expectation patterns for each system in more detail.",
            "Expectation patterns for natural gas as a transport fuel": " Fig. 1 presents the expectation patterns for natural gas as a transport fuel during the period 2000-2008. In Fig. 1a we see that the expectations are predominantly positive. In addition, we observe a strong rise in the number of expectations in 2007, followed by a decline in 2008 suggesting hype cycle dynamics. Fig. 1b illustrates that both entrepreneurial firms and the government play a dominant role in this technological innovation system. Also note that the expectations generated by government and entrepreneurs follow a similar pattern. First this may be an indication that expectations are aligned, second it may be an illustration of the fact that expectations are mutually interdependent and that there are feedbacks between the expectations expressed by government and entrepreneurs. That is, actors may strategically react to expectations expressed by other actors rather than act based on the underlying technology developments. This type of strategic behavior contributes to the hype. Fig. 1c shows the percentage of expectations that are 'specific' in relation to the total number of expectations and the percentage of expectations that are about 'the short-term' (b10 years) in relation to the total number of expectations. An example of an event describing a specific expectation about natural gas expressed by construction company Ballast Nedam is: Ballast Nedam expresses its intention to invest 75 million euros in the construction of 250 refueling stations for natural gas. \"The company fleet of 500 cars will switch to natural gas within the next 5 years.\" (Financieel Dagblad March 15, 2008-in Dutch). An example of a more general event contributing to positive expectations: \"Natural gas is a better alternative than biofuels for achieving clean mobility\" (Het Parool, January 30th 2008-in Dutch). When we consider the level of specificity and the percentage of expectations that consider the short term we observe a converging pattern in Fig. 1, that is, over time expectations become more specific and focus more on the short term. In the beginning of the period there were some years with mostly general expectation whereas towards the end of the period the level of specificity increases and most expectations are about the short term. As described above, the convergence of expectations is an important condition for the emergence and establishment of a dominant design and as such is a precondition for the system to move from the exploratory to the growth phase. This convergence of expectations is thus an indicator of the development of the technological innovation system [54].",
            "Expectation dynamics for hydrogen": " Fig. 2 shows the expectation dynamics for hydrogen as a transport fuel. Fig. 2a again shows a pattern with first a large increase in positive expectations and a subsequent decrease, an indicator for hype cycle dynamics. Fig. 2b illustrates that the entrepreneurial firms play a dominant role in the discourse about hydrogen technology for transport and, as in the case of natural gas, the expectation dynamics for government actors and entrepreneurs are similar. In the case of hydrogen (Fig. 2c) this convergent pattern is not observed. This is an indication that the hydrogen system is not yet ready to move to the next stage of development, the stage of commercialisation (of a dominant design). ",
            "Expectation patterns for biofuels": " Fig. 3 shows the expectation patterns for biofuels. Fig. 3a shows the expectation patterns for the overall biofuels technological innovation system. Again, characteristics of hype cycle dynamics can be observed. These dynamics do however differ from the observed dynamics for natural gas and hydrogen which showed a strong rise and subsequent decline in positive expectations. In the case of biofuels we see a strong rise in positive expectations followed by a strong rise in negative expectations. This is an indication that expectations are not shared in this case, indicating a lower guiding capacity for the innovation system. As this system consists of two technology generations Fig. 3 shows the dynamics for each generation separately. The graphs for the first (Fig. 3b) and second (Fig. 3c) generation biofuels indicate that this rise in negative expectations can almost completely be contributed to the first generation biofuels. At that time questions arose about the sustainability of this first generation due to its competition with food resources. Second generation biofuels were not associated with this problem, although biofuels remain widely criticized in general. Much of the negative press for biofuels in the period thus finds its roots in the competition between the two technological generations. Adversaries of the first generation of biofuels think the environmental costs of these fuels are too high and they fear that investment in this generation may lead to a lock-in, thereby hindering the diffusion of second generation biofuels. Proponents of the first generation, on the other hand, see the first generation as a stepping stone toward a more sustainable fuel system. With respect to the specificity of expectations shown in Fig. 3d we observe that observations become more general over time. Again this is an indicator that there is no sign of emerging consensus concerning the performance criteria of biofuels technology.",
            "Concluding remarks": " In this paper we have studied technological innovation systems in the exploratory phase of development by describing the expectation patterns of emerging sustainable technologies. Insight in these expectation patterns was obtained through analyzing the actual patterns of expectations expressed by actors within three case studies of emerging sustainable innovations: biofuels, natural gas and hydrogen. Using the method of event history analysis we have collected data on the expectations about these three technologies during the period 2000-2008. These three technologies are in different stages of development. Hydrogen as a transport fuel and second generation biofuels are currently only tested in small scale pilot projects. First generation biofuels and natural gas are commercially available but not yet implemented on a large scale in the Netherlands. With respect to the actors that express expectations we found that both entrepreneurial firms and government actors play a prominent role in the discourse about the investigated technologies. This role of government actors may be specific for sustainable technologies as the government naturally has a role in the development and diffusion of these technologies due to the double externality problem associated with innovations for sustainability. For all three technologies we found indications of hype cycle dynamics. That is, for all three cases we observed sharp increases in positive expectations followed by either a sharp decrease in positive expectations (natural gas and hydrogen) or a sharp increase in negative expectations (biofuels). While such hype patterns may be beneficial for technology patterns as they assist in mobilizing resources and legitimacy this is not necessarily so as only in the case of natural gas as a transport fuel we see a clear convergence of expectations. We argue that such a convergence of expectations can be used as an indicator for the extent to which expectations are shared. The lack of convergence in the biofuels and hydrogen system is an indication that in these systems there is not yet a broad consensus on the performance criteria for the technology. This lack of consensus can create barriers for further innovation system development. In the case of hydrogen this is consistent with the stage of development of the technology. In the case of first generation biofuels and biofuels in general the decreasing levels of specificity indicate that a reorientation of the system is taking place after the phases of hype and disappointment. Expectation dynamics for emerging sustainable technologies thus follow patterns similar to general expectation dynamics described in the literature. However the patterns observed in these three cases diverge from theory in two important ways. First, we observe an important role for the government. Second we observe that expectations do not always converge even when technologies already have some market share as in the case of biofuels. Several factors can explain the large influence of the government regarding sustainable technologies in the mobility sector. Switching to a new transport fuel involves considerable investment in infrastructure and changes in regulation indicating a role for the government [32]. Furthermore in the early stages of development these technologies are to a large extent dependent on government subsidies as they are not able to compete on price with fossil fuels. This dependence on subsidies might also help explain the second observation that expectations do not always converge. In the case of hydrogen this observation is consistent with the pre-market development phase of the technology. In the case of biofuels however there is already considerable diffusion due to regulations but no consensus yet on the best technological design (wait for second generation biofuels or use the first generation as a stepping stone technology). This lack of consensus may become a barrier for the further development of the biofuels system. Describing patterns of expectations in a systematic allows us to compare different cases and to identify typical patterns that may be associated with success or failure. The expectation patterns thus provide insights regarding the development of technological innovation systems and provides insights for policymakers especially when considering the implementation of market formation policies for sustainable technologies. More specifically we recommend that policymakers take expectation dynamics into account when basing policy on foresight and scenario studies that depend on technological expectations. "
        }
    },
    "10.1016/j.techfore.2010.05.001": {
        "file_name": "154 The emergence of hybrid-electric cars Innovation path creation through co-evolution of supply and demand",
        "title": "The emergence of hybrid-electric cars: Innovation path creation through coevolution of supply and demand",
        "abstract": "Hybrid-electric vehicles have experienced a significant rate of growth in the last 10 years. This is remarkable, since the automotive sector is typically averse to the more radical technological change of engines. The internal combustion engine has been around for more than 100 years after all.\n\nIn this paper we describe and explain the emergence of electric engines in the automobile market after 1990. We explicate the role of techno-economic mechanisms alongside social and regulatory mechanisms (including the social meaning of an engine). The co-evolutionary analysis is novel in the integrated conception of actor perspectives, feedback effects and competition between products. We find three sources of lock-in through path dependency: from demand, supply as well as the regulatory side. We conclude that automotive engines were significantly locked into a trajectory of internal combustion technology due to techno-economic mechanisms, which produced inertia despite social pressures. The creation of an alternative path, on the other hand, initially stalled. Various stakeholders were unsuccessful in marketing their electric or hybrid-electric vehicles in the 1990s, such as Peugeot/Citroen with various electric models, or Audi with their Duo in 1997. However, after 2000 we find that sustaining efforts of California's Air Resources Board and Toyota were triggering creation of a new innovation path of hybrid-electric engines.",
        "label": "Mixed",
        "text": {
            "Emergence of new technology": " In the last few years the automobile market has demonstrated a surprising rise in sales of a new type of engine: hybrid-electric engines. Consumers increasingly drive them and car firms more and more explore them. Critics argue that similar short-lived hypes appeared in the mid-1990s with electric vehicles and around 2000 on fuel cell vehicles, and they are right. Still, today's momentum is distinctive in one important way: hybrid-electric engines have been sold 1.5 million times worldwide now. How could this happen in a sector that is typically aversive to risky radical technological changes and a classic example of 'locked' into a dominant technology [1,2]? Studies in various scientific fields have addressed the emergence of new technology and innovation. Broadly there are three stands of literature. Although most economists treat innovation as just another investment opportunity, one strand originates from the Austrian economist Joseph Schumpeter (1883Schumpeter ( -1950)), who bequeathed us with a scheme of technological change consisting of inventionthe first practical demonstration of an idea; to innovationthe first commercial application of an invention to the market; to diffusionthe spread of the innovation into the market [3]. In this tradition a new wave of economists revitalized evolutionary theorizing of innovation [cf. [4][5][6] from the early 1980s onwards. Studies in this strand have explained the domination of internal combustion (IC) technology in the automotive sector for more than a century now as lock-in through path dependency [1]. The models are, however, as yet less applied to consumer products in a changing social context. For consumer products symbolic meaning or social connotation of products may play a significant role, for instance for hybrid-electric cars of which many owners see their vehicle as 'socially responsible', as 'the right vehicle for society' [7]. Progression of such connotation will affect the further development (supply side) and diffusion process (demand side) of the technology. There are currently few theories in this economic field that incorporate this interaction of such social and technological aspects [e.g. 8,9] and as Saviotti [10] notices, these dynamics are still poorly understood. A second strand of innovation studies, innovation diffusion studies, is conceptually broader and originates from social geography, later adopted in marketing studies. The focus in most diffusion studies is on aggregate patterns, which are often found to be S-shaped. The seminal work of Rogers [11] offers a typology of adopters based on when they adopt but does not offer a dynamic model of innovation diffusion in terms of endogenous and exogenous mechanisms. In the field of marketing the symbolic meaning or value that goods and innovations hold is well established [e.g. 12,13], where it is typically distinguished from the functional value. Symbolic value is as a social connotation or meaning attributed to the product, and individual consumers will have a certain degree of inclusion in such a social construct. It may be positive or negative (even at the same time, for different groups of consumers), thus adding value in the eyes of a consumer, or reducing it. A third strand of innovation literature originating from the sociology and history of technology, where authors have emphasized the social context in which technology is created and used. A key concept is the social construction of technology (SCOT), where 'technology' is viewed not as an objective entity (as in economic and technical studies), but rather described 'through the eyes of social groups' [14]. These authors demonstrated how various social interpretations of technology drive various directions of technological development. Authors in the latter two strands have addressed the interaction of technology and social factors [for example 8,[15][16][17][18][19][20]. Most recently Rip and Kemp [21] elaborated on co-evolution of 'the social' and 'the technical', analysing the emergence, transformation and decay of socio-technical systems. Their 'multi-level' model of innovation distinguishes between the macro level of the sociotechnical landscape, the mesolevel regime, and the microlevel niche. Geels [22,23] added the key idea that radical innovations come about through interactions between processes at these three levels. That is: the breakthrough from niche to regime level occurs gradually, as a new technology 'branches' or 'penetrates' different application domains, before entering mainstream markets. These studies have highlighted more than previous studies the patterns in which established technologies are sometimes abandoned and overthrown by emerging niches. Dijk and Kemp [24] have argued that these studies have been less clear on why some niches are 'successful' in growing and even overtaking a regime, while other niches die. Interactions between niche and regime are claimed to be important, yet the interactions are not specified in terms of processes; feedback effects, such as scale and learning, and taste formation mechanisms are neglected. Dijk and Kemp have suggested a conceptual framework that highlights actor perspectives and feedback effects. In this paper we elaborate on the latter framework by explicating the role of techno-economic mechanisms alongside social and regulatory mechanisms for the case of automotive engines. We present the emergence of (hybrid-) electric engines on the automobile market in the context of evolution of demand and supply of car engines, which results in a co-evolutionary analysis. We perform an explanatory case study, applying our co-evolutionary framework to this case. Explanatory case studies are suitable for applying pre-defined frameworks to a new case, testing causalities and explanatory value [25]. After amplification on our methodology (Section 2), we describe our framework and hypothesize that six feedback mechanisms are key in the emergence of hybrid-electric engine technology (Section 3). Subsequently, we provide rich descriptions of how and why propulsion technologies were developed and adopted after 1990, tagging two levels. In Section 4 we focus on aggregate patterns (sales levels and technological progress), while in Section 5 we address the micro level perspectives of individual stakeholders (firms, consumers, and regulators). Section 6 integrates the previous sections into a co-evolutionary framework. Section 7 draws conclusions. We find that automotive engines were locked into an established trajectory of internal combustion technology sector due to techno-economic mechanisms, which produced inertia despite some sustainability pressures. In the 1990s the creation of a new innovation path of electric engines initially stalled, since the vehicles were broadly regarded as expensive and unpractical due to little autonomy. However, after 2000 it recurred through hybrid-electric engines, mostly triggered by efforts of Toyota to find a new market, and stimulated by the gradual social formation of a positive connotation.",
            "Methodology": " In the following sections we perform an explanatory case study, applying our co-evolutionary framework to the case of automotive engines. Explanatory case studies are suitable for applying pre-defined frameworks to a new case, testing causalities and explanatory value. In our explanatory case study we fit in evidence from a range of other methods, most notably discourse analysis, patent analysis and a questionnaire survey. Such a combination of methods has a few advantages. The simultaneous use of various methods can improve the quality and adequacy of a study considerably, and conclusions are usually more convincing if they are based on several different sources of information [25]. Combining methods can compensate for one-sidedness. In complex issues, one method easily results in only partial explanation of a phenomenon, as in the blind men and the elephant tale (as observed in [26]). Combining methods has difficulties too. Integration of outcomes and knowledge elements is difficult to validate scientifically, and methods may have a similar bias. Roe argues the various methods need to be orthogonal (i.e. very different) in order to be used in the triangulation procedure [27]. Another fundamental issue is that various methods may stem from different paradigms, and are therefore possibly incommensurable. Mingers and Brocklesby [28] suggest such problems are not insurmountable. 1 So, although a theory on the use of different methods is still in development, we will include evidence from a range of methods in our explanatory case study, to facilitate the understanding of the multifaceted phenomenon of the emergence of hybrid-electric vehicles.",
            "Feedback mechanisms in co-evolution": " In our framework 2 we consider demand and supply as two groups of attributes that co-evolve [10,29,30]. When we speak of demand and supply we thus mean the demand side and supply side. On the supply side, suppliers are creating technological variety. Of the possible options that emerge, some are selected through purchases in the market to the exclusion of others. On the demand side we have heterogeneous people of different income and lifestyles, equipped with preferences, beliefs and ways of thinking. Market price is important, but certainly not the whole story behind supply and demand. Markets are socially embedded [21], and products are socially constructed [14]. Underlying supply and demand we find socio-economic actors, with ways of interpreting, expectations, capabilities, habits, etc. We therefore consider demand as more than actual sales, as including consumer attitudes towards various options. Supply is more than actual production, and involves capabilities, business opportunity, and future expectations towards the various options. The heterogeneity in potential adopters creates a variety of demand. In our scheme, there is present demand and future anticipated demand. Under influence of the latter, suppliers make decisions (select foci) about investment in research and development. By proposing solutions to problems, suppliers are viewed as creating technological variety (see Fig. 1). In our scheme we distinguish a micro level where the innovation is described through the eyes of actors (consumers and suppliers), and a macro level where aggregate indicators of the innovation are considered. We suggest that this micro-macro framework is instrumental to highlight both actor perspectives, and address dynamics between the layers (as we clarify below). These two issues, actor perspectives and feedback mechanisms, are what we want to highlight in comparison to the multi-level perspective (e.g. [23] in this journal) and the Technological Innovation Systems approach (e.g. [31] in this journal). The social context in which technology is created and used is not stable, but undergoing change due to the introduction of novelty and due to institutional and material adaptations that go with it [21]. Both at the supplier and at the consumer side various forms of learning take place. These forms of learning are interrelated, in the sense that at the very beginning suppliers have to inform consumers about the innovation, but then suppliers themselves gradually learn how to evaluate demand as an innovation diffuses. Learning entails the availability of new skills and knowledge, new social connotations, changing future expectations, new supplier-user relationships, and changes in the regulatory framework. Consumers, by their different ways of interpreting, using and talking about technologies, further contribute to their social shaping. This is part of what some call the domestication process of products into daily life [32]. Thus, both the technological hardware and the relevant social context change in a complex process with strong evolutionary traits. The process of co-evolution is thus socially enacted, but not planned by actors. In the case of vehicle engines, for example, the following actors are involved: car manufacturers, engine component suppliers, car users, car repair shops, sales persons, journalists, university researchers and teachers, banks, venture capitalists, shareholders, and policy makers. It is impossible to include all actors in a behavioural model of innovation diffusion. For the purposes of our framework, we include three types of actors on the micro level: consumers of the innovation (in the example: buyers of new cars), suppliers of the innovation (car manufacturers) and policy makers (regulators of the sector and sponsors of research and green products). In our scheme regulation adapts over time, but is not co-evolving in the same sense as demand and supply. Instead, we regard policymakers, and the regulation they impose, as a force that shapes the co-evolution of supply and demand. The actual practices of all actors translate into macro patterns, such as total sales of the various options, prices, technological progress of various options. These macro level indicators in return influence the individual agents on the actor level: it is a circular (micro-macro) process (see Fig. 2a). The studies of innovation we reviewed [24] have identified various feedback mechanisms during the emergence of a product market or industry. Between the micro-and macro level we distinguish (see Fig. 2b): \u2022 Increasing returns to scale: cost per unit fall as firms take advantage of economies of scale, allowing them to profitably sell products at lower prices, which stimulates sales and further scale economies (see Fig. 2b yellow). \u2022 Learning about the market: growing sales lead to better knowledge about the heterogeneity of demand (who prospective buyers are, their willing to pay for specific features, what is valued and less valued); knowledge which may be used for R&D and new product offerings, which will give rise to better products and more targeted marketing effort that will stimulate sales (See Fig. 2b brown). \u2022 Social construction of meaning: products obtain a social meaning, which will differ across groups; products may become more or less desirable because of this. The dynamics may stimulate sales (in the case of positive stories and connotation) or discourage them (in the case of negative stories and meanings) (See Fig. 2b pink). \u2022 Network effects: increases in usage lead to direct increases in value (as in the case of the telephone); increased usage of the product may also spawn the production of complementary goods such as fuelling stations and assets such as skills which increase the value of the original product; in the case of competing technologies the one with the greatest installed base and compatibility with existing systems has an advantage over the other (see Fig. 2b purple). Alongside these micro-macro processes, there are also micro-micro feedback loops: \u2022 Learning-by-doing: production experiences leads to improved skills and helps to discover cost-efficiencies in production, allowing manufacturers to reduce prices and increase sales and production (see Fig. 2b green). \u2022 Imitation of use: potential adopters have a tendency to imitate peers (taste formation) (see Fig. 2b blue) (at the supply side, producers may also imitate successful features of competitor products). The velocity of the loops differs. Some loops are more rapid, such as falling prices in the course of a few years, or the improvement of technological quality of new options. Other loops are slow or discontinuously changing, such as those involving social factors. In our framework, actor groups have a mental perspective or frame. A frame is the way in which the innovation is described or interpreted by an actor. The framing metaphor can be understood as a window or spectacles (worn by the actor group) that filters the total amount of information in a first impression (what it is about and what it important for them), and focuses attention on key elements and aspects within.  Using the example of an alternative engine, say electric propulsion, the user may perceive this as either a green engine, or just another engine, possibly an exciting new engine or something he finds hard to label (he or she may not give it any thought). For manufacturers, the engine may be perceived as a something that is of interest to their customers or to new customers, as something for which a clear or uncertain market is anticipated. For producers the profitability of an engine (the business case) is likely to be an essential component of the frame. Policy makers on the other hand may see the engine as a solution for air pollution problems or as something that is interesting from an employment point of view (new jobs). Frames are devices for interpretation by accentuating certain attributes of the car (engine): maximum speed, power or fuel use, etc. It is well established that goods and service hold symbolic as well as functional value [12]. So, besides functional attributes, there is an attribute of social connotation, symbolic meaning. The populations of (prospective) users and firms are heterogeneous: users and firms are very different in terms of individual characteristics (such as preferences and technological capabilities). The frames are unconsciously applied by firms, consumers and policy makers when they deal with various opportunities and problems of vehicles. With this novel framework we analyse the emergence of (hybrid-) electric engines in a changing social context as a dynamic process of co-evolution of demand and supply, mediated by feedback loops.",
            "Evolution of engine technologies": " In this section we sketch aggregate patterns of the technological evolution of the car engine after 1990. We examine innovation of both the ICE and electric engines, and address both technical aspects and diffusion of use.",
            "Internal combustion engine": " For more than a century now, vehicle engines are dominated by internal combustion (IC) technology. The engines constructed by Otto, Daimler and Benz in the 1880s have been greatly improved since then, though they are in principle surprisingly similar to today's engines. After 1990, car firms continued to refine the internal combustion engines, especially with respect to performance and emissions. In Germany, fuel consumption of the fleet typically decreased 25% from 1990 till 2003 [33], while average horsepower of the engine highly increased. 4 Trends in the Netherlands were similar to Germany (see Fig. 3). Initially average fuel economy remained fairly constant there from 1990 until 1997. This was despite a trend of increasing average vehicle mass, and therefore only possible due to more efficient engines. After 1997 growth in engine fuel efficiency surpasses growth in vehicle mass, resulting preference for heavy vehicles that the fuel consumption did not decrease at all in that period. in a decrease of average fuel use. The impressive rise in fuel efficiency was possibly through broader application of two new engine components in particular 5 : direct injection and variable valve systems [34]. These innovations comprise the following: Fuel injection (FI) is a system for injecting fuel into an internal combustion engine. Prior to 1985, carburetors were the dominant device for this. Lack of injection accuracy causes a fair share of incomplete combustion, which forms the primary source engine emissions. Improved (i.e. electronic) fuel injection systems were increasingly applied (40% market share in 1988, and nearly 100% by 1990) and reduced incomplete combustion. Direct injection (DI) systems can be seen as most recent generation of FI. Variable valve timing (VVT) makes it possible to change the timing of some or all of the valves of an internal combustion engine during engine operation. Optimizing valve timing at all engine loads and speeds significantly improves engine efficiency, power, and exhaust emissions. Gasoline mileage improvements of up to 20% can be achieved with VVT [35]. Production and sales levels of VVT and DI rose considerably after 1990 (see graphs in Appendix A). The diffusion of direct injection systems was fairly fast on the diesel market. Beise and Rennings [36] show that, in Western Europe, the growth moved from 5% to 70% in only 8 years. By 2001 it had reached almost 80%. Application on the gasoline market has been increasing as well after 2002 (reaching 13% in Europe in 2007). Diffusion of variable valve systems was also considerable, though initially mainly among larger engines (greater than 2.0 L). We found it has reached 40, 50 and 60% in Western Europe, USA and Germany respectively.",
            "Electrical engines": " From the mid 1990s onwards, electrical engines (re-) emerged as alternative technology for propelling vehicles. First this was as pure electric vehicles (Battery Electric Vehicle, BEV); later as hybrid-electric vehicles (HEV). Electric battery vehicles consist of an electric engine that moves the wheels, a battery for energy storage, and an electronic engine controller. Up to 1996, the production and sales of electrical vehicles was dominated by small companies outside the car manufacturing industry, most notably the Danish City El. Sales were very low (only a few hundred per year). Around 1995 though, car manufacturers showed an increasing interest in marketing their electric vehicles (just prior to California's ZEV requirements for 1996). After a time of showing prototypes at automobile shows, they now started to launch production vehicles. Most car manufacturers favored electrifying existing models as an initial, low-cost strategy (Renault Clio, Peugeot 106, etc.). Around 2000 however, it was undeniable that BEVs were unsuccessful as a product market (see sales levels in the Netherlands in Table 1), mainly due to limited range, and a higher price relative to comparable IC vehicles. Not more than a few thousand were sold yearly between 1995 and 2000 worldwide. After 1997 a few car firms launched hybrid-electric versions (HEV). Hybrids have similar range as IC vehicles. Toyota presented its Prius on the Japanese market in 1997, and Honda followed with the launch of its Insight in California in 1998. Prices were initially much higher than ICEs, but Toyota initially paid a premium of around 10% on each vehicle, to push down the price. It sold more than 15.000 HEVs annually in its first years. In 1999 Toyota's Prius was launched in California and later worldwide, followed by a 2nd generation Prius in 2004. By 2002 worldwide cumulated HEV sales exceeded the 100.000 mark, by 2008 1.5 million. Market shares reached around 0.5% in The Netherlands in 2005, rising to 2% in (first half of) 2008. In the USA it was around 4% in USA in first half of 2008. The trend in the annual sales of hybrid vehicles produced by Toyota is shown in Fig. 4. By 2005 the overseas sales of Toyota's hybrid vehicle, mainly in the United States, had surpassed those in the domestic market.",
            "Shifts in stakeholder perspectives": " This section examines the role of stakeholders in the evolution of car engine technology after 1990. Whereas the previous section focused on aggregate patterns, we now address the innovation through the eyes of three stakeholders: users, producers and policymakers, and how they changed after 1990. ",
            "User perspective": " Since we cannot address all car users in the world, we limit ourselves to evidence from a discourse analysis of the Dutch car market, analysis of stated preferences on the US market, and analysis of actual sales in The Netherlands.",
            "User frames": " Though various studies have concentrated on the social perception of automobiles [see 37,38], few studies have examined perspectives on car engines specifically. It is not clear how people perceive the propulsion technology of their vehicle, and how they come to choosing the one or the other. Through the analysis of newspaper and their car magazine supplements (see [39] for the complete study) we were able to determine what features obtained attention among potential users, and how such features were valued (as something positive or negative). Here we summarize the main findings for BEVs, HEVs and diesel engines successively. Our analysis disclosed that for BEVs in 1996 range was perceived a salient attribute (mentioned in 75% of the accounts), as well as price (55%). Both range and prices were negatively appraised, which shows that markets actors were dissatisfied with both functionality and price. Environmental impact (only 35%) had dropped in frequency in comparison to 1990, though it was positively appraised (assessment score of + 5). The social connotation score of BEV was 0 by 1996, which means neutral. By 2000 there was only one salient attribute: range (71%). This attribute was evaluated negatively (assessment score \u22125). Hence, perceived functionality was still low, and attention for BEV had decreased. In 2000 Toyota's hybrid-electric Prius was launched in The Netherlands. Our analysis disclosed that for HEVs prominent attributes up until 2000 were fuel use (59%), price (55%), and environmental impact (55%). By 2005, they were fuel use (63%) and environmental impact (37%). The higher price as a negative factor dropped in importance to 15%. Fuel use being a positive factor was increasingly appraised: scoring +15 in 2000 and even + 32 in 2005. The negative score for price dropped: from \u221214 in 2000 to \u22123 in 2005. The score for social connotation rose from +3 in 2000 to + 9 by 2005. Our analysis of articles disclosed that hybrids were mostly associated with low fuel use, while remarks on performance were few. Acceleration, an aspect of performance, was mentioned in only 17% of the accounts and appraised as +5 in 2005. This satisfaction was low in comparison to diesels. For HEV, there has been a shift in the frames between 2000 and 2005, which is shown in Fig. 5. Most remarkable is the decrease in emphasis of environmental impact (from 55% to 37%), simultaneously to a slight increase on fuel efficiency (59% to 63%). This may well have to do with increasing fuel prices in the early 2000s, and also with a consumer tendency to focus on individual benefits, instead of common goods (such as air quality). The change in frame for HEV was quite substantial, and took place mainly prior to the diffusion process: in 2005 the percentage of HEV in new car sales was only 0.5%. Apparently the frame was fairly flexible by at that time. For BEV, by contrast, there was not a big change in frames (between 1996 and 2000): it was stable in its negative appraisal of range, price and refuel time. We also examined frames of the diesel engine, which were increasingly equipped with direct injection systems (see Section 4). Performance attributes, such as engine capacity ('horsepower'), acceleration and torque, got most attention. Innovations of diesel engines were well appreciated, both in terms of (perceived) functionality, as in the social connotation. Between 1996 and 2005 the shift in framing was only minor (both in structure and in appraisal), which is shown in Fig. 6. The drop in appraisal for fuel efficiency is the only notable change. It may be because users got accustomed to the relatively high fuel efficiency of the DI diesel engine, and found it normal by 2005. The changes in frame-attribute appraisal reflect the technological innovations that occurred on the one side and changes in social perceptions on the other (emphasis on fuel economy, attention for climate change). Apart from discourse analysis, Mytelka [40] presents a study on stated preferences of cars, not on car engines. It shows the relative importance of fuel economy, next to other consumer car preferences, see Table 2. It shows that dependability 6 has always been a prominent attribute for (US) consumers. Fuel economy fluctuates in importance, most likely due to fluctuations of the oil price. (Most notable is the decrease in importance of fuel economy between 2004 and 2005, since the fuel price rose between those years.) Business consultants from Maritz-research studied change of consumer habits due to rising fuel prices (in France, Germany and the UK with responses of 1240 new vehicle owners, see [41]). On the statement 'I think about buying, or have bought, a vehicle with a more economical engine', 57% agrees mildly or strongly, while only 23% disagrees mildly or strongly. Based on these figures they conclude that a major share of European drivers is changing their car purchase considerations, due to rising fuel prices. How familiar are people with new propulsion systems? In the same research Maritz found 20% is very familiar with hybrid-electric petrol engines, 34% somewhat familiar, 39% has heard of the technology, and 8% is not at all familiar. Full electric vehicle are somewhat less known: 9% very familiar, 35% somewhat familiar, 48% has heard of the technology, and 8% is not at all familiar. Of all new/alternative engine technologies, hybrids are most familiar. What engine do they consider for their next vehicle purchase? Of the respondents, 24% considers or strongly considers electric, 47% for LPG, 55% for petrol, 60% for hybrid-electric, and 72% for diesel. In other words: hybrid-electric vehicles are considered more than petrol engines, if we believe what these people say. But what do they actually buy? That is the topic of the next sub-section.",
            "User behaviour": " Customers of new vehicles can choose their preferred type (and size) of engine, out of a range of alternatives (usually between two and six). In another paper [39] we analyzed the outcomes of such consumer choices for the 30th highest volume car types in The Netherlands, in total more than 220.000 choices in a year (obtained trough [42]). We found three types of (engine) consumer groups. A first group, consisting of 30 to 35% simply chooses the cheapest engine. The cheapest engine tends to be lightest, and this results in relatively high fuel economy (for its class). A second, largest share of customers is willing to pay a few thousand euros more for a more powerful engine (with lower fuel economy): this is the case in 60 to 65% of the purchases. Customers have different reasons for this: typically because they like sporty driving, for status, to drive more comfortable on the highway, or to use a caravan. Few customers are willing to pay a few thousands of euro's more for a cleaner engine: 5% or less. Often such an option is not available. 7 Adding up these 'green' ICE consumers with hybrid-electric drivers (and LPG drivers), makes the estimate share of 'green consumers' in the whole population around 2 to 5%. We found no evidence that this group has grown between 2003 and 2007 in The Netherlands. These 'green' drivers make up the third segment, which is the smallest one.",
            "Policy perspective": " From the 1970s onwards, governments were increasingly confronted with insights in(to) the severe health implications of vehicle emissions. Emission regulation at a European level was adopted around 1985; in the USA and Japan already in the 1970s. This section examines government bodies regulating the car (engine) sector. For simplicity we will not address the framing of the emission issue here; the political discussions (what is the problem, what are alternative solutions? what is the 'best' solution?) and formation of majorities is a too complicated matter for the sake of this paper. In this section we examine what the outcomes were, such as decided emission standards and subsidies on R&D. In Section 6 the impact of these regulations on the engine market and innovation process is addressed.",
            "European policy initiatives": " The regulation adopted in Europe in 1985 provided targets for around the year 1992. In addition, in the course of the 90s standards were defined in a series of EU directives staging the progressive introduction of increasingly stringent standards (see Fig. 7). Emissions of NOX, HC, carbon monoxide (CO), and particulate matter are regulated. Fig. 7 shows how requirements for diesel cars evolved, as an example. Similar progressive standards were set for gasoline vehicles. The Euro-directives provided the industry with requirements on pollutants for 5 to 8 years ahead. This gave vehicle manufacturers a focus point for their engine development work. From the beginning of 1990s onwards, it became more and more apparent to policymakers that apart from polluting emissions, another type of vehicle emissions, CO 2 , needed limitation as well. The EU chose a different strategy on this: a voluntary covenant between the EU and the automotive industry. 8 In 1998, after 2 years of negotiation, the EU signed agreements with the car manufacturer association of Europe (ACEA), Japan (JAMA) and Korea (KAMA), committing them to reaching 140 g/km by 2008/2009, which is a 22% reduction compared to 1995. In order to support these emission requirements, governments at EU and national levels have regularly provided funds for research and development (R&D) on cleaner engines. Also, to support this direction at the customer side, many national governments provided subsidies on the purchase of low emission vehicles, for example battery electric vehicles (mostly from the 7 Here, engines are meant that are specifically engineered for high fuel economy, without compromising on power. An example is the 3-liter engine from Audi/ Volkswagen, which can make 100 km on 3 L petrol. These engines are more expensive. Not all manufacturers offer these high efficiency engines. 8 Different legal proposals concerning the reduction of CO 2 from vehicles were discussed (e.g. fiscal measures) from the beginning of the 1990s, but no agreement could be reached between the EU member states. This is why they came to a voluntary approach then. middle of the 1990s onwards). After 2000, many EU countries also implemented energy labeling schemes. These intend to provide information to the customer on the fuel efficiency of vehicles relative to other vehicles of the same size.",
            "US policy initiatives": " Emission regulation in the USA was adopted in the middle of the 1970s, defining maximum Corporate Average Fleet Economy (CAFE) numbers. The CAFE program requires car manufacturers' fleets to meet specific average fuel economy levels (for a model year). The CAFE have been unchanged since 1996, requiring that the fleet averaged fuel economy of all passenger cars, sold by a car manufacturer in a specific year, exceeds 27.5 miles per gallon (while pickups, vans and SUV's must get an average of 20.7 m.p.g.). CAFE standards do not get progressively stricter over the years. Actually, the highest fuel average fleet fuel economy in the US was in 1987. Apart from these law enforced regulations, a voluntary agreement in the USA became important in early 1998, the National Low Emissions Vehicle (NLEV) Program. It was triggered by developments in California in the early nineties (see below). Nine states and more or less all automotive manufacturers agreed stricter tailpipe standards in 1999, and nationally in 2001. These were more stringent than those in place by the EPA. 9 Further, the US government subsidized the US Advanced Battery Consortium, cooperation between GM, Ford and Chrysler, started in 1991. In the 10-year program the government spent 814 million, while the three firms spent 980 million dollar.",
            "California": " Some governments found the European and US federal (EPA) standards too weak. Initiated by severe health problems in the Los Angeles area, the California Air Resources Board (CARB) had ambition to set stricter standards. When it learned about novel electric vehicles in 1990 10 , it set new standards to trigger further development and sales of electric vehicles. 11 It adopted the ZEV Mandate in 1990, requiring that by 1998 2% of all new cars sold in California would be \"zero emission\". In the year 2000 all new cars sold had to be either \"low emission\", \"ultra low emission\" or \"zero emission\". Moreover, by 2003 75% had to be low emission vehicles (LEV), 15% ultra low emission vehicles (ULEV) and 10% zero emission vehicles (ZEV). As Kemp [43] notices, the ZEV Mandate was a significant piece of legislation, since California represents about 4% of the world market for cars and about 12% the US car market. The Mandate was relaxed however later on, most notably in 1996 when the 1998-2002 requirements were abolished, and in 1998 when ZEV credits could be earned through partial electric vehicles. By 1994, four additional states had adopted the California ZEV mandate (New York, Massachusetts, Vermont and Maine); eight more have joint the National Low Emissions Vehicle (NLEV) Program, approving stricter requirements than EPA. In Section 6 the impact of these regulations on the engine market and innovation process is addressed.",
            "Firm perspective": " For manufacturers, a novel engine may be perceived in various ways: as something that is of interest to their current customers, to new customers, as a product for which there is a future market when further developed (but no immediate market), or as an engine for which the market prospects are highly unclear. For producers the profitability of an engine (the business case) is likely to be an essential component of the frame. This sub-section first addresses the framing of car firms, and then examines individual firm behaviour (strategies) on car engine developments after 1990.",
            "Firm frames": " In order to survive between competitors, vehicle manufacturers define a certain business strategy, which contains a technology strategy. They strive to develop vehicles that are attractive to the customer on a mass production and sales basis. The business strategy defines the current and near-future product mix that should make the company profitable and competitive. In support of the business strategy firm perform R&D, with budgets ranging from 5 to 15% of total firm turnover. Prototypes of novel engines are also shown at international motor shows as concept cars for PR reasons, but without the direct intention to be produced. The product launch strategy defines the technology on the near-future products. Each new car or engine is seen as a project which should achieve a certain return on investment in order to be approved. As long as production investments in a new producttechnology have no profitable outlook, a firm will wait with launching the product. On the other hand firms are eager to achieve first-mover advantage. This is the temporary monopoly advantage that will accrue to the assembler first producing a reasonably priced improved engine, attractive to consumers. Consumer preferences are therefore the most important driver of product launches; emission requirements are a boundary condition for product launches: new vehicles have to comply with the regulation.",
            "Firm behaviour": " Firms differ in their precise strength and weakness of capabilities for innovation [44]. In this section we examine typical behaviour of firms in the sector after 1990, while we also address individual firm strategies, both for ICE and for electric engines. To identify firm behaviour we consider patent data and new product launches. 12  Patent data and new product launches reveals that most car manufacturers were involved in developing or adopting variable valve timing (VVT) and new fuel injection systems (after 1990 most notably direct injection (DI) systems). Comparing the patent figures of ICE after 1990 on the one hand and BEV and HEV on the other, reveals a striking difference: total patent numbers of BEVs and HEVs are much lower [45][46][47][48]. Progress and attention for IC engines was a factor 8-10 larger. Analyses of Oltra and Saint Jean [61] on the French automotive industry confirm these figures: see investment figures of PSA in 8 as an example. The trends in Japanese patent applications for cleaner propulsion technologies by Toyota are given in Fig. 9 [49]. The green arrows indicate when revisions and modifications were made to California's ZEV regulation. It shows that patent applications of electric vehicles rose sharply in the early 1990s, triggered by ZEV, since Toyota relied heavily on the large US market for their exports (ibid.: 195). Quandt [50] concludes that the ZEV requirement was largely responsible for the electric vehicle development programs run by almost every global automobile manufacturer at that time (1994). He reports that Toyota assigned 100 engineers in 1992 to a new division with the mission of developing a 1998-model BEV for the California market. Further, Cohen et al. [51] reports that the project team of Toyota's hybrid system (starting by the end of 1994/beginning of 1995), had intensive interactions with Toyota's Electric Vehicle Development Divisioncommunication of their team leaders was called 'a catch-ball process'. The Toyota-Matsushita joint venture for battery development (starting in March 1995) for its hybrid system, was relatively easy since Matsushita was already a supplier for Toyota's electric vehicle development [52]. In other words, despite ZEV's failure to trigger BEV sales, it did have a lasting effect on technological capabilities of (some) firms. Firms improved ICE performance after 1990, since they observed and expected most consumer satisfaction there. The technological refinements enabled vehicles to accelerate faster even though they became heavier [53]. Most firms did not regard electrical propulsion as a profitable strategy to increase satisfaction of the majority of consumers. Some firms did explore the segment of green consumers with clean ICEs and electric engines, first with BEVs, later with HEVs. But these efforts suffocated after 12 For a more detailed analysis on how this regulation came about, see Kemp (2005). disappointing sales, and remained minor issues compared the incremental innovation of ICE engines. (Differences between firms are described below.) Research on new car engines is a costly activity, which pushed various firms in research consortia [54], especially for hybrids and fuel cells. The research collaboration of GM, Daimler and BMW on hybrid technology is an example. These collaborative activities are however currently strictly separated from the leading edge research that is undertaken in-house, because of the significant first-mover advantages. R&D work is executed on two different places in the industry: at vehicle manufacturers and at suppliers. Pilkington and Dyerson [55] conclude that there is a clear difference between ICE and BEV here. Much of the research activity in BEVs occurred within the supplier network (especially in Japan) rather than exclusively in the mainstream carmakers themselves. They explain  this to the need for more radically technology shift, required by the more radical change of regulation in California. This shift proved too great for them to make themselves, they argue. In contrast, the incremental innovation in IC engines could be met by existing capabilities and networks of firms. Nevertheless, diesel and gasoline innovations are also driven considerably from research at first tier suppliers, such as Bosch, Denso, Valeo and Delphi. Table 3 below sketches individual firm strategic activities after 1990 (i.e. three firms are shown here, further nine in Appendix B). Descriptions are limited to main concept cars and launches. The examination of individual firm strategic activities shows that in the last 15 years firms have strongly focused R&D and engineering on incrementally improving their ICE engines. Up to 1996 some attention was spend on BEV technology, obviously initiated by California ZEV mandate. In 1996, when the mandate was relaxed, most firms shifted to fuel cell technology, as a more Fig. 10. Schematization of co-evolution of demand and supply. promising alternative for BEV (even before BEV proved a market failure!). Exceptions were Toyota and Honda, shifting to both fuel cell and hybrid-electric technology. Toyota and Honda pioneered in launching hybrid vehicles, Ford followed (Ford Escape, 2006). Teske and Chanaron [56], firm strategies towards HEV (by 2006), cluster the manufacturers in three groups: pro's, cautious pro's, and most reluctant. In group 1 they see Toyota, Honda, Ford, and GM. In group two they regard Hyundai, Kia, PSA, Nissan, D/C and BMW. In group three they hold Renault, VW/Audi and Fiat. The chronology of the commercialization of hybrid vehicles by major Japanese auto companies is shown in Table 4 [49].",
            "Co-evolution of demand and supply through feedback mechanisms": " This section integrates aggregate trends of demand and supply of car engines (Section 4) with stakeholder perceptions and initiatives (Section 6). Fig. 10 below presents a timeline, with stakeholders (frames and behaviour) evolving on the micro level. Simultaneously, the accumulation of their practices leads to two distinct innovation trajectories on the macro level: ICE (Section 6.1) and (hybrid-) electric engines (Section 6.2). As an illustration we schematize developments chronologically, and visualize the feedback mechanisms on the two distinct innovation trajectories. One type of mechanism relates to techno-economic factors (learning and returns to scale), another to social factors (framing and social connotation). Regulations also influence these mechanisms. The development of the two-layered framework denote to co-evolution of demand and supply in a broad sense, while the trends of total sales (demand) at the macro level and total product offered (supply) denote to co-evolution in a more narrow sense. Fig. 10 illustrates that we have identified a strong ICE regime over the whole period after 1990: car firms supplied (practically solely) ICEs to meet demand for two large consumer groups: those seeking sufficient performance engines at the lowest price (segment 1), and those preferring more powerful engines at a slightly higher price (segment 2). We discuss the developments of the ICE regime according to various mechanisms that shape demand and supply below.",
            "ICE regime trajectory": "",
            "Learning-about-the-market": " Learning-about-the-market was a significant mechanism in co-evolution of demand and supply for ICE engines. Firms learned which engines had best business opportunity, and they learned on shaping the technology best for that opportunity. After 1990 technical capabilities for applying VVT (for gasoline) and DI (for diesel) in consumer vehicles grew at various firms, after pioneering launches of Honda in 1989 (VVT) and Fiat (DI) in 1987. Since emission regulation became increasingly stricter, firms found VVT an attractive option for more expensive, high performance side of the car market. DI was mainly applied in medium sized diesel vehicles: Fiat Croma and Audi 100. It was attractive for firms with large sales share of diesel engines, such as Fiat and VW/Audi. Around 1990, five out of 21 manufacturers had VVT systems in production vehicles, two had DI. These (launching) companies now learned from their own vehicles how VVT and DI could be best applied in high volume products. While some firms waited with application on production vehicles (often because that was not profitable yet and not required yet to meet regulation), they did advance on R&D work: their technical capabilities on especially VVT grew. (For DI, firms relied more on suppliers such as Bosch.) These efforts were based on expectations that, in time, VVT would be necessary for improving performance and emissions of IC engines. In 1992-94 the number of market applications doubled quickly. Firms learned that customers in this group were willing to pay extra for an engine (around a few thousands of euros) for increased performance. Manufacturers observed sales numbers that were large enough to earn back a major share of their R&D investments. After 1997-98 many firms believed VVT to be profitable for medium priced models. It was now a means to both increase performance, but also to keep emissions within limits (i.e. standards). Finally, around 2000, almost all manufacturers applied VVT and DI systems in one or more engine models. After 2000, it further spread to more models.",
            "Learning-by-doing": " Technical improvement of BEVs was meager. GM's EV1 model years 1996 and 1998 show a range extension from 55-95 miles to 75-150 miles. Maximum speed stayed constant at 80 mph. Toyota's RAV4 had similar max speed, and a similar range of 80-120 miles. A 1998 Citoen Berlingo had slightly lower performance: a range of 96 km and max speed of 95 km/h. For hybrids, core of the technological challenge has been on the battery packs. Most hybrids use conventional nickel-hydride batteries. Specific output of these batteries (kWh over kg) has not improved much after 2000. Engineers have advanced though on trade-offs between total battery power (settling zero emission range and fuel economy) on the one hand and vehicle driving performance (acceleration, max speed) on the other. Progression on the battery life-time has also been achieved. 13Learning strategies that firms employed for electric and hybrid-electric technology were similar as those for ICE technology. It varies from own R&D, research collaboration with competitors (such as GM, D/C and BMW in 2005), to licensingin engines or components from competitors (Ford licenses components from Toyota).",
            "Increasing returns to scale": " Scale benefits for BEVs were limited for two reasons. Total sales levels were only a few thousands a year, and also those sales were spread over more than 10 firms. There were no key suppliers (yet) who would supply batteries or electric engine systems to most car firms (as Bosch did for DI systems), so each supplier had limited batches. By 1993 prices of electric vehicles were more than double the price of their petrol counterparts [1]. In 1995 the prices were 40-50% higher than the cheapest version of the equivalent gasoline makes (for Peugeot and Renault). 14 [58] mentions that in 1998 an electric Peugeot was 25-35% more expensive than its diesel or gasoline counterpart, respectively. In 2005, the retail price of a Citroen Berlingo electric was still 30% above the petrol one. Since market launch of most of electric vehicles (by 1995), scale benefits were obviously limited: only 10 to 20% in 10 years. For hybrids, the majority of the increased cost of the vehicle is associated with the batteries. Despite growing production levels the nickel-hydride batteries have remained expensive, mostly due to high nickel prices, which is one of the basic materials. Scale benefits have been stronger though than BEVs, since almost all HEVs are produced by two firms only. Toyota and Honda will surely have benefitted from their increasing scale of production of HEVs.",
            "Social construction of connotation": " The development of social connotation of electric and especially hybrid-electric vehicles shows an interesting dynamic. In the 1990s we found that attention for BEVs was fairly high: 20 accounts, which is double the amount of direct injected diesels in that year. Social symbolic meaning was however underdeveloped: only in 15% of the accounts there was reference to it, in quite neutral statements. Most accounts were summing up technical characteristics. Around 2000 attention for BEVs had collapsed, and social connotation had not developed. Meanwhile, attention for HEVs had considerably, up to 22 accounts by 2000. Social connotation already appeared in one third of the accounts. They were mostly positive (with adjectives such as 'high-tech', 'environmental friendly', 'modern'), some were neutral, and one was negative. By 2005 attention had mounted up to 41 accounts, even more than direct injected diesels in that year. Social connotation appeared in about a third of the accounts, and its mainly positive appraisal had caught up with direct injected diesel. This indicates the dominant social climate of praise for hybrids. Apart from influencing consumers, this also affected policy discussions. Twenty-two percent of the accounts were directly part of a policy discussion, containing pleads for tax (or parking) discounts for hybrids, and later also announcements of actual regulation. So, in the growing climate of praise for hybrids, politicians started to mention hybrid vehicles as a solution for environmental problems. In The Netherlands, as well as in many other European countries, this has lead to fiscal policies that give a preferential treatment to hybrid vehicles. This has affected sales levels of hybrids directly (for instance in The Netherlands HEV sales tripped in 2008 after new regulation for lease drivers, see also De Haan et al. [59]). The indirect effects on technological development are less obvious. The number of hybrid models on the market in Europe is still limited (about four), but firms have launched more models with more fuel efficient gasoline and diesel engines. The slow growth of hybrid models may be because technological development takes time, holding up European and American firms to launch hybrid models. More likely, some firms believe than even despite social praise and fiscal incentives for hybrids, ICEs have still the largest short term potential for fuel gains and profits.",
            "Interaction of regime and niche": " Electric and hybrid-electric engines did not emerge in a vacuum: they emerged alongside existing dominant regime of gasoline and diesel technology. Innovation, progress and learning on electric technology took place alongside progress and learning on ICE technology. As acknowledged in Section 1, innovation is usually inert on, or 'locked-in', an existing path (path dependency). For car engines we have encountered three sources of lock-in. One source from the production side: it is economically not very attractive to invest much in a new, still immature technology. Those will not lead to more revenues in the short term. Competition on the present market is fierce, and it is (relatively) more attractive and necessary to invest in incremental innovation of the existing technology. This yields a pattern in which car manufacturers continuously refine the dominant design in order to improve environmental performance of ICEs. Since Ward [60] innovation scholars refer to this as the 'sailing-ship' effect. We have found a second source of lock-in at the consumer side: about 95% of consumers were satisfied with the way ICEs performed. They comprised two major consumer groups: those seeking sufficient performance engines at the lowest price, and those preferring more powerful engines at a slightly higher price. The remainder of about 5% (i.e. those who prefer clean and fuel efficient engines and who are willing to pay slightly higher purchase price for this) is the current niche market for hybrid technologies. For most consumers however, IC technology performed as they expected, at a predictable cost. They favored innovations of ICE over electric engines. We discerned a third source of lock-in related to regulation. We found that the European Euro 1 to 5 regulations for example have mainly led to an impressive though incremental innovation trajectory of ICE, decreasing certain emissions step by step [see also 61]. But they have not triggered radical innovations and escape from lock-in. (A similar effect of relatively weak environmental regulations on promoting incremental innovations, which has functioned to prolong the existing technological trajectory, is found in the chemical industry by Yarime [62]). On the contrary we found that California's ZEV mandate did stimulate an escape from lock-in of the ICE trajectory, as we found in our analysis of the firm perspective (Section 5.3) and is also found in other studies [63,64]. Until 1996 it put substantial pressure on firms to make R&D effort for alternative engines, enhancing technological competences on ULEV technologies (electric and fuel cells). After relaxation of the mandate in 1996, most firms relaxed efforts for radical innovations by putting them in a longer time-frame.",
            "Path creation": " Stimulated by California's regulation, Toyota had made considerable advancement in electric vehicle technology [49,50]. While all manufactures were relieved with ZEV relaxation, and lobbied for further reduction, Toyota saw a business opportunity for its electric engine technology, in the form of a hybrid-electric vehicle [52]. The Prius I (1997) was targeted at the 'green' niche in Japan, providing an extremely low fuel use (3.6 L per 100 km), while compromising on acceleration and maximum speed. When the Japanese niche was captured effectively, the crossing of the Pacific to California was undertaken. The Prius II was launched there in 2000, though with a renewed trade-off of electric power (increasing fuel use to 5.1 L per 100 km, but also increasing acceleration). This 'higher performance' Prius was received well in California, a state with a considerable amount of environmentally conscious consumers. By 2004 the (improved) Prius III was launched worldwide, and was received well in most countries by the green consumer segment. Total global sales provided Toyota with a considerable scale level, which probably made the hybrid venture profitable (by about 2005), though precise figures on this do not exist. Honda early followed Toyota in this endeavor, launching the Insight already by 1998. Other firms were reluctant, expecting hybrids to be worthwhile for a small niche of the market only. After 2005 firms were less certain on this, and increased R&D attention for hybrids. The crucial question is whether and when hybrids will become attractive for consumers in segment two: those who seek sufficient performance at the lowest price. If fuel prices continue to rise, a point may be reached soon where the extra purchase cost of hybrids will be recovered by lower fuel cost. Since this segment comprises around 35% of the market, this would mean an enormous boost to hybrid technology sales. Secondly, if the social connotation of hybrid technology continues to grow to an extent of surpassing the appreciation of cleaner and more fuel efficient ICEs, the share of consumers that is willing to pay more for HEVs would grow. At the same time, policymakers would then favor hybrid technology over cleaner ICE technology, which could lead them to introduce policies give an extra stimulus for HEV sales. Looking back to the period of 1997 to 2007, we observe that Toyota was effective in addressing the green consumer segment with hybrid technology, essentially triggering the creation and spur of the hybrid niche trajectory. Other companies have addressed this same low emission vehicle segment from time to time, by launching both IC technology (Golf ecomatic, 1993; Volkswagen Lupo 3 L in 2000; Opel Corsa eco in 2002; Mercedes A160), and alternative propulsion systems (notably PSA with several electric models, Audi with Duo hybrid in 1997). However, firms withdrew these vehicles from the market, and reduced efforts towards this segment, since in each case sales were disappointing. Toyota's Prius was rolled out vigorously to the worldwide green segment and also appealed to a slightly broader set of consumer (including those who like high-tech devices), paving a way to the wider application of hybrid technology in other models.",
            "Conclusion": " In this article we describe and explain the emergence of electric engines in the automobile market after 1990. We addressed aggregate level outcomes, such as total sales and technological progress in the sector, both for ICE and for electric engine technology. Furthermore, we examined the perspectives of three key stakeholders: firms, consumers and regulators, and how they changed. We found four key feedback mechanisms which underlie the niche and regime dynamics. We have identified a strong ICE regime over the whole period after 1990: car firms supplied (practically solely) ICEs to meet demand for two large consumer groups: those seeking sufficient performance engines at the lowest price, and those preferring more powerful engines at a slightly higher price. Starting with the pioneering launch of the Prius I (1997), Toyota was effective in addressing the small green consumer segment around the globe with hybrid technology, creating and spurring the hybrid niche trajectory. We can draw a few conclusions from the analysis. First, market niche trajectories need to pass a critical size in order to be viable. PSA was unable to reach a critical size of its electric vehicle activities, despite considerable investments and support from local and national governments (such as a large scale experiment in La Rochelle). The vehicles were broadly regarded as relatively expensive and impractical due to little autonomy. First year sales of HEV were to the order of 10 times higher then first year sales of BEV: about 15.000 vehicles versus about 1.500. Hybrids were appreciated for high fuel economy, similarly practical as ICs and benefitted from the positive social connotation. Somewhere in between these two values may be the critical size for a one-year-old market niche on the automobile market. Second, environmental regulators have hoped for the radical (green) innovation of car engines, but their regulation has mostly stimulated incremental innovation of ICEs, enforcing the lock-in. California's ZEV mandate is an exception, indirectly stimulating R&D on ULEVs. Third, social pressure from civil society (via connotation) does impact the momentum of technology trajectories, though only indirectly. After all, business and technology strategies of car firms are focused on consumers of new cars, not on citizens in general. The extent to which new car consumers are receptive to the social pressure is thus an important factor (hurdle). Further, the influence of social pressure is indirect via a second route, since it provides political support for new regulation, which will subsequently influence technological development. All in all, this paper adds to our understanding of historic and contemporary innovation paths and processes of car propulsion technology. They hint at the large complexities involved in the interaction of emerging niches with established regimes, which makes the predicting of the future paths impossible. The analysis has shown that the positive social connotation of a new technology contributes to counterbalance techno-economic path dependencies, affecting both consumers, producers and, not least, policymakers. For electric and hybrid-electric engines the latter group seems to be essential in order to gain further momentum in the future. Appendix A. Diffusion of VVT and DI after 1990 (source: own calculations, based interviews and data provided by Bosch and Delphi)"
        }
    },
    "10.1016/j.techfore.2008.04.013": {
        "file_name": "162 Functions of innovation systems as a framework to understand sustainable technological change",
        "title": "Functions of innovation systems as a framework to understand sustainable technological change: Empirical evidence for earlier claims",
        "abstract": "Understanding the emergence of innovation systems is recently put central in research analysing the process of technological change. Especially the key activities that are important for the build up of an innovation system receive much attention. These are labelled \u2018functions of innovation systems\u2019. This paper builds on five empirical studies, related to renewable energy technologies, to test whether the functions of innovation systems framework is a valid framework to analyse processes of technological change. We test the claim that a specific set of functions is suitable. We also test the claim made in previous publications that the interactions between system functions accelerate innovation system emergence and growth. Both claims are confirmed.",
        "label": "Mixed",
        "text": {
            "Introduction": " Innovation is increasingly considered crucial to deal effectively with the negative side effects associated with economic growth. Influencing the direction of innovation towards more sustainable directions is high on many political agendas. Issues like global warming, security of energy supply, local air pollution, and negative social effects of economic growth have strongly contributed to these insights. In recent literature a structural re-orientation of economic activity towards sustainability has been labelled as processes of sustainable socio-technical change, industrial transformation and (socio) technological transitions [1][2][3][4][5][6][7]. In these contributions, the emphasis lies on the development of new modes of governance to support these processes, e.g., transition management at the level of societies and strategic niche management and socio-technical experiments at the level of specific innovation processes [5][6][7][8][9]. Due to different disciplinary backgrounds only a limited number of insights from the field of innovation studies are applied to this new and rapid growing field of sustainable socio-technical change. This is remarkable since innovation is a key process in sustainable socio-technical change and the field of innovation studies has provided a vast amount of insights in the factors that explain processes of innovation and in the type of policy frameworks that support innovation. One of the frameworks from innovation studies that has the potential to contribute to the understanding of sustainable technological change 1 is the innovation system approach. It has become a well-established heuristic framework in the field of innovation studies. It presents insight in the factors that explain processes of innovation [10]. The framework has been adopted as an analytical framework and as guideline for science and innovation policy by numerous public organisations around the world [11][12][13][14][15][16]. Furthermore, a number of scholars have adopted the innovation system framework to study processes of socio-technical change and in many studies the focus was on emerging renewable energy technologies [17][18][19][20][21][22][23][24][25][26][27][28][29]. More specifically these authors have adopted the technological innovation system (TIS) approach as introduced by [30]. The focus of the TIS approach on the their structure. Typical indicators to assess the structure of the NSI are R&D efforts, qualities of educational systems, universityindustry collaborations, and availability of venture capital. Thus, most empirical studies on Innovation Systems do not focus on mapping the emergence of innovation systems and their dynamics [19]. However, in order to understand technological change, one needs insight in how the innovation system around a new technology is build up. Thus insight in the dynamics of the innovation system is necessary. Fortunately, in a technological innovation system (TIS), the number of agents, networks, and relevant institutions are generally much smaller than in a national innovation system, which reduces the complexity. This is especially the case when an emerging TIS is studied. Generally, an emerging innovation system consists of a relative small number of agents and only a small number of institutions are aligned with the needs of the new technology. Thus, by applying the TIS approach it becomes possible to study dynamics and to come to a better understanding of what really takes place within innovation systems [19]. According to Carlsson and Stanckiewicz [30] (p.94), a TIS is defined as: \"a network or networks of agents interacting in a specific technology area under a particular institutional infrastructure to generate, diffuse, and utilise technology.\" This implies that there is a technological system for each technology and that each system is unique in its ability to develop and diffuse a new technology [24]. A well functioning TIS is a requirement for the technology in question to be developed and widely diffused. The question remains, however, what determines whether or not a TIS functions well, other than defining success by the end result, i.e., a high level of technological diffusion? Edquist (2004) states that \"the main functionor the \"overall function\" of an innovation system is to pursue innovation processes, i.e., to develop, diffuse and use innovations\" [37] (p. 190). In order to determine whether a TIS functions well or not, the factors that influence the overall functionthe development, diffusion, and use of innovationneed to be identified. Jacobsson and Johnson [34] developed the concept of system functions, where a system function is defined as \"\u2026a contribution of a component or a set of components to a system's performance\". They state that a TIS may be described and analysed in terms of its 'functional pattern', i.e., how these functions have been served [34]. The functional pattern is mapped by studying the dynamics of each function separately, as well as the interactions between the functions. The system functions are related to the character of, and the interaction between the components of an innovation system, i.e. agents (e.g. firms and other organisations), networks, and institutions, either specific to one TIS or 'shared' between a number of different systems [38]. Recently a number of studies have applied the system functions approach, which has led to a number of system functions lists in the literature [17][18][19][20][21][22][23][24][25][26]. This paper uses the recently developed list of system functions at Utrecht University [19,[27][28][29]41] that will be applied to map the key activities in innovation systems, and to describe and explain the dynamics of a TIS. Function 1: Entrepreneurial Activities. The existence of entrepreneurs in innovation systems is of prime importance. Without entrepreneurs innovation would not take place and the innovation system would not even exist. The role of the entrepreneur is to turn the potential of new knowledge development, networks and markets into concrete action to generate and take advantage of business opportunities. Function 2: Knowledge Development (learning). Mechanisms of learning are at the heart of any innovation process. For instance, according to Lundvall: \"the most fundamental resource in the modern economy is knowledge and, accordingly, the most important process is learning\" [32]. Therefore, R&D and knowledge development are prerequisites within the innovation system. This function encompasses 'learning by searching' and 'learning by doing'. Function 3: Knowledge Diffusion through Networks. According to Carlsson and Stankiewicz [30] the essential function of networks is the exchange of information. This is important in a strict R&D setting, but especially in a heterogeneous context where R&D meets government, competitors and market. Here policy decisions (standards, long term targets) should be consistent with the latest technological insights and, at the same time, R&D agendas are likely to be affected by changing norms and values. For example if there is a strong focus by society on renewable energy it is likely that a shift in R&D portfolios occurs towards a higher share of renewable energy projects. This way, network activity can be regarded as a precondition to 'learning by interacting'. When user producer networks are concerned, it can also be regarded as 'learning by using'. Function 4: Guidance of the Search. The activities within the innovation system that can positively affect the visibility and clarity of specific wants among technology users fall under this system function. An example is the announcement of the policy goal to aim for a certain percentage of renewable energy in a future year. This grants a certain degree of legitimacy to the development of sustainable energy technologies and stimulates the mobilisation of resources for this development. Expectations are also included, as occasionally expectations can converge on a specific topic and generate a momentum for change in a specific direction. Function 5: Market Formation. A new technology often has difficulties to compete with incumbent technologies, as is often the case for sustainable technologies. Therefore it is important to create protected spaces for new technologies. One possibility is the formation of temporary niche markets for specific applications of the technology [39]. This can be done by governments but also by other agents in the innovation system. Another possibility is to create a temporary competitive advantage by favourable tax regimes or minimal consumption quotas, activities in the sphere of public policy. Function 6: Resource Mobilisation. Resources, both financial and human, are necessary as a basic input to all the activities within the innovation system. Specifically for biomass technologies, the abundant availability of the biomass resource itself is also an underlying factor determining the success or failure of a project. Function 7: Creation of legitimacy/counteract resistance to change. In order to develop well, a new technology has to become part of an incumbent regime, or has to even overthrow it. Parties with vested interests will often oppose this force of 'creative destruction'. In that case, advocacy coalitions can function as a catalyst to create legitimacy for the new technology and to counteract resistance to change. Both the individual fulfilment of each system function and the interaction dynamics between them are of importance. Positive interactions between system functions could lead to a reinforcing dynamics within the TIS, setting off virtuous cycles that lead to the diffusion of a new technology. An example of a virtuous cycle that we expect to see regularly in the field of sustainable technology development is the following. The virtuous cycle starts with F4: Guidance of the Search. In this case, societal problems are identified and government goals are set to limit environmental damage. These goals legitimise the mobilisation of resources to finance R&D projects in search of solutions (F6), which in turn, is likely to lead to Knowledge Development (F2) and increased expectations about technological options (F4). Thus, the fulfilment of the individual functions is strengthened through interaction. Vicious cycles are also possible, where a negative function fulfilment leads to reduced activities in relation to other system functions, thereby slowing down or even stopping the progress.",
            "Methodology": " All empirical cases that are compared in this article have used a similar method to analyse innovation system dynamics. The method used to map interaction patterns between system functions is inspired by the process method called 'Historical Event Analysis' as used by Van de Ven and colleagues [36,40]. Stemming from organisational theory, the usual focus is on innovation projects in firms and firm networks; in our case, the analysis is applied to a TIS level. Basically, the approach consists of retrieving as many events as possible that have taken place in the innovation system using archive data, such as newspapers, magazines, and reports. Lexus Nexus3 is used as news archive. The archive is complemented with articles from professional journals. The events are stored in a database and classified into event categories. Each event category is allocated to one system function using a classification scheme (see Appendix Table 1). During this procedure, the classification scheme was developed in an inductive and iterative fashion. The classification scheme and event categories are verified by another researcher to improve reliability. Any differences in the coding results of the researchers are analysed and resolved. Appendix Table 1 shows the allocation scheme of how events reported in literature are allocated to the system functions. We indicate whether the events are labelled as positive or negative. The contribution of an event to the fulfilment of a system function may differ considerably from event to event. Some events have a positive contribution to the diffusion of the technology, while others contribute negatively as for instance an expression of disappointment, or the opposition of an important political group. This is indicated in the allocation scheme by +1 and \u22121. The balance between positive and negative events yields specific insights into the slowing down of system growth or into controversies emerging around the analysed technology. The events are not weighted since the importance of an event is not known beforehand. Only after the construction of the narrative the importance of a specific 'watershed' event can be identified. The final outcome of the process analysis is a narrative (storyline) of how the development of the TIS has changed over time and the role of the different system functions within this development 4 . This narrative is complemented with and illustrated by several pictures in which the events are plotted over time 5 . In the narrative the focus is on extracting interaction patterns between system functions. Based on the content of the events and their chronological order, we are able to deduce the effect of one event onto another and the order in which such events occurred. By observing reoccurring sequences of events we are able to identify interaction patterns between system functions. Thus, the quantitative exercise is largely intended to strengthen a basically qualitative argument rather than presenting a statistically valid argument by itself. We do not perform a statistical analysis, since analysing correlations between different functions over time requires obtaining qualitative insights in their relations to construct a persuasive hypothesis. Only then, these hypotheses may be tested using statistical methods. We use cross-case analysis to test whether these patterns are case specific or whether they hold more generally. Insights in these patterns are the first step towards policy recommendations regarding the governance of this set of TIS [19]. We limit ourselves to a very short stylised description of each case where just the main interaction patterns between system functions are stated. For a more detailed description we refer to the original articles.",
            "Results": " In this section we provide the empirical material and arguments to answer our research questions. We start with the description of two success cases. Both cases show virtuous cycles. Then we describe two cases where virtuous and vicious cycles alternate. By these cases more insight is provided in the effect of virtuous and vicious cycles. We end with a case where hardly any system functions interact.",
            "Virtuous cycles building up": " We will start with describing the case of biomass digestion in Germany. Biomass digestion is a process to produce a gaseous fuel from organic waste or manure. The main adopters in Germany are farmers that seized the opportunity to convert their excess of manure into renewable energy. The build up of the innovation system starts to take off when the German Government introduces the Electricity Feed-in Act in 1990. This act states that producers of renewable energy are compensated for higher production costs compared to conventional electricity. This act guides the direction of search (F4) towards renewable energy technologies. Biomass digestion is recognised by entrepreneurs as a key technology to produce renewable energy and they start to create and diffuse knowledge (F2, F3), which leads to the set up of the first digestion plants (F1). The first trials show however that the current legislation is not sufficient to make a good business case for biomass digestion. Lobby activities (F7) by the German Biogas Association try to achieve a change in the institutional conditions. They are successful when shortly after the German government increases the feed-in rates in 1998 (F4). The level of the feed-in tariffs is such that a first market is formed for biomass digestion (F5), which results in the construction of initially about 200 plants each year (F1), resulting that by the end of 2003 about 1750 plants are standing. However, the German Biogas Association and entrepreneurs are not satisfied with the institutional conditions and additional lobby activities (F7) are undertaken to improve institutional conditions (F4). These requests quickly find a hearing by politicians, due to the presence of the Green Party in Parliament, and in 2004 higher feed-in tariffs are introduced (F5) that are guaranteed for a period of 20 years, thereby strongly reducing the uncertainties for entrepreneurs. The feed-in tariffs lead to a market formation, which leads to the final breakthrough of biomass digestion in Germany (F1), i.e. 2700 plants in 2005. This case shows that the positive interactions between six system functions explain most of the dynamics. The interplay between guidance of search by the government, entrepreneurial activities, lobby activities to counteract resistance to change and market formation prove to be dominant. Also resource mobilisation through different subsidy programmes and knowledge development contributed to the dynamics. Only the role of knowledge diffusion was difficult to verify in the empirical data, but with hindsight it seems fair to assume that much knowledge diffusion must have taken place between the farmers (adoptors, entrepreneurs) and the technology suppliers (entrepreneurs), as to improve the technology and achieve such a high diffusion in different regions.",
            "Virtuous and vicious cycles alternating": " The case described above shows mainly positive interactions between system functions. This is quite exceptional. In most cases virtuous cycles are alternated by vicious cycles. This is the case of biomass co-firing. This implies adding biomass as a feedstock to existing coal-fired power plants. This add-on technology is quite simple compared to most other sustainable energy technologies. Moreover, in this innovation system the agents, power plants and infrastructures are already in place, being part of the incumbent system. Nonetheless, the dynamics and sequence of events are interesting. The sequence of events starts with guidance of the government, stimulating the energy companies to reduce CO 2 emissions (F4). The energy companies comply by publishing an 'Environmental Action Plan'. This changes the direction of search towards alternatives for coal as feedstock. Co-firing is quickly recognised as a very promising option (F2). The government supports the ambitions of the energy companies to replace a certain percentage of coal with biomass, by the provision of resources (F6) and the formation of a market (F5) (the power producers received a subsidy for each kWh produced with biomass). This leads to the quick introduction of co-firing (F1). However, around 2000 a vicious cycle starts. Unclear and contradictory regulations regarding biomass co-firing (-F4) temporarily delay the entrepreneurial activities (-F1). The vicious cycle is broken by lobby activities by the energy companies (F7). This leads to agreements with the government about new institutional conditions that are well aligned with the needs of biomass co-firing technology (F4). On top of this the government forms an additional market for biomass co-firing by negotiating another voluntary agreement with the coal sector to reduce CO 2 emissions (F5). This is the final trigger to implement co-firing in all coal-fired power plants (F1). The third case also shows alternating virtuous and vicious cycles, but now the vicious cycle dominates. The case of biomass gasification in the Netherlands involves advanced technology to convert biomass very efficiently into electricity. The biomass gasification innovation system starts by the recognition of the potential of this technology by a small group of energy specialists. Positive experiences in Finland (F3) guide these Dutch energy specialists to focus on this novel technology (F4). A waste surplus problem and the climate change issue helps putting this technology on the political agenda (F4). Several desktop and feasibility studies on biomass gasification provide very positive results (F2). Due to these positive results and great enthusiasm of the energy experts, the expectations (F4) of the entrepreneurs and government are boosted to high levels in a short time span. As a natural consequence subsidies are provided for research (F6) and research programmes are set up (F2). The high enthusiasm and highstrung expectations, arising from positive results obtained from the research programmes, lead to the set up of two biomass gasification projects (F1). The above shows a strong virtuous cycle during the period 1990-1998, where positive expectations (F4) strongly influence positive system dynamics. However, the virtuous cycle is terminated in a very short period of time due to one key event: the liberalisation of the energy market. Energy companies start competing for customers by means of low energy prices, which lead to the termination of unproven, risky projects. A vicious cycle starts to take place. The lack of support by energy companies (-F4) results in less knowledge creation (-F2), less investments (-F6), less resources (-F6) and above all negative expectations (\u2212F4). These negative events reinforce each other and result that no more activities are carried out anymore, so that the system collapses within a couple of years. Until now, biomass gasification has still not diffused on a large-scale in the Netherlands. The fourth case deals with the development of biofuels in the Netherlands [28]. In this storyline biofuels are biomass-based liquid fuels for automotive purposes that may serve as a substitute for diesel. It is important to make a distinction between first and second-generation biofuels. First generation biofuels are based on rapeseed oil. The production process does not require advanced or complex technology. For second-generation biofuels woody material (lignocelluloses) is used as feedstock. Highly complex chemical process technology is needed to transform woody material into diesel substitutes. The build up of the innovation system around biofuels in the Netherlands is strongly influenced by discussions about which of these technologies should be pursued. The developments start with experiments (F1) around first generation biofuels in 1990. Policy programmes by the European Union and similar activities in Germany provide guidance for starting these initiatives (F4). Lobby practices (F7) for tax exemptions are successful for different projects and small niche markets are created by these tax exemptions (F5). Different scientific reports provide negative guidance (-F4) by stating that first generation biofuels are not a sound technological trajectory to pursue in the Netherlands due to too little environmental benefits and high costs. Government is in doubt what to do with these developments and does not provide clear guidance towards this technology (-F4). This leads to the situation that for individual projects is it sometimes possible to get a tax exemption but that no general tax exemption is put into practice. For this case no real build up of any kind of cycle is visible in this period. In 1998 the government initiates a technology development programme for the development of new fuels. Quickly after the start of the programme, a choice is made to focus specifically on second-generation technology and not on first generation technology. The technology programme sets in motion the interaction between many system functions. Resources are provided (F6) to stimulate the formation of networks (F3) and to support assessment research (F2). This in turn leads to different projects (F1). The projects are successful (F4), particularly with respect to solving important technical bottlenecks (F2). The programme serves as a catalyst that bundles and guides R&D projects that have, till then, been going on in relative isolation (F3, F4). As a consequence multiple entrepreneurs (F1) start new biofuels projects during this episode, even outside the programme. A clear interaction between the system functions knowledge development/diffusion and entrepreneurial activities starts to develop in this period. The final outcome of the programme should be the construction of a demonstration plant for second-generation biofuels. The government agrees to co-invest. However, it turns out that the parties are not willing to take the economic risks associated with the construction of such a plant (-F1), primarily due to the lack of a promising market (-F5). The analysis shows that a lack of vision and guidance (-F4) led to poor market formation activities for the first generation biofuels (-F5) and thereby the Dutch government not only slowed down the progress for first generation technology but unintentionally also for second-generation technology. The earlier observed interactions between the system functions come to an end. Things change in 2003 as the EU issues the Biofuels Directive [41]. This exogenous factor has drastic consequences. In contrast to the Dutch government, the EU is largely oriented towards first generation biofuels. With the new task of translating the EU directive to national policy, the national government reorients its policy. From 2003 on, the technology programme is given a new priority task (F4): the development of a generic market for biofuels. The first generation technologies are now increasingly perceived as bridges towards the implementation of second-generation fuels [41]. This changes the entrepreneurial climate and many regional entrepreneurs execute plans for the construction of small factories (F1). The projects are supported by a large number of agents; amongst them are farmers, farmers' associations and local government authorities (F3). Many of them are made shareholders (F6). Also, biofuels are promoted to potential users (F4). For these projects to be financially attractive, tax exemptions are requested (F7), and issued on project basis (F5). By 2005, the first (first generation) bio-diesel plant is built. This successful outcome (F4) triggers a pattern of cumulative causation that can be coined as a market-driven cycle and from 2002 on, numerous projects (F1) start all over the country, especially in rural areas. Thus the developments around biofuels in the Netherlands can be characterised by the notion that after a period of low interactions between the system functions, periods of virtuous cycles are alternated by periods of vicious cycles and vice versa. To summarise, the case studies described above show that the interactions between system functions lead to the (temporal) build up or deconstruction of emerging innovation systems. Virtuous cycles occur when several system functions are fulfilled, interact and reinforce each other. The question remains whether it is possible to have an innovation system where different functions are fulfilled but where no or only limited interactions take place. What type of dynamics follows from such a lack of interaction?",
            "System dynamics with limited interaction between system functions": " To illustrate a dynamics with limited interaction we turn to the case of biomass digestion in the Netherlands, which stands in sharp contrast to the successful development of this technology in Germany. Two observations stand out in this case. First, an irregular functional pattern is observed, as positive and negative system functions seem to take alternative turns every so many years. Second, during most periods only a limited number of system functions are fulfilled. In the early period of the emergence of the biomass digestion innovation system (1974-1987) only the system functions knowledge development (F2) and entrepreneurial activities (F1) occur as several pilot plants are set up as solution to the manure surplus problem (F4). However, no other system functions are triggered. In the following years, as the manure surplus problem is not solved, negative guidance against biomass digestion (-F4) severely hinders market formation (-F5) and investments (-F6). Surprisingly very little lobby activities occur (-F7). The biomass digestion entrepreneurs seem very weakly organised. Only in 1989 a cautious built-up of system functions occurs when guidance (F4), due to a waste surplus, where biomass digestion seems to be a potential solution, stimulates the knowledge creation and diffusion (F2 and F3) of biomass digestion, resulting in the set up of several plants (F1), seven plants in 1992. However system functions, such as market formation (-F5) and resource mobilisation (-F6) remain unfulfilled. Also lobby activities are too scarce to improve institutional conditions for digestion. One of the institutional barriers for manure digestion is that it is not allowed to add other biomass feedstock to the digester, a process referred to as co-digestion. If this would be allowed the biogas output of a digester and thereby also the profitability of the plant could be greatly increased. In 1995 the positive guidance turns into negative guidance (-F4), as biomass digestion is not recognised by the Dutch government as a renewable energy technology. Where the German entrepreneurs were able to show the German government that digestion is a well functioning renewable energy technology that deserves support, the Dutch digestion sector did not manage. No additional resources are therefore made available (-F6), forcing several plants to shut down (-F1). In 2003, the Dutch government aims to increase the share of green electricity (F4) and introduces a feed-in tariff system (F5). Due to this change in institutional conditions, agents of the biomass digestion sector see an opportunity to profit from this market formation (F5) and this time start a successful lobby to allow co-digestion and to put biomass digestion as a renewable energy technology on the political agenda (F7).",
            "Finally, between 2004 and 2006 an increase of biomass digestion plants occurs (F1).": " To summarise, between 1974 and 2003 no continuous built-up of system functions occurs. Some system functions are fulfilled but they do not interact with each other as to reinforce each other and trigger other system functions. This provides a scattered functional pattern that leads to an innovation system that is essentially muddling through, resulting in a very low diffusion rate of the technology in question. However, it still provides a seeding ground for virtuous cycles in a much later stage when the institutional conditions have changed.",
            "A cross-case analysis": "",
            "Are all functions relevant?": " Now that we know that processes of virtuous and vicious cycles actually occur we can test whether all seven functions are relevant as key factors that drive innovation system growth. We apply two different methods to answer this research question. First, based on the different event databases we can count how many events are allocated to each system function and calculate the share of each system function per case study and in total (see Appendix Table 2). Second, based on the earlier described cases, we argue what the relative importance is of the different system functions. First, we observe that all seven system functions used in the empirical analyses can be related to actual events that took place. This is an important observation since the absence of one or more system functions in the event databases might mean that these system functions are not relevant for understanding the build up of innovation systems. We also observe a disparity in the number of events allocated to each system function. This does not mean that the system functions with the most events are the most important ones. To some system functions many events may be allocated where the total influence may be lower than a small number of events for other system functions. Thus, since the importance of an event can only be known retrospectively, it is better not to weigh the events at all. Appendix Table 2 creates first evidence that all seven system functions matter, but not with respect to the importance of each system function. In order to understand which system functions are more important than others, it is necessary to apply the second method, which is based on the narratives that describe the dynamics of the individual TIS; it should become clear which system function turns out to be a strong driver for system change and which system functions impede system growth. \u2022 Entrepreneurial activities (F1) are a prime indicator whether an innovation system progresses or not. First, we observed that it is a very good indicator for technology diffusion. In most cases technology diffusion developed in line with entrepreneurial action. Second, entrepreneurial activities proved to be a central function that connects other system functions and thereby adds to the occurrence of virtuous cycles. We often observed knowledge creation (F2) being followed by entrepreneurial activities and in turn entrepreneurial activities triggering many other system functions. \u2022 Knowledge development (F2) is also important in all cases. This is not surprising since we studied complex technologies in early stages of emergence where uncertainty about technological performance is high. It is only natural that much R&D is necessary to solve technological problems and create a technology with acceptable specifications. Very often knowledge development preceded entrepreneurial activities or co-evolved with entrepreneurial activities. Thus entrepreneurs only dare to invest in new technological trajectories when a minimal knowledge base is present. When they do invest, the many technological problems that they encounter are solved with additional R&D efforts. An important finding is that knowledge development needs to be defined much broader than knowledge about 'how a new technology functions or performs'. Very often important processes of knowledge development are related to creating insights in the fit between new technologies and 1) existing business practices and 2) existing or new regulations. Another interesting finding with respect to knowledge development is that most of those novel technologies are 'new combinations' of already existing technologies, either transferred from another sector (digestion technology was already used in the 70s for wastewater treatment) or used with a different feedstock (biomass gasification could benefit from experience with coal gasification). \u2022 The role of knowledge diffusion (F3) is much more difficult to map. We have been able to measure the events where knowledge diffusion is likely to take place, such as workshops, conferences and technology platforms. However, the actual knowledge diffusion processes could not be measured in this way. Also much knowledge diffusion takes place in dyadic relations that are not reported in literature. So, many of the knowledge exchange processes do not become visible using this method. By interviewing agents in the innovation system, much more insight can be provided into the fulfilment of this function. Thus, the quantitative method is not optimal for measuring this function. In many trajectories we observe strong improvements in technological performance that matches the needs of technology users. Implicitly we may assume that knowledge diffusion and even learning has taken place. \u2022 Guidance of the search (F4) is an important system function. It stands at the base of many developments and leads to several courses of action, either positive or negative. We observed that strong guidance motivated entrepreneurs to enter a new technological field and that guidance directly influenced the amount of resources allocated to knowledge development. We also observed that a lack of guidance made the entrepreneurs reluctant to invest. Shifts in positive and negative guidance were mirrored by increasing and decreasing entrepreneurial activities. Also, most of the frustration of entrepreneurs in emerging innovation systems was due to rapid shifts in guidance and not so much due to other factors like problematic technological performance and availability of capital. \u2022 Market formation (F5) is often addressed at an advanced state of development, but it can significantly accelerate the build up of the TIS. For example, we observed that the success of biomass combustion in the Netherlands is directly related to the fulfilment of the system function 'market formation'. All other system functions are in place and a direct relation is visible between a well functioning system function: market formation and system growth. Just like the guidance function, the rapid shifts in market formation had strong effects on innovation system development. It proved to be difficult for the (Dutch) government to provide consistent policy with regard to guidance and market formation. \u2022 Resource mobilisation (F6) turned out to be relevant in each case study. Through (public) allocation of resources many knowledge development projects were started. It proved much more difficult to mobilise resources to build and construct plants. Both government and private investors were hesitant to provide these necessary investments. The reluctance by private investors was directly related to political uncertainty (guidance). During some periods large amounts of resources were invested to create a market. However, the political commitment to sustain the investments for market formation was often unstable. This led to the earlier described shifts in guidance and market formation. Only in the German case we observed a very stable institutional setting to allocate the needed resources for market formation. \u2022 Finally, the creation of legitimacy (F7) shows to be of utmost importance. It is a crucial function that positively helps to align institutions to the need of agents in emerging innovation systems. We observed that the absence of this system function is often an indicator for a poorly functioning innovation system and a poor alignment between institutions and the needs of the emerging innovation system. In most cases the interests of the incumbent innovation system are very well put to the front by incumbent advocacy coalitions with enormous lobby power. It proved difficult in most emerging TIS to form advocacy coalitions with enough strength to align the existing institutional conditions to their needs. We observed that the agents in an emerging innovation system do not easily pack together to form a tight network with a clear and strong standpoint. Often, different visions on the most ideal technology and ways to proceed impede strong coalition formation. Based on the observations above we conclude that all seven system functions are important variables that influence the build up of technological innovation systems.",
            "Are some interaction patterns generic for innovation system dynamics?": " Other observations that are made across the case studies relate to the specific interactions between system functions, key drivers and starting points of the virtuous cycles. For the majority of the virtuous cycles an important starting point seems to be the urgency of the government to comply with national or international goals on energy or climate change (F4) which triggers research for solutions (F2). In most of the cases the sequence guidance (F4) \u2212N knowledge development (F2) is observed. Often financial resource mobilisation (F6) takes place to make knowledge development possible. This contradicts the linear model where innovation processes are believed to start with either technology push or market demand. Our analysis of innovation system dynamics around sustainable technologies shows that pressure on the incumbent system to look for alternatives and expectations about novel technological trajectories often explain the start of new search processes. These forms of guidance are a much more indirect way of technology push and market pull then that the linear model assumes. Thus most of the sequences start with guidance (F4) and continue with knowledge development (F2) via resource mobilisation (F6). Following this string of events, subsequent sequences all differ from each other, since different agents are involved, which act and react in different ways. This shows that the dynamics are complex and that there is not one ideal way of how it can go. However, some functions proved to be key drivers that influence system change. A rise in entrepreneurial activities is observed when the system functions such as guidance of the search (F4) and/or market formation (F5) are fulfilled well. In several cases the positive guidance (F4) leads to an increase in entrepreneurial activities (F1) but a breakthrough does not occur until a market is formed (F5), which provides entrepreneurs and investors with a long term, stable perspective. Clear guidance and a well functioning market formation are in turn strongly influenced by the pressure that the entrepreneurs put on the authorities. A well organised set of entrepreneurs, that is capable of building up expectations about the new technology and is successful in influencing the government to adjust the institutional conditions in such a way that they are better aligned with their needs, is crucial. Another aspect that needs to be considered, are the technology characteristics. A well functioning, reliable and profitable technology is likely to gather more support and enthusiasm by entrepreneurs, investors and policy makers than a technology that is expensive and unreliable. Thus, positive technological characteristics will result in an easier fulfilment of system functions (e.g. cogeneration, co-firing and combustion). In other words, the technological characteristics are very important and influence the fulfilment of the system functions. This also works the other way around, as the system functions influence the technological characteristics (e.g. biomass gasification where no space and time was provided for the technology to develop further and for agents to experiment and build up experience). Finally, the maturity of the technology affects the functioning of the innovation system. When the technology is still in an emerging stage, system functions like knowledge diffusion and guidance are more important to the functioning of the innovation system than market formation. However, the exact relation between the maturity of the technology and the importance of each of the system functions is still unknown and more research is necessary in this area. Technology development and innovation system build up thus co-evolve in relation to each other. The fulfilment of the seven system functions and thereby the build up of the innovation system depend on expectations about the technology itself. Therefore technology development should be rather successful as to sustain these expectations. At the same time, the system functions are required to stimulate technological development and to raise expectations.",
            "Conclusions and strategy recommendations": " In the section below we will provide answers to the research questions posed in the introduction of this papertesting the suitability of the system functions selected and the functional pattern identified.",
            "All functions are relevant": " Our analyses showed that the system functions that were proposed in Hekkert et al. [19] all matter. By allocating the events to each system function we could determine whether one of the system functions is superfluous. It turned out that this is not the case. We recognise that for the system function of knowledge development, the method of archive research is not as suitable as for other system functions, as not many specific events for knowledge diffusion may be identified. Not all events found in literature could be allocated to one of the system functions. One other category that would comprise the unallocated events is 'external factors'. This covers events like oil crises, Chernobyl, power shortages in California, and international climate change agreements. These events have been included in the narrative but not conceptualised in a formal way. Thus, in its conceptualisation of technological change, the approach focuses strongly on activities endogenous to the innovation system, rather than exogenous factors. It is of course possible to come up with a different set of functions using the same empirical material. Our analysis started by retrieving many events from literature, categorising those in a limited set of event categories and finally allocating these event categories to the seven functions. Each event category is specific to one function. However, another group of researchers with different backgrounds might highlight different processes and come up with a different categorisation of events and thereby to a different set of functions. The basic difference between these lists of functions would be that some functions are divided into more specific functions while others are presented in a more aggregate form. We have not done the exercise to show that our set of events and event categories could or could not be allocated to the other lists of functions presented in literature. Furthermore, we observed that more events could be allocated to some system functions than to others, but that the quantity does not mean that the system function with more events is more important than a system function with fewer events. In fact, we deduce that for some system functions, such as market formation, the impact of the event is higher than for events allocated to knowledge development. Also, it can be noted that there are less of such high impact events. Finally, we restrain from weighing events as the importance of each event can only be known from hindsight and would therefore bias the storyline.",
            "Functions interact with each other": " Other than merely testing the system functions, we also explored whether system change is related to virtuous and vicious cycles. We compared several case studies of different emerging technologies with each other and observed that indeed the positive interaction between system functions is a very important mechanism for change, i.e. the breakthrough of emerging technologies. Negative interactions between system functions instead hamper the diffusion of the technology and in some cases provoke the collapse of the innovation system. For most case studies we observed that virtuous and vicious cycles altered, and that a domination of virtuous cycles is the exceptional case. Looking more specifically at the dynamics of virtuous cycles, it becomes clear that a number of system functions play an especially important role. A rise in entrepreneurial activities (F1) is observed when the system functions such as guidance of the search (F4) and/or market formation (F5) are well fulfilled. In several cases the positive guidance (F4) leads to an increase in entrepreneurial activities (F1) but a breakthrough does not occur, until a market is formed (F5) that provides entrepreneurs and investors with a long term, stable perspective. Clear guidance and a well functioning market formation are in turn strongly influenced by the pressure that the entrepreneurs put on the authorities. A well organised and capable group of entrepreneurs is crucial to build up expectations about the new technology and to successfully influence public policy to adjust the institutional conditions in such a way that they are better aligned with their needs.",
            "Limitations": " It is important to notice that all cases analysed in this paper deal with sustainable energy technologies. The dynamics of the innovation systems related to these technologies might be quite specific. The energy sector itself is conservative, different governments have a very influential role in these trajectories and innovation processes are strongly influenced by the societal need for clean energy and a reduction of carbon emissions. Further research is required to expand the empirical cases to different sectors and technologies. "
        }
    },
    "10.1016/j.techfore.2006.08.006": {
        "file_name": "173 The bumpy road of biomass gasification in the Netherlands",
        "title": "The bumpy road of biomass gasification in the Netherlands: Explaining the rise and fall of an emerging innovation system",
        "abstract": "In this paper, the concept of System Functions of Innovation Systems is applied to provide an explanation of the success or failure of an emerging technology, i.e. biomass gasification, with empirical data on the evolution of this technology in the Netherlands during 1980\u20132004. A new list of System Functions has been developed lately and is used to identify the most relevant events in the evolution of the Biomass Gasification Innovation System. We show that a structural misalignment occurred between the institutional framework within which the technology could have been developed and the technical requirements of the technology. Finally, the absence of System Functions such as the guidance of the search, resource allocation and advocacy coalition explains the failure of this technology over time.",
        "label": "Mixed",
        "text": {
            "Introduction": " The issue of stimulating the development, diffusion, and application of renewable energy (renewables) remains high on the political agenda of many countries. Despite numerous attempts in this direction, such as the set up of European research programs for the demonstration and promotion of renewable energies, 1it has proven to be difficult to replace large quantities of fossil fuels with renewable alternatives. Actually, the renewable energy supply for IEA 2 countries has increased from 4.6% of the total primary energy supply in 1970 to 5.5% of the same in 2001 [1]. However, Jacobsson and Johnson [2] counter these disappointing figures by noting that a process of diffusion of renewables is now starting to take place. They base this more optimistic message on the high annual growth rates of different renewable energy sources. The annual growth of total renewables supply has been 2.3% over the last 33 years. Notably, the same for new renewables (including geothermal, solar, and wind) has been 8% during the same period. Despite such high growth rates, the share of renewable energy sources in global Total Primary Energy Supply (TPES) remains low due to the vast size of the global energy market. The current situation of heavy dependency on fossil fuels 3 and the difficulty for renewables to have a major breakthrough is captured well by the term: 'carbon lock-in' [3]. Under this condition, fossil fuel technology benefits from long periods of experience, leading to high efficiency, low costs, optimal institutional arrangements, and many vested interests [3]. As a result, the emerging market for renewables has to depend very much on government support to expand. Many obstacles are also to be overcome in order to realize their smooth diffusion. Since these obstacles differ for each country and for each technology, our knowledge on the diffusion process of renewable technologies is limited. More insight is, therefore, needed on the process through which renewable technologies emerge and how they are able to achieve successful diffusion in society. From the earlier studies on the transformation of energy system [4,5], we have learned that the success of a new technology is not only determined by its technical characteristics but also by the ability of the Innovation System (IS) that develops, diffuses, implements, or rejects new biomass technologies. A well functioning IS vastly improves the chances for the success of the technology in question to be developed and diffused. In this paper, we analyze the development and diffusion of biomass gasification technology in the particular context of the Netherlands. The choice of this technology is justified by the fact that biomass is considered to be one of the most promising alternatives to replace fossil fuels since it is a diverse energy carrier with a multitude of potential sources and applications. The gasification technology, in turn, is generally considered to be a very promising technology to convert biomass into useful products. First, the conversion efficiency of biomass into electricity is much higher than that for biomass combustion and digestion. Second, by means of gasification, besides the production of electricity, biomass can also be converted into feedstock for the chemical industry and for the production of liquid biofuels. The expectations around this technology are, therefore, quite high and many actors see it as the technology to achieve a breakthrough for biomass as modern energy source [6][7][8][9]. However, despite its high efficiency, wide range of applications, and high expectations, biomass gasification has not been successfully developed, diffused, and implemented in the Netherlands so far. Our main research question, therefore, is: What are the inducement and blocking mechanisms that have determined the evolution of biomass gasification in the Netherlands? This question is addressed by utilizing the Innovation System concept as a framework and the empirical data on the evolution of this technology in the Netherlands during 1980-2004.",
            "Technological change and Innovation Systems": " The underlying theory of this paper focuses on how to break out of the 'lock-in' of established systems and how to resolve the difficulty that firms encounter when developing new technologies and bringing them to the market. Unruh [3] argues that \"industrial economies have been locked into fossil fuel-based energy systems through a process of technological and institutional co-evolution driven by pathdependant increasing returns to scale.\" He calls this situation 'carbon lock-in', since it creates persistent market and policy failures, which inhibit the diffusion of carbon-saving technologies despite their apparent environmental and economic advantages. Unruh [3] argues further that the \"lock-in occurs through combined interactions among technological systems and governing institutions, which perpetuate fossil fuel-based infrastructure in spite of their known environmental externalities and the apparent existence of cost-neutral, or even cost-efficient, remedies\". These technological systems can be regarded as large complex systems of technologies embedded in a powerful conditioning social context of public and private institutions. It is this context that determines how technological systems evolve. We focus on a specific part of this social context that we label as the IS. This is the set of actors and institutions that determine the generation, diffusion, and utilization of a new technology. The Energy Innovation System is part of the overall Innovation System and leads to the generation and diffusion of innovations that are used in the energy system. Once an Energy Innovation System is focused on specific technological trajectories such as the more efficient fossil fuel conversion technologies, alternative technologies can be locked-out for a long time even if they demonstrate improvements upon the established systems [3]. It is impossible to isolate a single factor that could unlock the system. However, the existing Innovation System could lose viability when the selection environment changes and starts providing new challenges that cannot be met by the dominant technological trajectories or that require advances, which are possible only at very high marginal cost [10]. This opens the windows of opportunities for the new technologies. But, such opportunities in and of themselves are not sufficient to unlock the system. Many opposing forces are likely to slow down or even stop the successful development and diffusion of emerging technologies. So, what is needed to increase the chance of new technology development to become successful? The theoretical model we use in this paper is based on the notion that when a new technology, in our case biomass gasification, is invented, an emerging Technology Specific Innovation System (TSIS) surrounds it. For this technology to become successful, several activities need to occur within the emerging TSIS, especially those needed to develop, support and implement the technology. As an illustration, a possible course of activities is described subsequently. In the initial phase, the TSIS is bound to consist of merely scientists and engineers, who invent and further develop the technology due to specific policy goals. Then, they would persuade financers to invest in R&D by presenting high economic returns for the technology. As technological success augments, so do the expectations. This, in turn, leads to further growth of the TSIS as more actors are likely to enter and specific institutions are set in place to support the technology. With the flow of financial resources, more technology developers pick up the new line of research. At a certain point, policy makers also enter into the system as subsidies, development programs, or niche markets are developed for the new technology. Thus, the TSIS grows both in size and influence and it co-evolves with technological development. At a certain point, the sheer size of the TSIS is so large that it is able to take over large parts of the incumbent Energy Innovation System (creative destruction). Our main point of interest here, therefore, is: what are the determining factors that foster the growth of an emerging TSIS, entrenching it in society and allowing it to gain ground in the existing Energy Innovation System? Edquist [11] states that these determining factors can be traced by identifying all processes that take place in the IS, influencing the development, diffusion, and application of an innovation. These processes are also called 'Functions of Innovation Systems', which are referred from here on as System Functions. Jacobsson and Johnson, who developed the concept of a System Function, define it as \"a contribution of a component or a set of components to a system's performance\", where the components are actors, relations between actors, and institutions and the performance is considered in terms of the rate of development, diffusion, and implementation of a new technology [2]. They argue that an Innovation System \"may be described and analyzed in terms of its 'functional pattern', i.e., in how these functions have been served\" [2]. The functional pattern can be mapped by studying the dynamics of each System Function separately plus the interdependencies among the System Functions. By assessing the functional pattern, insight is created into the performance of an IS. Thus, to understand the inducement and blocking mechanisms of technology development, diffusion, and implementation, the functional pattern of the related TSIS needs to be described and analyzed, particularly through time. Depending on the phase of development of the innovation system, we can expect differences in the functional patterns. In earlier works within the literature [2,[11][12][13][14], different sets of System Functions are proposed. In this article we build on the work of Hekkert et al. [5], who propose the set of System Functions, 4 as shown in Table 1. We expect that the more System Functions are fulfilled, the better the performance of the IS will be, resulting in, thereby, higher chances for a successful development, diffusion, and implementation of new technologies. Both the individual fulfillment of each System Function and the interaction dynamics among the functions are of importance. Virtuous interaction patterns between System Functions could lead to a reinforcing dynamic within the IS, whereas vicious interactions could cause the IS to collapse eventually. For example, an increase in knowledge and positive research results can lead to high expectations of the emergent technology, attracting new actors and additional resources for the development of the emergent technology. Obviously, this leads to more research activities being initiated (see Fig. 1). Apart from the reinforcing cycles, vicious cycles can also be active within the system. For instance, a negative fulfillment of a function might lead to negative outcomes with respect to the fulfillment of other functions, resulting in a declining functional pattern. In this case, the cycle might bring down the whole system before it eventually collapses. An example in this respect could be the cutback of a national subsidy program and its negative impacts on the expectations over the possible success of the technology. This would cause entrepreneurs to stop their activities, thus further decreasing the expectations, which eventually would lead to the abolishment of the remaining subsidies. The practical relevance of this framework is that policy initiatives directed at stimulating sustainable change of the energy system, should focus on stimulating weak System Functions to increase the chances of virtuous feedback taking place. Additionally, by identifying the underlying tendencies of the occurrence of vicious cycles, appropriate policy recommendations can be developed to prevent or resolve the occurrence of those cycles in the future. For a thorough understanding of these processes, historical empirical analyses are necessary. Moreover, since the dynamics are often specific to both technology and nation, a focus on a particular technology within the institutional context of one country is justified5 [15]. Below we describe how we analyzed the dynamics of the Biomass Gasification Innovation System in the Netherlands.",
            "Methodology": "",
            "Historical Event Analysis": " We propose to use as much quantitative indicators as possible in order to be able to map functional patterns over time. For this purpose, we developed a method inspired by 'Historical Event Analysis' as used by Van de Ven et al. [16] and Poole et al. [17]. Stemming from organizational theory, their focus is mainly on the company and company networks. But, in our case, the analysis is applied to a technological system level. Basically, our approach consists of retrieving as many historical events related to a technological development as possible. Such information is gathered essentially from professional journals, newspapers, and websites. The events are stored in a database with a systematic classification and allocation to the System Functions. The methodology results in a coherent sequence of events related to the development, diffusion, and implementation of biomass gasification in the Netherlands during 1980-2004. This sequence is, then, the basis for the storyline that empirically describes the evolution of biomass gasification. The events are also plotted for a graphic description of the functional patterns. To construct the functional patterns, all events are weighed the same. However, in the storyline some relevant events are highlighted by naming them explicitly. A distinction should be made regarding the nature of the contribution of an event to the fulfillment of a system function. Some events have a positive contribution to the development of the technology, while others contribute negatively as, for instance, an expression of disappointment or the opposition of an important political group. The positive and negative events are counted and represented separately. This way the functional pattern might yield specific insight into the controversies that emerge around the analyzed technology. The fulfillment of the System Functions is represented by graphical activity patterns, where per function, events are aggregated per year. A positive line represents the total amount of activities per year that contribute positively, whereas a negative line represents activities that contribute negatively to that particular function. The graphs are used to illustrate the qualitative storyline about the dynamics of the biomass gasification IS that is extracted from the sequence of events. Table 2 shows the scheme of how events reported in literature are categorized by System Functions. We indicate whether the events are labeled as positive of negative and give an overview of the total amount of events per function. The historical event analysis was partly validated by interviews with various actors in the field6 [18].",
            "The case of Dutch biomass gasification": "",
            "Gasification technology": " The traditional way to convert biomass into electricity is through biomass combustion. The hot exhaust gases of the combustion process are subsequently used to produce steam that is processed through a steam turbine to generate electricity. An innovative and more efficient method is gasification of biomass. In this case biomass is combusted in an oxygen-starved environment, where the end products are CO and H 2 gases (so called product gas or syn(thesis) gas). In contrast to solid biomass, this producer gas can be fed into a gas turbine to produce electricity at a much higher efficiency (35-40%) than combustion (25-30%) [15,19,20]. Biomass gasification is a flexible technology, since product gas can be used not only to produce electricity but also feedstock for chemical processes [15]. However, there are some fundamental requirements that limit the flexibility and efficiency of biomass gasification technology. The first is that a constant and sufficient supply of biomass has to be guaranteed for an installation to be able to run efficiently. Also, there is a need to ensure the quality and type of biomass. The cleaner the biomass, the lesser the costs that are involved in complex cleaning processes. Furthermore, dry biomass is more efficient than wet biomass, since no additional drying is needed. Finally, the type of gasifier used also determines the size of the installation. For small-scale applications (b 5 MW) fixed bed gasifiers are more efficient, whereas fluidized bed gasifiers are more efficient for large-scale applications (N5 MW) [20][21][22]. In this paper, we focus on biomass gasification plants where only biomass is gasified. Combined gasification of coal and biomass is not included as coal is the major feedstock used and the biomass share is only marginal, resulting in other technical properties than full biomass gasification [23]. We are aware of the experimentation of coal and biomass co-gasification in the large-scale (205 MW) coal gasification plant called 'Buggenum', but due to the above-mentioned reason, we will not include the trajectory of this project [24][25][26]. In addition, we focus on the use of biomass gasification for electricity production. Biomass gasification as for the production of transportation fuels (e.g. Fischer-Tropsch fuels) is developed in quite a different innovation system. Therefore, it is not analyzed in detail but briefly sketched in order to illustrate the dependencies between both innovation systems. The main attention for biomass gasification in the Netherlands starts in the early 1990s. In the previous period, the Dutch government mainly stimulates research on alternative energy sources by publishing formal policy documents (1982 -White Paper on Renewable Energy; 1989 -National Environmental Plan (NMP); 1990 -White Paper on Energy Saving). However, these official documents are not backed up by other policy initiatives, which results in low funds for research on renewable energy; the engagement of implementation remains on general terms and on a voluntary basis [27][28][29]. At the beginning of the 1990s, two urgent problems are identified. The Netherlands lack sufficient landfill space for waste, resulting in several knowledge development programs set up by Novem, 7 to reduce the amount of final waste by converting waste into useful energy (1989 -EWA program; 1990 -NOH program, 1992 -EWAB program) [30]. In addition, the awareness of the negative consequences of using fossil fuels increases, causing the need to develop and implement alternative energy conversion technologies to become more urgent [31]. These two problems guide the search towards new technologies that could solve these problems (F4) and create legitimacy for new development paths (F7). The idea for large-scale biomass gasification is until now still rooted in Dutch research on coal gasification and development activities of small-scale biomass gasification units for developing countries. However, positive results obtained abroad incite the idea to use biomass gasification as an alternative conversion technology for waste surplus in the Netherlands [32,33]. In addition, the province of North-Holland8 sets policy aims to provide a clean, sustainable and affordable energy supply by combining wind energy and biomass gasification (see the next section for a detailed description of the North-Holland project) [34]. This triggers the commission of an inventory studies for gasification of wet biomass wastestreams for electricity production, where it is found that these biomass streams can also be used for gasification and that they reduce costs due to their negative value [35]. In addition a study trip to biomass gasification projects in Sweden9 , 10 and Finland11 is organized by the Dutch 'Biomass Technology Group (BTG)', to obtain more knowledge about the high potential of biomass gasification technology and the possibility to set up such plants in the Netherlands [36,37]. During the same period, Novem publishes a report that demonstrates that biomass gasification of energy crops like poplar and miscanthus for electricity production can also be quite profitable, which has put biomass gasification on the political agenda. The report states that electricity production is preferred to biofuels' production from conventional agricultural crops [31]. This major impact report shifts the current guidance of the search away from the use of biomass for automotive fuels towards the use of biomass for electricity by means of gasification (F4). This report triggers more research; desktop studies show that biomass gasification has a higher energy efficiency than biomass combustion (37-40% vs 25-30%) and that production costs can be reduced by using biomass waste streams instead of energy crops [6,35,[38][39][40][41] (F2). Due to these positive characteristics, the sustainable energy sector expresses high expectations of biomass gasification [42][43][44][45] (F4). In addition the EU 'Thermie' program 12 is started and several projects receive financial support from it (e.g. Zeltweg, Austria; Lathi, Finland; Amer-plant, The Netherlands; Arbre-project, UK) [15]. Also, Shell shows interest and invests in a biomass gasification project in Brazil; however the project is not realized [32]. As a result, and in a very short time, biomass gasification is considered to be equally useful as other competing renewable energy technologies, as the following quote shows: The contribution of biomass to the energy supply is gaining more and more importance. The most realistic routes that can be used for the production of electricity are either gasification or cocombustion of biomass in existing installations (EPON-project), combined-heat-and-power (CHP) application and the conversion of biomass into biogas. [46] The high expectations of biomass gasification in this period are also reflected in the short development time that is expected for commercialization of the technology, and in the plans to invest in technology development. Braber et al. [47] state the following: In the coming years, more emphasis will be put on gasification, since this technology has the potential to be cost-effective and to convert waste and biomass with a high energy efficiency. Lots of efforts are expected to be necessary to achieve these expectations, since in 2000 it will be evaluated whether gasification can be implemented on a large scale. [47] Knowledge development indeed picks up. Studies are carried out (F2), which show that wet biomass (organic waste, sludge, etc.), only thought to be suitable for digestion or fermentation, can also be used for gasification, providing additional biomass resources for gasification and higher energy output than for digestion [6,48] (F6). In addition, technological problems are not considered to be a major obstacle, as the next fragment shows: The gasification of organic household waste is researched by the Department of Science, Technology and Society at Utrecht University. Since no compost is being produced during gasification and due to its lower conversion costs, this conversion system has chances to become a realistic option. The practical problems, cleaning the syn-gas from alkali-and heavy metals, do not form any unsolvable problems. [41] These expectations result in a specific research program, the 'National Biomass Gasification Research Program 13 ' by Novem, aiming to demonstrate biomass gasification technology in a number of projects. These projects not only lead to knowledge development (F2) and more financial resources (F6), but also guide the search by highlighting the importance of this technology (F4). The aim of the program is the following: Special emphasis will be put on the set up of a circulating fluidized bed gasifier for the gasification of biomass waste. The aim is to demonstrate the techno-economic feasibility and to provide long-term perspectives for this technology on the large-scale conversion of waste and biomass. [47] To recapitulate, positive results from abroad and a high impact study (Novem) puts biomass gasification on the agenda and quickly results in the rise of expectations for biomass gasification in the early 1990s. This, in turn, triggers a series of activities that can be classified as Knowledge Development, Guidance of the Search, and Mobilization of Resources. The rise of a virtuous cycle is observed, since positive results from research (F2) result in high expectations of biomass gasification (F4), which, in turn, result in the set up of research programs in the context of which demonstration projects are set up (F2, F6). However, not all System Functions in the Biomass Gasification Innovation System receive attention in that first period. In addition, there are several critical voices that warn against following the hype without first solving technical problems and obtaining consistent support from the government. One of the leading figures in this field expresses it as follows: There is no clear-cut national program about biomass in the Netherlands. Some projects are being prepared, but mainly for the co-combustion of biomass in coal plants. [49] An additional problem is the lack of market formation (F5) by the Dutch government. To attract more research funds (F6) and to get entrepreneurs interested (F1), a clear vision of the future market for these types of technologies is necessary. At this time, there are no subsidies, feed-in tariffs, or launching customer activities of the government. A spokesperson from an energy distribution company states the following: There are possibilities to set up gasification plants in the Netherlands, since there is enough hay and verge grass that could be used as short-term options. However, who is going to pay for it? [50] Finally, there are some critical voices that warn against rushing the set up of large-scale plants (due to high expectations and promises (F4) and ignoring technical problems), as long as the technology has not been proven, as expressed by Mr. Smakman, project leader of the EWAB program [50,51]. \u2026 A long-term development is needed before gasification will be established in the Netherlands and the future of gasification is difficult to predict, since there is no experience and expertise in the Netherlands for this technology. Additionally, practice is unmanageable, so the new technology has to be 'proven' first, before it will be accepted. [50] In this period, two projects aiming to realize large-scale application of biomass gasification dominate the dynamics of the Biomass Gasification Innovation System. Both projects receive much attention in the Dutch energy system and they trigger many other processes in the IS, as we will see in the following paragraphs.",
            "The ups and downs of the North-Holland project": " In 1993, the Province of North-Holland, the coordinator of the national energy companies, SEP, 14 several energy companies, UNA and PEN, and researchers from ECN 15 design plans for the first largescale gasification project in the Netherlands (F1, Entrepreneurial Activity) [52][53][54]. Several feasibility studies are carried out over the years to assess the location, scale, and biomass streams [54][55][56][57][58] (F2, Knowledge Creation). At the end of 1994, the pre-studies are completed and the decision is taken to gasify waste wood, thinning and other residues in a 30 MW installation linked to a combined heat and power (CHP) system in the region of North-Holland. The expectations are high and it is predicted that the plant will be constructed at the beginning of 1998, run for a few years on trial and subsequently be sold to a user, for example UNA [55]. During the project, several established actors in the Dutch energy system express their serious interest in this technology, which results in an advocacy coalition formation (F7). This, in turn, leads to a mobilization of resources (F6) (1.5 million EUR for the complete project) and more research to reduce the initial technical and economic uncertainties (F2). The entire initiative can be regarded as the creation of a niche market for gasification technology (F5), since the national governmentbacked up by the consortium of private parties involvedindirectly stimulates the potential returns by encouraging provinces to incorporate renewable energy into their energy mix [34]. The first phase of the North-Holland project therefore boosts several functions in the Biomass Gasification Innovation System. Negotiations continue until 1997. However, one year before the construction is supposed to start, experiments demonstrate that the economics of the project are disappointing, in contrast with previously favorable outlooks, and that the North-Holland project is not economically profitable [21,59]. In addition, there are uncertainties about the wood delivery. No suitable wood delivering company is found that provides long-term contracts (10 years), due to the uncertainty of wood prices [34] (Lack of resources (F6)). In addition, the pre-building time span stretches in such a way, that the liberalization of the energy market starts to interfere with the project plans. This national liberalization movement (which started in 1998 for the entire electricity sector) turns out to have dramatic consequences for this project, one of which is the growing fear that the SEP agency, one of the project partners, will be discontinued [34,60]. Furthermore, energy companies become reluctant to invest in high-risk projects. The fact that biomass gasification is an unproven technology results in insurmountable technological uncertainties. Therefore, the guidance of the search quickly shifts away from emerging energy technologies such as gasification (F4) [34,60]. The delays for realization of biomass units is not only due to technical aspects, but due to the energy world that is reluctant to take high risks in the continuously proceeding liberalization and due to the reduction of oil prices. Expensive and risky projects are not realized without problems by the free market anymore. [61] 14 From 1948 until 1998, the 'SEP' was the coordinator of the national energy companies. 15 ECN is the Energy research Centre of the Netherlands; From 1994 ECN carries out several feasibility studies, among others for the North-Holland project, on various biomass streams (organic waste, wood, paper, etc.) and on the economical and technical potential of integration of a gasifier and a gas turbine. In 1996 a circulating fluidized bed, BIVKIN, is set up, with the aim to collect information about the gasification process and properties of different biomass streams. In a short period of time the gasifier becomes a reliable installation due to the collaboration of ECN, Stork, HoSt, Afvalzorg and Novem. In 1999 the gasifier is equipped with a gas cleaner developed by HoSt and plans are made to apply the technology commercially [57]. Finally, the Province of North-Holland and the energy company ENW (successor of PEN) decide to abort their ambitious gasification project in 1998 [62][63][64]. The final decision is caused by a build-up of disappointments in the technology and growing disagreement between the parties involved with respect to various technical and economical aspects, i.e. the unreliability of the technology, high costs and high risks [60].",
            "The tedious trajectory of the Amer-plant": " The second large-scale project is started in 1996, three years after the initiation of the North-Holland project, by a consortium of PNEM, 16 NUON, 17 EPZ 21 and BFI 18 (F1). The size of the plant is planned to be 30 MW with an atmospheric circulating fluidized bed (ACFB) gasifier for co-firing, where the combustible gas from the gasifier will be co-combusted in the nearby coal-fired power plant 'Amer-plant', operating with a CHP-unit, delivering 600 MWe of electrical power as well as up to 350 MWth of district heating [65][66][67][68][69]. Once again, the expectations are high. It is promised that the plant will be operational in 1998, as shown by the following quote (F4) [68]: This plant will convert construction-and demolition wood into combustible gas, which can be cocombusted in the Amer-plant. There are several advantages of wood gasification: 46.000 ton coal will be saved, 115.000 ton CO 2 emission reductions will be achieved and 100.000 ton less wood waste will be dumped. From a feasibility study it is evident that such a plant will be profitable. If the construction starts by the end of 1996, then the plant will be operational in 1998. [68] However, shortly after, the consortium aborts the project because the use of waste wood proofs to be economically unfeasible for this application (F6). It turns out that it is more profitable to export the cleaned demolition wood to Sweden, than to use it for biomass gasification in the Amer-plant. This results in a lack of biomass resources to run the plant [70]. However, expectations of biomass gasification technology are still high and in 1997, EPZ restarts this project. This time, however, with a different wood delivery company [71]. The preparations pass off quickly and plans are that the plant will be operational in two and a half years: The plans for constructing a wood gasification plant on the site of the Amer-plant in Geertruidenberg by the electricity company EPZ is in an advanced stage. (\u2026) The internal publication of EPZ writes that 'this is about a world premier'. The technology is new and has not been applied on commercial scale in combination with an electricity plant. [71] In 1998, subsidies are received from the European Union (F6) (Thermie program, 5 Mio. EUR) and the Dutch government (CO 2 -emission reduction plan, 6 Mio. EUR) and in 1999 the construction of the gasification plant enters the last phase; it should be finished by the end of the year [71][72][73]. In 2000, the construction is completed and the installation should be operational. The project receives much exposure in the (renewable) energy system of the Netherlands, as shown in the following quote: There are high expectations for the Amer-plant, where the gasified biomass is blown into the nearby coal plant. This project is just starting and any positive experiences could mean the long awaited breakthrough. [74] 16 Dutch energy companies. 17 NUON and EPZ are energy production companies. 18 Waste processing company now called SITA. However, positive experiences fail to occur. Technical problems hamper a smooth running of the gasifier, making modifications necessary. The major problems are the gas cooling (from 900 \u00b0C to 220 \u00b0C) and gas cleaning, since the contractor, Lurgi, 19 has no experience with waste wood, but only with coal. The behavior of the waste wood ash is different, clogging up the exhaust and causing congestion [15,69]. In 2001, a temporary modification is carried out, marking a second phase of operation, in which numerous othermore structuralmodifications are carried out. Both the gas cleaner and gas cooler are rebuilt to accommodate the properties of the ashes. Finally, in 2003, the plant is operational nearly fulltime, as most of the problemsespecially the gas cooling problemhave been solved due to the modifications [75]. From 2004 onwards, the contract with Lurgi is discontinued and Essent takes over the maintenance and operation of the gasification unit, since enough knowledge and experience (F2) have been built up over the years. Finally, on the 1st of September 2005, after seven wearisome years (during which only few kilowatt-hours have been produced), the modifications of the plant are finalized [75]. The story of the Amer-plant shows that the high expectations of biomass gasification were just too optimistic. Note that in 1992, the gas-cleaning problem was considered to be a technical problem, which could easily be resolved. However, it turned out to be one of the main problems, postponing a smooth functioning of the Amer-plant for 7 years. Part of the reason for this problem is that the contractor did not have the necessary experience and expertise to foresee and resolve technical problems that would occur during biomass gasification. These problems might have been avoided if an experienced contractor would have been involved.",
            "The breakdown of expectations": " Now that we have described two projects more in detail, we will return to describing the developments at system level. In 1998, the energy market is liberalized and the waste market deregulated. Despite the high expectations in the previous period, biomass gasification failed to prove itself as a reliable, economically attractive, and efficient technology. The North-Holland project is aborted in this year and it is still unclear how the Amer-plant will turn out to perform. The choice of the main industrial parties in the liberalized market is not to use biomass gasification technology: Energy companies have not embraced biomass gasification yet; partly it is still in demonstration phase and not a proven technology yet [\u2026]. Furthermore, the liberalization of the energy market makes energy companies reluctant to take risks. Companies prefer proven technologies rather than doing innovative things. [76] As a result, hardly any research and development on biomass gasification for electricity production occurs in the following 2 years (F2). The hype of gasification clearly ends here (F4) [72]. In 2000, the government antagonizes all further developments related to biomass gasification, by formulating a strict emission regime based on current coal combustion plants. The few initiatives for smallscale biomass gasification plants 20 are immediately unprofitable under the new rules, since now additional gas cleaning is needed to comply with these rules (F4) [77]. As a consequence, no further research and exploration activities are carried out (F2), bringing the development of biomass gasification for electricity production to a halt. In this period, a vicious cycle becomes dominant, since there is no guidance of the search (F4), resulting in a lack of demand and expectations (F4), causing no more research to be funded (F5) and carried out (F2).",
            "Revival of biomass gasification?": " However, in the period 2002-2004, a revival of biomass gasification seems to occur. The drive for this revival comes from a different direction. The European Union stimulates its member states to substitute part of the fossil-based automotive fuels by biofuels. In the Netherlands, so-called 'second generation' (2G) biofuelspartly based on gasification technologyare preferred to the so-called 'first generation' (1G), which can be associated with conventional technologies [78,79]. This results in publicly financed research programsmost notably the GAVE platformto develop the conversion technologies necessary for the production of these fuels, e.g. most notably the NECST/NEO program in 2001 and the GAVE subsidy programs in 2001 and 2002 (F2, F4) [80,81]. From 2001 on, a large number of entrepreneurs and research institutes -Shell, ECN, etc.conduct fruitful R&D on gasification processes for the production of Fischer-Tropsch Diesel and hydrogen. As a consequence, this period is characterized by many renewed guidance activities on behalf of the national government (F4) and R&D activities by entrepreneurs and researchers (F2) [82]. The chances for a large-scale application of biomass in the Netherlands are high. Also the use of biomass for biofuel production is expected to increase to 10% in Europe, this could be achieved from linseed or rapeseed or by gasification of biomass. [83] However, when the pressure of the EU to comply with the biofuels directive increases in 2003-2004, the 2G biofuels technology is still not ready for market introduction. As a result, the support for the 2G biofuel trajectory shifts to the background as the conventional fuels become more popular [84]. Finally, history seems to repeat itself as technological optimism turns into disappointment within a very short period of time.",
            "Functional pattern": " In this section, the functional patterns are described by using graphical representations; the number of events per function per year is plotted over time. The patterns observed are explained by referring to specific events within the storyline, as given above. All figures show a remarkable absence of activity before the 1990s (see Figs. 2-6). In the 1990s things change; the main driving force within the Biomass Gasification Innovation System now is the search for alternative energy technologies to replace fossil fuels. As a result, several research programs are set up to assess the application of gasification technology for energy production (F4, see Fig. 5 peak in 1992). Experimentation and research provide positive results (F2, see increase in knowledge development activities from 1991 to 1998 in Fig. 3). Expectations grow as biomass gasification is increasingly mentioned as the solution to a sustainable energy production (F4, see Fig. 5 peak in 1995 and 1997-1998). This sequence of events corresponds with a positive interaction between the System Functions: the more research is done (F2, Fig. 3), the more positive results are obtained and publicized (F3, Fig. 4), the    more resources are allocated to the technology (F6, Fig. 6), ensuring further development of biomass gasification (F2, Fig. 3). This, in turn, stimulates entrepreneurs to take their chances and set up two largescale plants for biomass gasification (F1, Fig. 2, the two large-scale projects are marked within the graph). Throughout those years, other small-scale plants are set up as well (F1, Fig. 2, peak in 1998). Thus, between 1992 and 1998, different System Functions are fulfilled, driven by high expectations. A pattern of function reinforcement emerges, resulting in the build-up of a virtuous cycle. However, in this period (1992-1998), actors of the Biomass Gasification Innovation System express their disappointment and reveal system flaws (see Fig. 7 and the quotes in the gasification storyline). This shows a lack of activities, resulting in some functions to be hardly or negatively fulfilled. For example, actors express their disappointment; their main concern is the fact that the national government does not provide uniform, consistent, and long-term regulations throughout the years (see Fig. 7, negative opinions about the system). In this figure, the actors' opinions are counted over the years; the representation shows that there are more negative opinions about the system than positive ones (only one in 2002). Thus, we see that the technology itself is perceived as positive, but the Innovation System is criticized heavily. In addition, some actors are skeptical about the hype around biomass gasification technology; they warn entrepreneurs not to be carried away without proving the technology first (see Fig. 7, negative opinions about biomass (BM) gasification). In retrospect, these voices seem to have made an accurate analysis. Furthermore, there are expressions about the lack of resources (see Fig. 6 negative line) and the lack of support from advocacy coalitions (F7, no graphical representation due to lack of data). Nonetheless, in the period of 1992-1998, it seems that these negative or lacking functions are outweighed by the positive build-up of activities, due to the hype and high expectations that dominate that period. However, as the energy market is liberalized in 1998, the high expectations are shattered quickly. Unsolved technical problems and a poor economic performance ensure that biomass gasification is not ready for introduction in a turbulent market environment. This results in the discontinuation of the North-Holland project (Fig. 2, see markings in the graph) and the closure of several other small-scale plants that had been set up in previous years (Fig. 2, see negative peak of projects aborted in 1998). In addition, most of the other activities in the Innovation System are discontinued as well; entrepreneurs and energy companies are reluctant to take high risks within the context of a liberalized market. No more research and studies are carried out (Fig. 3, drop of positive line after 1998), allocation of resources (F6, see Fig. 6, drastic drop of positive line in 1998) and specific guidance (F4, Fig. 5, drop after 199) for biomass gasification are discontinued. In addition stricter emission regulations are introduced in 2000, which results in the shut down of several small-scale plants (see Fig. 2, negative line between 1999 and 2004 representing the shut-down of small-scale plants). Thus, the sequence of events after 1998 results in the collapse of the previous virtuous cycle. The revival around biofuels seems to bring biomass gasification technology back on the political agenda as a key technology for 2G fuels, however no increase of other activities occurs then. The critics on the IS remain highly negative, due to inconsistent government policy that did not manage to realize a breakthrough for the 2G biofuels (see Fig. 7 negative opinions about system).",
            "Conclusions": " Despite the promises of high-energy conversion efficiency and the wide variety of applications, biomass gasification has not been successfully developed and implemented in the Netherlands. We applied the Functions of Innovation Systems framework to obtain more insight in the dynamics of the Biomass Gasification Innovation System and the determining factors that induced or blocked the evolution of this new technology. The most important insights gained are highlighted below. The main inducement factors for the evolution of biomass gasificationin the period studiedare the high expectations and optimism about biomass gasification being an efficient and profitable energy production technology. This results in the initial hype where the build-up of the Biomass Gasification Innovation System becomes a reality; System Functions such as entrepreneurial activities, knowledge development, knowledge diffusion, guidance of the search and resource allocation mutually reinforce each other in this period. This virtuous cycle lasts for a period of 6 years (1992)(1993)(1994)(1995)(1996)(1997)(1998). One of the important blocking mechanisms arises when two drastic changes occur in the institutional system within which biomass gasification technology develops. Firstly, when the energy market is liberalized in 1998 and, secondly, the emission regulations are changed, biomass gasification technology has not booked enough positive results to be accepted as a proven technology. Many actors become reluctant to further support biomass gasification, which results in the abortion of various initiatives and activities. This is reflected in the decline of function fulfillment, i.e. no more entrepreneurial activities, decreasing knowledge development, no more specific positive guidance, and no more resources allocated to biomass gasification. The main blocking factorthroughout the entire periodis the absence of the national government with respect to a clear and consistent policy towards biomass gasification. Over the years, the opinions of actors within the biomass gasification innovation system show that there is an absence of available public resources, guidance, and other forms of support for biomass gasification. From our case it seems reasonable to assume that gasification technology still needed a protective environment to be able to further develop. Instead, the above-mentioned events forced the entrepreneurs to move to a free market environment and to either accept or completely reject the technology. When a new technology is served-off like this, two opposite conclusions can de drawn. The first is that the innovation system was successful in screening out unfit technologies and the second is that the innovation system did not function well enough to protect emerging technologies in the market environment. In this case, clearly the second conclusion needs to be drawn since for a technology to be declared incompatible, many experiments should be carried out first that show that the technical problems cannot be solved. In the Netherlands, though only one project was realized and after several years the technical problems were solved. For an emerging technology to have any impact, it normally has to go through a lengthy, uncertain and painful process of trial and error. However, in this case, only one project went through this process, all other projects were already dismissed before the first trial phase. Thus, the general conclusion that can be drawn from this, is that a structural misalignment occurred between the institutional framework within which the technology could have been developed, on the one hand, and the technical requirements on the other. Here, the government should have intervened by creating the right conditions for emerging technologies like biomass gasification, for instance by stimulating the System Functions. As a final point, the System Functions approach proved useful in ordering the large number of events that took place in this process of change and it allowed for a quantitative analysis that proved to be very useful in underpinning the empirical storyline. Usually, Innovation System studies look at the structure of the system and the diffusion of a technology is the performance indicator. However, in the case of emerging technology, no diffusion has taken place yet, thus other performance indicators are needed. By using the System Function approach we have identified what really happened within the system. This allowed us to identify the weak and strong points in this development and we were able to draw lessons from it. Also, the fact that we analyzed this wearisome story in terms of System Functions, will allow us to compare this case with more successful developments. In this way we can learn how functional patterns differ in troublesome and successful processes of technological change. This is crucial information when the aim of policymaking is to contribute to well functioning sustainable energy innovation systems."
        }
    },
    "10.1016/j.techfore.2013.08.036": {
        "file_name": "181 Heading towards a multimodal city of the future",
        "title": "Heading towards a multimodal city of the future? Multi-stakeholder scenarios for urban mobility",
        "abstract": "In redesigning city infrastructure to become sustainable and future-oriented, critical city subsystems, such as the urban mobility system, present a serious challenge. In order to avoid regime stalemates and path dependency, substantial changes to the urban mobility systems are required to limit economic, ecological, population and institutional constraints. We argue that the socio-technical system of multimodal mobility has the potential to solve some of today's urban mobility challenges. Multimodal mobility combines both private and public transport modes, thereby capitalizing on the benefits of various systems. Realizing that mobility systems are non-monolithic and transitions require interdisciplinary analyses, we adopt a multi-level perspective with actors across different fields. This paper aims to guide cities in developing a long-term future vision of urban mobility systems in Germany while drawing on considerations of transition theory. Our comprehensive approach, conceptualized through a strategic issue management framework, draws on empirical evidence from three parallel Delphi studies and several focus group workshops to present strategic implications to firms, public authorities, and customers. Among others, the strategy agenda for stakeholders must coordinate efforts to utilize system strengths, advance intelligent transport systems, diversify the portfolio of public and private financing, change business models, and create a renaissance of civil participation.\n",
        "label": "Mixed",
        "text": {
            "Introduction": " Urban areas are populated by over half the world's population and are anticipated to witness most of the population growth in the following forty years. By 2050, the population in urban areas is expected to increase by 2.6 billion to 6.3 billion people [1]. Until recently, the provision and organization of city subsystems was widely perceived to be a simple engineering and administrative issue [2]. However, the contemporary pressures faced by cities cannot be dealt with by the infrastructural systems and legacies often developed over the 20th century in many western contexts [3]. It is of the utmost importance for vital city subsystems, such as the transportation system, to function efficiently to support the future development of sustainable urban infrastructures [4, p. xvii]. Personal mobility is considered to fulfill a societal function [5]. In fact, urban mobility is one of the greatest challenges that cities currently face [6]. Individual mobility in urban areas is increasingly reaching its limits since progressive urbanization has caused continuous rising demand for the urban mobility systems [7,8]. By 2050, urban dwellers will spend an average of 106 h in traffic jams per year, three times more than today [6]. Hence, road networks are suffering from recurrent congestion, the accessibility of city centers is deteriorating, and the environmental impact is already considered to be too high E-mail addresses: alexander_spickermann@gmx.de (A. Spickermann), volker.grienitz@uni-siegen.de (V. Grienitz), heiko.vondergracht@ebs.edu (H.A. von der Gracht). 1 Tel.: +49 271 740 2520; fax: +49 271 740 12520. 2 Tel.: +49 611 7102 2100; fax: +49 611 7102 10 2199. [9][10][11]. In addition to these challenges, the changing urban mobility patterns of people, the related demographic changes, and the dwindling investment capacity of public authorities need to be considered. As a consequence, citizens, businesses, and governments are often dissatisfied with the state of urban mobility. Therefore, a way to modernize the current urban mobility systems has to be found, so that economic, environmental, and institutional constraints are limited and sustainable, and competitive city mobility subsystems are achieved to further improve personal mobility. Although technological advancements have decreased the impacts of individual journeys, they have often only provided temporary and partial solutions [12][13][14][15]. Therefore, it is improbable that such improvements alone can sustainably reduce the impact of transport. In fact, \"transitions do not come about easily, because existing regimes are characterized by lock-in and path dependence, and oriented towards incremental innovation along predictable trajectories\" [13, p. 495]. Therefore, responses to the current challenges for cities require more fundamental restructuring of the transportation system in the years to come [2,3,16]. Over the past 10 years, researchers have labeled these substantial system changes as 'socio-technical transition'. Such transition not only requires major changes in technology, but also organizational and structural changes for both supply and demand [e.g. 17]. One measure to deal with urban mobility constraints is to promote public transport. However, efforts to stimulate more frequent use of public transport have seldom been successful. It seems to be impossible to compete with individual motorized transport [18]. The socio-technical system of multimodal mobility, however, seems appropriate for solving some of today's mobility problems. The concept of multimodal mobility changes the view on the traditional strictly dichotomous choice between either private or public transport. Unlike unimodal transport, multimodal transport uses two or more transport services. Combining private and public transport modes offers the benefits of both systems while avoiding their weaknesses [19]. Current multimodal mobility concepts are fragmented since they were developed over different time periods by different actors [2,10]. Therefore, a comprehensive, wellplanned multimodal system is required. A socio-technical transition towards such a new, sustainable urban multimodal mobility system requires long-term orientation to successfully adapt and innovate business models and invest in appropriate resources [20,21]. Approaches deployed in foresight and futures research tend to be suitable for such a long-term transition process [16,22]. Thereby, previous experiences cannot be merely extrapolated into the future [23]. Instead, approaches that promote broad planning perspectives have to be incorporated [24]. Fundamental to such systemic transitions is the notion that mobility systems are non-monolithic and constitutes multiple relationships. Therefore, a large variety of stakeholders, representing diverse social interests, should be involved in planning activities from the onset [25,26], including businesses, political institutions, national governments, and households. Previous research on dynamic market systems has highlighted a variety of different participatory approaches that can be used to assess future activity: Delphi panels [27,28], scenario planning [29], stakeholder analysis [30], and participatory workshops [31,32]. Thus, effective coordination of these forms of analysis would enable successful transitions from current mobility systems to more advanced systems, by predicting numerous challenges for multiple actors. Strategic issue management (SIM) may support the conceptualization and research of such a socio-technical transition to a multimodal urban mobility system. Strategic issues are generally defined as events that would affect companies in the future [33]. Liebl and Schwarz [34] expanded upon this definition by stating the importance of novelty and adjustment that surround these particular events. Thereby, the integration of SIM and foresight methodology produces a holistic framework to contribute to the quality of long-term decision making quality [35,36]. In this paper, we contend that the limited amount of progress made thus far in enhancing the sustainability of urban mobility indicates the necessity to apply an interdisciplinary approach with multi-level involvement of actors and institutions across different scales [25,37]. We aim to provide insight into the dynamic interactions between stakeholders' actions and the resulting impact on system change. To reflect ongoing discussions and varying perspectives of stakeholders, the purpose of this paper is to develop partially-contradictory multi-stakeholder scenarios on the future of urban mobility in Germany. Inspired by future challenges for urban mobility and considerations of the socio-technical system theory, we develop a vision of urban mobility for the year 2030, based on desired parameters. Additionally, the paper aims to incorporate the various views of future images to study how urban mobility is likely to evolve in the long-term and shed light on the way the preferable future for 2030 can become reality [26], elaborating on managerial and governmental implications. In line with Wells and Nieuwenhuis [38, p. 3] we argue that \"transitions need to be managed or orchestrated rather than simply left to market forces.\" Thereby, we exemplify a scenario building approach using three parallel real-time Delphi surveys [39] for data generation, along with multiple focus group workshops. A time horizon until 2030 allows the assumption of trend reversals, whether with regards to the environment, technology, or behavior. The paper commences with a review of previous futureoriented urban mobility research and a discussion of sociotechnical transition theory and SIM. A structured research approach demonstrates how a combination of a SIM process and foresight methodologies can guide cities to achieve such transitions to sustainable urban multimodal mobility systems. Next, the results of three parallel Delphi studies are considered, which addressed scenario development from a multi-faceted perspective with more than 200 panelists. Based on normative scenarios, we elaborate on the results of focus group workshops to develop strategies and implement an action plan to make the aspired to urban mobility situation a reality in 2030. Our holistic approach involves all major stakeholder groups in the field of mobility services and supports strategic decision making while offering guidance for firms, public authorities, and customers in creating sustainable urban mobility in Germany. The paper concludes with recommendations for future research.",
            "The need for purposive urban mobility system transition": "",
            "Review of future-oriented urban mobility research": " Foresight activities are useful in identifying diverse future perspectives in order to better understand contrasting ideas and opinions [40]. Acting in dynamic environments requires a well-developed perception of the environment and its inherent societal challenges [41]. Monitoring trends and detecting weak signals in the business environment can better prepare stakeholders for the future while managing everyday business activity [42]. The future of urban mobility has been intensely debated over the past few years and various forms of foresight approaches have emerged in the field. A selection of relevant recent academic research on future-oriented urban mobility publications is presented in Table 1. Since current economic, ecological, population, and institutional circumstances compel companies, agencies, and governments to continuously deal with the future of the urban mobility systems, we did not limit the review to the academic discussion. In fact, we researched 49 reports, from which we derived clusters that included focal topics and overlaps of classification criteria. To visualize the semantic similarity, we applied multidimensional scaling (MDS) 3 [43][44][45]. The results are presented in Appendices A to C. Advancements in technology and innovation have been considered to be key success factors in meeting the challenges of urban passenger transport. Especially with regards to decreasing the environmental impact, the focus of previous works was placed on alternative drive technologies, including improved fuel efficiency, alternative fuels, and propulsion systems [e.g. [46][47][48][49]. In 2010, the German government launched the National Platform for Electric Mobility (NPE), which was designed to integrate environmental protection into industrial policies and propel Germany at the forefront of the electric mobility market. The initial plan was to have one million electric drive vehicles (EVs) registered in Germany by 2020, supported by approximately \u20ac1.5 billion in federal aid [50,51]. However, recent interim reports revealed significant challenges regarding non-monetary incentives for such measures and re-adjusted their initial target for EVs to 600,000 [51,52]. Moreover, such technological perspectives of urban mobility investigate the effectiveness of intelligent transport systems, information technology, and location-based services [e.g. 18,53,54]. Past research has shown that the quality of transport information affects customers' mode of transport choice [18]. In particular, information would be most valuable to the user if traveler data were integrated [82]. Thus, it is important that multimodal travelers are provided with information prior to and during a trip [18]. According to a study by Zografos et al. [83], frequent travelers, as well as older people, perceive the benefits of an integrated journey planning system to be more substantial than non-frequent and younger travelers. Previous works also modeled customer preferences for urban travelers. Thereby, some authors concluded that costs and personal mobility needs outrank environmental benefits [55][56][57]. However, Wegener [60] indicates that transport energy will no longer be abundant due to finite fossil fuel reserves, and that in order to accomplish greenhouse gas reduction targets, transport energy must become more expensive. Especially among young adults in Germany, travel trends show decreasing levels of car ownership and use, as well as disappearing gender differences [9]. Another research stream started to assess potential new business models for mobility providers and regarded such reorientation strategies as a key megatrend in the automotive industry [38,63]. Thereby, highly integrated strategies become increasingly important while greater public and private sector synergies need to be encouraged [15,68]. In fact, authors have determined that the types of value resulting from inter-firm relationships have changed over the years from operational performance improvements towards a stronger focus on integration-based values, such as improved collaboration and partnerships [84]. For instance, the growing importance of car-sharing is expected to support changes in mobility patterns [63][64][65]: Many experts believe that electric mobility will only be successful if suitable car-sharing models are created [e.g. 63,67]. In a study recently conducted by Sch\u00e4fers [85], more than half of the participating companies perceived it feasible to combine car-sharing with electric mobility in the future. Other research streams focus on modeling the effectiveness of incentives and regulation [e.g. 48,73,74], marketing [e.g. 77], and fare types in public transport [77,79,80]. Overall, previous publications primarily dealt with rather myopic views and did not adequately consider multistakeholder perspectives of corporations, public authorities, and customers. However, future mobility systems require comprehensive services for numerous stakeholders with diverse sets of target systems [e.g. 47,86]. Since a wide range of different stakeholders is seriously concerned with the urban challenges to come, collaborative countermeasures become inevitable [87,88]. To date, only few articles have addressed the topics of future mobility and relationship research. Although the decisive transformative influence of public authorities has been stressed [69][70][71], cross-sector synergies are rarely explicit, since the link between foresight planning activities and political decision making has often been neglected [89]. Moreover, although undeniably important, technological innovations have often only provided temporary and partial solutions [12][13][14][15]. Hence, the broader vision of the urban transport system tends to be neglected, in favor of focusing upon the various technological elements instead. Potter and Skinner [15] stressed the importance of developing holistic strategies that incorporate areas not traditionally associated with the transport planning process. In addition, the majority of identified publications analyzes how already prevalent structures may develop in the future but does not explicitly consider the opportunities for new business model innovations. Although numerous projects show different scenarios, such as car sharing [63][64][65] or new car concepts [66], they do not explicitly assess strategies for different stakeholder preferences, or limit their elaborations to innovative concepts for motorized private mobility with a unimodal transport consideration. Consequently, by considering a variety of established concepts in foresight, including the Delphi method and a series of multi-stakeholder focus group workshops, this research makes an initial attempt towards an integrated scenario analysis of the future of urban mobility, particularly considering the diversity of stakeholders and their different opinions involved in the transition process.",
            "Socio-technical transition, the MLP, and the conceptualization towards a multimodal system through SIM": " The review of recent literature revealed the shortcomings of addressing the system of urban mobility in a holistic manner to incorporate a diverse set of stakeholders. A multimodal mobility approach has the potential to guide sustainable transition and solve today's transportation problems [9,10]. Consequently, cities need to \"\u2026respond strategically to generic pressures by developing managed systemic change in the socio-technical organization of key aspects of their infrastructure\" [2, p. 479].  We will discuss how socio-technical transition theory and the conceptualization through a SIM process can support cities in developing sustainable urban multimodal mobility systems. Socio-technical transitions are characterized by significant technological advancements, market shifts, modified user practices, policy amendments, and alterations to cultural connotations [17]. To understand sustainable transitions, an interconnected three-level framework is offered by the multi-level perspective (MLP) [5,90]: \"\u2026 (it) provides an overall view of the multi-dimensional complexity of changes in socio-technical systems\" [13, p. 495]. (1) The regime level represents the established practices or institutions of a given system. Change occurs incrementally rather than radically. Technological innovations are filtered. (2) At the socio-technical niche level, experimentation and learning are encouraged. Radical innovations and novel technologies are developed and proliferated. Small networks comprise this area, which is largely protected from external influences. (3) The landscape level refers to the overall setting of tangible and intangible aspects. It creates the broader context in which actors and coalitions of actors operate, and applies pressure on existing regimes, leading to tensions and windows of opportunity. As proposed by MLP, transitions need to be managed in order to decrease the inherent uncertainty which goes along with change. Transitions involve regime shifts, where processes interact with each other at the regime level but also with other levels [13]. Socio-technical transitions typically evolve over long time spans and concern diverse stakeholders. Thereby, \"in the course of such a transition (radically) new products, services, business models and organizations emerge, partly complementing, partly substituting existing ones\" [16, p. 991]. SIM supports the conceptualization of a socio-technical transition to a multimodal system in urban mobility. Traditionally, SIM aims at detecting weak signals and upcoming strategic issues expected to affect organizations and their environments [33]. Dutton et al. [42,p. 308] defined a strategic issue \"as an emerging development which, in the judgment of some strategic decision makers, is likely to have a significant impact on the organization's present or future strategies.\" SIM is highly dynamic and continuous, allowing companies to instinctively react to a particular event, thus making them more tolerant of changing environments [91]. As an actively orchestrated process, SIM requires stakeholders within a system to adapt their strategies in order to ensure or improve the systems' sustainable performance. To analyze the complex multi-dimensional changes in socio-technical systems, we integrate the three analytical levels of MLP into the SIM process.",
            "Research approach and methodology": " Although various classifications for an SIM framework exist in literature [e.g.92], three generic phases have been identified to guide our conceptual framework (Fig. 1): (1) strategic issue orientation, (2) strategic issues assessment and (3) purposive strategy transition. Since strategic information is usually confidential in nature, it is necessary to consult a variety of sources in order to ensure reliable information [63]. Therefore, we considered a variety of established concepts in foresight, including three parallel Delphi surveys in real-time format [39,93] and a series of multi-stakeholder focus group workshops for data generation.",
            "Strategic issue orientation for urban mobility system transition": "",
            "Phase 1.1: Identification of strategic issues": " Previous research has emphasized the importance of the systematic identification of strategic issues for consideration in subsequent Delphi studies [94][95][96]. Therefore, we pursued a rigorous phase-based procedure to unravel a list of strategic issues considered to shape the future state of urban mobility. The process was facilitated by a core team of three senior researchers with several years of experience in urban mobility research, explicitly pertaining to the multi-level transition perspective (please refer to Fig. 2). To determine the various factors that are expected to influence the future of urban mobility, the environmental scanning approach comprised of several creative workshop sessions with the core research team in combination with searches of databases. Consequently, we compiled futureoriented urban mobility knowledge through searches of scientific databases (e.g. EBSCO, Emerald Insight, ScienceDirect, Datamonitor) as well as trend databases. 4 Furthermore, in order to cross-validate our initial set of influencing factors (i.e. issues), we consulted the representatives of the senior management of four German automobile manufacturing companies, two politicians, and five frequent urban commuters. This cross-validation of possible issues through the interaction of information-gathering methods ensured face and content validity. Overall, we compiled an initial set of 168 issues based on heterogeneous contributions. In a subsequent assessment of the core research team, the initial set of issues was narrowed to a list of 27 strategic issues with particular relevance to the topic. This scoping was done in an open discussion process, in which consensus for strategic issue selection was perceived as 100% agreement among the core team members. Thereby, particular attention was paid to avoiding similar issues under different labels.",
            "Phase 1.2: Prioritization of strategic issues": " Prior research on the design of Delphi surveys has demonstrated that response rates are lower and surveys are more often improperly completed, the more projections are included [97]. Therefore, our goal was to reduce the number of projections to an effective minimum. In order to comprehend the complex topic of the future urban mobility, the long list of 27 strategic issues was transferred into a cross-impact matrix 5 [98][99][100] to further prioritize them for inclusion in our scenario study. Cross-impact analysis (CIA) is based on the assumption that events are interrelated rather than independent [101]. The core team members individually prioritized the strategic issues based on their highest mutual impact. Subsequent scores of individual intensity of activity and interconnectedness were calculated, leading to a final prioritization of strategic issues. We selected the top 16 strategic issues for Delphi projection formulation, based on methodological practices of CIA research, 6 which was appraised by the researchers to represent a suitable time effort for panelists [102]. The insights from our MDS analysis on current governmental and agency reports (compare Section 2.1) further complemented the prioritization of strategic issues, which were broadly grouped into six dimensions: (1) technology and urban planning, (2) value orientation and consumption, (3) collaboration, (4) financing and capital, (5) market structure and competition, and (6) implementation lead.",
            "Phase 1.3: Development of future projections": " In a next step, we transformed the final set of 16 strategic issues into short, controversial Delphi projections for the year 2030. Since the formulation and development of Delphi projections influences the reliability and validity of the obtained data significantly [95,102,103], we deliberately followed methodological rules [e.g. 104]: among others concerning nonambiguity, exclusion of conditional statements, explanation of scientific or technological terms [103,105], balance of conciseness and length [106,107], and optimal processing time reflected in length of the survey [97,108]. In order to ensure clarity in the formulation and improve ambiguous statements, cognitive interviews were held with respondents from the sample population [104,109]. Based on the results of these qualitative pre-tests, minor modifications were made. The final set of Delphi projections on the future of urban mobility is presented in Table 2.",
            "Strategic issue assessment through parallel Delphi studies": " Delphi surveys were conducted in order to obtain expertbased assessments of the strategic issue-based projections' probability of occurrence and desirability. Thereby, we objectified the process to evaluate strategic issues.",
            "Phase 2.1: Concurrently performed Delphi studies": " The underlying principle of the Delphi method is that group-based forecasts are considered to be more accurate, compared against those made by an individual. The method surveys experts and efficiently applies a structured dynamic group communication process to explore and interpret data, thereby avoiding negative effects such as the halo or bandwagon effect [27,110,111]. Gnatzy et al. [39] complemented the work of Gordon and Pease [93] by introducing an online Delphi survey, which provides participants feedback in real time. We applied this method to our research in order to simplify the survey process and improve the validity of the data collected by reducing the effects of panel mortality and research fatigue [112,113]. Our study combines insights from three parallel Delphi studies based on diverse target systems to multi-stakeholder scenarios. By consistently applying the same 4 We placed explicit attention to trend spotting and searched various trend databases for future-relevant knowledge concerning the focal topic of multimodal urban mobility: e.g. iKnow, Shaping Tomorrow, TechCast, TrendONE, TrendWiki, and Trendwatching. 5 Cross-impact analysis is an analytical tool for assessing and mapping relationships and interactions between system components. The analysis is performed by means of a cross-correlation matrix. We applied the software CIM 8.1. The program is able to process 8 to 30 components. 6 The threshold for final inclusion of strategic issues was defined by: (1) the highest level of individual intensity of activity and interconnectedness scores (sum of total active and total passive scores), (2) at least one of the total active or total passive scores was above 26 (accounting for half of the maximum number of individual intensity of activity and interconnectedness scores). Delphi format, we ensured standardization and homogeneity of the studies and a high level of comparability. Each projection in the Delphi studies was assessed according to its expected probability (EP) and desirability (D), and arguments could be given to justify these assessments.",
            "Database": " In order to ensure the reliability of research results, it is essential to identify and select the appropriate experts to participate in a Delphi survey [114]. Previous researchers have explicitly emphasized integrating a diverse set of viewpoints in scenario development to prevent misleading consensus of similarly oriented stakeholder opinion [115,116]. We reason that involving groups of individuals with different functional and cognitive backgrounds in evaluating strategic issues could be a way to increase ambivalence in perceptions about strategic issues. Thereby, in addition to representatives from industry and public authorities, we purposely included customers in the panels because they are mostly affected by socio-technical changes to urban mobility. In total, we identified and contacted 721 designated subject matter experts in Germany, distributed among a multitude of 12 stakeholder subgroups. Following suggestions of prior researchers [117], we thereby incorporated both easy-to-observe surface-level panel selection criteria and value characteristics as deep-level diversity dimensions. In particular, criteria in selecting panel members included type of organization, current job position and profile (particularly decision makers with foresight capabilities, such as board members, strategists, analysts, business developers, governors, and ministers), education or academic title, publications, speeches, and recommendations by peers. The final Delphi sample consisted of 201 panelists (76 industry experts, 68 public authorities, and 57 customers), accounting for a diverse set of interests (Table 3). The overall response rate of 27.9% is sufficient for this type of survey and analysis since Delphi surveys do not aim for representativeness, rather a high degree of expertise and heterogeneous viewpoints [117][118][119]. The satisfactory response rate also reflects the urgency and interest in the topic, as well as the success of personal recruitment of panelists via telephone. In order to evaluate non-response bias, we separated participants into early respondent and late respondent groups. Late respondents were considered to characterize nonrespondents [120,121]. Upon introduction of a Mann-Whitney test to the data, no statistically significant discrepancies were  observed among early and late respondents. On this basis, we deduce that the study does not exhibit non-response bias.",
            "Phase 2.2: Multi-stakeholder scenario development": " The results of the Delphi surveys formed the basis for the multi-stakeholder scenario development process and adjacent stakeholder strategy development. For the identification of relevant scenario content, a consensus analysis of each dimension was conducted. Thereby, a variety of analytical methods guided the development of multi-stakeholder scenario development (Fig. 3). The results of our inter-Delphi study analysis provided the basis for our scenario levels three and two: the overall basis scenario (level 3) includes those projections where the inter-Delphi analysis results in consensus for each stakeholder group involved; level 2 demonstrates consensus among two of the three stakeholder groups involved. Overall, for inclusion of Delphi projections in the respective scenario levels, we determined that Delphi study results should show an (1) equal and (2) clear tendency in mean values on EP and D. To test for significant differences among the three Delphi panels, we conducted group comparisons among the panels based on the dependent variables of EP and D for our 16 projections. We tested for inter-group consensus in all three Delphi panels which could be achieved through any of the following three criteria: (3a) A satisfactory interquartile range (IQR), whereby we defined consensus by an IQR of not larger than 1.00 for D and 25 for EP [122,123]. (3b) Given that cognitive bias has been said to cloud human reasoning regarding probabilities of occurrence, we considered consensus based on the desirability bias [124]. In comparison to projections with neutral desirability, desirability bias has caused participants in previous Delphi surveys to judge probabilities of occurrence as higher if desirability is high and as lower if desirability is low. Consequently, some projections could have been assessed to be more likely (or unlikely) because experts consider their occurrence to be desirable (or undesirable). (3c) Finally, the Kolmogorov-Smirnov test revealed that our score distribution significantly differed from normal distribution. Therefore, we applied nonparametric tests during our analysis. The Mann-Whitney U test was used to control for significant differences of the three major stakeholder groups. For those projections that did not achieve inter-Delphi survey consensus during the previous analyses, an intra-Delphi analysis provided additional insights in the stakeholder scenarios. The projections with intra-group consensus were assigned to the respective stakeholder scenario in level 1. As a final scenario level, a subgroup comparison was conducted for those projections that could not be allocated up to this point (level 0). Furthermore, the participants' arguments (3492 in total) guided the allocation of projections in the respective multi-stakeholder scenario levels.",
            "Phase 3.1: Purposive transition strategies: a participatory multi-stakeholder workshop approach": " Based on earlier strategic issue assessments, we conducted a series of three focus group workshops to elaborate on appropriate strategies for the three stakeholder groups (industry, public authorities, and customers). The workshops with a total of 39 participants, who also participated in the Delphi surveys, were conducted in order to discuss recommendations for stakeholder strategies on the transition paths. Thereby, the discussions aimed at gaining insights in the different stakeholder objectives. The focus group method was chosen because it facilitates a small group of individuals to intensely investigate topics [125]. We restricted our focus groups to a maximum of 15 people to keep the group manageable [126]. Participants were selected based upon their positions in the organization and their high degree of commitment to the Delphi survey (according to number and length of written arguments). The core research team of three senior researchers guided the conversation. The workshop discussions were based on previously identified dissent topics from approximately 3500 Delphi arguments (1322 arguments stemming from industry; 1246 arguments provided by public authorities; and 924 arguments stated by customers). In order to induce honest and detailed responses, specific questioning techniques were used by the moderators. In addition, various respondent reactions were prompted by considering different aspects of an issue and clarifying or amplifying where necessary. However, the moderators also ensured that the discussion was spontaneous and natural in order to promote comments and ideas unexpected or unimagined by the researchers. As a result, we were able to determine a path towards sustainable urban mobility scenarios in Germany for the year 2030 while identifying implications, capabilities required, and business opportunities for involved stakeholders.",
            "Multi-stakeholder perspectives on the future of city mobility": " Invited experts were asked to assess the desirability (D) and probability of occurrence (EP) of the projections on the future of urban mobility, and to provide reasons for all answers. The qualitative arguments were generated from the expert panel discussions and were used to enrich the scenario formulation and to identify influencing factors. The outlined methodological approach enables stakeholders to address multifaceted challenges of multimodal transport systems, analyze opportunities, and provide a more precise understanding of conditions required to implement such a system. Formulating scenarios presents an alternative to linear extrapolations. Due to the considerable amount of changes expected for a wide range of different stakeholders, we conducted a multi-stakeholder analysis on the future of urban mobility.",
            "Aggregated results for scenario development": " Table 4 provides an overview of the quantitative results of our three Delphi studies, whereas Table 5 shows the summary of projection allocation based on stakeholder consensus. Based on the criteria framework for our multi-stakeholder scenario development outlined in Section 3.2.2, consensus was achieved for certain projections of the desirability dimension. Eight projections, in which consensus was achieved for all three panels, account for the basis level of the desirable scenario development [TP1, TP3, TP4, VC1, VC3, CO1-2, MC2) since dissent discussion did hardly occur between the stakeholder groups. With regards to level 2, we allocated projection FC2 to consensus among industry representatives and public authorities, while projections TP2 and IL account for consensus among public authorities and customers. Since these evaluations indicate significant differences in some cases among the three stakeholder groups, we tested for intra-group consensus (levels 1 and 0). Since projections FC1 and IL3 account for intra-group consensus, some projections only result in subgroup consensus. In three cases, dissent remained and could not even be resolved by a subgroup analysis. Drawing on the results of the probability dimension, the average results are marked by considerable dissent among the panelists. Consensus for all three panels was achieved for only three projections [TP1, VC1, CO1] while seven projections were allocated to scenario level 2 [MC1, MC2, TP4, CO2, IL1-3]. Resulting projections were checked for intra-group consensus Notes: EP = Probability of occurrence (0-100%); D = Desirability (5 pt. Likert scale; 5 = very high); IQR = interquartile range; EP/IQR adj = calculated potential desirability bias; missing values for IL1, IL2, IL3 result from stakeholder-specific Delphi study design: for instance, industry experts were not requested to rate their own leading skills since we expected these ratings to be highly subjective. and in five cases, dissent could not be resolved by a subgroup analysis. In addition to the quantitative assessments, qualitative information was evaluated; this was derived from the written arguments that were given by panelists, concerning their opinions towards projection characteristics. In previous conventional Delphi studies, conclusions were primarily drawn from the quantitative assessments. However, in recent years the qualitative results have gained more credibility [127]. We aimed at identifying underlying assumptions of experts' ratings to explore not only what experts believe, but also why they do so. As we sought to formulate scenarios that necessitated ample contextual and argumentative information, qualitative analysis was essential. Thereby, we gained insights as to which factors will advance and influence the future of urban mobility. The panel discussions were comprehensive and intense, which corresponds to the complexity of the topic. Therefore, quantitative assessment alone would not have been sufficient to understand all ambiguities.",
            "A desirable vision of urban mobility": " The vision of urban mobility describes a desired state for the year 2030, shared by a diverse set of stakeholders, to provide guidance and orientation to relevant actors [128]. In reference to Fig. 3, the overall basis scenario (level 3) constitutes the foundation of the desirable multi-stakeholder vision, indicating consensus on projections among the entire panel.",
            "City mobility 2030 is multimodal, driven by collaborations, and thereby efficient": " The basis scenario is derived from consensus among the 201 panelists, where a multimodal mobility system is most desirable [VC1]. In 2030, customers will use a variety of complementary mobility options, whereby the use of private motorized vehicles will be substituted by mobility services to a significant degree. Customers will appreciate multi-modal mobility solutions compared to motorized individual transport due to time savings [VC3]. Traditional business models will expand, providing integrated mobility services to customers. A comprehensive mobility platform will facilitate integrated route and tariff planning, efficient choices of service offerings, as well as secure payment processing from a single source [TP1]. Thereby, smartphones and other mobile devices will become the omniscient companion and enabler of multimodal city travel. In the ideal case, after registering, users will be able to personalize a multimodal mobility application according to their requirements. Thereafter, location-based information about next travel options will be received based on individual travel preferences, including integrated options for motorized individual transport, public transport, or sharing options (e.g. car sharing, rent a bicycle, or shared-ride). This information will be filtered according to price, comfort level, as well as travel time since latest real-time information on traffic conditions will be integrated. Simultaneously, the choice of the respective transport mode(s) can be reserved while receiving the electronic booking code. When entering the respective transport mode, the user will be automatically recognized via chip or code. At the end of his or her journeywith or without a combination of different modes-the payment processes will be handled automatically. At the end of the month, the customer will receive an overview of his or her mobility account, in which all trips are listed in detail. Thereby, individuality, transparency, and data security will remain in focus: For instance, different payment systems will be offered to customers (e.g. flat rate, prepaid) and applications will be expandable to provide information on charging conditions of electric vehicles or the location of the nearest charging station. The main prerequisite for successful future urban mobility will entail customer-oriented collaborations, comprising traditionally independent infrastructure subsystems and the public sector [CO1, CO2]. The multimodal mobility market will be controlled by corporations that provide and understand mobility as a service [MC2]. The mere production of infrastructure and transportation means will cumulatively play a minor role. Thereby, multi-modality will allow users a convenient, ecologically-friendly and resource-optimal locomotion, making it the most appealing and sustainable form of mobility [TP3]. Traffic problems will become a thing of the pastexisting resources and infrastructure will be deployed optimally in all respects [TP4].",
            "Perspectives on the probable future of urban mobility": " The outlined vision can only become a reality if it suits the determining factors and is attractive to the various stakeholder (levels) involved. The results of the main influencing factors for the probable futures showed a limited amount of overall consensus. However, since the analysis of qualitative arguments revealed that there are comprehensible explanations for both directions of future development in many of the presented topics, we derived clear indications of likely developments in the major fields. In fact, the main purpose of the exchange of arguments in a Delphi survey is to reduce the information asymmetry and to generate convergence or divergence in experts' assessments. Despite widespread dissent among experts, we clustered clear indications of likely developments of the socio-technical transition for urban mobility based on major strategic issue dimensions identified.",
            "Individualization of lifestyles and flexible access to multimodal services": " Lifestyles in the post-industrial society will be subject to more dynamic changes than ever before. The diversity of options in all areas of life will contribute to everyday life becoming increasingly complex. The focus will be on the need for individuality. Substantial evidence indicates that there will be the need for more flexible, individual mobility. According to our panelists, the emotional attachment to cars will dissolve in a large portion of the population. The analysis of projection VC2, reflecting mobility users' value orientation regarding the traditional ownership of transportation means, points to the importance of considering differing age groups during the establishment of urban mobility solutions. In particular, younger adults will no longer place mobility on the same level with car-mobility [VC2(YAD)]. More and more (young) people will consider their choice of transport more consciously and situational for many reasons. Among others, mobile, multifunctional and prestigious devices, such as smartphones, will play a major role for the generation of \"digital natives\". Thus, with the use of new technologies, time, attention, and budget are finite. With limited budgets, different desires have to be fulfilled and expensive items, such as cars, might lose their appeal. The car orientation, which developed for every age cohort over recent decades, will stagnate and is expected to decline in the future. However, since the majority of the panelists argue in favor of rationalizing mobility (i.e. paradigm shift) and expect modal choices to be made according to the situation, a number of retired persons regard private transportation as a status symbol even in the future that includes pride of ownership and fascinates [VC2(RET)]. Therefore, in view of continuing demographic changes, the expectations of retired persons have to be considered with particular attention. Against this background and in the light of rising costs of mobility and a more subdued economic outlook, urban mobility requirements will be increasingly pragmatic and often resolved via multimodal transportation [VC1]. Current borders between individual and collective mobility markets-partly supported technologically-will be overcome by 2030. The social movement will turn away from universally usable transportation means towards a flexibly applicable \"virtual fleet\" that combines various means of transportation. Thereby, features, such as convenience (e.g. ticketing, pricing, and mobility cards), ease of use, and constant transport availability, will be key enablers. The more intuitively people can use mobility services, the more likely that multimodal mobility behavior will become a routine (and used without \"thinking\"). Innovative sharing options, such as car-sharing or bikesharing, demonstrate exceptional future potential according to the Delphi panels. Thereby, the flexibility during the choice of individualized modes is expected to be more important than single technology solutions, such as the electric car. Moreover, experts expect demand responsive transport (DRT) to become increasingly prevalent in urban areas. DRT will provide shared-ride transportation according to passenger requirements in pick-up and drop-off locations. Hereby, advanced technology will be used to flexibly adapt routing and scheduling of small and medium-sized vehicles [78]. Overall, according to the survey panelists, users' modal choices will differ, depending on individual needs, personal budgets, available alternatives, and regulatory restrictions, such as low emission zones or access restrictions. In fact, there will also be future customer segments with distinct differentiation and individualization desires: customers who are willing to pay extra for safety, comfort, reliability, and swiftness.",
            "System strengths-multimodality as a collaborative measure": " The future of the urban mobility systems is expected to involve mobility clusters that can provide mobility services as a one-stop service. In line with previous research, our panelists valued customer-oriented collaboration as the basic condition for success [CO1]. It is apparent that a single company will not be able to satisfy the needs of all customers, given the complexity of the urban mobility systems. Demand for additional expertise, which in turn is present outside the traditional mobility domain will increase. Therefore, service companies and business clusters will dominate the market for multimodal mobility. Transversal \"mega-operations\" are expected to become mandatory and necessary for survival in the industry. In fact, collaborative urban measures need to be seen from an even broader perspective than ever before. Due to technological, political, and social dynamics, relevant and growing system interfaces will emerge. The surveyed experts expect a shift away from individual companies offering short-term, fragmented services to strategic partnerships offering longterm mobility. City subsystems, which were formerly largely unrelated, will converge and mobility, energy and telecommunications will interlink noticeably. Corporations will be able to offer triple-networked mobility with transport, energy, and communication services. In the long-run, these convergences will lead to the development of new market segments and an extension of the traditional mobility concept. Thereby, industry representatives and policy makers from the survey expect new players, especially in the area of information and communication technology (ICT), who were formerly inactive in the mobility domain, to increasingly access the mass market of mobility [MC1]. Some have already entered the market with innovative solutions (e.g. Google, Microsoft, and Apple). Given a comparable offer, long-term competition will depend on the quality of customer data and the depth of services. The surveyed industry representatives and public authorities expect car manufacturers to transform their business models to provide mobility services [MC2]. In addition to technical challenges, multimodal mobility will mainly be a question of marketing attractive offers. Thereby, marketing and technology are expected to be the core competencies of OEMs.",
            "Integrated multimodal travel information": " Modern data communication will provide unprecedented opportunities for networking in the area of mobility and will demonstrate the potential of collaborating measures between the transportation system and the ICT system. Since future urban mobility is expected to be the intelligent combination of all modes and offerings, it is conjectured that the quality of urban mobility systems that adopt a multimodal approach [TP1] will be increased through the supply of travel information. Nevertheless, there are considerable challenges involved in the integration of data derived from multiple stakeholders in the multimodal mobility domain for information and direction guidance. An interconnected trip planning system would be the most effective way to provide individualized information to multimodal travelers [TP1]. The advantage of such an integrated and comprehensive mobility platform is indisputable: consensus was achieved among all panelists and this projection had the highest mean EP estimate of the study. Customers of urban mobility systems are primarily concerned with how to travel from one location to the next: they will require a one-stop shop solution, a synergetic overall system covering all phases of the trip through a single source. A satisfactory solution has to consider all alternatives and adapt to personal user preferences concerning time, costs, and number of hops on a trip [VC3]. Moreover, transport uncertainties, for example due to unexpected transport disruptions, could be mitigated by sending personalized realtime information to the traveler via various means of communication (e.g. text messages, email, or other smartphone applications). From a customer perspective, this kind of comprehensive platform would offer one single Graphical User Interface (GUI), which is fed by different individual solutions based on the one-face-to-the-customer principle. A promising interconnected multimodal mobility platform has already been set up by a European Commission-funded project called WISETRIP. 7 Thereby, multimodal trip information is sourced from a diverse set of journey planners to provide a user-friendly communication interface. It combines multilevel information and delivers dynamic personalized data by linking and cooperating with various sources of journey planning engines. Travelers will be able to easily request information, regardless of place and time, and receive various solutions for their trip. Further developments need to consider real-time events affecting trip performance (e.g. traffic, accidents, and weather conditions) as well as mobile and social media extensions [129]. To individualize information even further, experts expect a personal mobility assistant to be available on customers' smartphones. This application would update the traffic situation and gradually learn customers' personal mobility habits, such as their usual travel times, frequent trip destinations, preferred means of transport. An increased willingness of customers to disclose personal information is therefore required to offer cumulative individualized service offerings. The transition towards future urban mobility will be driven by those who accept such personal information being used for mobility purposes-the so-called digital natives. Our Delphi foresight project participants regard themselves as being spearheads for the mobility transformation to multimodal systems. These individuals will trigger a paradigm shift in information: Rather than information being \"pulled\" by the customer to actively obtain travel guidance, information will be \"pushed\" or sent to the customer based on the stored mobility profile. By 2030, the integration of travel information will be advanced significantly through intelligent transport systems and smart vehicles. However, complete connectivity and intelligent traffic solutions will remain a vision well beyond 2030. Panel experts indicated that there will be an expected trade-off between customer convenience and company access to personal information [TP2].",
            "Multimodal transport initiation through private sector leadership": " The current economic situation in Germany is considerably better than in other parts of Europe. For 2012, a record amount of tax revenue is expected. Nevertheless, aspirations to reduce long-term national debt remain. The combined debt of federal, state, and local budgets in 2010 amounted to a record \u20ac2 trillion, the per capita debt to almost \u20ac25,000 and the debt ratio (i.e. the amount of public debt to GDP) amounted to just over 80% [130,131]. Accordingly, by 2030, measures for fiscal debt reduction are expected to still be in place. In addition to these known and quantifiable risks, there are uncertainties about the impacts of the financial commitment to the European Union. Over the next years, EU payments for transport infrastructure and public transport services will be due. For instance, by 2014, the revision of the regionalization of federal funds for urban rail transport will have to be paid. Moreover, legislation has decided that federal government financial support of transport infrastructure in federal states shall terminate after 2019 [132]. As a consequence, the complexity of a future multimodal transport chain can (and will) not be handled by general governments independently. Increasingly, the focus will be placed on private sector leadership to design efficient multimodal mobility concepts that promise optimal operational success [IL1]. The public sector will control regulatory actions and will primarily moderate tasks and provide resources [IL2]. An adequate supply of public transport will have to be financed with less public and more private funding in the future. Government subsidies for urban transport are expected to be reduced further [FC2], leading to privatized public transport that will become partially more expensive. Moreover, despite denials from public authorities, road use charges in cities will be very likely by 2030 [TP4]. Overall, mobility users will be forced to dig deeper into their own pockets. The participants agreed that governments will ensure multimodal mobility. Thereby, the government will safeguard the provision of basic services in terms of organization and control mechanisms (through laws), but will leave the operation to private firms. Transportation and infrastructure must be guaranteed by the government (at least roads and possible modes of transport) but implementation and execution will be the responsibility of private corporations. Thereby, mobility operators will have to cover their own costs as well as the costs for maintaining their products and services. Bidding and commissioning will be based on the principles of free market economy: the best companies will be selected. Through tariff restrictions, the government may influence the use of certain modes of transportation. The administration will be handled by infrastructure companies, with the state determining the quality management.",
            "Stakeholders' disputes over the future of urban mobility": " In order to sustain the constructive debate among the stakeholders involved in the transition process, we elaborate on conflicting stakeholder viewpoints. Since complete presentation of all controversial topics is beyond the scope of this paper, we restricted the content to three key unexpected aspects and unique findings of the multi-stakeholder scenario matrix and qualitative arguments provided by Delphi panelists. First, while public authority experts are indecisive regarding the willingness to share personalized information for optimal mobility service offerings [TP2(PA)], industry experts endorse its prevalence. Personal needs can be better targeted with greater access to data. These panelists also expect convenience to prevail over data sensitivity since \"transparent customers\" already exist (e.g. social media profiling). On the contrary, panelists belonging to the users of mobility, namely young adults and retired people, would prefer to restrict the provision of personal data [TP2(YAD, RET)]. These groups fear data breaches will continue to increase and a low level of standardization will impede implementation: depending on the mobility provider, specific requirements should have to be met as part of the system integration. Consequently, the expected spearheads for the urban mobility transformation (i.e. the so-called digital natives) cannot simply be ascertained by the inclusion of surface-level criteria, such as age differences. Second, industry representatives picture electric drive vehicles as a key success factor for multimodal mobility concepts (TP3), since they not only account for a modified drive system, but also a system change for developing new business models that foster multimodal mobility. The alleged weaknesses of alternative drives make them an ideal complement traditional public transport for short distances in urban settings. The electric vehicle can be integrated into multimodal concepts and help promote the meaningful integration of transport modes, particularly in conurbations. Furthermore, it is argued that electric mobility will serve as a networking function in different industries. Surprisingly, some public authority representatives are undecided concerning this issue and voice the opinion that the technology of the drive system is irrelevant to multimodal mobility concepts or that electric mobility solely accounts for a transition technology in motorized private transport [TP3(PA)]. In reality, federal, district, and local authorities as well as public transport organizations do not agree on the issue. Nonetheless, Germany is currently pursuing novel energy policies and has the most ambitious and longest-term expansion targets for renewable energy internationally. In fact, the federal government initiated the Energy Concept 2050 and the National Platform for Electric Mobility (NPE) that aims to connect climate protection with industrial policies, thus placing Germany as the leader within the market of electric mobility. Another stakeholder controversy between industry and public authorities regards the financing and capital dimension of our study. Mobility services and infrastructure providers expect multi-modal mobility to become a profitable investment by 2030 [FC1(MSP)]: as an emerging megatrend, multimodal mobility presents attractive opportunities and provides a sound return on investment. Thereby, access to (private) investors will fuel the necessary innovations. In addition, due to the diverse set of stakeholders involved, complex structures will require a variety of investors and specialists. In contrast, federal, district, and local authorities mutually agree that return on investment should not be the focus of financial investments since lucrative offers for investors mean high costs for the end user [FC1(FAU, DAU, LAU)].",
            "Purposive transition strategies: towards a multimodal city design": " Hasson and Keeney [133] recommended validation and continuation of Delphi findings via other methods and external knowledge. Hence, subsequent to the Delphi study, focus group workshops were held to identify the most important factors for potential users and stakeholders of multimodal mobility in order to realize sustainable mobility.",
            "General stakeholders-strategic agenda": " According to the focus groups, attractiveness will be the leading criterion to establish customer-focused integrated multimodal transport. Mobility systems are often designed for the comfort of operators, rather than for the needs of consumers. The focus groups derived four essential attractiveness features from a customer perspective: (1) ease of use, (2) availability, (3) the total cost of ownership, (4) and comfort. In addition, a diversified portfolio of public and private sources of financing will be needed, including new financial instruments and a move towards the \"user pays\" and \"polluter pays\" principles. Thereby, public and private transport \"payas-you-go\" charges should be integrated while reflecting marginal costs. Integrating these costs may be achieved with global position systems (GPS), direct short-range communication, smartcards, mobile telephones, and other technological advancements. The tenor of the focus groups was that efforts of individual sectors and actors should be better aligned. Although multiple research efforts enhance the probability of innovations and the range of solutions, joint or coordinated efforts across sectors and actors may be more effective in certain fields. Transport service providers often complain of a lack of innovative solutions. However, manufacturers of transport solutions often wait for clear market signals before developing new solutions and do not always comprehend users' needs. It is important to overcome technology lock-in and institutional 'silo' thinking. Existing structures and stakeholder alliances hamper full realization of the potentials of alternative modes of transportation or benchmarking examples from other industries. Innovations in adjacent city subsystems could benefit the mobility industry. Such innovations would be advantageous to transport operators, but, since they normally function at low profit margins, they do not have sufficient incentives to make investments in fresh strategies. Therefore, stimulating innovation in mobility and transport will require mobilizing not only mature segments of the transport market but also integrating them with existing or emerging players from the telecommunications, health, financial services, and energy supply sectors. As a result, a clash of interests and entrepreneurial cultures may be conducive to non-conventional and visionary thinking. These measures will support in focusing efforts and creating new dynamics. However, to ensure quick, large-scale implementation and deployment of new transport technologies and services, public intervention may also regulate and create standards to ensure interoperability or continuity of service, ensure intellectual property rights, and provide procurement and financial incentives if the market does not respond sufficiently. In addition to identifying general stakeholder issues, the focus groups proposed solutions for current and future challenges, targeting the three main stakeholder groups involved in the multimodal mobility system.",
            "Industry-strategy agenda": " Establishing connectivity among urban mobility subsystems appears fundamental for multimodal mobility transition. Essential conditions for the success of connected mobility are already in place and technological progress in terms of front-end and back-end technologies will advance passenger transport further: front-end technologies include cellular network technologies (i.e. long-term evolution (LTE) and 5G in the near future), Internet Protocol version 6 to allow encryption and verification of authenticity of data packages, and near field communication (NFC) to allow unique user identification and thus secure authorization of payment transactions; back-end technologies include cloud computing, digital identity, and new methods of analysis to handle \"Big Data\". The focus groups consider the ability of cars to communicate with their environments (C2E), or cars with other cars (C2C), or both (C2X) a difficult challenge in the future. However, it can be argued that technological progress makes deployment of, for instance, road-side units not a mandatory aspect, since upcoming cellular network technologies will probably allow to accommodate the car-generated traffic. Google believes that in the future, internet-based applications for C2X communication will be possible in cars via smart devices, therefore, built-in solutions will not be required [134]. Overall, to set up intelligent transport systems, networks are required. Despite technical progress, smart solutions for better traffic flow require overcoming old barriers. So far, competitors have largely limited efforts to their domains. Although technically possible, networking with other modes of transport or mobility services is hardly seen. This fragmented value chain is not only economically unsatisfactory but countervails the logic of connected mobility in which value is created in networks, intermodal and transsectorally. Nevertheless, the first intelligent transport system programs are ongoing 8 : for instance, a first field trial to test C2X opportunities and challenges is currently being held in the Frankfurt am Main region of Germany, where OEMs, suppliers, and ICT companies have bundled efforts. 9Nevertheless, the real quantum leap into the modern age is likely to be \"Mobility 2.0\". Today, we refer to \"City 2.0\" as the city of the future with many intelligent components: real-time traffic management, interactive and communicative intelligent charging systems, lighting that is adapted to the requirements and the number of members present at a particular place, etc. Thereby, \"Mobility 2.0\" is based entirely on the city of tomorrow. Intelligent interaction among mobility modes would be a main element of such a city and available to all residents. As previously demonstrated, some innovative solutions already exist that have not yet been broadly used by companies. For connected mobility to become a reality, they will have to rethink their business models. At present, corporations almost entirely lack comprehensive strategies for integrated mobility. Integrating changing mobility business with current business activities and processes will become critical for future sustainable success. Corporations must anticipate modified mobility behaviors by 2030 in endeavors. The adaptation needs to go far beyond a gradual change in the product portfolio. Firms need to deduct future business areas based on a mobility vision. Structured analysis of make-or-buy decisions is required. An appropriate strategy must be aligned to the company's individual market positioning (e.g. premium vs. low-cost vs. entry segment) and must not dilute it. In establishing an integrated business model, close integration with the traditional core business is crucial. Given the wide range of possible activities, companies need to define strategic areas in order to not miss opportunities for growth. Companies that expand into new mobility services have to base future business models on existing skills, and source expertise from other sectors via collaborative activities. Early positioning of mobility services with specific test cases (trial & error) may provide crucial information to develop comprehensive future mobility solutions. It is necessary to anticipate new competitors at critical points in the value chain-especially where customer interfaces are compromised. Especially in the initial phase, it is important to create high degrees of media coverage in order to convince potential users of certain mobility concepts. Some mobility concepts have already been successful: especially the concept of car sharing is a showcase innovation model of the mobility services industry with tremendous potential. In 2005, there were 77,000 car sharers in Germany, using 2,600 cars; the numbers increased to 220,000 sharers and 5600 cars by 2012 [135]. Schaefers [85] determined that over 30% of the population would at test car sharing; while approximately two-thirds have a positive attitude and would consider car sharing for private purposes. Currently, a new concept is emerging concerning private car sharing among individuals. The provider autonetzer.de provides a platform to find the appropriate and nearest shared car with various insurance solutions.",
            "Public authorities-strategy agenda": " Past protests against large infrastructural projects have demonstrated that it has become more difficult for public authorities to execute plans. Public opinion frequently suggests that people do not feel adequately informed about planning projects. A frequently voiced suspicion is that many citizens have become less interested in societal needs and more in preventing projects being implemented \"in their own backyard\". Furthermore, a whole new dimension of citizen participation has evolved: people have started taking over parts of infrastructural planning. In the last three years, more than 400 new cooperative associations have been established to jointly develop local climate-friendly energy supply in Germany [136]. Therefore, the focus groups questioned how timely government planning actually is. With current planning procedures, affected citizens can only make objections within a limited period of time and address very specific conflicts of interest. By the time the project is made public, the primary planning of the project has already been completed and the social benefits of a project are not subject to discussion with the citizens. Early and extensive public participation in multimodal mobility planning processes would require qualitative information, a results-oriented methodology, a culture of dialogue and an increased amount of communication in order to meet the growing need for information and citizen participation. Mobility policies will have to accommodate public participation with new designing and planning methods, in addition to the formal and prescribed procedures by law. Public contribution to mobility projects could lead to sustainable multimodal mobility systems. In addition, the focus groups highlighted the need to develop new business models for public and private transport services, such as shared ownership. There is general agreement that public passenger urban transport accounts for a service which cannot be provided by private organizations without governmental intervention. However, public transport requires financial support. Since governmental budgets are restricted, public transport funding by users and additional private capital is required to finance infrastructure investments. Other approaches, such as public-private-partnerships (PPP) in road construction will also be adopted for public transport and their effectiveness and efficiency can be measured empirically. In this context, public authorities should promote competition and market liberalization in the field of public transport. Although it is expected that a large portion of public transport companies would not be competitive in an open market, it is the only way to improve efficiency and make mobility more cost-effective in the future. Furthermore, local, state, and federal governments should cooperate in allocating investments to multimodal mobility. Funding should be fairly distributed in creating transport systems. Control instruments, such as regular process reports and key performance indicators, also have to be implemented to measure if public authorities are working efficiently and if funding is being used wisely. Such measures would cause the different levels of government to compete against each other in a healthy manner. Furthermore, competition would be encouraged among regions. If one city works efficiently, it is considered to be good for its image. Other cities will strive to follow. Moreover, the focus groups discussed restructuring internal processes to reduce operational and administrative overhead, data privacy regulations, and incentive schemes for multimodal mobility including mobility counseling.",
            "Customers-strategy agenda": " During panel discussions it became apparent that the transformation towards more efficient, clean, and safe urban transport requires proactive customer support. Since more detailed and reliable information is required by consumers to improve their individual mobility situation and to attain the best offers (in terms of price, time, comfort, etc.), a comprehensive mobility platform to support such optimal information access in travel planning (i.e. information to be \"pushed\" to the customer) requires continuous maintenance of end-user profiles. By joint efforts, industry, public authorities, and customers continuously need to promote the substantial added value that such systems offer in multimodal mobility while simultaneously considering the voiced fear of data misuse. Furthermore, the perspectives of end-users should be considered already in the design of future mobility services. As such, end users need to communicate their ideas and become involved as \"active citizens\" (e.g. during citizens' initiatives) to ensure sustainable and environmentally-friendly multimodal mobility. Overall, the greater the interest and involvement of citizens is, the more current and on large-scale multimodal mobility arises. Finally, customers have to be willing to pay for improved mobility performance. In fact, mobility users must critically examine and balance their demands: while some customers require a continuous increase in individuality and exclusiveness, their payment behavior will need to be aligned accordingly. Therefore, advancements in mobility, which cater to diverse customers' demands and needs, can be costly in terms of time, money, and effort.",
            "Conclusion": " This research has found that large scale changes will be necessary to deal with the challenges facing the German urban mobility systems. In fact, the mobility sector, public authorities, and customers must break away from conventional thinking. Consequently, the socio-technical transition theory guided our research and the conceptualization through a SIM process helped to analyze the complex multi-dimensional changes required in developing sustainable urban multimodal mobility systems. By applying a participatory research approach, we provided an initial attempt towards integrated multi-stakeholder scenario planning for future urban mobility. Such prospects for the future generate stimulating perspectives not only for strategic planners, but also for governmental authorities and other stakeholders in making city mobility more effective and efficient. With regards to methodological advancements, integrating multi-stakeholder viewpoints in scenario development meaningfully complements the methodology by enhancing information substance and eventually increasing the usability of scenarios. The Delphibased SIM process provides a new functional approach concerning the various issues that surround multimodal mobility, thus allowing researchers to develop strategies and frameworks that consider the dynamic nature of the environment. Urban mobility is a highly dynamic and complex concept to consider with the goal of redesign. Therefore, we argue that a preferred vision of the future has to first be articulated before a new urban mobility system can be designed and implemented: one which is sustainable and matches user requirements. The Delphi study results highlight that the integration of individual and public passenger transport is highly desirable and expected to be essential for future urban mobility. Thereby, multimodal mobility-a concept that uses a variety of different transport modes for travel-will increase. Overall, multimodal mobility presupposes three conditions: the presence of multiple transport means customized to the specific situation; sufficient information for the correct decision between several options in real time (especially with the support of mobile technology); and a change in social habits and behaviors. Although there is a mixed picture for the development towards such a multimodal mobility system, we extracted major elements that will influence multimodal city design. Thereby, customers expect increasing freedom of choice in the design of their mobility chains and a variety of transport means with different goals. Nevertheless, the demand for individual locomotion and high autonomy remains. To account for multimodal options, the utilization of system strengths is indispensable. Alternative vehicle drives are expected to gain in importance, not only in terms of emission reduction but also as a meaningful supplement to traditional public transport. Intelligent transport systems with modern data communication are advancing; complete connectivity however will remain a vision beyond 2030. The private sector leads in designing multimodal mobility systems due to more efficient approaches for commercial success. In the course of our research, focus groups proposed solutions for current and future challenges in urban mobility systems. Technological advancements in intelligent transport system communication, including connected mobility for private and public transport, will be provided by the private sector. However, technical solutions alone are unlikely to reduce the impacts of transport to a level which is deemed sustainable. In fact, integrated strategies are necessary that also involve areas not typically associated with the transport planning process. Among others, the strategy agenda must coordinate efforts, diversify the portfolio of public and private financing, change business models, and create a renaissance of civil participation. As with every research endeavor, this paper faced some challenges throughout the course of research and has its limitations. Although we identified the strategic issues through structured environmental scanning techniques and expert interviews, we focused on an overall and broad discussion of major aspects to keep the level of complexity manageable and the time effort required of participants reasonable. However, while accounting for such a variety of dimensions, it is important to capture the complexity of the multimodal mobility system. The authors acknowledge that the work could benefit from additional content assessment. Therefore, further research could address: (1) individual aspects identified in the present paper at a much higher level of detail; (2) discontinuities, wildcards, and weak signals since their selective inclusion may highlight new strategies and scenarios, possibly evoking a greater degree of tolerance to withstand changes within the environment and industry; (3) more in-depth dissent analysis by age, gender, functional area, and position in the organization and also by responses on probability and impact. Furthermore, we acknowledge that developments in different regions or so-called megacities differ from the German urban mobility context and therefore, to some extent, require adaptations to the recommendations presented in this paper. However, we feel that innovative socio-technical transition approaches for the German urban mobility systems can be transferred and guide as an initial field trial for developing innovative ideas: in particular, future research avenues could focus on developing countries and their enormous market potential for developing and expanding mobility infrastructure over the upcoming decades. Finally, this paper focused on passenger transport; future research could consider freight transport and even expand the scope to considering related city subsystems, such as the utilities or health system [137]. Conclusively, future research could investigate the interconnectedness of city subsystems in more depth. Overall, we feel that multimodal mobility will become essential for city center accessibility, and its attractiveness will depend on the quality of mobility services offered. Therefore, we return to where this paper commenced: in the future, it is not about reducing mobility as such since individual mobility is the prerequisite for social participation, progress, growth, and self-realization. Rather, a socio-technical transition towards a sustainable urban mobility system should organize transportation smartly while fulfilling the multi-dimensional complexity of the changes outlined. So far, many researchers and practitioners have had a unidimensional mindset and have concentrated on vehicle transportation, primarily cars. However, this does not suit the complexity of requirements for urban mobility. We need to understand mobility systematically. Future research efforts will certainly support in broadening multimodal mobility perspectives."
        }
    },
    "10.1016/j.techfore.2009.03.002": {
        "file_name": "182 Cumulative causation in the formation of a technological innovation system",
        "title": "Cumulative causation in the formation of a technological innovation system: The case of biofuels in the Netherlands",
        "abstract": "Despite its worldwide success, the innovation systems approach is often criticised for being theoretically underdeveloped. This paper aims to contribute to the conceptual and methodological basis of the (technological) innovation systems approach. We propose an alteration that improves the analysis of dynamics, especially with respect to emerging innovation systems. We do this by expanding on the technological innovation systems and system functions literature, and by employing the method of \u2018event history analysis\u2019. By mapping events, the interactions between system functions and their development over time can be analysed. Based on this it becomes possible to identify forms of positive feedback, i.e. cumulative causation. As an illustration of the approach, we assess the biofuels innovation system in The Netherlands as it evolved from 1990 to 2007.",
        "label": "Mixed",
        "text": {
            "Introduction": " The literature on innovation systems stresses the importance of path dependency, positive feedback and cumulative causation for understanding technological change and long-term economic growth [1][2][3][4]. However, our insight into what more generally could be called system dynamics is still limited [5,6]. The majority of innovation system studies conducted so far start from the aggregated perspective of a national or sectoral economy. The scope and complexity of such systems make a thorough analysis of dynamics difficult. As a result of this, most empirical studies aim at making static comparisons. Our understanding of innovation system dynamics is especially lacking for systems that are only just emerging [6,7]. This is a crucial problem since it is these innovation systems that can still be shaped and influenced; cf. Collingridge [8]. The conscious shaping of an innovation system becomes especially relevant when one considers that technological change plays a crucial role in the transition to a sustainable energy system. The fluidity of emerging innovation systems makes the task of supporting sustainable energy technologies extremely challenging. This is illustrated by their exceptionally low market shares, despite efforts by many European governments to support their development [9]. Currently, renewables are locked-out of the energy system [10]. This not only implies the absence of a well-functioning market for renewables but also an immature supply system and poor-or unfitsupporting infrastructures, in terms of technology, policy, knowledge bases, finance, user communities etc. Even if trust is placed in a particular emerging technology, it is still unclear how it should be supported [11]. Therefore, the aim of this study is to contribute to insights into the innovation system dynamics that induce or block the successful development and diffusion of emerging sustainable energy technologies. We do this by, theoretically and methodologically, expanding on the Technological Innovation Systems (TIS) approach [3]. 1 The TIS is a social network, constituted by actors and institutions, which is constructed around a specific technology. 2 Recent TIS literature stresses that emerging technologies need to pass through a also possible to consider activities that negatively contribute to a system function. Obviously, these negative contributions imply a (partial) breakdown of the TIS. The premise is that a TIS should positively realise multiple system functions, each of which covers a particular aspect of technology development. Based on a review of innovation systems literature, a shortlist of seven system functions has been formulated [5]; see Table 1 for definitions. Various 'lists' of system functions have been constructed [13][14][15][16][26][27][28]. Authors like Bergek et al., Hekkert et al. and Suurs give useful overviews [5,29,30]. The lists show much overlap and differences reside mostly in the particular way of clustering activities. However, we agree with Edquist that our knowledge is still provisional and needs to be adjusted as our insight grows. The list needs to be confirmed (or falsified) by empirical evidence [14]. For a large part such empirical validation has been provided, for instance, in studies by Negro, Alkemade and colleagues [23,24,31]. These studies support our assumption that the set of system functions as given above corresponds well to the empirical data relevant in the field of sustainability innovations. The seven system functions are considered a suitable set of criteria for the assessment of a TIS in the formative stage. We expect that as actors, institutions, technologies and networks are successfully arranged to induce the fulfilment of system functions, the chances of technology diffusion will increase. To some extent, system functions need to be realised simultaneously, since they can complement each other. A TIS may very well break down due to the absence of a single system function. For example, Kamp [32] shows that the Dutch wind energy innovation system was well developed in the 1980s but collapsed as the result of an important deficiency, namely the absence of Knowledge Diffusion between the emerging turbine industry and potential users, the latter being energy companies in particular. This means that system functions are expected to reinforce each other over time. Indeed, a positive interaction between system functions is considered necessary for TIS build-up to occur. According to Jacobsson and Bergek [33], the fulfilment of system functions may result in a virtuous cycle. For example, the successful realisation of a research project, contributing to Knowledge Development [F2], may result in high expectations, contributing to Guidance of the Search [F4] among policy makers, which may, subsequently, trigger the start-up of a subsidy programme, contributing to Resource Mobilisation [F6], which induces even more research activities that contribute to Knowledge Development [F2], Guidance of the Search [F4], etc. Thus, interaction between system functions results in cumulative causation. Multiple forms of cumulative causation may exist. In the ideal situation, the sequence of activities will form a virtuous cycle and trigger a take-off. Conversely, a sequence may also result in conflicts, a complete standstill, or even a vicious cycle. In short, multiple sequences are conceivable that result in a positive, or negative, development process. In this respect our approach reflects the opposition of the innovation systems approach to the linear model that states that technology development is characterised by a fixed sequence of activities: R&D, prototype testing, niche-market development, up-scaling; cf. Lundvall [21]. The identification of various forms of cumulative causation, or motors of innovation as they can be called [34,35], will be at the core of our analysis. Motors of innovation cannot be regarded as independent of the structures of a TIS. On the contrary, motors of innovation emerge from a configuration of structural factors and in turn rearrange that configuration. There exists a mutual relation between the structural configuration of a TIS and the system functions which are realised in it. For the purpose of this paper, the focus will be on the dynamic aspect, i.e. the system functions. Nevertheless, the most important actors, institutions and technologies that actually make up the TIS will be revealed in the analysis. In fact, as will become clear in the next section, system functions are always directly related to such structural factors. Note that the dynamics that unfold through the emergence of cumulative causation are primarily the result of factors (or events) internal to the TIS. However, they will be influenced by external factors as well, such as technical possibilities, historical shocks, and international trends. These will be mentioned in the analysis as background movements.",
            "Method": " The analysis of a TIS in the formative stage requires a methodology that captures the microdynamics that contribute to its realisation. Traditional methods fall short here. For example, bibliometric methodologies, as applied to publications or patents, are ",
            "F1. Entrepreneurial Activities": " At the core of any innovation system are the entrepreneurs. These risk takers perform the innovative commercial experiments, seeing and exploiting business opportunities.",
            "F2. Knowledge Development": " Technology research and development (R&D) are prerequisites for innovation. R&D activities are often performed by researchers, but contributions from other actors are also possible.",
            "F3. Knowledge Diffusion": " The typical organisational structure of an emergent innovation system is the knowledge network, primarily facilitating information exchange.",
            "F4. Guidance of the Search": " This system function represents the selection process that is necessary to facilitate a convergence in development, involving, for example, policy targets, outcomes of technical or economic studies and expectations about technological options.",
            "F5. Market Formation": " New technologies often cannot outperform established ones. In order to stimulate innovation it is necessary to facilitate the creation of (niche) markets, where new technologies have a possibility to grow.",
            "F6. Resource Mobilisation": " Financial, material and human factors are necessary inputs for all innovation system developments, e.g., investments by venture capitalists or governmental support programmes. F7. Support from Advocacy Coalitions The emergence of a new technology often leads to resistance from established actors. In order for an innovation system to develop, actors need to raise a political lobby that counteracts this inertia, and supports the new technology. limited to the analysis of Knowledge Development, while social network analysis is limited in that it detects only network formation, i.e., Knowledge Diffusion or Support from Advocacy Coalitions. Similarly, firm data are well suited to analyse Entrepreneurial Activities, but are less suitable to construct indicators for other system functions. A more flexible, yet systematic, methodology to analyse the realisation of system functions is the event history analysis, as developed in the context of organisation studies; see Poole et al. [17]. The event history analysis employs a particular worldview, based on a so-called process approach which can be summarised according to the following assumptions: \u2022 The world is made of entities that perpetually participate in events. These entities may change over time. With respect to the TIS, this means that structural factors are to be considered as subjects of change. \u2022 The world can be understood as a development process in which these events form one or more sequences. To understand a development process is to understand the logic of a sequence of events. \u2022 The logic of event sequences is the logic of a plot in a narrative. Events that are part of a plot are not (only) related to each other by an efficient causality (the simple logic of mechanics) but (also) by final and formal causality. Final causality relates to the goal directedness of agents, whereas formal causality refers to the intangible forces that shape actions, like routines, regulations, institutions and technologies. The main implication for the analysis in this paper is that system functions do not represent variables in the traditional sense. Instead system functions may be understood as (interpretative) categories of events. In line with this, motors of innovation are to be understood as event sequences that correspond to a meaningful 'plot'. See Suurs [30] for an extended overview of this idea. The event history analysis offers the possibility of operationalising and measuring system functions by relating them to events. Within the context of a TIS analysis, an event can be defined as an instance of change with respect to actors, institutions and/or technology which is the work of one or more actors and which carries some public importance with respect to the TIS under investigation. Examples of such events are studies carried out, conferences organised, plants constructed, policy measures issued etc. Note that events are directly associated with structures. Hence, system functions are always about (changing) structures. The basis of the event history analysis is the construction of a narrative. The following procedure explains how to do this and how to distil meaningful event sequences.",
            "Collect data from literature": " A variety of literature was collected, including professional journals, newspapers, periodicals, reports, websites. See Table 2 for an overview of all sources used. In total about 1100 events were retrieved to form the basis of our analysis. An important aid was the Lexis Nexis database in which a large number of source are digitally available. The following keywords were used (translated from Dutch); bio(-)fuel, bio(-)ethanol, bio(-)diesel, dme (dimethylether), fischer-tropsch, htu (hydrothermal upgrading), pure plant oil, ppo (pure plant oil).",
            "Construct a database": " A database was constructed containing events in chronological order. This was done by reading through the literature and separating, throughout each text, the events reported. The identification of events was an inductive exercise for which the conceptual framework of system functions was used as a heuristic, in the sense that with the definitions of system functions in mind it was possible to interpret particular reports as events. In this respect the events should be considered constructs of the researcher. They make up an intermediate level of representation that lies between the concrete literature reports and the abstract concepts.",
            "Mapping events to system functions": " The database provided an overview of the content of events and the time of their occurrence. Based on this overview, the events were clustered into types that corresponded to the system functions. The outcome, an event typology, is presented in Table 3. Note that each event type is mapped on a particular system function. This way events serve as indicators of system functions. 5Events can contribute to system functions either positively or negatively. Therefore, the events in the database were categorised as either positive or negative. For example, events that were categorised as Guidance of the Search were rated positive/negative when they expressed a positive/negative opinion regarding the technology under investigation. Likewise, within the category of Support from Advocacy Coalitions, there were positive lobbies and negative lobbies. 6It is important to remark that the system functions guided the interpretation of the literature but did not force it. When important events could not be allocated to either one of the seven functions, this would have been an indication of an incomplete set of system functions. Also, if for a specific system function only a small number of events would have been found without a clear indication of bad system performance, this system function would have been considered as irrelevant (unless explanations could be mobilised to account for it). In this case, all event types could be mapped on the current set of system functions, which is a (tentative) validation of the seven system functions used here. The allocation scheme resulting from our literature search is given in Table 3.",
            "Patterns of events": " The next step was to analyse the event data. Based on the ideas of Abell [36] and Poole et al. [17], event data were subjected to two types of analysis. Both are based on the recognition of patterns in event data: trend patterns and interaction patterns. Both techniques are means to develop a plot, and thereby to construct a meaningful narrative that captures the development of a TIS. Of the event types used for quantitative analysis, the number of events available is given, as well as whether its effect is positive or negative with respect to its contribution to the BFTIS (sign).",
            "Trend patterns": " The first technique aims to derive trends from aggregated data over a period of time. Ideally, this is done quantitatively by plotting the aggregated number of events for each year per system function. The slope of the graph represents the increase or decrease in the activities per system function. This representation is useful as it gives insight into major turning points of the TIS development such as, for instance, a sudden decline in the intensity of the Guidance of the Search function. If the available data allows it, more detailed insight can be obtained into the way system functions are specifically fulfilled. For example, the analysis could show a shift in the share of activities conducted by particular actors (public or private). Alternatively, there may be shifts in the share of different technological varieties being developed (as, in our case, with respect to a first-generation and a second-generation of biofuels).",
            "Interaction patterns": " The second technique aims to track causal chains of events based on the sequence in which they occur. If trend patterns represent outcomes of TIS development, then interaction patterns offer a possible explanation for these outcomes. To understand this, it is important to realise that events can be connected through 'leads-to' relations, to form a sequence; cf. Abell [36]. Many events refer to other events; these references can be tracked by checking the content of the events in the database. For example, a promise to support the construction of a biofuels plant may be followed by the construction of that plant. Also, a positive lobby may result in the award of subsidies or the adjustment of institutions. The overview of event references enables us to construct a narrative in which event sequences serve to construct storylines. By interpreting events as indicators of system functions, according to Table 3, it becomes possible to identify the role that particular system functions play within event sequences. If particular system functions recur in an ordered sequence, this implies a cyclic mechanism: a motor of innovation. The event sequence indicates a virtuous cycle if it forms a repetitive loop of system functions reinforcing each other. The example of the virtuous cycle presented in Section 2 was already formulated in terms of events: the successful realisation of a research project (Knowledge Development) results in high expectations (Guidance of the Search) among policy makers, which subsequently triggers the start-up of a subsidy programme (Resource Mobilisation) which induces even more research activities (Knowledge Development). A vicious cycle would involve a cascade of negative events. Note that event sequences may diverge, as one event may lead to multiple other events, or converge, as multiple events may be necessary before they can lead to one other event. I will attempt to reduce this complexity by summarising such leads-to relations on the level of system functions. For example, by stating that an important policy measure (Guidance of the Search) results in an increase of firm entry (Entrepreneurial Activities). Insights from both analyses mutually strengthen each other. The trend patterns can be used to distinguish and characterise particular 'episodes' in the narrative. The interaction patterns unfolding within an episode may explain the occurrence of the trend patterns.",
            "Triangulation": " The construction of the event sequences and the narrative is done as 'objectively' as possible based on empirical sources. Still, the interpretation of the researcher is a crucial factor. To minimise personal bias, the narrative is verified, i.e., triangulated, and if necessary reconstructed, by including feedback from interviews with experts. 7 In this case, the expert feedback led only to minor adjustments of the storyline. In the next section, we reconstruct the development of the BioFuels TIS (BFTIS) and refer to the various system functions as F1, F2, F3 etc., following Table 1. The narrative is chronologically ordered and divided into six episodes. Motors will be identified for each episode, if present. The background movements of the BFTIS are covered as an introduction to each separate episode.",
            "The event history of the BFTIS": " Before starting the narrative, it is important to introduce a remarkable (technological) feature of the BFTIS, namely the existence of two distinct technology groups: first-generation (1G) and second-generation (2G) biofuels. Both technology groups connect to different knowledge bases and separate sectoral backgrounds. The 1G fuels are based on conventional technologies, mainly adopted by farmers' organisations. Agricultural crops are used, such as rapeseed or sugar beet, to produce biodiesel or bioethanol. The 2G biofuels originate from science-based technologies (chemical and biotechnological). These technologies involve the conversion of woody biomass, consisting of waste wood or cultivated energy crops, into 'biocrude', 'Fischer-Tropsch biodiesel' or 'cellulosic bioethanol' (all synthetic substances). Both 1G and 2G biofuels are currently in a pre-commercial stage of development. For 2G biofuels the distance-to-market is much larger than for 1G biofuels. It is expected that-in the long term-2G biofuels offer the possibility for larger reductions in CO 2 emissions at lower costs than 1G fuels. 8 Another advantage of 2G biofuel technologies is that they can draw upon a wider variety of biomass resources, including waste materials. On the other hand, the 1G biofuels seem to offer a better perspective in terms of costs and implementation in the present and in the near future. As will be shown, the dynamics of the Dutch BFTIS largely revolve around a clash of these two technology groups. With respect to utilisation in vehicles, biofuels may be used in their pure form but then significant vehicle changes are necessary. For blends, only minor changes are necessary. The exception to this is Fischer-Tropsch biodiesel, which can be used in regular diesel engines.",
            "Emerging biofuel technologies (1990-1994)": " During the early 1990s, there is no political urgency for a sustainable energy system. Oil prices are low and the climate issue is barely mentioned in (international) political arenas. The biofuels issue arises in Europe as an effect of a background movement: the decline of the agricultural sector. The European trade protectionism of the past decades has resulted in massive production surpluses and an unacceptable budgetary burden [38]. In countries such as France and Germany, where (bulk) agriculture is relatively important, biofuels are first presented as a way out of this impasse. With the production of non-food crops, the sector could be aligned with a new market with new opportunities. In 1992, within the context of this 'agrification' idea, Europe proposes to financially support biofuels [39] by proposing a scheme for generic tax exemptions. Furthermore, farmers are offered a premium for the cultivation of non-food crops. Environmental benefits are mentioned as the prime reason for these subsidies [40,41]. In the Netherlands, this background movement is picked up by a group of entrepreneurs who start adopting biofuels [F1]. In the rural province of Groningen, a public transport company starts a trial [F2] with bioethanol in buses. A number of actors is involved, among them the alcohol producer Nedalco [42]. Another trial [F2] is started in the city of Rotterdam, where buses are fuelled with biodiesel. Funding is provided by the companies themselves and through European subsidies [F6]. Figs. 1 and 2 illustrate that these and other entrepreneurial experiments and trials [F1, F2], are the first signs of a Dutch BFTIS taking shape. The trials [F2] turn out to be technically successful [F4] despite the fact that the engines of the buses in Groningen incidentally catch fire [43]. A less positive outcome of the experiments is their low economic feasibility: under the present circumstances, biofuels cannot compete with fossil fuels [F4]. At this time biofuels fall under the same tax legislation as fossil fuels. Measures of national support are absent [F4, F5]. This relates to the emergence of a controversy around the use of biofuels. Illustrative of this is that, in 1992, the Dutch government agency for energy and environment (Novem) states that implementation of biofuels is too expensive compared with co-firing biomass in power plants [F4] [44,45]. Various assessment studies [F2] now set the tone for a 'debate' [F4] that will go on until today. Regional actors emphasise the strategic and environmental value of biofuels, whereas scientists and environmentalists stress their meagre performance. The Dutch government initially remains silent due to its internal division on the biofuels issue [F4]. In spring 1993, the Ministry of Agriculture takes a stance against public support [F4] [46], whereas the advisory council on social-economic issues (SER) advises it to support the experiments [F7] [47,48]. Only a year later, in 1994, the Ministry of Agriculture decides to announce fiscal support of biofuels [F4], whereas the Ministry of the Environment expresses doubt [F4] [49].",
            "Cumulative causation": " The within this episode suggest a segregation of the development of 1G biofuels and 2G biofuels. The event sequence related to 1G biofuels is characterised by the creation of a market environment [F5]. This has resulted in a guaranteed demand for biofuels, leading various firms [F1], encouraged by expectations [F4], to enter the TIS and start investing in the commercial production of 1G biofuels [F1, F6]. Where successful, this leads to even higher expectations [F4] and more entries and investments of firms [F1, F6]. This form of cumulative causation may be labelled a Market Motor. The 2G biofuel technologies are still driven by an Entrepreneurial Motor as characterised in the previous section. The further development of this motor is currently uncertain due to the rapid expansion of 1G biofuels. On top of this, the biofuels controversy rages on, undermining the long-term perspective for the development of biofuel technologies, 1G and 2G alike [F4]. It seems that the BFTIS is on a tipping point. Either, the BFTIS actors, including the international ones, manage to establish a consensus on what biofuel options are worthy of support, or else the BFTIS will dissolve and break down as the result of ever-increasing uncertainty.",
            "The shaping of the BFTIS (1995-1997)": " From 1995 onwards, a background movement is the gradual shift within the international energy domain; the climate issue is becoming a matter of political interest and the concept of biomass is becoming important in the energy sector [50,51]. In the Netherlands, a first series of projects is initiated which contributes to a sequence of further activities. It starts in 1995 in the rural province of Friesland, where two boating companies initiate adoption experiments with biodiesel [F1] [52]. An important reason is the increasing regulatory pressure with respect to the surface water quality [F4]. Biodiesel is biodegradable and poses only a limited threat to the water quality. The companies demand a national fuel tax exemption for the project [F7]; the provincial government and the district board of agriculture support the idea by forming an advocacy coalition towards the national government [F7]. They are successful and a first tax exemption is provided, for two years [F6] [52]. As the province decides to adopt biodiesel for its fleet of service boats, a virtuous cycle emerges. The adoption experiment improves existing knowledge [F2] and, most importantly, it serves as an example to others in the field A crucial barrier to these developments is that, meanwhile, various impact assessments [F2] yield contradictory or negative results for 1G fuels [F4]. Fig. 3 shows the negative climax of this movement in 1996. The national government does not take a clear stance in the debate, as tax exemptions are issued on project-specific grounds [F6] instead of on the basis of a policy strategy. There is at this point in time no structural form of support [F4]. An issue that keeps coming up in this respect is the budgetary gap that would have to be filled if a generic fuel tax exemption was to be issued [F5] [53]. Around the same time, in 1995, Nedalco, an alcohol producer, starts to play an influential role in pressing the national government to change the tax scheme. Nedalco's business expansion [F1] starts with a trial production of bioethanol [F2] [54]. Together with other companies, plans are made for a pilot plant [F3]; pressure is put on the government to issue a tax exemption [F7]. According to Nedalco, returns cannot cover the investments without a tax exemption [55]. Nedalco succeeds in raising attention to the possible advantages of bioethanol [F4]; see the trend in Fig. 3. Its political lobbies [F7] are complemented by positive announcements in the media [F4] and by the outcome of new assessment studies [F2], carried out under the supervision of Novem [F4], confirming the potential of its project [56] [F4]. In the summer of 1997, Nedalco succeeds in persuading [F6] the national authorities to guarantee a ten-year tax exemption [F5] for the annual production of 30 million litres of bioethanol. Furthermore, a subsidy is promised for the expansion of Nedalco's activities [F6] [57]. However, the apparent success is undone by the fact that the tax exemption turns out to be insufficient to cover the investments [55]. 9 As a result, the project is discontinued [F1] and the plans remain just a promise. Nevertheless, Nedalco's project is successful in the sense that it takes a stance against the government's resistance to (1G) biofuels. A lasting effect of Nedalco's activities is the recognition in the field of 1G biofuels as a viable option. Fig. 3 illustrates this trend as a rise to a high level of guidance (mainly expectations), involving all types of biofuels by 1996. So far, not a drop of biofuel has been produced within the Netherlands, although a first attempt to supply biofuels has been made. The episode is characterised by an increasing attention on biofuels and by the first real steps being taken by national government authorities to actually support biofuels. The tax scheme remains an important barrier, still not differentiating between fossil fuels and biofuels. Also, the government mainly follows the entrepreneurs instead of taking a strategic lead. This is about to change. In 1996 the possibility of using 'solids to liquids' technology starts receiving media coverage [F4]. Academic researchers and environmentalists have mainly been calling attention to the negative properties of 1G fuels [58][59][60], thereby discrediting the biofuels option as a whole [F4]. However, their criticism now becomes more constructive as they propose an alternative in the form of 2G biofuels [F4]. Previously, the 2G technologies group had been developed in R&D settings [F2] but now a small company named Biofuel-a spin-off from Shell-joins forces with several industrial parties and starts working on the construction of a first pilot plant for the production of 'biocrude' [F1, F3] [61]. This R&D project is financed by both Shell and a national subsidy programme [F6] [62].",
            "The separation of 1G and 2G biofuels (1998-2000)": " In 1998, the climate issue becomes an important background movement. A milestone is the signing of the Kyoto treaty by member states of the European Union in 1998. The European target is to realise more than 60% of the CO 2 reduction through the use of biomass [63]. In the Netherlands, this target is adopted by various government programmes [64][65][66]. On top of this the automotive sector is increasingly considered an important target for energy policy [65,67]. 10 A most significant event during this episode is the initiation by Novem of a national programme for the assessment and support of gaseous and liquid CO 2 -neutral energy carriers-the GAVE programme [68]. So far, the emerging BFTIS has received little government support. A troublesome factor is the biofuels controversy. GAVE manages to establish a breakthrough in the status quo, by starting up a motor that triggers the following three trend patterns. The first trend pattern is related to Guidance of the Search. Scarcity of biomass has been increasing as a result of growing demands for electricity production [F6] [69], causing a dispute on the use of biomass streams for transport versus electricity purposes [F4] [53]. However, an influential study [F2] authorised by GAVE [70], designates that biofuel production could certainly be favourable, provided that production scales are sufficiently high [F4] [71]. Moreover, a range of alternative energy sources already exists for electricity production, whereas little has been achieved for the mobility domain [F4]. With this argument, GAVE turns to the responsible government ministries and manages to put the issue on the national policy agenda [F7] [68]. A second trend initiated by GAVE is Knowledge Development in the field of 2G biofuels. In 1999, GAVE's first move is to authorise a number of assessment studies [F2] aimed at removing the controversy around various biofuel options [F4]. A pre-study results in a shortlist of fuel chains to be analysed in more detail [72]; the results are based mainly on energy balances and cost figures [F2]. The advice is to support exclusively projects which guarantee a CO 2 reduction of at least 80% [F4] [68]. Subsequently, all 1G options are (de facto) excluded from further assessments. It is within this context that the term 2G biofuel is actually invented to distinguish the contested agricultural biofuels from technologically advanced options [68]. Figs. 2 and 3 show this trend. From 1998 to 2000, the 2G biofuels attain dominance over 1G biofuels. The programme creates a spin-off in the form of new undertakings of Nedalco and the Biofuel Company. The Biofuel Company starts working on a pilot plant [F1] and manages to realise a proof of principle for the HTU process, a 2G technique for the production of biodiesel, particularly suitable for (wet) waste [73]. Originally, the R&D activities [F2] are not specifically aimed at producing automotive fuels; in fact, the possibility is barely mentioned [F4] [74]. However, from 2000 onwards and triggered by GAVE, the Biofuel Company's technological progress is increasingly considered a contribution to the substitution of petrol-based resources [F4] [74][75][76]. Nedalco has also shifted its attention in response to the rise of 2G biofuels [F1]. With the original plan discontinued (as mentioned above), Nedalco now studies the possibility of 2G biofuels [F2]. A highly innovative R&D project on the production of cellulose ethanol is initiated. Other organisations involved are Wageningen University, TNO, 11 and Shell [F3]. The project is partly funded with government subsidies [F6] [55]. The third trend is GAVE's contribution to Knowledge Diffusion. As Fig. 5 shows, there are no meetings specifically on biofuel [F3] in the period 1990-1998. From 1998 onwards, general biomass energy meetings become more important, yet, they are still mostly directed at the stationary use of biomass. 12 Meetings specifically on biofuel (mainly 2G fuels) start occurring from 1999 onwards. Fig. 3 shows the positive impact of GAVE on Guidance of the Search. From 1998 to 2000, the 2G biofuels attain dominance over 1G biofuels.",
            "A tentative offer (2001-2002)": " In the new millennium, the issue of sustainable mobility is put on the political agenda. Besides the climate issue, the issue of security of oil supply is becoming more urgent, especially since 9/11. In the Netherlands, these background movements are reflected in a variety of policy measures aimed at reducing fuel consumption in the mobility domain [77]. Despite weak ministerial support, the work of GAVE continues [78]. From 2001 to 2002, GAVE installs a subsidy programme [F6] aimed at guiding entrepreneurs towards the realisation of demonstration-scale fuel chains [F4] [79][80][81]. The programme consists of two tenders for a total budget of approximately 2 million \u20ac. The first step is to stimulate the formation of coalitions [F3] and to support assessment research [F2]. The 80% CO 2 criterion still holds; the emphasis is on innovative fuel production. As a result, all new projects [F1] are exclusively directed at 2G biofuel technologies. Two entrepreneurial experiments [F1], focusing on combining biomass gasification with Fischer-Tropsch synthesis, are characteristic for this episode. If successful, they could enable the production of biodiesel from practically any biomass source [F4]. The projects are set up by two alliances [F3]; the Shell-ECN network and the TNO-Nuon network, and various other actors, such as banks, a car company, and many others [82]. The projects are successful [F4], particularly with respect to solving technological bottlenecks such as gas cleaning [F2] [83]. The final purpose of the subsidy programme was to realise a commercial demonstration. By the end of 2002, possibilities are considered [F4], as both alliances are viable candidates and GAVE has a sum of 5 million \u20ac to offer [F6]. Unfortunately, both parties decide to discontinue [F1]. The main reason is that building a commercial-scale plant would cost far more than 10 million \u20ac, which would not be feasible without a flanking market stimulation programme, e.g. tax exemption measures [F5, F6] [68,84]. The subsidy programme stops [F6]; once again, the absence of sufficiently powerful market creation policies forms a critical barrier to the further development of the BFTIS [F5] [68]. This would require a tax exemption for biofuels or a scheme that promotes obligatory use. Towards the end of the episode, political pressure from the EU increases [85][86][87][88][89]. In the Netherlands, this background movement results in a lobby from national parliament [F7] [90], pressing the national government into issuing generic tax exemptions for experiments with automotive biofuels [F5] [91][92][93].",
            "European intervention (2003-2005)": " In 2003, the EU decides on a biofuel directive forcing its members to substitute a percentage of the supplied automotive fuels by biofuels [94]. This background movement has drastic consequences as the EU is more fond of 1G biofuels than the Dutch government. With GAVE's subsidy programme terminated, and with a new national task of implementing the EU directive, a reorientation of government policy is imminent [95]. Therefore GAVE is issued with a new priority task [F4]: the development of a generic market for biofuels. The 1G technologies are now increasingly perceived as a stepping stone towards future use of 2G fuels [68,96]. In 2003, once again, Nedalco starts influencing the field. With the directive being taken up by national policy makers [F4], the alcohol company now works on a new business plan for the large-scale production of (1G) bioethanol [F1] [55]. However, despite the policy shift [F4], concrete market stimulation measures are still not in effect [F5]. Once again, Nedalco pleads for a long-term tax exemption [F7]. Within the context of this lobby, the promise of 2G technologies serves as important leverage, as in the intermediate period, Nedalco's venture in R&D on 2G ethanol has been extraordinary fruitful [F4] [55,68]. The national government shows interest, but does not readily respond [F4]. The project is halted [F1]; Nedalco restlessly awaits the disclosure of the future Dutch biofuels policy. Despite the absence of a clear and supportive national programme [F4], a variety of 1G initiatives commence from 2002 onwards [F1]; see Fig. 1. One of the most influential endeavours is initiated by a company named Solar Oil Systems (SOS). This small business starts off adjusting conventional diesel engines to PPO fuel 13 [F1], but in 2002, SOS expands its activities by preparing the construction of an oil mill. The project is supported by more than 25 partners, among them farmers, farmers' associations and local government authorities [F3] who are made shareholders [F6]. The company's downstream activities are covered by promoting biofuels to potential users [F4]. In order for the project to be financially feasible, SOS demands a tax exemption [F7] [97,98]; see Fig. 4. The government eventually agrees with the company's terms [F6]. The SOS network makes sure that multiple system functions are realised simultaneously [99], which results in a positive spinoff. In March 2005, the first Dutch oil mill is completed; the oil is delivered mainly to fleet vehicles of the provincial government. This success triggers a large number of events: from 2002 onwards, entrepreneurial projects [F1] are initiated throughout the country, most specifically in rural areas; see Fig. 1. The oil mill is often mentioned as an example [F4] [100][101][102][103]. Once again, it is the regional authorities and entrepreneurs-this time supported by a European directive-that drive the BFTIS forward. The rural developments are complemented by the initiation of the Energy Valley cluster [F3] [104]. This cluster strives for the alignment of public investments with local economic interests [F4, F7]. A remarkable trend that emerges is a counter movement formed by the oil industry, environmentalists, and academia [101,105,106]; see the negative peaks in Fig. 3 and 4. The controversy around 1G and 2G seems to increase. However, at the same time there is a stronger Guidance of the Search for 1G biofuels than ever before. Moreover, there is an increasing support, both in terms of Guidance of the Search and in terms of Support from Advocacy Coalitions, for biofuels in general. The choice for 1G or 2G biofuels was first presented as a conflict of opposites, but now it seems that the BFTIS actually supports the co-existence of the technologies.",
            "A market in distress (2006-2007)": " With oil prices rising, biofuels are becoming an ever more important subject of energy policies, not only in the EU but worldwide [37]. A drawback is that, with market diffusion of (1G) biofuels taking off globally, the resistance to biofuels is growing at the same time. The controversy becomes greater when studies show that the increased land-use for energy crops-for 1G and 2G alike-results in rising food prices and in the deforestation of vulnerable natural areas like rainforests [108]. In the Netherlands the EU directive is translated into national policies [F4]. 2006, a generic tax exemption is issued (as a temporary measure), which is replaced, in 2007, by a scheme of obligatory blending [F4, F5]. The scheme obliges oil companies to sell biofuels as an increasing share of their fossil-derived fuel sales; from 2% (on an energy basis) in 2007 to 5.75% in 2010 [109]. In addition, to promote R&D on 2G biofuels a 60 million \u20ac subsidy programme, specifically directed at 2G biofuels production pilots (IBB), is introduced for 2006-2014; with 12 million \u20ac allocated for 2007 [F6] [110]. 14As the result of these supportive policies, the number of business start-ups increases [F1]. Biofuel plants (1G) and logistics facilities are being built in Rotterdam harbour [108]. A positive effect of the biofuels market that has been created, is that entrepreneurs no longer have to lobby for subsidies [F7]. Instead, successful businesses breed even more start-ups without the need for specific government interventions [F4] [108]. An exception is formed by entrepreneurs aiming for the further development of 2G technologies. The 2G biofuels are, as yet, not developed far enough to be commercially viable [37]. The support for R&D, and the anticipated market, induces a number of companies, like Shell and Nedalco, to invest resources [F6] in 2G technologies R&D [F1, F2]. Also, plans are made, most notably by Nedalco, for the construction of 2G pilot plants. These initiatives are, however, largely dependent on government funding, and the resources allocated are marginal [F6]. Indeed, they are comparable to what was available within GAVE and this turned out to be insufficient at the time. But now that there is a market, Nedalco continues its course of activities in much the same way as it began, by lobbying the government for a large subsidy [F7]. According to the latest information, the company was granted a subsidy for the building of a 2G pilot plant, but is currently (2008) uncertain whether these plan will be realised [108]. Despite the strong position in terms of Knowledge Development, entrepreneurs are generally hesitant to initiate Entrepreneurial Activities. The problem in general, for potential 2G biofuel producers, is the uncertainty of the biofuels market [F5]. After all, it remains to be seen whether 2G biofuels can eventually compete with 1G biofuels [F4]. This uncertainty is the more striking in the face of cheap imports from Brazil and Eastern Europe. In fact, even 1G biofuel producers have a hard time competing with the biofuel imports [F4, F5]. This is a reason for some entrepreneurs to call for protectionist policies in the biofuels trade, especially since some of the imported biofuels are deemed 'unsustainable' [F7] [108]. The latter point relates to a more stringent issue: a renewed rise of the biofuels controversy. With the increasing market diffusion, scientists and environmental organisations have continued to stress that biofuels are not a solution but a problem [F4, F7] [111,112]. Their distress calls are heard by politicians and the Dutch government picks up on this by falling back on the original distinction between 1G and 2G biofuels, although it is a more fine-grained distinction this time around. A system of sustainability criteria is developed that should allow policy makers to incorporate the CO 2 -reduction potential and land-use of particular biofuel chains [F4] [113]. The most recent development is that a debate has started, on the EU level, about the question whether the biofuels directive should be adjusted to take into account such sustainability criteria. Dutch policy makers have a large say in this discussion since they have already started to develop sustainability criteria, as a response to the early rise of a biofuels controversy in the Netherlands [F4, F7] [108].",
            "Reflections": " The event history analysis has allowed us to conceptualise the development of the BFTIS in terms of system functions. Occurrences of cumulative causation have been pointed out, in the form of three motors, and particular drivers and barriers related to these motors have been revealed. In this section we will answer our research question: How did innovation system dynamics influence the formation of a Dutch biofuels innovation system from 1990-2007? This section also outlines strategic implications for policy makers and entrepreneurs.",
            "Lack of continuity": " As we have seen, cumulative causation mostly emerged where entrepreneurs started deliberately to shape the BFTIS. Notable examples are the boating companies and an ethanol producer, initiating an Entrepreneurial Motor, and the recent successes around 1G biofuels, triggering a Market Motor. Furthermore, the GAVE programme initiated virtuous dynamics in the form of an STP Motor. However, our analysis has also shown that these motors often came to a halt. As a result, there has been little continuity in the development of the BFTIS. The absence of follow-ups to Entrepreneurial Activities played a key role. This was illustrated by the isolation of the early adoption experiments with public transport, the termination of Nedalco's expansion plans, and the failure of GAVE to realise demonstration projects. Recurring barriers were the absence of Market Formation and the general lack of a consistent Guidance of the Search by the national government, both of which could have been overcome with more dedicated policies. Also entrepreneurs could have made a stronger point for the support of virtuous dynamics, as will be discussed below. In general, our case shows that the fulfilment of various system functions is important and that during the build-up of system function fulfilment, various forms of cumulative causation-motors of innovation-play a role. Ideally, these motors coexist, but more realistically, they will gradually emerge and follow up on each other to provide 'step by step' increases in functionality of the TIS. For instance, a motor exclusively driven by subsidised R&D may pave the way for a market-based motor phasing in later. The challenge for policy makers and entrepreneurs is to be aware of such possibilities, to facilitate the necessary underlying interactions, and to be flexible, yet enduring, in response to unexpected shifts.",
            "The linear model of innovation": " The strength of a systematic and consistent policy approach is shown by the main success of the Dutch biofuels policy: its impulse to R&D developments around 2G biofuels via the GAVE programme. The resulting technical successes were internationally appreciated. However, as soon as the national government decided that biofuels were to be supported, its strategy was to initiate exclusively Knowledge Development among incumbent industry networks. The orientation was on lab-scale Knowledge Development whereas Market Formation activities were absent. The failure of GAVE to start demonstration projects can be ascribed to the absence of such complementary system functions, mostly Guidance of the Search and Market Formation. As a result, the 2G projects were a technical success, but turned out to be economically infeasible. The general lesson to draw from this is that the linear model of innovation is still operational today. the sole purpose of a governments is to boost R&D, the other activities of the system are neglected, meaning that potentially powerful feedbacks remain absent.",
            "A controversy": " The absence of a broader scheme of national support can be related to the controversy on whether 1G biofuels have the potential to contribute significantly to a sustainable mobility domain. Environmental organisations, academic scientists, and oil companies have pressed officials on the national level to refrain from support, whereas entrepreneurs and farmers have stressed the opportunities for economic growth and environmental gain. As a result, the great variety within the BFTIS has become the driver of a conflict that continues today. This conflict is mirrored in the realisation of various system functions, mainly in Guidance of the Search and Support from Advocacy Coalitions. The conflict is largely caused by the fact that the national government has not taken a clear stance. On the one hand, project-specific tax exemptions were issued, thereby fostering the 1G biofuels, while, on the other hand, the government increasingly adhered to arguments of the counter lobby, promoting 2G fuels. The other side of the story is that entrepreneurs and scientists did not adhere to a joint cause, rendering a conflict almost impossible to avoid. The result was that when the EU directive was issued in 2003, the TIS was hardly developed enough to diffuse biofuels into the market. Perhaps excluding alternatives from support is sometimes justified. In the case of emerging technologies, however, it can be argued that such choices are unwise as technological performances are as yet uncertain. Moreover, the emergence of motors depends on the preservation of variety within the TIS. The implication for entrepreneurs and other private actors is to bury the hatchet with respect to their mutual disagreements and to join forces. Only by 'running in packs' can they increase their chances of establishing a foothold within the incumbent mobility domain; cf. Van de Ven [34]. A joint effort would also contribute to the construction of a shared vision. This would serve as a beacon for policymakers in search for a consistent policy framework. The challenge for policy makers is then to refrain from selecting technologies altogether, and, instead, to build and facilitate an environment consisting of actors and institutions aiming for inclusion.",
            "Levels of government authority": " The development (and policy) of biofuels has largely been the result of European pressure. The Dutch government was-for numerous reasons-not particularly inclined to respond to European signals. A striking outcome of our analysis is that it was mainly small entrepreneurs, collaborating with farmers' associations, providers of public transport, and provincial fleet owners that picked up these incentives. Also the (regulatory) Guidance of the Search, Resource Mobilisation, Market Formation, and much of the Knowledge Development relevant for the entrepreneurs was provided by public authorities on the level of regions and provinces. Of the three motors identified, national policy only played an initiating role in one of them-the STP Motor. The other motors were generally hampered rather than supported by the national government. This observation can be related to the more general discussion on globalisation, and the simultaneous regionalisation, of knowledge-based economies. Despite the importance of a nation as a politico-economic entity, one cannot deny the increasing importance of global and regional innovation processes. A theoretical implication is that a TIS analysis may benefit from a more systematic analysis of the European policy level; this way factors that are now considered exogenous may appear as part of the endogenous dynamics. A practical implication is that the policy maker at the national level does not necessarily have to be a prime mover. In fact authorities and entrepreneurs at the local level could well take the initiative. A case in point is the fact that the more influential motors (the Entrepreneurial Motor and the Market Motor) both started off as 'Europe-driven' regional developments. National government could have backed up these developments by targeting the system functions that were yet poorly developed.",
            "Summary": " In short, the formation of a TIS requires that multiple system functions are increasingly fulfilled by a broad group of actors, consisting of governments and entrepreneurs alike. Within the Dutch BFTIS the conditions have not been very supportive for this to happen. With conflicting views by entrepreneurs, environmentalists and scientists, and with the national government hampering most system functions, the emerging motors have largely failed to develop. Only recently has the European biofuels directive resulted in the creation of a market for biofuels. This seems to have triggered virtuous dynamics within the BFTIS, both among entrepreneurs and policy makers, although the biofuels controversy still rages on and the future of the BFTIS seems more uncertain than ever.",
            "Concluding remarks": " We started this paper by expressing the need for increased insight into the formative stage of innovation system development, particularly in order to be able to support sustainable energy innovations. We adopted the TIS framework and argued for a focus on system functions. By analysing and evaluating the development of biofuels in the Netherlands, we illustrated how the build-up of system functions can be conceptualised and measured over time. Our study empirically confirmed the importance of dynamics, and offered insights into the influence of various motors of innovation that contributed to the build-up of a TIS. Our case study revealed three motors that supported biofuels development in the Netherlands; an Entrepreneurial Motor, a Science and Technology Push (STP) Motor and a (promising) Market Motor. The STP Motor involved research and development guided by a government programme. The Entrepreneurial Motor was initiated by entrepreneurs pushing government to support them. The promising Market Motor was driven by positive expectations and policies directed at the formation of a mass market. What does this add to the existing innovation systems literature? First of all, our approach allows for a fruitful combination of quantitative and qualitative analysis, that is fit for recognising and interpreting historical patterns. In our case study we systematically pointed out how system functions developed and interacted. The motors and their effects, spanning a long period of time and covering a broad variety of activities, could not have been identified by using a more traditional approach, such as a patent analysis or a formal network study. Nor could such dynamics have been found by describing and comparing institutional setups for different innovation systems. Second, our approach offers advantages with respect to the integration of empirical and conceptual work. With event history analysis, case studies can be conducted in a systematic way, with the list of system functions serving as a powerful heuristic framework. By focussing on events, clustering them in event types, and then (indirectly) attributing them to system functions, a 'self-fulfilling prophecy' bias is prevented. This is important as the system functions, as concepts, are still in the process of being validated. If more case studies are carried out in this way, then the dynamics of different TISs can be compared, leading to a more general insight into what system functions matter, and into the types of motors that (may) occur. This way, eventually, this empirical approach has the potential to make a strong contribution to a better theoretical understanding of innovation system dynamics. Our approach provides a new perspective on energy and innovation policies. Instead of targeting mainly the supply-side (R&D programmes) or the demand-side (market creation policies) of the innovation chain, it stresses the systemic nature of technological change. This means that policy instruments should contribute to the formation of new technological innovation systems, thereby increasing the success chances of new technologies. The set of system functions offers a heuristic model that indicates the most crucial policy targets. If a particular system function is lacking, attention should be paid to it. In more advanced policy designs, the presence of motors should be monitored, and policy may then be directed at supporting these forms of cumulative causation. There are also implications for entrepreneurs active in an emerging technological field. Their chances of survival will improve when the innovation system develops further. Therefore they should be aware of innovation system dynamics and their pivotal role in contributing to motors. By running in packs, and organising themselves into alliances, they are likely to be more influential, and more successful in innovating."
        }
    },
    "10.1016/j.techfore.2012.04.005": {
        "file_name": "188 A dissent-based approach for multi-stakeholder scenario development",
        "title": "A dissent-based approach for multi-stakeholder scenario development -The future of electric drive vehicles",
        "abstract": "In this paper, we present a novel approach for generating scenarios in multi-stakeholder environments. In order to address one of the most imperative environmental and societal challenges related to mobility, we explore the future of electric drive vehicles (EDVs). Since many different stakeholders are involved in the socio-technological transition from internal combustion engines (ICEs) to EDVs, we present a dissent-based scenario development process, which uses the Delphi technique for data generation. In total, 140 experts from 15 stakeholder groups participated in this German-based survey and assessed controversial projections for 2030. Results reveal a considerably high degree of dissent. In order to cope with different viewpoints in the scenario development process, we utilize a novel 5-step dissent analysis for further insights into possible futures. Thus, we account for potential differences among stakeholder groups (step 1), the effect of a desirability bias (step 2), as well as the impact of outliers (step 3) and bipolarity (step 4) in the survey results. Finally, we identify different clusters of experts through latent class analysis (step 5). Based on the results of the dissent analysis, seven partially conflicting multi-stakeholder scenarios for the future of EDVs in 2030 are developed.",
        "label": "Mixed",
        "text": {
            "Introduction": " Mobility implies that an indispensable part of modern society and an ever increasing number of people around the world have access to technology-based means of individual mobility. Between the years 2000 and 2009, the total amount of motor vehicles increased by more than 25%, surpassing the one billion mark for vehicles worldwide [1,2]. At the same time, the mobility of people and goods is a significant economic factor in itself. The automotive industry has grown to become the single largest manufacturing sector in the world [3,4]. However, the current mobility system entails a variety of substantial challenges. These challenges encompass, among other aspects, problems such as noise exposure, land fragmentation, accidents, and air pollution. Road transport is one of the largest contributors to greenhouse gas emissions and more than 95% of the total external costs of mobility are caused by road traffic [4,5]. Therefore, it will be essential to transform the current mobility system in a way that social and environmental damage is limited. One of the key challenges on the path towards sustainable mobility is related to the internal combustion engine (ICE) [6] currently the worlds' dominant power train technology. Since engine technology is constantly evolving, ICEs have largely succeeded in advancing in step with social needs and expectations over several decades [7]. As a consequence, today's vehicles emit much lower levels of air pollutants than decades ago. Nevertheless, the transition towards more sustainable mobility formats Previous works also assessed the technological transition from ICEs to EDVs from a corporate perspective. Avadikyan and Llerena [39] proposed fourpartially conflictingstrategic rationales of investment efforts of firms producing hybrid vehicles, thus explaining the disparity of strategic postures within the automotive industry. Moreover, different facets of the future of EDVs, such as alternative fuels [40] and battery technology [14], have been investigated. Offer et al. [12] analysed costs for EDVs and ICEs and summarised that electric drive vehicles will have lower life cycle costs than ICEs by 2030. In addition, researchers have pursued various approaches to develop scenarios on the future of EDVs. Turton [41] quantitatively modelled a transition scenario until the year 2100. Drawing upon theoretical considerations of socio-technological transitions, van Bree et al. [42] developed four scenarios from ICEs to EDVs. Previous publications also conceptualized scenarios dealing with particular topics, such infrastructure requirements [8], and EDVs' impact on grid systems [43]. Table 1 summarises a selection of the most relevant research on future-oriented and EDV-related publications. Previous publications primarily dealt with rather narrow issues of the socio-technological transition. Despite being helpful in understanding single underlying mechanisms and challenges related to the socio-technological transition, they lack an integrated view of the transition that accounts for technological, political, customer-oriented, and industrial perspectives of the potential transition from ICEs to EDVs. Additionally, existing scenario research on the future of EDVs does not adequately account for the diversity of the stakeholders involved in the transition. However, former research on the scenario method has called for the integration of different viewpoints into the scenario development process to avoid invalid consensus among similarly thinking stakeholders [45][46][47]. By applying the Delphi method, we therefore make an initial attempt towards an integrated scenario analysis of the future of EDVs that accounts for the diversity of stakeholders and related opinions involved in the transition process.",
            "Methodology": " Since its establishment in civil research in the 1960s, the Delphi technique has become a widely-accepted research method [26,48]. It has frequently been applied by researchers to the mobility and transportation research domain [49][50][51][52][53]. The method is used most adequately in situations of high uncertainty that require a mixture of scientific evidence and social perception [54]. In applying the Delphi technique, we provide an anonymous and structured group communication process that allows experts to effectively deal with the complexity of the research area at hand [55]. Thereby, we are also able to capture different viewpoints on the future of EDVs and to quantify the dissent of the ongoing debate on the socio-technological transition from ICEs to EDVs. Moreover, the Delphi technique allows for the inclusion of a variety of different stakeholders affected by and involved in the socio-technological transition. We conducted this research project in 2010 and 2011. The project was funded by the Automotive Institute of Management at a German business school.",
            "Development of Delphi projections for the future": " Since the Delphi survey questionnaire is a central pillar for a study's success [56], we followed a structured design process in developing future theses (i.e. projections) to identify influencing factors considered to shape the future status of EDVs. Theoretical considerations indicate that socio-technological transitions inherit changes of both technology and the society the technology is embedded within [10,17,57]. By their very nature, technological transitions are characterised by a co-evolutionary process in which society or a complex subsystem of society changes [19]. To account for this co-evolutionary process, we identified four  [39] 2010 Clarification of the effect of technological uncertainties on the investment behaviour of firms during the transition process from ICE to HV Real options reasoning approach Offer et al. [12] 2010 Lifecycle cost comparison between different power train concept and scenario elaboration",
            "Sensitivity analysis": " Steenhof and McInnis [13] 2008 Impact analysis of three low-carbon light-duty vehicle technologies: electric vehicles, hydrogen fuel cell vehicles, and ethanol-fuelled vehicles System simulator Turton and Moura [44] 2008 Global analysis of the potential of vehicle-to-grid systems and their impact on global energy system Energy optimization model Turton [41] 2006 Elaboration of one sustainable automobile transport scenario Model-based calculations Segal [34] 1995 Development of forecasts for the market for EDVs in California Conjoint analysis dimensions of the socio-technological transition that served as thematic guidelines for the development of the projections: (1) technology, (2) policy, (3) user, and (4) market structure. 2In order to generate the projections, brainstorming sessions were held with a research team of four academics. Scientific databases (e.g. EBSCO, Emerald Insight, ScienceDirect, Datamonitor etc.) were intensely searched for influencing factors related to the future of EDVs. The resulting influencing factors (57 in total) were allocated to the four dimensions of the socio-technological transition. In a subsequent group discussion, the 25 key factors with the highest impact on the topic under consideration were selected for projection formulation. We transformed the influencing factors into short and provoking projections for the year 2030. According to Parent\u00e9 and Anderson-Parent\u00e9 [58], the higher the number of projections, the higher the likelihood of a reduced response rate and not properly completed questionnaires. Therefore, we set the threshold for the maximum number of projections at 15, which was estimated to represent an adequate time effort for participants. Subsequent pre-tests validated this estimate. Next, the author team consulted eight automotive industry representatives (six senior managers from four different German original equipment manufacturers, OEMs, and two senior managers from one German 1st-tier automotive supplier) as well as four political decision makers to assure that the projections were not ambiguous. As a final step, three academics, who did not belong to the author team, independently checked the projections for content and face validity (i.e. length, comprehensiveness, meaningfulness) [59] as well as reliability by pretesting the Delphi questionnaire since the clarity of the statements directly influences the reliability of the results [60,61]. The projections were then refined as necessary. In the following discussion, we will outline the final set of future projections according to the four dimensions of socio-technological transitions.",
            "Technology": " Challenges related to the battery technology form the nucleus of the factors that limit EDVs' marketability [62]. In its current stage of development, lithium-ion battery-propelled vehicles have an operating range of 150 to 200 km; while ICE-propelled vehicles have an average operating range of 300 and 600 km. Recharging lithium-ion batteries also requires a long period of time. In 2004, merely 50% of the material in rechargeable batteries was used for energy storage [63]. Projection 1. 2030: With respect to the triple bottom line (i.e. economic, ecological, and social value), battery-operated electric power trains have become the dominant power train concept. In addition, engineers have to consider the entire life cycle of batteries in the design process. Since battery material disposal is environmentally harmful, recycling and waste management counteract battery technology's marketability [62]. Moreover, largescale production of EDVs could potentially be constrained by limited resource availability, which reinforces the importance of recycling [64]. In contrast, some anecdotal evidence suggests that recycling of batteries is only a temporary challenge today on the path towards the marketability of EDVs and will be technologically and economically solved within the next years. Projection 2. 2030: The challenges of recycling batteries in electric drive vehicles have been overcome. Another hurdle for EDVs to overcome is related to the generation of electrical power from renewable sources [33]. Depending on the country-specific mix of energy generation, EDVs' total pollution might exceed that of conventional ICEs [7]. Regardless of the source of electrical power generation, increasing market penetration of EDVs will lead to an increase in the demand for electricity, which will impact the transmission and storage of electricity [62]. Projection 3. 2030: Energy for electric drive vehicles primarily originates from renewable sources.",
            "Policy": " The risks related to fossil fuels are one of the main political drivers for the technological transition from ICEs to EDVs. According to the International Energy Agency [65], the maximum rate of petroleum extraction (peak oil) was already reached in 2006. In addition, a great proportion of the world's fossil fuel reserves are located in politically unstable countries [41]. Past events, such as the oil crisis in the 1970s, have demonstrated that supply shortages of fossil fuels are not merely a fantasy of ICEs' opponents, rather a credible threat to the production and usage of ICEs. Due to EDVs' paramount potential in achieving de-carbonized mobility, political intervention can be observed on a global scale [42]. Recently, the German government passed a National Development Plan on EDVs, setting a goal of having 1 million electric vehicles registered in Germany by 2020 [66]. In order to achieve this target, the German government will provide \u20ac1 billion funding for research and development activities until the year 2013 [66]. Projection 5. 2030: Electric drive vehicles are available and used in the market primarily due to public authority intervention. Another important step on the path from ICEs to EDVs concerns battery power infrastructural requirements: Widespread and convenient refuelling facilities are needed to ensure the reliability of EDVs. This would accelerate EDVs' market diffusion [67]. In this context, previous research addressed the so-called \"chicken-and-egg problem\" or the dilemma of what as to come first [31,68]: According to this idea, potential customers would not be willing to buy EDVs without the proper infrastructure of energytanking facilities. However, suppliers, such as energy companies or automotive manufacturers, avoid investing in the establishment of EDV-related infrastructure without sufficient sales volume. Start-up funding initiated by the government could potentially resolve this dilemma. Projection 6. 2030: Comprehensive recharging infrastructure has led to a strong market diffusion of electric drive vehicles. At the local level, government authorities have established a variety of regulatory instruments related to access restrictions schemes (ARS) to improve the environmental conditions in certain cities [42]. Thus, many developed countries have established environmental zones in major cities to regulate the number and type of vehicles (i.e. low-emission vehicles) allowed to enter the city on a particular day, according to the level of air pollution. Recent events indicate that numerous cities are about to tighten urban access regulations in the near future [69]. Due to more restrictive urban access regulations, electric-propelled vehicles appear to have an advantage over ICEs long-term because of their low emissions [2]. Projection 7. 2030: In numerous cities, only local emission-free vehicles are permitted.",
            "User": " Anecdotal evidence and previous research indicate that most car users have a positive attitude towards EDVs [33,70,71]. One of the main reasons for customers' positive attitude towards EDVs is said to result from their image as being relatively environmentally-friendly in comparison to ICEs [72]. Despite car users' environmental concerns, previous research concludes that users are hardly willing to pay an extra premium for EDVs [15]. In order to assess the willingness to pay for EDVs in the future, we proposed the following projection: Projection 8. 2030: Users are willing to pay more for electric drive vehicles. Vehicle performance characteristics, such as horsepower, acceleration, and torque, are valued by car users [32,72]. Therefore, EDVs are not able to compete with ICE-propelled vehicles since EDVs only achieve 20% of the performance levels of conventional gasoline engines [73]. Although environmentally-aware individuals might be able to live without a \"high performance\" car, others are not willing to do so. Projection 9. 2030: ICE-propelled vehicles continue to dominate the number of car registrations. Car ownership not only merely serves as a means for individual mobility, but is also associated with a certain social status and standard of living [9]. However, the motorization rate in Western Europe is declining and there are signs suggesting that owning a car, as a form of status symbol, is also decreasing. The average motorization rate among young German men between 18 and 29, for instance, declined by 30% in the period from 2000 to 2009 [74]. At the same time, alternative vehicle usage, such as carsharing, is becoming increasingly popular [9,16]. Projection 10. 2030: Regardless of the technological advancements to electric drive vehicles, car ownership in general has become significantly less important. In the initial phase of its market diffusion, it is generally assumed that EDVs will primarily be used in urban areas since the distance range in inner cities is comparatively low [42]. When using EDVs for concepts like car-sharing as opposed to car ownership, for instance, the comparatively higher costs of purchasing and maintaining EDVs can be compensated. We summarise these ideas under the term \"multi-modal mobility\" in a broad sense, for instance an individual interested in joining a car-sharing service still needs to be mobile in picking up or after delivering the car: walking, biking, or using public transport. Projection 11. 2030: Consumers primarily use well-organised multi-modal mobility services (e.g. local public transportation, carsharing, railways).",
            "Market structure": " The technological transition from ICEs to EDVs encompasses more than a mere shift in power engines, it also affects other cars' subsystems, such as engine cooling components. Not only OEMs are investing large sums in new technologies, but also their suppliers and sub-suppliers. Battery-propelled vehicles represent a complex product system that affects other vehicle subsystems and value creation processes alike. For example, in order to reduce the weight of EDVs, the white body stage, or stage of production where only the metal parts of the car have been welded together, the seats, and body trims have to be re-designed [7]. Consequently, there will be major changes in value chain activities. With respect to battery technology, tremendous research endeavours are currently being conducted by the supplier network [72]. Projection 12. 2030: The establishment of electric drive vehicles has led to a considerable reduction of the share in value creation of original equipment manufacturers (OEMs). The area of after-sales services might also be affected by the technological transition. The maintenance requirements for EDVs, for instance, are likely to be significantly different than for ICEs. Moreover, new skills are required to deal with high-voltage batteries. Projection 13. 2030: The structure of the after-sales market has changed significantly with the establishment of electric drive vehicles. Since car manufacturers previously focused on designing and mass-production of ICEs [7], these car manufacturers have not been able to invest sufficient time and effort in EDV-related technologies. Patent analyses support this speculative impression: The number of patents for ICEs compared to EDVs after 1990 was still higher [72,75]. As a consequence, new innovative actors will emerge and potentially vitalize global competition. Projection 14. 2030: New market participants shake up the automotive industry significantly. Contrary to new automotive companies in the Western Hemisphere, Asian competitors are gaining visibility in EDV-related areas. The Chinese government, for instance, developed a programme worth 10 billion Yuan to position its automotive companies at the forefront of the EDV movement. At the same time, Western OEMs are preparing for the socio-technological transition with considerable investments and skill developments. Projection 15. 2030: Asian car manufacturers dominate the worldwide market for electric drive vehicles.",
            "Expert selection and Delphi survey procedure": " Selecting appropriate experts is of paramount importance for the reliability of Delphi research results [76][77][78]. Although literature does not stipulate strict rules concerning panel size, we aimed to include at least 100 experts in the Delphi survey in order to attain a comparatively large data set and collect diverse opinions of the socio-technological transition from ICEs to EDVs. We aimed to include all related stakeholder groups and their diverging perspectives on the future of EDVs. By means of desk research and expert consultation, we identified 15 interest groups, which can be summarised in three major stakeholder groups: industry (IN),3 society (SO), and academia (AC). In doing so, we allude to the theoretical notion that socio-technological transitions are advanced or impeded by various stakeholders: no single actor can ultimately induce transformation processes [79]. To identify appropriate experts, participation lists of EDV-related conferences were screened, desk research was conducted, and existing industry contacts of our university were targeted. The following criteria were applied for expert selection [80]: (1) knowledge and experience of the issues under investigation (2) capacity and willingness to participate (3) sufficient time to participate (4) effective communication skills In total, we identified 421 experts, who met these criteria. After expert identification, candidates were contacted via telephone. Those who agreed to participate were subsequently sent individualised emails explaining the scope and purpose of the research endeavour. We chose a real-time Delphi survey variant to streamline the survey process, thus enhancing data validity by minimising research fatigue and panel mortality [26,27,81]. To ensure anonymity throughout the survey process, participants were randomly equipped with personalized hyperlinks. Once hyperlinks were activated, experts were forwarded to an online Delphi platform. Within the scope of the research, experts assessed the projections in terms of expected probability of occurrence (EP), impact on the industry (I), and desirability of occurrence (D) for the year 2030. Experts were asked to rate the expected probability on a metric scale ranging from 0 to 100%. Additionally, experts evaluated the impact and desirability of occurrence for each projection related to the automotive industry's environment on a 5-point Likert scale ranging from 1 (very low) to 5 (very high). For all three categories, experts could voluntarily submit qualitative arguments to justify their assessment and to enhance the information quality [82,83]. After evaluating each projection individually, the statistical group opinion was calculated and provided in real-time, thereby each expert had the opportunity to immediately review, refine, and revise first round answers. At the end of the survey, participants were forwarded to a summary portal for an overview over the participants' assessments of all future projections. During the three month survey period, experts were allowed to re-access the Delphi portal via the summary portal at any point in time to keep abreast of the ongoing discussions and to review own assessments in light of new comments and statistics.",
            "5-step dissent analysis based on Delphi": "",
            "Stakeholder groups and aggregated results": " In total, 140 experts participated in the survey (response rate of 31%). To account for a potential non-response bias, we compared assessments of early and late respondents of the survey, assuming that late respondents demonstrate characteristics of non-respondents [84]. We split participants into two groups and conducted a Mann-Whitney test to compare the differences in responses (both first and final assessment). The results revealed no significant differences between both response groups. Thus, we conclude that no significant non-response bias was present. Table 2 summarises the participants in the Delphi survey. The industry stakeholder group included 85 members accounting for 61% of the whole sample, the academia stakeholder group had 30 participants (21%) and the society stakeholder group comprised 25 participants (18%). With 27 experts, the largest sub-group of the panel was automotive suppliers (19%). Overall, 24 Delphi participants (17%) worked for original equipment manufacturers (OEMs), 13 were (9%) car dealers, 5 participants were employed by energy companies (4%), 4 worked for electric driven vehicle manufacturers (3%), 3 were vehicle fleet providers (2%) and 3 were employed by infrastructure providers (2%). Approximately 16% (22 participants) of the Delphi participants were representatives of universities and institutes, 5 participants were academic advisors (4%) and 3 participants were market researchers (2%). Approximately 10% of the participants were active in the German government: seven participants came from German political parties and seven were representatives of large and medium-sized lobbyist groups (each 5%). Six journalists (4%) and 5 representatives from non-governmental organisations (4%) also participated in our study. Moreover, the consumer perspective was considered by including participants form market research. Given the high number of experts and heterogeneity of stakeholders involved, we draw from a solid data base for the elaboration of multi-stakeholder scenarios. Experts logged into the survey portal several times during the Delphi survey process to track and possibly adopt their assessments. On average, each expert returned 2.4 times to the Delphi portal during the survey process and provided more than 11 arguments, which proves the participants' interest in the research project. As standard deviations decreased for all projections from the first to the final assessment, convergence in expert opinions was observeda classical phenomenon in Delphi studies. In line with previous research [27,85,86], we considered interquartile ranges (IQR) less than 25 to represent agreement of opinion among experts for EP estimates. For the dimensions of impact (I) and desirability (D), we regarded IQR 1.25 as a maximum to represent consensus as IQR = 1.25 corresponds to 25% of the 5-point Likert scale. Table 3 summarises both initial and final assessments of the Delphi survey. As depicted in Table 3, the panellists consider the occurrence of Projection 4 (oil-related risks) as fairly likely (average EP estimate: 79%). In contrast, the EP of Projection 1 was considered to be unlikely by the year 2030 (average EP estimate: 28%). The remaining projections were assessed with an average EP value between 40 and 65%, indicating that the panel was rather uncertain about the expected probability of occurrence. As demonstrated by IQR scores between 26 and 46 and standard deviations between 22 and 29, the final assessments of the expected probability had a broad range. For the EP estimates, experts disagree on all 15 projections. In addition, the impact dimension of three projections are marked by an IQR greater than 1.25 and dissent is even more prominent for the desirability dimension (desirability's IQR greater than 1.25 for seven projections). In summary, the Delphi panellists merely agreed on more than one evaluation category for 6 out of 15 projections. We use this assessment as the basis to define projections with consensus, this means our panel reached consensus in 2 out of 3 dimensions (EP, I or D) in the evaluation of the projections. Given the widespread dissent, deriving multi-stakeholder scenarios directly from the aggregated Delphi results appears problematic. As a consequence, the usability of such scenarios by stakeholders involved in the transition may be limited. In order to increase the informational substance of the multi-stakeholder scenarios by integrating the diversity of opinion, we therefore address the observed dissent in greater depth in the following sections. More specifically, we adhere to a 5-step dissent analysis approach, as illustrated in Fig. 1, in order learn to determine the root of dissent. Previous research has demonstrated that feedback-based judgements are less exposed to cognitive and personal biases than initial assessments and that participants develop a stronger rationale and confidence [87] for their decision after being provided with aggregated group feedback [88]. In addition, the feedback tends to harmonize the informational basis for all panellists, thus potentially contributing to the reduction of uncertainty in assessment behaviour. Therefore, we use final projection assessment as the basis for the dissent analysis.",
            "Stakeholder-group analysis": " Given the complexity and multifaceted character of the topic at hand, the diverging interests of the panellist may cause dissent. According to Geels [17], socio-technological transitions are characterised by group struggles and tensions among different societal groups. Industry experts, for instance, might have a more discriminative mindset regarding EDVs than academia or society due to their daily work. There is anecdotal evidence that experts of the automobile industry, who have many years of experience in calibrating and optimizing ICEs, tend to be less open to socio-technological transitions than academia or society [7,72]. One might also speculate that experts acting in politics and associations consider socio-technological transition towards EDVs more desirable than other stakeholder groups, particularly because of EDVs' potential to reduce external costs of mobility. We tested the projection assessments to determine significant differences among the three major stakeholder groups. Since the data is not normally distributed, we applied the nonparametric Mann-Whitney-U test (see Table 10 in Appendix A). The evaluations reveal significant differences in some cases. For instance, the society group indicates higher desirability for using wellorganised multi-modal mobility services than industry representatives (Projection 11). Due to the partially significant differences among the three stakeholder groups, we checked for intra-group consensus. The results demonstrate that the stakeholder groups reached consensus for certain projections: industry experts agreed on EP assessment of Projections 4 (oil-related risks) and 5 (state intervention) (IQR = 20 for both projections); academics agreed on EP assessment of Projections 1 (dominant power train EDVs), 4 (oil-related risks), and 14 (new players) (IQR = 24 for all three projections); and the society stakeholder group agreed on Projections 4 (oil-related risks), 12 (decreased value creation), and 13 (after-sales-markets) (IQR= 20 for both projections). Intra-group consensus was achieved for the impact category: except for the society stakeholder group assessment of Projection 1 (dominant power train EDVs), intra-group consensus was reached for all other projections. In conclusion, significant intra-group effects were detected and intra-group consensus was reached for numerous projections on EP estimates (Industry: 2-5, 9 and 11-15; Academia: 1-5, 8-9 and 12-15; Society: 2-4, 9, and 11-15). In contrast, the stakeholder group analysis did not result in the resolution of dissent for the desirability dimension. Stakeholder-group analysis 1 2 3 4",
            "Desirability bias analysis": " The occurrence or non-occurrence of dissent can be affected by the desirability of a projection. The so-called desirability bias can cause experts to judge the probability of desirable (undesirable) projections higher (or lower) than experts that perceive those projections as neutral [88]. Rowe and Wright [82] revealed that such a negative effect may not be eliminated through the Delphi procedure itself. Thus, a Delphi expert might assess a projection as being more probable if he desires its occurrence. For Delphi research, it is therefore advisable to measure the potential desirability bias and its influence on the Delphi projections' assessments. Such an analysis helps the Delphi facilitator to enhance the decision base. In our research at hand, we analysed the potential desirability bias in order to examine the possible influence of dissent or panel consensus on the data. Differential desires in our heterogeneous sample could cause probability estimates to diverge and impede the achievement of a 'true' consensus. Therefore, we followed a post-hoc procedure proposed by Ecken et al. [88] in order to calculate adjusted probability estimates and interquartile ranges as well as the interquartile range change. In the post-hoc procedure, we adjusted the (average) probability of occurrence of each Delphi projection for the correlation between the experts' desirability and probability (if the correlation is significant; see [88] for details). The adjusted values for both final EP and IQR are reported in Table 4. By considering the desirability bias, consensus was achieved on Projections 1 (dominant power train EDVs) and 4 (oil-related risks). In total, interquartile ranges decreased for 12 projections, increased for three projections (recycling, renewable energy and willingness to pay), and remained unchanged for one projection (decreased value creation). The effect of the desirability bias is particularly high for four projections, for which the final EP score changed by more than 10%. The analysis revealed that experts' assessment of Projections 9 (dominance of ICEs) and 15 (dominance of Asian players) were affected considerably by their undesirable nature (increase of EP value: 10%). On the contrary, the adjustments for Projections 3 (renewable energy) and 2 (recycling) resulted in a decrease by 16 and 11% respectively, demonstrating the desirable nature of the two projections. In essence, accounting for the desirability bias resolves the dissent of two projections (dominant power train EDVs and oil-related risks).",
            "Outlier analysis": " Another potential explanation for the dissent may lie in the existence of outliers, which can bias the average score and inflate standard deviations [89]. To account for potential outliers, we transformed final values into standardised z-scores and analysed these for the acknowledged threshold of 2.58 (absolute values). It is generally assumed that if more than 1% of the data is located above this limit, potential outliers might affect average results [89]. This limit is only exceeded by Projection 1 (dominant power train EDVs; 1.4%). Therefore, we excluded all data points exceeding the threshold of 2.58 (2 data points with EP assessment of 90) and re-calculated the value of IQR. The IQR value for Projection 1 (dominant power train EDVs) remained unchanged. Consequently, accounting for outliers does not affect the dissent of our Delphi results.",
            "Bipolarity analysis": " An additional explanation for the dissent of future projection evaluations potentially stems from a bipolar data distribution [86]. Average dissent-marked EP estimates between 40 and 60 might result from two opposite groups that assessed probability estimates both with a high score (EP larger than 60%) and a low score (EP smaller than 40%). Likewise, dissent for the assessment categories \"impact\" and \"desirability\" might also result from a bipolar data distribution. We analysed histograms of all 45 evaluation categories (15 projections with 3 evaluation categories each) as a first approach to detect bipolar data distribution. Bipolarity was not observed for any evaluation categories. According to Scheibe et al. [86], bimodal distribution potentially indicates an important difference in opinion. Therefore, we additionally spotted modes of final values to assess whether the projections exhibit bimodal distribution (see Table 5). As depicted in Table 5, the assessments of Projections 4 (EP) and 10 (D) show two modes. Both modes are located above 50% for the EP estimates of Projection 4 (oil-related risks). This projection has, as already addressed in Section 4.1, a high average probability of occurrence and does not fall within the average EP range of 40 to 60. With respect to Projection 10 (car's loss of significance), the two modes lie directly near each other (D = 2 and D = 3). Therefore, a bipolar distribution towards the scale ends cannot be observed. In summary, dissent among the Delphi participants is not driven by broad bipolarity of our data. The dissent of the projections can partially be resolved by the previously conducted analyses. However, two out of 15 projections (6 and 10) are neither characterised by partial intra-group consensus nor does the consideration of the desirability bias result in an agreement of opinions (IQR for EP estimates below 25). Thereby, the results indicate that the dissent cannot be explained by the previously conducted analyses. By identifying distinct types of experts via latent class analysis (LCA), we therefore aim to dissolve the dissent in Projections 6 (recharging infrastructure) and 10 (car's loss of significance) in the following section.",
            "Latent class analysis": " Compared to conventional clustering approaches, LCA offers several advantages that are relevant for the purpose of dissent dissolution. First, LCA builds on statistical models and is thus less arbitrary than ad-hoc measures used in traditional clustering approaches [90]. Formal tests can be used to check the validity of the model and researchers are equipped with statistical criteria to make decisions about the number of clusters. Second, and in contrast to standard hierarchical clustering approaches that use ad-hoc measures to determine homogeneity, LCA defines homogeneity in terms of probabilities and relies on a maximumlikelihood criterion to identify clusters [91,92]. This criterion allows for the determination of the posterior probability for each expert belonging to each cluster [93]. Due to its probabilistic clustering approach, LCA accounts for uncertainty in allocating experts to specific classes [90]. In allusion to Magidson and Vermunt [90], we define our latent class model through unconditional probabilities of belonging to each latent class and conditional response probabilities as parameters: \u03c0 efghijt \u2261 \u03c0 X t \u03c0 A EP =X et \u03c0 A I =X ft \u03c0 A D =X gt \u03c0 B EP =X ht \u03c0 B I =X it \u03c0 B D =X jt \u03c0 t X refers to the probability of belonging to latent class t = 1,2,\u2026T of latent variable X. Manifest variables A EP to B D denote the Projections 6 (recharging infrastructure) and 10 (car's loss of significance), which are specified for the assessment dimension of expected probability (EP), impact (I), and desirability (D) with subscribed abbreviations. Accordingly, \u03c0 et AEP/X refers to the conditional probability of getting e-th response to variable A EP from members of class t, e = 1,2,\u2026100; \u03c0 ft AI/X , f = 1,2\u20265, describes the conditional probability of getting f-th response for variable A I and \u03c0 gt AD/X , g = 1,2,..,5, for variable A D . We assume that a specific number of assessment behaviour exists for the projections and that experts can be grouped into a small number of clusters known as latent classes. We aim to determine the number of latent classes T that are sufficient to explain the relationships among the observable variables [86]. The hypothesis that all observations fall into one cluster, the T = 1 model, is the starting point of the analysis. \u03c0 efghij \u2261 \u03c0 A EP e \u03c0 A I f \u03c0 A D g \u03c0 B EP h \u03c0 B I i \u03c0 B D j The successive model (T = 2 model) assumes that all observations fall into either the first or the second class. This process continues until the model that fits the data most appropriately is found [90]. For data analysis, we used the software programme Latent Gold 4.0 [94]. Table 6 summarises the cluster models. Since there is no single method to determine the optimal number of clusters in LCA [93,94], we considered several common statistical indicators to identify the most adequate data-fitting models. The Bayesian Information Criterion is useful for assessing the goodness of fit for a model [95]. The most adequate number of clusters occurs when the value of BIC is at its lowest level [93]. Moreover, the likelihood ratio statistics (\"L 2 \") portrays a key statistical indicator [94]. The larger the value, the poorer the model fits the data and the worse the observed relationships are described by the specified model. Another method to judge the goodness of fit is to assess the percentage reduction of L 2 from the one-cluster model and to select the number of clusters from the model beyond which this reduction is regarded as minor [94]. In addition, the Consistent Akaike's Information Criterion (CAIC) is useful for assessing the goodness of fit for a model [90]. Dunn et al. [93] argue that the p-value of a cluster model should be larger than 0.05. Apart from statistical indicators, interpretability issues such as cluster sizes and characteristics should be taken into account when selecting a specific model [93]. In light of both statistical indicators and practicability issues, we selected the 3-cluster model for further analyses (see model marked bold in Table 6). Table 7 illustrates the model parameter estimates for each cluster. R 2 shows how well a parameter is explained by the model [94]. Wald statistics reveal that the model indicators of Projection 6 discriminate between the clusters in a statistically significant way (p b 0.05). The model indicators of Projection 10 discriminate between the clusters in a marginally statistically significant way (p b 0.10). Table 11 in Appendix B illustrates the conditional probabilities of the assessment behaviour based on the three clusters. The highest conditional probabilities (top 3) are marked in bold. The cluster sizes vary between 58 (cluster 1) and 8% (cluster 3).",
            "Cluster 1: car keepers": " It is very likely that the majority of experts assigned to the first cluster assume that the recharging infrastructure for EDVs will be in place by 2030. Experts assigned to the first cluster reveal a distinct desirability for the projection to become reality. However, cluster 1 members consider it rather unlikely that the car's general significance will have declined by 2030, which they assess with a comparatively low desirability score. Due to their positive attitude towards the recharging infrastructure and their negative attitude towards car's loss of significance, we label the first cluster \"car keepers\".",
            "Cluster 2: ambiguous attitude": " The overwhelming majority of cluster 2 members consider it as fairly unlikely that an appropriate recharging infrastructure for EDVs will be established by 2030. They also have a neutral attitude regarding the desirability of Projection 6 (recharging infrastructure). The probability distributions indicate that cluster 2 members are fairly uncertain about the significance of the car in 2030. As Table 11 in Appendix B depicts, the probability that cluster members assessed the projection with an EP score below 50 sums to 45%, while the probability that the cluster members assessed the projection with an EP score above 50 amounts to 44%. Despite cluster members' unclear assessment behaviour regarding EP estimates, they indicate desirability for Projection 6. Due to their evaluation pattern, which fluctuates between a negative and a neutral attitude, we label the second cluster \"ambiguous attitude\".",
            "Cluster 3: system changers": " Experts assigned to the third cluster reveal a rather optimistic attitude regarding the recharging infrastructure for EDVs by the year 2030. Furthermore, cluster 3 members believe that the significance of cars will decline, which they also assess with a high desirability score. We name the third cluster members \"system changers\" due to their optimistic approach to change. Based on probability membership estimates, we allocated each Delphi participant to a specific cluster and re-calculated the average results for Projections 6 and 10 for each cluster. As depicted in Table 8, intra-cluster consensus was reached for both projections in the first and the third cluster. In contrast, cluster 2 members did not reach consensus on both projections. Table 9 summarises the results of the dissent analyses.",
            "Multi-stakeholder scenarios for electric drive vehicles in 2030": " The results of the projections for which the expert panel agreed in at least two of the three assessment categories were used for the first level of the multi-stakeholder scenarios (see 2nd column of Table 9). Additionally, we allocated the results of these projections to the first level for which the consideration of the desirability bias resulted in consensus (Projections 1 and 4). In total, the evaluations of eight projections were used for the first scenario level. Since projections allocated to the first scenario level are marked by consensus for the entire panel, this level forms the basis of the multi-stakeholder scenarios (scenario 1). For the second scenario level, we grouped the results of those projections for which the stakeholder group analysis resulted in intragroup consensus (see Section 4.2.). Building on the differences of the stakeholder groups' assessments, we elaborated on three distinct stakeholder scenarios (scenarios 2a-2c). In summary, the evaluations of five projections were used for the second scenario level. For the third scenario level, the results of the latent class analysis in Section 4.6 served as the basis for data input. Drawing on the cluster-based assessments of future Projections 6 (recharging infrastructure) and 10 (car's loss of significance), we developed three partially conflicting scenario parts (scenarios 3a-3c). Fig. 2 depicts the three levels of the multi-stakeholder scenarios for EDVs in 2030 graphically. We abstracted the main quantitative and qualitative survey results for the final multi-stakeholder scenarios. The size of the box border surrounding the scenario text is in accordance with its importance (i.e. thicker border indicates greater consensus of opinion; thinner border indicates lower consensus). The scenarios on the second and third levels state alternative scenarios, which describe partially contradicting prognoses for EDVs. The bold dotted line connecting the three scenario levels indicates the scenario pathway most likely to occur for the majority of the sample. All scenario parts were checked for internal consistency and intuitive plausibility by three independent researchers. In total there are 7 scenario parts, which can be combined to form 9 different scenario paths, (e.g. 1 + 2a + 3a, 1 + 2a + 3b, 1 + 2a + 3c, 1 + 2b + 3a, etc.), because the parts on the different layers are independent from each other. Despite widespread dissent among experts, there are several aspects of the socio-technological transition for which a large proportion of the expert panel achieved consensus. For instance, agreement of opinion is observable for environmental pressure regarding market diffusion of EDVs. Most experts agree with the statement that the environmental pressure will have increased significantly by 2030. Moreover, consensus was reached on the regulatory mechanisms' impact on the industries involved in",
            "Increased environmental pressure and fragmented technological breakthroughs": "",
            "Industry: State acts as driver Cluster 1 : Car prevails = Size of text box border represents percentage of sample size": " The fact that many cities only allow for local emission-free vehicles to enhance life quality in urban areas has strongly affected the automotive industry. Considering the increased risks associated with oil and gas, involved actors push EDV's market diffusion. As a consequence, the proportion of value creation has declined among OEMs and services related to EDVs have undergone diverse changes. The challenges related to battery recycling have been solved and the energy for EDVs originates to a certain extend from renewable sources of energy. Despite fragmented breakthroughs, however, EDVs could not (yet) prevail as the sole powertrain technology. Major battery-related technological challenges such as energy storage could not be solved on a broader basis. Both Western and Asian car manufactures lead the car market.  the development and commercialization of EDVs. Furthermore, Delphi panellists agree upon fragmented breakthroughs in the technology-related areas. Moreover, there is consensus regarding the impact of EDVs' market diffusion on value creation proportions and services. Nevertheless, most experts do not consider it to be very likely that by the year 2030 EDVs will dominate the number of car registrations. While consensus can be observed in questions related to environmental and technological aspects, other facets of the socio-technological transition feature strong dissent. Therefore, the different stakeholder groups partially serve as a potential explanation for dissent. In scenario parts 2b and 2c, both society and academia picture the industry to take a leading role on the path of the sociotechnological transition from ICEs to EDVs. However, the two stakeholder groups disagree on which market participants will take the lead. According to experts from academia, new automotive players will primarily push the market diffusion of EDVs, while the society stakeholder group considers incumbent firms to be at the forefront of the EDVs movement. In contrast, industry experts envision public authorities to act as the main driver of major technological change (scenario 2a). Additionally, the assessments regarding future mobility behaviour demonstrate considerable differences among the stakeholder groups on the second scenario level. Thus, for scenario part 2c, which was based on the assessment of the society group, mobility behaviour will change in 2030. In contrast, scenario part 2b describes unchanging customer behaviours. Diverging opinions not only stem from different stakeholder groups, but are also partially due to unobservable, latent parameters. The projection regarding the future significance of vehicles (Projection 10) serves as a demonstrative example to illustrate the latent parameters. Thus, the scenario outlined in 3a envisions a continuing high importance of owning a vehicle in 2030. This scenario was based on the opinion of the majority of experts. In contrast, there is a minor group of experts that considers the car's loss of significance for 2030 to be likely, which provides the fundament for scenario part 3c. Based on the assessments of 33% of the experts, scenario part 3b, in turn, describes a more differentiated picture of the car's significance in 2030.",
            "Conclusion": " Theoretical underpinnings suggest that socio-technological transitions are either advanced or impeded by various stakeholders. Regarding the transition from ICEs to EDVs, we find that previous works lack the adoption of such a multi-stakeholder view which simultaneously accounts for the technological, political, customer-oriented, and industrial perspectives of the potential transition from ICEs to EDVs. By their very nature, socio-technological transitions are also characterised by tensions among different societal groups, since some stakeholders hope to gain or to take advantages, while others are afraid of losing power and influence [17]. Consequently, different stakeholders take diverging roles within socio-technological transitions and communicate theirsometimes controversialperceptions of a desired transition process [17]. Inspired by these theoretical considerations, we developed a set of thought-provoking projections that offers a multistakeholder view on the socio-technological transition from ICEs to EDVs. The results of the Delphi survey reveal a wide range of diverging opinions, resulting in a remarkable degree of dissent. Therefore, we attempted to shed light on the different perceptions via a 5-step dissent analysis approach. The results of the dissent analysis reveal differences of opinion among the stakeholder groups. In particular, the differences become apparent regarding the question which stakeholder group will lead the path of socio-technological transition from ICEs to EDVs. Additionally, the results of the latent class analysis illustrate differences in the assessment of the future importance of vehicle ownership. Drawing from the results of the 5-step dissent analysis, a set of partially conflicting multi-stakeholder scenarios for EDVs in 2030 were elaborated upon. Our dissent analysis allows for a more profound interpretation of diverging viewpoints in multi-stakeholder environments. For the field of EDVs, we were able to establish a rich data base for strategy and policy making. The scenarios need to be continuously discussed and addressed by all parties involved in order to jointly work in a common direction. The scenarios have pointed to the key dissent fields, which have already generated further debate. In particular, we derived four major directions for action for policy agenda. These topics are currently being elaborated upon in subsequent multi-stakeholder workshops and ongoing scenario exercises, such as on multi-modal mobility. The topics include: driving the technological advancement of new power train technologies, in particular the safety, reliability, cost and range of batteries; inspiring and creating customer enthusiasm for new power train technologies via driving experiences, etc. in order to accelerate early adoption of EDVs; establishing intelligent, multimodal solutions that lead to a paradigm change in the choice of mobility and increased collaboration among all involved stakeholders; and implementing reliable structures both short-term (such as supporting basic research) and long-term (such as offering consumers incentives to buy EDVsgovernmental and/or automotive industry) to encourage EDV market penetration. As with every research endeavour, our paper has some limitations. The key focus of this research was on the German automotive market. We surveyed a multitude of different stakeholders in Germany. Nevertheless, the projections were assessed against a global background. Future research could also focus on other country's perspectives on the future or might concentrate on a comparison of perceptions. In particular, a comparison of an Asian and Western panel might provide interesting insights. Another limitation is that we only covered the consumer perspective by including market research participants in order to focus on technological and infrastructural developments for EDVs. Including the consumer perspective might be an even more interesting research stream for the future. Moreover, we concentrated on relevant factors that ought to shape the socio-technological transition in the future. However, future research focusing on additional facets of the socio-technological transition is needed in order to more fully understand underlying mechanisms. Another notion is that as long as there is enough fossil fuel, even stakeholders involved in decisionmaking concerning alternative powertrain technologies might be hesitant to implement them. Future research could also focus on more concrete classification schemes for multi-stakeholder scenario analyses as well as success factors, impact analyses, and specific requirements for each stakeholder group. In our view, developing differing and partially conflicting scenarios based on detailed, dissent analysis meaningfully complements the scenario methodology. In doing so, this provides a reasonable approach to avoid overconfidence in the future [96]. At the same time and in line with previous research, we feel that integrating different viewpoints in the scenario development process avoids invalid consensus among stakeholders sharing the same thoughts and attitudes [45]. Thus, accounting for different viewpoints in the scenario development process enhances information substance and ultimately increases the usability of scenarios. "
        }
    },
    "10.1016/j.enpol.2010.03.073": {
        "file_name": "22 Policy stakeholders and deployment of wind power in thesub-national context",
        "title": "",
        "abstract": "As climate change mitigation gains attention in the United States, low-carbon energy technologies such as wind power encounter both opportunities and barriers en route to deployment. This paper provides a state-level context for examining wind power deployment and presents research on how policy stakeholders perceive wind energy in four states: Massachusetts, Minnesota, Montana, and Texas. Through semi-structured interviews, state-level energy policy stakeholders were asked to explain their perceptions of wind energy technology within their state. Interview texts were coded to assess how various drivers promote or hinder the deployment of wind power in sub-national contexts. Responses were dominated by technical, political, and economic frames in all four states, but were often driven by a very different rationale. Environmental, aesthetic, and health/safety frames appeared less often in the discourse. This analysis demonstrates that each state arrived at its current level of deployment via very different political, economic, and technical paths. In addition to helping explain why and how wind technology was \u2013 or was not \u2013 deployed in each of these states, these findings provide insight into the diversity of sub-national dialogues on deployment of low-carbon energy technologies.",
        "label": "Mixed",
        "text": {
            "Introduction": " Climate change mitigation in the United States requires fundamental changes in the way electricity is produced and consumed. In this context, renewable energy has emerged as an important component of a less carbon-intensive electricity generation system. Wind power is the fastest growing energy resource in the United States, at 42 percent of all capacity additions in 2008 (Wiser and Bolinger, 2009), but significant geographic variability persists in its deployment. The distribution of the wind resource is one factor influencing these disparities, but cannot fully explain the geographic differences (Toke et al., 2008). The complexity of wind deployment patterns becomes apparent when mapping the best wind resources over actual deployment. Six states (Texas, California, Iowa, Minnesota, Washington, and Oregon) accounted for 65 percent of nationwide new turbine installation in 2008 (AWEA, 2009). In contrast, the Great Plains states of Nebraska, South and North Dakota have some of the nation's best wind resources, but they make up only 4 percent of the total national installed wind capacity (AWEA, 2009). State-level energy policy such as renewable portfolio standards, siting policies, and mandatory green power programs have been shown to be correlated with wind deployment (Bohn and Lant, 2009;Menz and Vachon, 2006), although some states have seen little new deployment despite seemingly supportive policies (e.g., Massachusetts) and vice versa (e.g., Texas, Iowa). Neither energy policy nor the distribution of the wind resource fully explains state-variation in patterns of deployment. A highly complex socio-political context surrounds state-level decisions, policy, and discourse around energy technology development; understanding this context is critical to comprehending deployment of wind power as well as deployment of other emerging energy technologies. State level processes, institutions, and organizations are important forces influencing electricity generation and consumption across the United States (Rabe, 2004). Although federal energy policies outline broad directions for the U.S. energy system, states have historically been the main locus of influence on the electricity system. State legislatures have authority to pass statutes that shape the electric power industry, impact the relative use of different energy sources, target local economic development, and set environmental goals. Some state legislatures have paved the way for restructuring the electric industry (Mattoon, 2002). Public utility commissions permit the construction and expansion of power plants and transmissions lines, and -together with other agencies -monitor compliance with environmental regulations (Sautter and Twaite, 2009). In traditionally regulated states, commissions also set electric power rates. Various stakeholders at the sub-national level also have an informal influence on state policy adoption (Berry and Berry, 2007;Gray, 1973). The diffusion of energy technical innovations is also influenced by stakeholders (Bird et al., 2005;Breukers and Wolsink, 2007;Jacobsson and Johnson, 2000;Rao and Kishore, 2010). Energy technology development is embedded within various energy system institutions at the state level. Stephens et al. (2008) have proposed an integrated research framework, the socio-political evaluation of energy deployment (SPEED) framework, to facilitate a more nuanced understanding of the interconnected complexities of energy technology deployment. The SPEED framework provides a structure to explore interactions among socio-political factors influencing deployment, including regulatory, legal, political, economic, and social factors. The framework encourages multiple approaches to exploring these socio-political factors including policy review (Wilson and Stephens, 2009), media analysis (Stephens et al., 2009), and stakeholder interviews. Building on this structure, this paper uses the results of semistructured interviews with policy stakeholders to provide a comparative assessment of wind deployment in four states: Massachusetts, Minnesota, Montana, and Texas. It examines the state-level interactions among economic, political, technical, cultural-aesthetic, and environmental factors that have facilitated deployment of wind power in Minnesota and Texas, and hindered deployment in Montana and Massachusetts.",
            "Case study selection and context": " This research applies a comparative case study approach, which can be a powerful tool to study uncommon or multifaceted phenomena (Ragin and Becker, 1992;Siggelkow, 2007). Small-n qualitative studies are widely used in policy studies (Bennett and Elman, 2006;Mahoney, 2007). Cases that are negative for the outcome of interest are often included to assess whether ''disconfirming observations'' (Mahoney and Goertz, 2004: 656) exist that contradict hypothesized relationships. Here, we use a diverse case selection method to conduct a cross-case analysis of negative and positive outcomes of interest, since ''encompassing a full range of variation is likely to enhance the representativeness of the sample of cases'' (Seawright and Gerring, 2008: 301). Massachusetts, Minnesota, Montana, and Texas were selected because their contexts for wind deployment are very different and they exhibit variation in two important dimensions: (1) wind deployment and (2) policy status relevant to wind technology deployment. This variation enables a comparative assessment of the context in states where policy has been more or less effective and in states where other socio-political factors are important. Texas, Montana, and Minnesota each have a large on-shore wind resource potential while Massachusetts has a smaller, but still sizeable resource. Texas and Massachusetts also have an off-shore resource. An important number of policies relevant to wind technology deployment are in place in both Massachusetts and Minnesota, whereas Texas and Montana have fewer such policies. Montana and Massachusetts have relatively little installed wind power, but the wind energy sector is large and growing in Minnesota and Texas. Texas has a significant wind resource, particularly in the Panhandle area, and wind capacity is growing faster than in any other U.S. state (Wiser and Bolinger, 2008). At 9410 megawatts installed wind capacity in December 2009, it is the largest producer of wind energy in the United States (AWEA, 2009). Electricity prices are fairly high compared to other U.S. states and have helped wind power's competitiveness with other power sources. Minnesota also has a strong wind resource, in particular in the Southwestern part of the state, along the Buffalo Ridge. With an installed capacity of 1809 MW as of December 2009, Minnesota is the fifth largest wind power producer in the nation (AWEA, 2009). Of all U.S. states, Minnesota has the second highest penetration of wind power in the electric system, with wind generation providing 4.8 percent of all electric power in 2007, more than twice as much as in Texas (EIA, 2009c). Recent increases in wind capacity have been driven mainly by an agreement between the state and Xcel Energy (the power company that supplies 50 percent of Minnesota's electricity) over the storage of nuclear waste that involved a commitment to wind production. Wind deployment in Minnesota has also been supported by a commitment to community-based wind projects. In contrast, wind resources in Massachusetts and Montana have not been extensively developed. Of the four states, Massachusetts has the least installed wind power, currently only 15 MW (AWEA, 2009). The majority of the wind resource is located off-shore. 1 The Cape Wind Project, which was to become the nation's first off-shore wind farm, has ''faced tremendous political, social, and legal challenges'' (Phadke, 2010: 1) and is lodged in a lengthy permitting process as local residents have opposed the project on aesthetic, environmental, and economic grounds (Kempton et al., 2005). Likewise, Montana, a state with high wind power potential, has just begun to utilize its large resource, with only 375 MW capacity developed in December 2009 (AWEA, 2009). Much discussion of wind power development in Montana has focused on transmission, because as an electricity exporter Montana could potentially satisfy demand in nearby states that are ramping up their renewable goals.",
            "Methodology": " To evaluate socio-political differences and their impact on wind deployment, interviews were conducted with influential actors from each of the case-study states. While several other studies have examined public perception of wind power (Devlin, 2005;Firestone and Kempton, 2007;Wolsink, 2007), the goal of this research is to understand the perceptions of stakeholders who actively participate in shaping the policy and legislative processes that influence energy technology deployment at the state level. Analyzing the perceptions of experts who are deeply involved in policy and markets relevant to a technology differs from assessing public acceptance in its focus on institutional factors (Agterbosch et al., 2007). A diverse set of policy stakeholders that had taken part in state-level political activity related to energy technology policy were identified and solicited for interviews. The policy stakeholders were initially selected through searching state legislative committee testimony where energy bills were presented and discussed. Additional stakeholders were identified via snowball sampling 2 during the first round of interviews. A total of eighty-four stakeholders from all 1 Off-shore wind power is generally estimated to be 2-3 times more costly to develop than on-shore resources (Blum, 2009;National Academies of Science, 2009). 2 Snowball sampling consisted in asking interviewees for suggestions of additional policy stakeholders to interview. four states in various positions within the policy process were interviewed (see Table 1). The interview protocol can be found in the supplementary online material. Content analysis of the interviews was used to provide comparative insights on stakeholder perceptions of wind deployment. Content analysis helps identify patterns of meaning in qualitative data, especially when analyzing large amounts of text (Holsti, 1969;Krippendorf, 1980). We employed a priori coding (Creswell, 1998), meaning that our coding categories were developed from a theoretical foundation as opposed to emerging from the material (Stemler, 2001). In this approach, codes are prestructured from theory and refined during coding to ensure a high degree of exhaustiveness and mutually exclusive coding categories (Weber, 1990). Interviewees were prompted to speak broadly to challenges and opportunities of wind power, and responses were coded into theoretically predefined categories. Building on previous analysis (Stephens et al., 2009), we developed explicit guidelines for analyzing and assigning interview content to socio-political context and risk/benefit frames. Stephens et al. (2009) proposed adapting Luhmann's (1989) social function systems theory for analysis of the socio-political context of state-level energy deployment. In applying social function systems theory to ecological communication, Luhmann (1989) proposes that society's responses to environmental perturbations are structured by functional subsystems, with economy, law, science, politics, religion, and education playing key roles. Responses to system-wide issues such as environmental pollution can only be achieved through communication across multiple subsystems. Since each subsystem possesses its individual code (e.g., money in the economic system), and messages have to be translated across subsystems, responses to systemwide issues are encumbered and slowed down. A full assessment of any system-wide issue therefore requires systematic examination of the codes used to communicate its perception across all relevant subsystems (Peterson and Peterson, 2004). This analysis used social function systems theory to provide the systematic framework for analyzing stakeholder perceptions associated with wind technology. The codebook was developed based on six social function frames: aesthetic and cultural, economic, environmental, health and safety, political, and technical (see Table 2). Additionally, to differentiate patterns of negative and positive evaluations, risk perception served as a frame for evaluating and incorporating discourse on wind technology. The transcribed text of each interview was coded using QSR International's NVivo TM 8 qualitative analysis software, a textanalysis program that facilitates coding and quantitatively assessing large amounts of text. The unit of analysis was an ''utterance'' -a complete unit of spoken language -into which interviews were segmented as proposed by Hruschka et al. (2004). Because utterances do not have an equivalent in written language (Kurasaki, 2000), we used sentences as the proxy unit of analysis. Due to the complexity of both the codebook and the analyzed material, each interview was coded by two coders, who then compared their work to reconcile the interview into a single set of codes (refer to supplementary online material for a more detailed description of this method). The results were analyzed quantitatively by comparing the number of sentences coded in each frame and qualitatively by reviewing the content of the coded text.",
            "Coding results": " One out of four sentences was coded as relevant to one of the six frames, for a total of 4198 coded sentences. An overview of all coding frames, broken down by negative and positive coded sentences as a percentage of the entire interview material, is provided in Fig. 1.  Overall, the technical aspect of wind technology was mentioned in almost 9 percent of sentences, making it the most frequently discussed frame. Responses were almost evenly balanced between positive and negative categories. This indicates that technical challenges and opportunities take a prominent position in the framing of wind technology. The political frame was the second most commonly referenced frame, closely followed by the economic frame. In both of these categories, the interview texts included more positive than negative comments. The environment and aesthetic frames were discussed much less frequently. The former was roughly balanced between positive and negative responses, while the latter was more negative than positive. The health frame was only mentioned twice, indicating that potential health benefits or risks from wind power do not emerge as salient issues in any of these states. When broken down by state, substantial differences in stakeholder perceptions of wind power emerge from each frame (Fig. 2). The technical frame captures aspects of the technology related to a state's resource base, electricity infrastructure, and research potential. Within the technical frame, on the positive side, wind energy was seen as having substantial ''resource'' and ''promise.'' On the negative side, problems with transmission capability and intermittency were mentioned most often. Based on the aggregate numbers, policy stakeholders' discussions appeared relatively balanced between positive and negative aspects of technology. On average, positive comments outweighed negative comments in Massachusetts and Minnesota, while stakeholders in Montana and Texas had more negative comments. This simple comparison of the number of comments does not reveal the very different state contexts which become apparent when assessing the substance of the interview texts. While Massachusetts stakeholders attach positive aspects to wind technology in principle, the Minnesota stakeholders spoke often from personal experience. Similarly, in Texas, the slightly more negative discourse seems related to system saturation and integration issues experienced with large-scale wind power deployment. Further, stakeholders in Montana, a state with relatively low wind deployment, appear to attach more importance to technical barriers than in Massachusetts, where public acceptance issues are more salient. The political frame of wind deployment was the second most commonly mentioned risk/benefit frame. Its frequency indicates the relevance of political processes in wind deployment, confirming findings by Menz and Vachon (2006) and Bohn and Lant (2009) on the importance of policy for the deployment of renewable technologies. In particular, Minnesota and Texas stakeholders spoke more of both the positive and negative aspects of the political frame than those in the other two states. In Montana, negative comments prevailed, while Massachusetts stakeholders had only slightly more positive than negative comments, reflecting the contentiousness of wind energy in this state. References to the economics of wind energy were also common. Across all four states, the economic frame incorporates the financial aspects of wind development, including its costs relative to other energy sources, potential for revenue-generation and job creation, and ownership patterns within each state. Texas had twice as many positive as negative economic references, the largest difference of any state (Fig. 2), and a sign of the economic success of wind power in this state. In Massachusetts and Minnesota, positive economic references also outweighed negative ones. Montana was the only state where negative economic comments predominated. With regard to the environmental frame, stakeholders' attention to risks and benefits in this category varied considerably, and showed the greatest disparity across states of all categories. In Minnesota, positive comments outweighed negative ones more than 3:1, while Massachusetts had two positive comments for every negative reference to the environment. In contrast, both Montana and Texas had 30 percent more negative than positive references to the environment. More frequent mention of the environmental frame by stakeholders in Massachusetts and Minnesota corresponds to the stronger policy status in those states, and could indicate that the connection between environmental issues and wind energy is more salient. In Montana and Texas, wind deployment is not strongly associated with climate change mitigation, although environmental concerns such as habitat loss and bird and bat kills did feature prominently within the discourse of some stakeholders. 3In every state, aesthetic comments were more negative than positive. This result is consistent with a previous comparative study on media framing of wind deployment in the same states (Stephens et al., 2009). In contrast to the media analysis results, stakeholders mentioned the aesthetic category significantly less often than other frames, indicating that aesthetic concerns are present in every state, but appear to be less influential or pertinent than other categories for implementers and others deeply involved in wind energy policy. They are not as prevalent in these stakeholders' perceptions as in the media. There is minimal mention of the health and safety frame (one mention each in Minnesota and Texas), indicating that they are not perceived as playing a major role in wind deployment. Although the possibility of decreased air pollution was brought up by a handful of respondents, associated health benefits were not mentioned explicitly in any of the interviews.",
            "Comparative state context discussion": " This section details the interview analysis results within each state context by exploring stakeholder quotes within the discourse patterns emerging from the frame analysis, and discussing them in relation to the differing energy and regulatory systems (see Table 3 for an overview of the energy and policy context in each state). Quotations from the interviews are identified by state and interview number, i.e. MA11 refers to the 11th interview from Massachusetts. To allow for the assessment of themes within a state, Fig. 3 depicts the distribution of coded sentences by frame for each state, with percentages based on only the coded material.",
            "Massachusetts": " A typical New England state, Massachusetts is densely populated and relatively affluent. This urbanized state uses less energy than the other states in the study. 4 The population of 6.5 million has grown little in the past decade (U.S. Census Bureau, 2008), and energy demand increases have likewise been slow. Despite deregulation, its electricity system is characterized by high rates and a highly concentrated industry structure. Massachusetts has no notable fossil fuel reserves. It relies heavily on imported natural gas (50 percent of resource mix) to satisfy electricity demand, and at a quarter of all generation, coal is used significantly less than in the average U.S. state (EIA, 2007). As a result, both absolute carbon emissions and carbon intensity are not as high as in the other states in this study (EIA, 2009b). Massachusetts has taken several different approaches to reduce greenhouse gas emissions, including emissions targets, climate action plans, and regional greenhouse gas reduction initiatives. Massachusetts also has adopted legislation aimed at renewable energy deployment, including interconnection standards, a renewable portfolio standard, and net metering. The RPS requires renewables to make up 22 percent of sales in 2022, and an additional 1 percent every consecutive year, with no expiration date set at this point. In addition, Massachusetts' public benefits fund spends $25 million annually on renewable energy. Policies encouraging renewable energy development, however, provide no guarantee that wind power technology will be deployed in the state. Although they have increased the amount of renewable energy sold in this state, it is generated elsewhere: ''historically, Massachusetts has never been able to produce enough renewables to meet its standards (MA1).'' 2007 was the first year no alternative compliance payments were used to meet the renewable portfolio standard; at the same time, only 12 percent of the energy used to satisfy the renewable goal was generated in-state (Massachusetts Department of Energy Resources, 2008). As part of the ISO-NE (Independent System Operator New England) interconnection system, Massachusetts faces congested transmission infrastructure while also struggling with severe siting difficulties (Vajjhala and Fischbeck, 2007). So while ''there are actually a lot of market signals that have happened in the state through legislation over the last couple of months (MA11),'' ''the real challenge is to site the major wind facilities (MA10).'' In fact, 17 of the 18 stakeholders interviewed in Massachusetts mentioned siting, permitting or 'not-in-my-backyard' issues as important obstacles to wind development. Many stakeholders cited a combination of local resistance and burdensome siting and permitting rules as the main factor in delaying wind deployment: ''there are multiple projects that have been in the planning and permitting stages for many, many years that have been appealed, that have bumped into local opposition, etc., and that has been probably the greatest thing that has slowed down wind development in the state (MA4).'' Technical difficulties also hinder rapid expansion of wind energy in the state. Specifically, transmission is lacking between areas with good wind resources and the population centers that require additional electricity. In the words of one environmental non-profit manager, ''there's no transmission lines in the places where they want to build wind. They tend to be in the very remote areas (MA01).'' At the same time, ''It's a huge resource and we should find a way to use, to get more of it out there (MA10). '' In economic terms, stakeholders in Massachusetts had more positive references than negative, reflecting the perceived economic benefits of the technology. Wind is competitive with conventional generation in the state, but only through aid from policies subsidizing its installation and operation. According to an employee at a regional environmental non-profit, ''The Global Warming Solutions Act [y] will incorporate the cost of carbon into the marketplace and I think will put wind energy and other renewables on a more even keel or even footing with traditional fossil fuel generation (MA17).'' Many of these policies encouraging wind development make a direct connection between the technology and its ability to mitigate climate change: ''Wind has this sort of large scale industrial capability that is very promising from a climate change perspective to deliver bulk  alternative energy from burning carbon, [y] from burning coal and oil (MA08).'' These environmental benefits, however, are countered by the potential for negative consequences. For example, one staffer at a prominent environmental non-profit said, ''We went to a series of hearings for the Cape Wind project, for instance, and a lot of the community feedback was, it's ugly, it hurts wildlife (MA05).'' Despite this perception by members of the public, many of the stakeholders did not view those concerns as a substantial barrier to the technology's deployment. ''Actually the data with the new wind turbines and wind blades, it's actually very nominal [y]. You have more birds flying into buildings than you have getting affected by the turbine technology (MA05).'' Likewise, while interviewees acknowledged that there was substantial opposition to wind development based on aesthetic concerns, they considered it a minor setback to the large-scale deployment of the technology: I strongly believe that once you start getting turbines up, it will ease some of the arguments on aesthetics, and getting turbines up will [y] educate people about how wind works. [y] They don't quite understand how it works and what the noise level is or what it looks like, etc. (MA11).",
            "Minnesota": " Like Massachusetts, Minnesota, with a population of 5.2 million (U.S. Census Bureau, 2008), has strong policy relevant to wind technology, but it has been much more successful in deploying wind technology. Minnesota is significantly less urbanized than Massachusetts, and faces quite different challenges in its energy system, having to continuously balance between the Minneapolis-Saint Paul metropolitan area and the rest of the state. While the urbanized Minneapolis-Saint Paul area is prosperous, fast growing and densely populated, much of the remainder of the state is less affluent, with many areas sparsely inhabited and experiencing population decline. A small number of investor-owned utilities serve the interstate corridors connecting the major population centers, resulting in a highly concentrated electricity industry. In contrast, rural areas are generally supplied by small municipal and cooperative utilities, which account for about a third of the electricity sold in the state (EIA, 2007). High voltage transmission line siting has historically been a contentious issue in Minnesota, not so much because of proximity to populated areas, but in part because of perceptions of unfair distribution of benefits and costs to urban versus rural populations. Minnesota's electricity generation is dominated by coal (61 percent). Although nuclear power supplies another 25 percent of the state's electricity (EIA, 2007), the large amount of coal results in a carbon-intensive fuel mix and significant absolute greenhouse gas emissions. Despite the importance of the electric sector in greenhouse gas emissions, neither environmental nor health concerns were mentioned prominently in the Minnesota interviews, suggesting that these concerns are not perceived as influential in wind deployment. Stakeholders in Minnesota talked about some opposition to wind based on environmental concerns, but its importance was downplayed in several interviews. In contrast, technical aspects play a significant role in the Minnesota context. Reliability and storage were frequently cited as important technical issues to address. Similar to Texas the wind resource is large, but the power lines used to transmit that resource to the load centers are used to capacity. ''We have tremendous wind potential here, [but] some of the big obstacles that we have are [y] the transmission capacity to deliver that wind, so there's a lot of things that have to happen, in a lot of areas where we'll need policy help to move us in that direction (MN02).'' Transmission aspects were mentioned by all but five interviewees in Minnesota. Minnesota has policies in place to encourage wind development, including a staggered renewable portfolio standard, culminating in 25 percent renewable sales by 2025 for all utilities but Xcel Energy, which has to achieve 30 percent renewable sales in 2020. In addition, Minnesota's public benefits fund spends $19.5 million annually on renewable energy programs. Similar to Massachusetts, there are several pieces of legislation that focus on greenhouse gas reduction. In Minnesota, ''Climate change has really driven the market for wind power, the environmental benefits; and it has served to catalyze the governors in their region, through the Midwest Governor's Association, through their climate change goals (MN20).'' Almost all stakeholders portrayed these renewable energy and climate change policies as very successful in encouraging wind deployment, and most saw additional policy as a major factor for the continuing growth of wind power. ''I think that in Minnesota we've done the right thing by working on the policies necessary to promote wind actually in all forms for development in the state (MN15).'' Actors in the state have even gone as far as saying that Minnesota is a leader in developing wind through policy action: Minnesota's already taken a fairly aggressive stance on wind power and it's one of the leading states right now in saying what proportion of power has to come from renewable resources, which most likely means wind. So I think that in the last legislative session, Minnesota sort of went toward the head of the pack in the nation as far as states on the wind power issue (MN19). These policies have also been successful at making wind economically competitive with conventional generation. ''Many of those [renewable energy] standards are met through wind power because it's right now so economical compared to a lot of the other renewable technologies (MN08).'' Partly, that is due to the fact that ''carbon emissions have to be considered in the decision process of selecting new generating sources (MN5),'' by attaching a price to carbon in the integrated resource planning process. An additional economic factor in Minnesota is the incorporation into the renewable portfolio standard of community-based energy development (C-BED), including a special tariff, micro-loan programs, and tax exemptions. 5 This type of legislation supporting community wind aims to establish local ownership that directly benefits rural communities and is not seen in the other states studied. As a result of the C-BED regulations, local communities have ''see [n] a benefit in wind (MN21).'' Overall, the economic benefits of wind power have reduced local opposition to the technology's development: The fact that we live in an area where we have a very sparse population sort of automatically facilitates the development of wind farming in this area. And it works; it's a synergistic opportunity with agriculture. [y] I've encountered very little resistance in the general population to doing more (MN15). While there was some discussion of aesthetic-based opposition to wind power in Minnesota, public acceptance issues were not prominent. Most of the pushback has been associated with concern about transmission lines, rather than wind turbine siting or permitting. According to one environmental advocate, I just extol them with how beautiful wind turbines are, [y], but [there is] nobody, nobody that's come up to me and says, 'I really love the sight of the transmission line' (MN05). Opposition to transmission lines dates back to the controversy between utilities and farmers in the late 1970s, when two electric cooperatives attempted to site a line from North Dakota to the Minneapolis area.",
            "Montana": " Montana is a Rocky Mountain state with a population of less than 1 million people (U.S. Census Bureau, 2008) spread out over a very large land area, without any major metropolitan areas. Per capita income is low; energy consumption is moderately high and growing slowly. Montana is a major exporter of electricity, selling 45 percent of total generation in 1999 to other states (Jiusto, 2006). Montana holds more than a quarter of the nation's estimated recoverable coal reserves, and close to two thirds of its electricity is produced from coal (EIA, 2009b). Consequently, the state has the highest carbon intensity of all states in this study, at 0.9 metric tons per MWh. However, it is also one of the top producers of hydroelectric power in the U.S. and combined, coal and hydro generation provide 97 percent of Montana's energy needs (EIA, 2007). The electric industry is highly concentrated and retail sales are dominated by investor-owned utilities, with about a third of load served by rural electric cooperatives (EIA, 2009b). Montana's status as an electricity exporter was frequently cited by the stakeholders interviewed in the state. Technical and economic concerns were often placed in the context that any electricity generated by wind would be exported. ''The big problem is that Montana's got this tremendous resource for generating electricity using renewable sources, but the question is getting it out of the state (MT02).'' From another respondent's perspective, ''We've got good potential for wind development but we don't have the resources to firm that wind power up. We can't have the ups and downs on the power or on the electrical grid (MT10).'' In addition, Montana stakeholders were more likely to question general feasibility of wind projects, reflecting the fact that there is currently less experience with wind power in Montana than in Texas or Minnesota. This perspective is also reflected in Montana's policies and legislation. The state created a renewable portfolio standard in 1999, but ''there have been some attacks on renewable energy standards, pieces of legislation that would undermine it, that would reduce its impact, its ability to spur growth of new wind development in the state (MT17).'' Despite having both a mandatory green power option and a public benefits funds, few wind projects have been fully developed, and while the American Wind Energy Association ranks Montana as fifth in the nation for potential capacity, it is 21st in total generation (AWEA, 2009). Montana was the only state in our study where negative economic references outweighed positive ones. In this largely rural state, stakeholders were concerned about the costs of wind power's intermittency and the difficulty that small generators face when entering the electricity market. In the words of one respondent, ''We don't have an economic system that creates a situation where small players can get involved in a distributive power system. We have huge forces, huge companies coming in and charging us rent basically to use our resources (MT16).'' As more wind power is developed, channeling at least some of the economic benefits to local residents may prove important in maintaining public acceptance for wind power. The example of Minnesota shows that community-based development can be instrumental in creating broader support for the wind industry. Unlike in Massachusetts and Minnesota, no connection was made between climate change and the adoption of wind energy in Montana. Rather, proponents of the technology felt they had to distance themselves from environmental concerns while advocating for its deployment. In the words of one energy developer: ''They don't talk about climate change much, because it's easier to talk about saving money with wind power (MT04).'' Stakeholders in Montana also raised some substantial concerns about the technology's environmental impact on wildlife, including bird and bat kills and impacts of transmission lines on prairie species.",
            "Texas": " Texas, the largest state by landmass among the lower 48, has a population of over 23 million (U.S. Census Bureau, 2008), distributed among a number of urban centers (Houston, Dallas, Austin and San Antonio) amid large rural areas. Per capita income is moderately high, but unequally distributed between rural and urban areas. The state has experienced rapid population growth over the past decade. Electric consumption is the highest of all states in this study, at roughly 16 MWh per capita. Texas is one of the few states to have successfully deregulated its electric energy sector and created a highly competitive industry with a large number of power marketers balancing traditional utilities. Natural gas makes up 50 percent of the electricity supply, but despite the higher cost of this resource, electric rates hover around the national average (EIA, 2009a). Another 37 percent of electric energy is produced from coal, and as a consequence, the carbon intensity falls in the mid-range. The majority of lower 48 natural gas and petroleum reserves are in Texas; the state supplied 25 percent of all natural gas and 21 percent of all oil produced in the U.S. in 2005 (EIA, 2008). While all four of the states talked about technical problems and benefits, stakeholders in Texas discussed the technology from the perspective of already having an abundance of wind deployed and experiencing both system integration issues and transmission bottlenecks. In Massachusetts and Montana, the technical issues were represented as problems faced at the beginning of deployment. In Minnesota, transmission and saturation issues were surfacing, but were not as prevalent as in Texas. One reason why the Texas case is unique is that the state encompasses its own transmission reliability structure -Electricity Reliability Council of Texas (ERCOT) -that is separate from other regional grids. Therefore, almost all wind deployed to comply with the Texas RPS is installed within the state boundaries. In the words of one state government official, We now have so much wind on the grid that Texas being an electrical island, having ERCOT, Electricity Reliability of Council, contained within the state boundaries, it means that if you rely heavily on wind generation and the wind generation does not occur because a front blows through or low pressure system dips and suddenly there's no wind, then you have to be ready to back it up with other generators that have to be dispatchable within ten minutes. And ERCOT is really just learning how to operate a grid with this much wind energy on it. No other grid anywhere in the United States has had to do this yet (TX07). An additional difference within the technical discussion in Texas was its focus on concrete steps to ensure the future development of wind energy in a state that has already seen much capacity installed. Both Texas and Montana voiced more negative than positive assessments of technological issues, but in Texas, problems were associated with the development and system integration of even more wind, in a context where wind is already an important part of the resource mix. Legislation relevant to wind-power deployment first came about in the late 1990s, when the inclusion of specific quantities of renewable power was made a condition of restructuring. Unlike the other three case study states with their generation goals, Texas sets a capacity goal. The most recent goal mandates 5880 MW of renewable generation capacity by 2015, with at least 500 MW from non-wind sources. As of 2009, that goal has already been surpassed. It amounts to about 5.5 percent of current nameplate capacity, a far less ambitious goal than in the other states, and it will be interesting to see if the legislature adopts higher targets in line with actual deployment. In absolute terms, a lot of new capacity has been added, although proportionally, Texas actually generates less wind power than states like Minnesota or Iowa. More recent state energy bills in Texas frequently deal with transmission, property rights clarification and the costs of wind development, reflecting the issues experienced by a large and rapidly growing wind industry. To address intermittency and transmission problems, the state authorized the development of additional power lines intended explicitly for wind energy. As part of its Competitive Renewable Energy Zones (CREZ) initiative, the state government has determined the areas within the state with the best wind potential, and is building transmission lines in those areas as an incentive for developers to begin wind farm construction. While transmission limitations have been identified as problems in other states, Texas is actively taking steps to improve their electricity infrastructure and ensure that there will be market access for wind generated in West Texas and the Panhandle area: once we had the trade success in terms of wind generation in Texas, it became obvious that there were major transmission constraints, and the PUC [y] had a couple of big announcements on [the CREZ process] recently to put between $5 billion and $6 billion worth of transmission lines in place to bring wind energy from the Panhandle and West Texas to the urban areas of the state (TX 19). Even though Texas was one of the first states in the country to establish a renewable portfolio standard, it was not framed within the context of climate change mitigation. Instead, it was viewed as an economic development opportunity, with supporters interested in ensuring that urban air pollution does not increase with a deregulated energy market. Texas also did not pass any additional green laws to support the renewable mandate, unlike Minnesota and Massachusetts. It does however have simplified siting rules. The Texas legislature implemented the minimum policy possible, and then stepped back. In the words of one Texas energy industry consultant, In Texas, we have sort of a lighter touch on the rules. We have this RPS. We have a few other things that say, 'This is what we want you to do. We're trying to level the playing field. We're gonna give you some incentives. But then it's up to you guys to decide what you want to do beyond that.' Well, those rules have served as enough of a catalyst to get the wind market going. [y] And if you can compare to 2007 as a year [y] Texas installed 25 times more wind than California, even though their laws require more than our laws. But [it is] just sort of the voluntary, letting the market work [mentality]. Because even though they've got all these laws, they kill it, they strangle it with all these regulations. And it just, it doesn't go forward (TX12). Economic factors offer a partial explanation for why wind has expanded so quickly in Texas. First, Texas has a restructured electricity market and the energy market and infrastructure is a profit driven system where anyone expecting a favorable return on investment will propose and build generation facilities. The second economic factor that has driven the development of wind energy in Texas has been competition with natural gas and its relative price of installation. Much of the generation within the ERCOT grid comes from natural gas. As a result, Wind typically displaces natural gas generation. As natural gas prices have gone up and stayed high, the cost of generating electricity with natural gas is basically what wind is competing with. So it competes very favorably. If wind had to compete with coal or nuclear, it wouldn't, but it doesn't (TX07). Because wind energy was competing with natural gas instead of cheaper sources such as coal, the Texas renewable energy credits and federal production tax credit helped ensure the technology's economic feasibility. It remains to be seen how recent decreases in natural gas prices will affect this. Like Montana, there has been minimal association between wind deployment and climate change mitigation. It's [y] politically difficult for a legislator to [y] stand arm in arm with the environmental community, regardless of how good the idea is. And [y] that's a problem perception. Alternative energy, renewable energy, wind energy, solar power, have the perception of being things advocated by tree huggers, with beads, you know, wacko, liberal type folks. And so, there's [y] just the knee jerk perception among some legislators that anything that some of those folks may have to say is just rejectable out of hand (TX03). To get around this barrier, stakeholders ''don't talk about climate change when [they] go over to the capitol; [they] talk about economic development (TX09).'' Although climate change was not mentioned specifically to encourage wind development, some environmental concerns have arisen as the technology has been adopted. Most of the negative environmental references in Texas concerned a pending lawsuit with high media attention. The suit focuses on the siting of turbines along the Texas coast and associated concerns about high numbers of projected migratory bird kills. ''They have a whole legal challenge, and they've been joined by some small, local environmental groups like the Corpus Christi Audubon Society and others that are uncertain about the impacts to birds and the wetlands (TX10).'' These specific issues are compounded by the concern that ''the rush [y] [to] go forward with all wind power may actually set the whole movement back, if you put it in the wrong place and you start having [y] big impacts on bats or migratory birds and raptors (TX09).''",
            "Discussion and conclusions": " Our results highlight the different issues and pathways that have led each state to its current wind power situation. In Montana, stakeholders seem to struggle most with uncertainty related to costs and technical feasibility in a newly established sector, and they question the role of large companies outside of the state exploiting the wind resource for their own gain. In Texas, with a large amount of wind already deployed in the state's electricity generation system, technical issues also are a major concern, but in the context of system integration and transmission bottlenecks. Economics also appear to be a major driver in Texas; economies of scale combined with the relatively high price of electricity, a competitive market and the relatively low price of wind make wind power a financially viable resource. In contrast, the case of Massachusetts shows that where costs of wind are high and societal perceptions of a technology are negative, the desired deployment outcomes can be difficult to achieve even in a high-price energy system with supportive policies. Finally, wind in Minnesota benefits both from a supportive policy environment and positive public opinion. Although the proportion of wind within the system is much higher in Minnesota than in Texas and transmission is an issue, within Minnesota transmission is not yet perceived as highly limiting as it is in Texas, with its unique alignment of overlapping state borders and transmission reliability system boundaries. Examining the state context for wind technology deployment reveals many different discourses surrounding wind energy in the four study states. Technical, political, and economic aspects of wind power were most frequently mentioned by interviewees. In all of the states, policy stakeholders suggest that these aspects of the socio-political system play a much larger role in the development of wind technology than environmental, aesthetic, and health/safety risks or benefits. Another common thread across all states was the issue of transmission, which currently seems to be perceived as the most important challenge for further increases in wind power. Despite these similarities, each of these states is at a very different stage of wind deployment and the discourse within the states reflects these differences. The cost competitiveness and market access for wind is emphasized in both of the high deployment states. In Minnesota, it was traced back to the policy regime and subsidy structure, while in Texas, it was associated with the characteristics of the existing energy system. In contrast, costs were described as a major barrier towards diffusion in both low deployment states. Responses also varied with policy status. Minnesota and Massachusetts have several policies that explicitly call for reductions in greenhouse gas emissions and stakeholders more often linked wind deployment directly to climate change mitigation, but only Minnesota has managed to deploy wind energy to meet climate-related goals. Montana and Texas, on the other hand, do not have policies focused on greenhouse gas emission reductions, but Texas has become the leader in wind deployment across the country. This set of observations suggests that climate policy and energy technology deployment are decoupled in some contexts. The weakness of environmental motivations merits further analysis, since it remains unclear whether environmental benefits are perceived as unimportant, or, on the contrary, are so well-established that they merit no further discussion. Overall, the results of this study demonstrate why current deployment patterns cannot be explained simply by either resource capacity or enabling policy. The success of wind development depends on the state-level socio-political context and each state has a unique combination of factors contributing to this context. Policy, although successfully driving wind power in some places, is not sufficient, nor is it necessarily the dominant factor in determining deployment patterns. As wind and other renewable resources continue to be developed, it is important to recognize the influence of other socio-political and economic factors. The relative importance of these interconnected factors will evolve with the maturation of the technology and the industry, as well as growing public awareness about climate change and energy issues and evolving climate and energy policy. These results, while based on the specifics of four states, have relevance to deployment in other states and contexts. Proponents of wind technology in a state just beginning deployment can learn from successful framing strategies in areas with a more mature industry. Proponents of wind technology in a state with significant deployment have a host of different issues to address. State-specific barriers are also important to consider, including the political risk of linking wind energy to climate change, transmission constraints, economic development, and distributional conflicts between urban and rural populations. As wind turbines become more common, transmission and system integration constraints, as well as resistance against visual impacts could slow deployment in some areas. In a similar vein, the secondary nature of environmental and health aspects associated with wind power implies that stressing these aspects may in fact be, if not detrimental, at least unhelpful for proponents of wind power. Unlike other studies focused on general public opinions of different energy technologies, this study presents how policy stakeholders think about wind power deployment within their particular state contexts. It offers insights into the discourse of actors who are both deeply involved in the deployment of wind power and participate actively in the policy process. Social acceptance of renewable technology has institutional market and political dimensions (W \u00fcstenhagen et al., 2007). Interviews with influential experts can surface these complex issues directly, rather than accessing them indirectly through social acceptance indicated by public opinion and media discourse. In particular, political and technical deployment aspects emerge as more salient than in work on public perception or media portrayal of wind. Along with other expert stakeholder studies (Hansson and Bryngelsson, 2009;Varho and Tapio, 2005), our approach therefore provides a complimentary view to studies on media and public perception of new energy technologies. Each of these on-going state-level debates informs the creation of a federal climate and renewable technology policy. As the U.S. begins to design policies to reduce greenhouse gas emissions and deploy low-carbon technology, policy makers and energy planners would be wise to recognize the influence of state-level sociopolitical factors in shaping the context of low-carbon technology deployment. Acknowledging and understanding these state-level socio-political factors can help bridge the gap between designing low-carbon energy policy and deploying energy technologies for climate change mitigation."
        }
    },
    "10.1016/j.enpol.2011.08.064": {
        "file_name": "29 Factors in low-carbon energy transformations",
        "title": "Factors in low-carbon energy transformations: Comparing nuclear and bioenergy in Brazil, Sweden, and the United States",
        "abstract": "Policies to address climate change by reducing greenhouse gas emissions might be made more effective if we can better understand the pathways by which transformative technologies become significant components of energy systems. Indeed, the central question of mitigation revolves around the scope of policy to influence or accelerate the diffusion of low-carbon technology. While market forces clearly influence technology deployment, understanding the longer-term and large-scale changes in the energy system requires a broader understanding of the relative influence of institutional, behavioral, and social factors. This paper presents the results of an interview-based, comparative case approach to investigating systematically the relative importance of these non-economic factors influencing technological change across technology and country contexts. We identified two low-carbon energy sectors (bioenergy and nuclear power) that underwent significant changes over the past 50 years in the energy portfolio of three countries: Brazil, Sweden, and the United States. We identified nine categories of factors that might contribute to these large technological transformations, and then evaluated, via interviews with sector participants in each country, which factors were viewed as being determinative or highly influential in the trajectory of that technology in their country context. We also draw out policy implications and directions for future research.",
        "label": "Mixed",
        "text": {
            "Introduction": " Policies to address climate change by reducing greenhouse gas emissions might be made more effective if we can better understand the pathways by which transformative technologies become significant components of energy systems. Over the next century, emissions generated by fossil fuels must eventually approach zero in order to stabilize atmospheric CO 2 concentrations (Clarke et al., 2007). Current scenarios suggest that this stabilization will require the accelerated and widespread global deployment of a combination of non-emitting and low-carbon energy technologies. Yet while this requirement is clear, the most effective policies and social processes required to effect such a transformation are far from understood. Indeed, many of the controversies surrounding how to structure climate change mitigation and adaptation policies-including financing, what counts as action, and how to measure progress against uncertain goals-are based on differing assumptions about the potential and likely pathways for technological change (Prins et al., 2010). The central question of mitigation, therefore, revolves around the scope of policy to influence or accelerate the diffusion of climatechange-related technology (Holdren, 2006). Understanding the market forces that influence technology development and deployment is undoubtedly essential, but understanding longer-term, large-scale changes in the energy system requires a broader understanding of the relative influence of institutional, behavioral, and social factors. Changes can stem, for example, from government regulation and policy, differences in firm expertise and infrastructure, international and national security needs, innovation networks, or leadership. Other factors discussed in the literature include the availability of technical expertise, risk-taking behavior in partners and suppliers, co-benefits such as employment in declining sectors or increased national standing, the origin and method of capital infusion, an evolving or permissive regulatory structure, development of diversified markets, standardization of parts and systems, and public acceptance. The case can inevitably be made that each of these is important in specific circumstances (Montalvo, 2008). Nevertheless, a question remains as to what extent any of these factors are influential across technologies or country situations. This paper presents the results of an interview-based, comparative case approach to investigating systematically the relative importance of these non-economic factors influencing technological change across technology and country contexts. We identified two low-carbon energy sectors (bioenergy and civilian nuclear power) that witnessed dramatic changes over the past 50 years in the energy portfolio of three countries: Brazil, Sweden, and the United States. Based on existing literature covering innovation and technological change, we identified nine categories of factors that might contribute to large technological transformations. We then set out systematically to evaluate, via interviews with sector participants in each country, which factors were viewed as being determinative or highly influential in the trajectory of that technology in their country context. In this paper, we present the results of this study and draw out policy implications and directions for future research.",
            "Weighing factors in technological transformations": " The immense challenge of climate change has prompted calls for emissions mitigation to be treated as a new ''Manhattan Project'' or ''Apollo Project.'' The motivation for such an effort is no doubt wellintentioned, but the analogy to these past, successful, large technology projects is not necessarily illuminating. As Prins and Rayner (2007) have pointed out, these heroic projects were able to be successful because they were relatively focused, ''tame problems,'' exhibiting clear goals, a narrow scope of technical action, and welldefined end points against which to measure progress. Addressing climate change, in contrast, requires a broad transformation of infrastructure over long periods of time, a transformation that depends on both the development of new technologies and an increased rate of diffusion of technologies into the economy. In this paper we refer to this broader process-which subsumes individual technologies and regulatory contexts-as ''technological transformation,'' although this term can have wider uses in the literature. While our concern in this paper is to better elucidate the factors and processes underpinning energy technology transitions, our analysis is best understood within a wider field of research that seeks in its broadest form to understand the coevolution of technology and society. Research on the characteristics of large-scale technological transformations dates back over a century: early observations of transitions over the industrial revolution led to models of long-wave cycles of change, logistic (or S-shaped) diffusion curves (Tarde, 1903) and learning curves (Wright, 1936), and to Schumpeter's theories on creative destruction (Schumpeter, 1974). Newer approaches include theoretical elucidations of sociotechnical systems, historical analyses of specific technologies, narrower empirical investigations of technological diffusion over time, and modeling of innovation and diffusion (Rip and Kemp, 1998). Each of these lenses on technological transitions can be useful for imagining how a transition from a high-carbon to a low-carbon economy might unfold. A basic starting point for understanding how technologies change over time is to focus on the individual technological components, and thereby to understand how these are invented, how they are refined, and how they over time emerge as ''winners'' over pre-existing and competing technologies. Those basic observations of a roughly S-shaped diffusion curve, while fitting empirical observations, do little to elucidate the causal processes of diffusion, which are essential for prospective modeling and theoretical understanding (Grubler, 1997). Other fully specified but general process descriptions have been developed and evaluated in the literature-for example, that it might be limited by information flows (like epidemics) or that it might be a function of different firms having different propensities to adopt a technology at any given time (Geroski, 2000;Meade and Islam, 2006). Such process models inform our understanding of large technological changes, but observations of real-world transformations often confound parsimonious treatment. Case studies such as Hughes' history of electrification in the United States, Britain, and Germany (Hughes, 1983); Van Den Ende and Kemp's study (1999) of computer regime transformations, or Dobbin's study of railway introduction and expansion in the United States and France document these large shifts in technological systems (Dobbin, 1994;Van Den Ende and Kemp, 1999). Another historical approach has focused not on sectors but on individuals, actors, and successful entrepreneurs (see, e.g., Stokes, 1997). Historical case studies such as these are effective at highlighting contingency and complexity in technological diffusion but are not sufficiently broad for us to draw general lessons. A third framework for studies of technological diffusion tries to embed the general processes within real-world institutions. Such studies focus on what are frequently called innovation systems-incorporating technological and social factors to understand and test general principles of technological change (Hekkert et al., 2007;Montalvo, 2006). Such investigations can focus on general characteristics of innovations systems in one country context (Liu and White, 2001) or can focus on specific sectors such as energy or clean technology (Jacobsson, 2000;Hekkert and Negro, 2009). In this area, one of the key questions is how the process of diffusion happens in practice, and methodologies are usually casebased and focus on transfers among individual actors-between individuals, between firms, and within firms (Battisti, 2008;Montalvo and Kemp, 2008;Markard andTruffer, 2008a, 2008b).",
            "From innovation to technological transformation": " While the distinction is necessarily somewhat blurred, a related strand of inquiry focuses less on the details of how individual technologies emerge and become widely adopted, but rather on large-scale technological transformations. Such transformations can be seen to subsume one or more adoptions of new technology. From this perspective, the study of technological transformations should necessarily be informed by insights on the processes of innovation and diffusion (Grubler et al., 1999). Yet this approach seeks to embed the rise of individual technologies in a broader understanding of shifting socio-technological regimes over long time scales (Ayres, 1990;Bijker, 1995). For example, the rise of the railroad in this view can be understood not only as a technological innovation that then enters use-following a predictable pattern over time, but also embedded in a broader transformation to industrial revolution energy systems, social organization, and markets, with benefits for industry, government, and consumers. While the discussion of such technological transformations is far from settled, several models have emerged (Coenen and Lopez, 2010). Probably the dominant model is referred to as the multi-level perspective (MLP), which articulates three fields of activity, at different scales, that collectively provide the basis for technological transformations to occur (Geels, 2002;Genus and Coles, 2008, with Markard and Truffer, 2008a, 2008b). The first level comprises niche innovations, the proverbial ''light bulbs:'' novel inventions that are able to be refined over time-not because they are initially highperformance or profitable, but because they have a niche market. These are ''configurations that work'' (Rip and Kemp, 1998) with relatively defined boundaries, but include human as well as artifactual elements. Sociotechnical regimes, understood as the shared understanding of technical knowledge as well as supporting institutions and infrastructure in a particular field, constitute the second level. Third, the sociotechnical landscape is a slowly shifting external environment that is outside the control of the individual actors in the sociotechnical regime. This framework has proven sufficiently flexible to accommodate a variety of observed transitions, although with some refinements and modifications. Geels and Schot, for example, identified four distinct transition pathways-some involving a true transformation, and others, for example that are more simply viewed as technological substitutions, with the caveat that succeeding incremental changes can become transformative (Geels and Schot, 2007). Genus and Coles, moreover, identify two branches of discussion in the literature depending on whether the goal is primarily descriptive (''systems in transition'') or prescriptive (''transition management''). Much, but not all, of the literature on energy transitions has been oriented toward understanding the management side, with the goal of structuring more effective and efficient policy interventions. The research presented in this paper spans both dimensions, with our investigation being primarily descriptive but structured in such a way that we believe can help identify potentially fruitful policy pathways. While the technological transformations literature has deliberately adhered to general theories not specific to any one technology or sector, many scholars have investigated energy transitions in particular. Kemp's work on the challenges of inducing regime shifts (Kemp, 1994) and Rip and Kemp's theoretical exploration of technological change in the context of energy (Rip and Kemp, 1998) helped frame the issue. Parallel work focused on governance of sustainable transitions (Smith et al., 2005) and embedded specific case inquiries more directly in the emerging theoretical literature (Kemp et al., 1998;Shove and Walker, 2007).",
            "Factors driving technological transformations": " In explaining observed technological transformations-whether in energy or other sectors-scholars have proposed a number of explanatory variables driving diffusion and change. (Sometimes these explanatory variables are called ''forces'' or, as in this paper, ''factors''.) Technological developments, regulations, and costs are all interlinked factors that collectively help explain why one technology might supplant another. Many studies have asserted with some vigor the conclusion that relative prices (and, by extension, pricing policies) for energy technologies cannot account fully-and at times, account only poorly-for the observations (Jacobsson and Lauber, 2006;del R\u0131 \u00b4o Gonza \u00b4lez, 2005;Tayloret al., 2003;Montalvo and Kemp, 2008;Kemp and Volpi, 2008). That non-economic variables can play an important role in clean technology diffusion is therefore well established, and in a way not particularly surprising. Past experience with such large-scale technological ventures highlights linked policy, cultural, and economic challenges, some of which may not be amenable to technological solution (La Porte, 1994). After all, in most national contexts, energy has a long history of being heavily regulated and has much overlap with energy security concerns-to claim that energy is a competitive market similar to that for, say, computer memory, is absurd. In his empirical assessment of the Spanish pulp and paper industry, del R\u0131 \u00b4o Gonza \u00b4lez identified three sets of factors that underpin decisions on clean technology: firm exogenous and endogenous factors, conditions of the adopters, and characteristics of the technology (del R\u0131 \u00b4o Gonza \u00b4lez, 2005). Montalvo's extensive review of factors affecting the adoption of cleaner technologies identified drivers in eight categories: public policy, economics, markets, communities and social pressure, attitudes and social values, technological opportunities and capabilities, and organizational capabilities (Montalvo, 2008). Jacobsson and Lauber investigated renewable energy diffusion in Germany and argued that institutional change, market formation, advocacy, and entry of firms were the key dimensions underpinning the critical initial period of technological development (Jacobsson and Lauber, 2006). A fundamental question that remains, however, is the relative importance of each of these clearly plausible factors in driving technological transitions. Montalvo and Kemp point out that despite the recent applied research into technological transformations, ''few studies into cleaner technology have tried to measure the relative importance of [endogenous and exogenous] mechanisms'' (Montalvo and Kemp, 2008).",
            "Research needs: Empirical studies of the drivers of energy transformations": " Despite the great societal interest in the topic and the perceived benefits of improved transition management, research into clean technology diffusion and technological transformations has suffered both from a lack of detailed empirical studies and an underdeveloped set of methodologies (Kemp and Volpi, 2008). A few recent studies have begun to address this gap. For example, Verbong and Geels (2007) and then Kern and Smith (2008) assessed past and prospective Dutch energy policy in the context of the MLP and technological management literature. Kern and Smith, for example, found that transition management approaches rooted in the MLP tended to neglect critical factors relating to politics and policy and failed to reflect shorter time horizons in firm perspectives (Kern and Smith, 2008). Del Rio Gonzalez's aforementioned study of the Spanish pulp and paper industry takes a similar approach (del R\u0131 \u00b4o Gonza \u00b4lez, 2005). Lopolito et al. focused their empirical study on one dimension of the MLP perspective, namely the development of innovation niches in biorefineries in Italy (Lopolito et al., 2011). Methodologically they focused on analyzing the interconnectedness and interrelationships of social networks operating around this nascent technology and suggested network-derived metrics for factors such as willingness to adopt, power, and knowledge (Piore and Sabel, 1984). Romijn and Canilis evaluate biofuels development and niche creation of a specific policy context of Tanzania (Romijn and Canilis, in press). Although these studies focus more narrowly on the niche-creation dimension of the MLP, their methodology introduces the possibility of a more general comparison across cases. These single-country approaches were useful in introducing extensive empirical investigation of a single case to highlight flaws in prescriptive approaches, and in developing methodologies, but they leave open the question of how much can be general across different country contexts. Other studies take a comparative international approach. Jacobsson and Bergek synthesized earlier literature to compare the experiences in Germany, Sweden, and the Netherlands, thereby drawing general lessons about the dominant driving and inhibiting factors operating across all three (Jacobsson and Bergek, 2004). Luken and Rompaey surveyed managers from 105 plants across four sectors (pulp & paper, textiles, leather, and iron/steel) in nine countries, asking them to rate the importance of ten factors in decisions to adopt clean technologies. Using a basic ranking system, they found that high costs were the most significant (negative) factor, and that current and anticipated future regulation were next in importance (Luken and van Rompaey, 2008).",
            "Our approach: Relative importance of factors across countries and sectors": " These strands of literature clearly show that large, long-term technological transitions are not easily generalizable, but that there are certain characteristics that may be consistent, or at least important in many transitions (Frantzeskaki and de Haan, 2009). In addition, it is well established that technological transitions in energy are affected by economic costs of technologies and their substitutes, but that these are at best imperfect and loosely coupled to actual outcomes. Finally, the theoretical literature on energy transformations has been to some degree hampered by the relative paucity of empirical research from which to draw, especially in which case investigations are approached systematically to enable more effective generalization. The research presented in this paper seeks to address all three of these research gaps. Many factors explaining technological transitions have been discussed in the literature. Our goal was to assess, through a systematic series of interviews, the relative importance of the factors in low-carbon energy transitions. We structured our study as a comparative case analysis, focusing on large-scale, low-carbon energy transitions in three countries (Brazil, Sweden, US) in each of two technological categories (bioenergy and nuclear power). Interviewees were drawn from expert communities in each of these cases, and our common protocol enables some cross-comparison of results and the ability to generalize across countries and sectors. The next section describes this research approach in more detail.",
            "Methods": "",
            "Case selection": " We sought to establish the factors viewed as most important in influencing significant energy technology transformation across country and technology contexts. Our methods entailed selecting cases, conducting interviews with key experts in each case context, and analyzing interview data both qualitatively and quantitatively. We chose two technology classes-bioenergy and nuclear power-across three countries: Brazil, Sweden, and the United States. Collectively, these countries exhibit similarities in their respective patterns of energy technology adoption, and thus offer a useful and valid sample for analysis and generalization of results.",
            "Bioenergy": " The application of bioenergy technology has varied across time and country. The two primary approaches to using biological sources of energy in our cases have been via solid-fueled electricity generation (e.g. woodchips or agricultural residue) and via conversion to liquid fuels. Ethanol has attracted renewed attention as a potentially renewable transportation fuel, although controversy surrounds its net environmental impact and energy balance (Farrell et al., 2006;Searchinger et al., 2008;Pimentel and Patzek, 2008). Each of the country cases illustrates efforts to adopt and diffuse ethanol as a major element of the transportation fuel mix and each focuses on factors identified in the literature as necessary elements of successful technology diffusion (Malone, 2003;Dooley, 2006). From studies of ethanol and bioenergy adoption in Brazil (Goldemberg, 2009;Coelho et al., 2006;Geller et al., 2004;Moreira and Goldemberg, 1999;Pousa et al., 2007), Sweden (Bj \u00f6rheden, 2006;Ericsson et al., 2004;Nilsson et al., 2004;Uba, 2010;Wang, 2006) and the United States (Tyner, 2008;Hoekman, 2009;Hohenstein and Wright, 1994), we collated several important variables, including policies giving preferential treatment to bioenergy-related technologies, government-industry relations, the role of technological innovation, relevant domestic natural resources and feedstocks, and perceptions of technology risk on the part of key stakeholders. While these and other variables are influential in the successful adoption and diffusion of new energy technologies, the bioenergy cases discussed here offer particularly valuable studies of the interplay of technological and natural resource variables. The availability of sufficient domestic supplies of high-quality (i.e., energy dense and economically convertible) feedstocks for ethanol production and the state-of-the-art conversion technologies may be more decisive than other variables in determining success or failure.",
            "Nuclear": " Volatile petroleum prices, geopolitical conflicts in fossil-fuelrich regions, increasing energy demand from emerging economies, and climate change have contributed to a recent resurgence of interest in nuclear power based on its potential to address energy security without emitting carbon dioxide or regional pollutants (Sailor et al., 2000). As a source of electricity that could, from a technical standpoint, provide a substitute for large, centrally sited, baseload coal-fired power, nuclear power could significantly reduce greenhouse gas emissions. Nevertheless, varied experiences with nuclear power underscore the relatively minor role that technical feasibility and technological elegance have within the wider social matrix (Hultman, 2010). Interrelated problems of spiraling costs, government policy, and public opposition led to a virtual moratorium on the construction of new nuclear technology for decades. 1Re-examining this telling experience in nuclear deployment provides a useful comparison to the ethanol case. Nuclear power experienced a contentious history and cost escalation in the United States, which led to a long period of uncertainty in the industry (Bupp and Derian, 1981;Zimmerman, 1982;Cowan, 1990;Rhodes, 1993;Pool, 1997;Charpak and Garwin, 2001; The University of Chicago, 2004;Koomey and Hultman, 2007;Hultman et al., 2007;MIT, 2009). Sweden has had a mixed experience with nuclear power (Segelod, 2006;H \u00f6gselius, 2009;L \u00f6fstedt, 1996;Michanek and S \u00f6derholm, 2009;Nordhaus, 1997). After a program of aggressive domestic technological development, in 1980 voters elected to phase out all nuclear power by 2000. This policy was later reversed, but policy has experienced periods of ambiguity and, after Fukushima and renewed political opposition in nearby Germany and Switzerland, the future of nuclear in Sweden remains unclear. Brazil provides a third model: like Sweden, it began developing a domestic nuclear industry and continues to run one commercial reactor, but unlike Sweden, it did not develop a large-scale commercial nuclear power industry (Gall, 1976;de Carvalho and Sauer, 2009;Cabrera-Palmer and Rothwell, 2008). Brazil's halted nuclear development can offer some insights into additional non-economic barriers to the adoption of this technology.",
            "Factor selection": " The process of choosing a set of factors for interviewees to assess was initiated by an extensive review of the several literatures, focusing on case studies and theoretical descriptions as well as quantitative analyses on non-economic factors. The review covered political and sociological literatures at international, national, sectoral, and firm levels, and is described further in Appendix A in the Supplementary Information. This resulted in a list of 54 factors that were then evaluated and grouped by the project team, who critically assessed definitional and evidential issues and classified factors under appropriate categories. We then piloted the factor set with two experts, making changes in the set used for the full 78 interviews. We did not attempt to eliminate redundancies or overlaps in these varied literatures, preferring to hear the analyses of our respondents as they used their expertise and (often firsthand) experience to determine the important non-economic factors. Thus, the factors presented here are still, to a degree, open to interpretation. However, we found fairly substantial agreement on meanings for those factors respondents considered important.",
            "Data collection": " Together, the two technologies across three countries comprise six research comparisons (Brazil-Nuclear, Brazil-Bioenergy, Sweden-Nuclear, Sweden-Bioenergy, US-Nuclear, US-Bioenergy). For each comparison, the team selected roughly 12-15 interviewees across four categories: government officials and policymakers, industry managers, researchers, and industry analysts. The team conducted semi-structured interviews that began with an open-ended question asking what factors the interviewee considered important in the development of nuclear power or bioenergy in his or her country. Then interviewees were presented with a set of nine cards, each of which described a factor derived from the literature on technological transformation. These factors are shown in Table 1 and also described more fully in Appendix B in the Supplementary Information. Participants were asked to assign weights to the factors they consider most important in the diffusion process for the technology. Interviewees were asked to sort the cards into three categories: determinative (i.e., absolutely essential to the diffusion of the technology), important (but not determinative), and not important. For this paper, we report on the results from a collection of 78 interviews conducted in Brazil, Sweden, and the United States from March 2009 through January 2011.",
            "Coding and data analysis": " Interviews across the six cases yielded substantial information, both in the form of responses to structured questions on factors as well as responses to open-ended questions about technological and political contexts. These data are sometimes challenging to interpret by nature, since parsimonious quantitative analysis would ignore the rich texture in the data that may be essential for understanding the transitions. Yet, focusing only on the narratives makes the discovery of consistent strains across cases difficult. We therefore present three complementary approaches to the data: participant narratives, self-reported factor weights, and coding analysis of factors. First, participant narratives synthesize histories from careful compilation of the significant events as reported by participants in interviews. In all cases, participants showed broad agreement on the major events and relationship to technological change. We must acknowledge that these views of events are clearly not necessarily independent of each other, since the stories have no doubt been rehearsed extensively within each industry over the years. Nevertheless, given that the participants were in many cases deeply involved in the transitions, we feel these are helpful complements to the more systematic analysis. Second, we compiled the primary factors in the six case transitions, as reported by participants. Such self-reported data are central to tying the participants' own narrative histories to specific factors, and, crucially, to seek participants' weighting of the importance of each. It should be noted that a statistical analysis of these data is potentially problematic. First, while we made all efforts to ensure that we were discovering diverse inside perspectives on the respective cases, we cannot assert with full certainty that our expert sample is representative of a full population. As such, we present the data as likely representative, but at the same time, we deliberately refrain from false statistical precision and methods, such as means testing, that assume representative samples. Third, we assessed the same factors by coding participant interviews and then investigating the responses. We took this two-part approach to allow for the possibility that participants might rate some factors differently when prompted in a structured survey as opposed to talking about them informally. Both the narrative responses to the open-ended question and the categorizations of factors for the 78 interviews conducted in the current project were coded using NVivo. Within the 9 predetermined factors (Table 1), we identified 48 sub-factors that were then coded individually to investigate the dominant features of each factor. The sub-factors were not pre-determined, but rather were derived from the breadth of the interviews and reflect only the details and concepts discussed. They were primarily chosen for inclusivity of the data, rather than for mutual exclusivity between sub-factors, but honest attempts were made to avoid redundancies. (For more detail, see Appendix B in the Supplementary Information). Each interview was individually coded based on the presence of a sub-factor if the interviewee mentioned or described a sub-factor as important, whether negatively or positively influential. While many interviewees explored the entire history of a technology, which helped to enrich the narratives, the coding only focused on the central question of this research: which factors where important in the initial development of this technology? Instead of recording the frequencies of each sub-factor's occurrence, which would reflect how much an interviewee cared to discuss a topic, we recorded whether a sub-factor was discussed as important at least once in an interview. Therefore, the importance of a sub-factor was measured by the number of interviews in which it is mentioned, allowing us to compare the occurrence of sub-factors in one case (e.g. US-Nuclear) with the other five cases. We then ranked each sub-factor by the percent of International policy and foreign affairs Perceptions of international community, politics, and markets; risk of sanction; and presence of international polices. 8. Regulation Regulatory pressure and enforcement, regulatory and incentive uncertainty, and regulatory entities. 9. Miscellaneous external conditions Specific external conditions. interviews in which is it mentioned from each case: 0-49% as not important, 50-74% as important, and 75-100% as determinative.",
            "Results": "",
            "Narrative responses": " In their narrative answers to the open-ended question, ''What factors do you view as most important in the development of [Nuclear Power/Bioenergy] in [Brazil/Sweden/United States]?'', interviewees in both Sweden and Brazil told similar stories about how nuclear and biofuels technologies became major players (e.g., nuclear and biomass in Sweden, ethanol in Brazil) or negligible/minor contributors to the energy sector (biofuels in Sweden, nuclear in Brazil). In the United States, the narratives diverge somewhat-not in the factors themselves, considered as a set, but in the emphases and details given by individual interviewees. In the following sub-sections, we present narrative histories based on the interviews we conducted; they are provided as a complement to the subsequent analysis of factor weights and are not meant as stand-alone histories.",
            "Bioenergy-Brazil": " At the time of the 1973 oil crisis, approximately 80% of Brazil's oil was imported. When oil prices increased, the import bill increased from 500 million to 4 billion dollars, which drastically worsened Brazil's trade balance. The 1975 Proalcool Program, a revision of an earlier ethanol program, was seen as a solution to both energy and economic problems, gave new economic life to the floundering domestic sugarcane industry, and addressed regional imbalances with movement to the interior and rural development. The technology was available. On the production side, some distilleries could already produce ethanol in addition to sugar, so sugarcane mills were upgraded to be able to produce more ethanol. For demand, because of the 1931 mandate, car engines could already run on ethanol blends. Institutional support and memory came from the Institute of Sugar and Alcohol (IAA), which also facilitated partnerships among the private sugar plantations, the World Bank, and equipment manufacturers. Over 100 new mills opened in the 1970s. However, many of the cane plantations were traditionally run by families who were inexperienced with the new technologies, management, and labor relations. The Proalcool Program supported the ethanol industry through quotas, price floors and ceilings, tax incentives to produce ethanol and cars that ran on pure ethanol, requirements to provide ethanol pumps and use them exclusively on weekends, bank financing for only E100, higher taxes on gasoline-fueled cars, subsidies for transporting ethanol, and a mandatory ethanolgasoline blend, which started at 5% and increased to a current 20-25% blend level. In addition to policy, Brazil also utilized its expertise in sugarcane technology and products and increased support for research in developing high-yield cane varieties and improving ethanol fueled engines. The sugarcane mills shared knowledge and technologies. Mill consultants also played active roles in transmitting technology to mills and improved mill production processes. Finally, equipment manufacturers, like Dedini and Zenini, also played a crucial role in ethanol production. After this rapid expansion of ethanol production and consumption, three factors reduced the ethanol market: reduced oil prices, increased sugar prices, and reduced government support. During the 1980s, the price of oil fell, and ethanol became less competitive with gas. In addition, the new constitution of 1988 started to liberalize and reduce government involvement in the economy, funds for the Proalcool program ceased in 1989, and IAA was dissolved. Further, sugar mills began to export sugar, realizing higher sugar prices in the international market. Consumers began to have difficulty in obtaining ethanol, so demand for -and then production of -E100 cars decreased. By 2000, E100 cars were only available by special request. Many mills went bankrupt, and inefficient mills were closed or consolidated. In addition, the national oil company, Petrobras, had succeeded in finding oil off the coast, so energy security was not so pressing to the government. The second ethanol expansion began with the private sector development of flex fuel engines, which brought stable ethanol demand to the market and supported a solid integration of ethanol into the fuel market. In addition, research had dramatically improved production so that the ethanol price was competitive with gasoline. Currently, ethanol prices are very competitive at gas stations, and consumption of ethanol is higher than pure gasoline. The firm structure has also become more and more important as mergers and acquisitions represent almost 30 billion dollars.",
            "Bioenergy-Sweden": " With the onset of the OPEC oil crisis and rising concerns about acid rain, the combination of established district heating (DH) networks with domestic forest biomass fuels presented municipal governments across Sweden with a ready pathway to clean, secure, and affordable energy. A large number of Sweden's municipalities already had both municipally-owned electric utilities and DH systems in place. DH systems were originally built in the 1940s both to provide heat for industrial processes and to alleviate the often severe air quality problems stemming from coal use and coking that had plagued urban centers for decades. During the uncertainty and insecurity of World War II, the ease of fuel-switching that DH systems provided was recognized as a great advantage. Most Swedish municipalities were also situated close to forests and related industries that produced abundant streams of biomass wastes (e.g., logging operations, sawmills, and paper manufacturers), so switching from imported oil to domestic biomass was relatively easy. Sweden's decentralized political system also facilitated the country's transition to bioenergy. Sweden's 288 municipalities collect a significant share of their respective budget revenues through taxes levied locally and exercise a high degree of administrative and political autonomy. As such, municipalities were the main drivers behind Sweden's transition to the use of bioenergy, and the strategic alliances that municipalities formed with forest industry associations, sawmills, and the transportation industry played important roles in facilitating the knowledge exchange and easy adoption of biofuel technologies. Municipalities also recognized that adoption of biofuels would keep a larger share of revenues within their respective administrative boundaries, creating jobs and spurring economic growth. Since all major domestic constituencies (i.e., the forest, transportation, paper, and lumber industries; municipal and national governments; power producers; and the general public) saw the transition to biofuels as advantageous, no significant political obstacles impeded its progress. As fossil energy prices fell in the late 1980s and 1990s, so did economic incentives for investment in alternative energy sources. However, climate change concerns emerged as a key driver behind the switch to biomass energy. To sustain both interest in and incentives for investment in bioenergy and other renewable energy sources, Sweden's national government adopted two policies that have provided a stable regulatory environment for renewable energy: a tax on the carbon content of fossil fuels and a Green Certificate (GC) program that required fossil power plants to purchase offsetting credits from non-fossil energy producers. The GC program complemented the push effect of the carbon tax by creating a pull toward renewable energy generation and DH systems, since owners of wind, bioenergy, and other renewable electric plants received direct payments from electricity consumers. The program also provided government grants to assist companies and municipal governments to invest in new renewable energy facilities. Following the institution of these two policies in the early 1990s, bioenergy's share of final energy use in Sweden more than doubled to approximately 30% by 2009. Renewable energy now accounts for more than 60 percent of Sweden's primary energy supply.",
            "Bioenergy-United States": " Although the liquid biofuels industry in the United State did not attract federal policy support until the 1970s, an ethanolpowered transportation fleet had been considered since the early twentieth century. Despite early efforts by the automotive industry to promote ethanol, plentiful and low-cost gasoline remained the economic choice, especially as Prohibition-era regulations inhibited the penetration of alcohol fuels in the US market. During World War II, US ethanol production rose to 600 million gallons annually, as fuel producers ramped up production as a gasoline additive to alleviate fuel scarcities. Production fell quickly following the war, as government contracts ended and the discovery of huge oil deposits, particularly in Saudi Arabia, shored up the long-term dominance of gasoline. The 1973 OPEC crisis renewed interest in ethanol as a means of reducing US oil import dependence. The Carter Administration and Congress responded to the oil crisis with the Energy Tax Act of 1978, which provided a $0.40 per gallon subsidy to ethanol producers and a federal excise tax exemption for ethanol-blended gasoline. At the same time, the 1975 decision to phase out tetraethyl lead as an octane booster in gasoline, also created significant opportunities and incentives for US ethanol producers. A complementary import tariff prevented low-cost foreign producers, such as Brazil, out of the US market and helped facilitate a resurgence of US ethanol production and use. As a result, by 1980, there were some 100 commercial ethanol plants operating in the United States. After sluggish growth in the 1980s, the industry took off again when the Clean Air Act Amendments of 1990 mandated the use of reformulated gasoline in non-compliance areas. Although methyl tert-butyl ether (MTBE) was commonly used for this purpose, its toxicity and environmental liabilities from the contamination of soil and groundwater prompted refiners to switch to ethanol. A resulting de facto ban on MTBE combined with high gasoline prices made ethanol a profitable commodity again. Production accelerated as demand grew from 900 million gallons in 1990 to 1.4 billion gallons in 1995. Following the gasoline prices in the early 1990s, associated mainly with the Persian Gulf War, gasoline prices fell to previous levels. Production stagnated for more than a decade, and significant consolidation occurred in the industry. Marginal growth occurred in proportion to overall growth in US fuel consumption in that period, but, in the absence of structural changes in the market or policy environment, ethanol was poised to remain a slow-growth commodity in the United States. In the early 2000s, resurgent gasoline prices, the threat of war in the Middle East, and climate concerns renewed interest in domestic biofuels. Congress codified these concerns in the 2005 Energy Policy Act (EPAct), which instituted a Renewable Fuels Standard (RFS) and set new reporting and compliance requirements for fuel producers. The RFS mandated that specified quantities of biofuels be consumed each year, beginning at 9 billion gallons in 2008 and increasing steadily thereafter. The subsequent Energy Independence and Security Act (EISA) of 2007 ramped up the provisions of the RFS, increasing annual biofuels use to 36 billion gallons by 2022. These laws effectively guaranteed a long-term domestic market for ethanol producers. The subsequent explosive growth of ethanol proved politically popular as well, since US agribusiness and corn growers, both powerful political constituencies, were major beneficiaries and proponents of the expansion.",
            "Nuclear-Brazil": " To sustain Brazil's rapid growth in the late 1960s (the ''Brazilian Miracle''), the military regime sought to increase the supply of energy. Nuclear power was seen as a good option for generating a complementary source of baseload energy to the hydroelectric and coal plants. The nuclear program was developed and implemented throughout the military dictatorship; it supplied energy, but also fulfilled a political goal of symbolizing Brazil's increased sophistication and met strategic goals in expanded technological capabilities, increased industrialization, utilization of large domestic uranium reserves, and provision of the opportunity to develop nuclear weapons. Following successful examples in Europe and the US of nuclear power generation, President Geisel, under increased pressure to find domestic sources of energy after the 1973 oil shock, created the Brazilian Nuclear Corporation (Nuclebra \u00b4s). Nuclebra \u00b4s was directed to expand Brazil's nuclear research program into energy generation under Brazil's initiative to shift energy production to domestic sources. Through the US's Atoms for Peace Program, construction of Brazil's first reactor, Angra 1, began as a turnkey project by Westinghouse in 1971. Because enrichment technology was not included, Brazil signed an agreement with West Germany in 1975 for Angra 2 and 3, in order to obtain the technology associated with the entire nuclear fuel cycle. The government supported these efforts through several state-run companies like Nuclebra \u00b4s and the National Commission of Nuclear Energy (CNEN). CNEN coordinated nuclear efforts among the universities, industry, and research centers. The private sector at that time either did not or could not participate. The second oil shock in 1979 magnified economic and political problems, and lowered energy demand, so President Geisel decreased funding for the nuclear energy program. Brazil was also pressured by the US under the Carter Administration to stop the nuclear program in order to meet US non-proliferation goals. In addition, public support had decreased after nuclear accidents at Three Mile Island, Chernobyl, and Goi\u00e2nia. As a result, construction of the Brazilian-German reactors stopped. Further, oil deposits were found off the Brazilian shore, relieving some of the pressure to find alternative domestic sources of energy. However, a parallel nuclear program, with support from the Brazilian Navy and IPEN (Instituto de Pesquisas Energeticas e Nucleares), operated throughout the 1980s and eventually developed a complete centrifuge uranium enrichment process. Since the early 2000s, nuclear energy has received renewed interest as a viable alternative source of baseload electricity. In addition to advancing general economic development and sophistication, the government's renewed support stems from (1) concerns that the remaining sites for new hydroelectric power are in the Amazon, far away from urban centers and problematic socially and environmentally; (2) domestic development of enrichment technology (although production has not yet reached industrial scale); and (3) the capability to directly finance reactors and fuel production through state-run enterprises and the associated lower-risk parameters. Public opinion is also more favorable; however, the impact of the recent crisis in Japan remains to be seen. Finally, international perception is also more positive, and Brazil has signed the Non-Proliferation Treaty. Currently, the major challenge is to implement a national policy which delineates responsibility and ownership clearly enough for efficient resource use. In addition, there is a lack of qualified human resources, as most of the skilled workforce is approaching retirement.",
            "Nuclear-Sweden": " In 1945, a US delegation made an unannounced visit to Sweden to look at the uranium deposits, which, while of poor quality, were some of the largest in Europe. Sweden did not do business with the United States, but after World War II, the Swedish government realized that nuclear weapons were the weapons of the future, and the country desired an effective deterrent weapon as it sat neutral between NATO and Russia. Sweden quickly realized that it had the capacity to develop such nuclear weapons through heavy water reactor projects that could produce weapons grade material. The government founded Atomenergi, a state-owned nuclear research company, to run a research center in Studsvik and develop nuclear reactor and weapons technology. Atomenergi and Vattenfall, the state-owned utility, designed and built the first heavy water reactor demonstration plant in \u00c5gesta, which started up in 1963. Surprisingly, Sweden developed the technology independently instead of licensing from another country. \u00c5gesta successfully produced electricity and could produce small amounts of weapons material, but it was considered too small. A plant in Marviken followed, but the ambitious design made it too unstable for start up and was turned into an oil-fired generation plant. Support and need for a nuclear weapons program dwindled and officially ended when Sweden signed the Nuclear Non-Proliferation Treaty at the end of the decade. After WWII, hydropower had fueled Sweden's industrial revolution, but the limits of hydropower became evident, and the environmental impacts of coal and oil were quickly seen as unacceptable. Energy independence also became more important. Nuclear power became the obvious choice, especially since the large baseloads already fit into the pre-existing centralized hydropowered electricity systems. The government under Prime Minister Tage Erlander invested in research and development on heavy water reactors through Atomenergi. Private companies started to challenge the government's monopolistic reign on nuclear power. ASEA, a manufacturing firm, led by Curt Nicolin, took the risk to develop its own light water reactor technology, again without a license. In 1965, ASEA signed a contract with Vattenfall to build Oskarshamn Unit One, which came on the grid in 1972. In the mid-1970s, the government-owned Atomenergi forced a merger with ASEA, becoming ASEA-Atom. Together with Vattenfall and a large cadre of newly-trained nuclear engineers, 12 nuclear power plants were built and operated in Sweden over the next decade. By the end of the 1970s, the political tone had changed, challenging the safety and impact of nuclear technology. The Centre Party gained control in Parliament and its leader, Gunnar Hedlund and his advisor, physicist and Nobel Laureate Hannes Alfve \u00b4n, thought nuclear power to be extremely dangerous. The advent of the environmental movement, Rachel Carson's Silent Spring, and the Three Mile Island nuclear accident in 1979 culminated in a moratorium on construction and a public referendum on nuclear in 1980, resulting in an agreement to phase out nuclear by 2010. As the century ended, little action had been taken to shutdown any plants, given that nuclear constituted nearly 50% of generation. Pressure was placed on the Social Democrat-led government by citizens, the Centre Party, and several neighboring countries to close two reactors in Barseb \u00e4ck. An agreement was reached in 1997 to close the two reactors, which served ostensibly as an alternative to the complete 2010 phase-out advised by the Centre Party. This meant that the government could continue, and has to this day, upgrading the reactor units in the existing plants, extending their life to 55 or even 60 years. For the foreseeable future, nuclear power will remain a large part of the Swedish energy system. Issues of safety and waste, especially, remain, and companies like SKB were created to deal with these issues.",
            "Nuclear-United States": " The demonstrated power of nuclear energy to kill wartime enemies gave way to a push for nuclear energy to make electricity, as articulated by President Eisenhower's ''Atoms for Peace'' programs. There was a promise of electricity ''too cheap to meter,'' coupled with rising demand, which gave nuclear a luster-one respondent called this ''magic'' associated with the new technology. Participants agreed there was a very visible champion in Navy Admiral Hyman G. Rickover, who essentially chose the light water reactor. Electricity demand was rising at 6% or more per year, with the expectation that this rate would go on indefinitely, and costs were expected to decline as companies gained experience with building nuclear plants. Despite the uncertainties, from technical to financial, the federal government gave the strongest possible support; massive government subsidies were very effective in the early years. The Atomic Energy Commission (AEC)  regulated nuclear energy, working with the congressional Joint Committee on Atomic Energy to devise processes for siting, waste management, and research and development-all essential to the industry's development. Until the late 1960s, nuclear power became an increasingly important part of meeting the overall energy demand growth. The Price-Anderson Act (1957) and other regulations minimized the financial risks of building nuclear plants, firms were eager to build, and costs declined as bigger generators were built. In addition, concerns about the environmental impact of coal burning led to a reluctance to build coal-fired plants until uncertainties about regulation were settled. In contrast, the US government was in the business of funding new technologies, from development through deployment. Many plants were built while regulations were evolving, and the AEC operated fairly independently. Utilities felt a mission to serve rising demand, and construction firms took pride in being part of the nuclear expansion. In the 1970s, anti-nuclear forces, always present as a deep distrust of the military foundations of nuclear as well as environmental concerns, increased their activities at the same time that economic downturns, rising costs of nuclear generation, and lower demand made nuclear power less attractive. The 1979 Three Mile Island (TMI) accident was a visible ''breaking point'' for nuclear, but the conditions of change were already present before this accident. There has been much talk of a ''nuclear renaissance'' in the US The question of how to build a capital-intensive plant with minimal environmental impact is perhaps the biggest question, though after the failures at Fukushima there will also be new questions of safety. The industry learned from TMI, productivity was rising and safety had improved, but challenges remained in standardization and regulation. The government has streamlined licensing, and public attitudes have become more positive.",
            "Results-Self-reported factors": " Our interview protocol involved asking participants to assess which factors (see Table 1) they viewed as ''determinative'', as opposed to simply ''important'' or ''not important.'' Fig. 1 shows the resulting assessment of factors, according to technology and country. It is clear that, in aggregate, the factors of domestic policy and characteristics of the technology were seen as determinative, a result we will return to in a later section of the paper. This figure, however, demonstrates a broad pattern of consensus that several factors, foremost among them domestic policy, were determinative across the six cases, as demonstrated by the factors with the highest cumulative responses. The figure also shows some divergence by sector in the factor perceptions, which is also evident from the differences in response across country and technology (cases are denoted by color and the vertical bar demarcates the two technologies). Fig. 2 shows these differences through relative frequency, as well as the contributions by each country to the total for each sector. While domestic policy and technological characteristics were consistently ranked highly in both nuclear and bioenergy, some variation is apparent in the rankings of corporate culture (more heavily weighted by nuclear), decision-making characteristics of the firm (nuclear), and international policy (bioenergy). Individual cases exhibit other variations as well, providing more detail into the importance of each factor between sectors and countries. Fig. 3 displays the rankings of each of the six cases. In addition, to better understand the relative importance of each factor, we define a simple normalization statistic, which we call the relative prominence f. The relative prominence is simply the number of times that a specific factor i was identified as ''determinative'' (n det,i ) compared to the total number of times all factors were identified as determinative (N det ): f i n det,i N det Fig. 3 also shows f for each factor within each case. Domestic policy is clearly dominant across all cases, but its contribution was more prominent in some cases than others. For example, domestic policy in Brazil Nuclear (f\u00bc0.26) is less prominent than Sweden Nuclear (f\u00bc 0.29) despite having a greater relative frequency. While technological characteristics ranked second cumulatively (see Figs. 1 and 2), much of that weight appears to come from both sectors in Brazil (Fig. 3a and b) and US Nuclear (Fig. 3e).  Technological characteristics were ranked lower and were less prominent in the other cases. Regulation (REG) was relatively important for both US Nuclear (f\u00bc0.17) and US Bioenergy (f\u00bc0.16), but was substantially less important across the other four cases. Corporate culture (CC) ranked in the top half in the nuclear sector but ranked in the bottom half of the bioenergy sector, with the of Sweden (Fig. 3d). Similarly, international policy (INT) ranked consistently in the top half of the bioenergy sector, yet ranked relatively much lower in the nuclear sector. Characteristics of the firm (FIR), characteristics of the sector (SEC), and decision-making characteristics (DEC) all generally fell out in the middle of the rankings across the six cases.",
            "Results-Coding to reveal structure within factors": " While the participant assessments of ''determinative'' factors are illuminating, the nine factors themselves are (deliberately) broad. Each panel displays the relative frequency rating f for each of nine factors within that specific case (e.g., a\u00bc Brazil Nuclear). As discussed in the text, f provides an index of how strongly an individual factor was weighted compared to the other factors within that case. Note that the f are ranked from least to greatest for each case; as such the left-hand axis varies across (a)-(f). However, the nine factors are uniquely color-coded (e.g., Domestic Policy (DOM)\u00bc darkest gray and Firm Characteristics (FIR) \u00bcwhite) which allows for comparison of rank order and magnitude across cases. Our interviews, however, allowed us to probe any structure within each of the nine factors by analyzing participant responses in finer detail. To do this, we coded each of the interviews for 48 sub-factors. We then clustered each of these sub-factors within the nine predetermined factors to see what elements of each factor were most important in the development of the technology in each case, which added more texture to complement the narratives. Figs. 4-6 present the results of this coding analysis for Brazil, Sweden, and the United States, respectively. Fig. 4 shows the results for Brazil. For the nuclear sector (Fig. 4a), four factors were identified to have at least one important or determinative sub-factor-representing 50-74% or 75-100% of the interviews, respectively. Seven sub-factors were determinative-Coalitions (75%) and Technical Expertise (75%) within Characteristics of the Sector; Technology License (75%) within Characteristics of the Technology; Energy Security (83%) and Government Investment (75%) within Domestic Policies; and International Policy (83%) and International Relationships (75%) within International Policy & Foreign Affairs. For Brazil Bioenergy (Fig. 4b), three sub-factors were determinative across three factor clusters-Complementary Industries (100%) within Characteristics of the Sector; National Strategy (77%) within Domestic Policies; and International Policy (100%) within International Policy & Foreign Affairs. Fig. 5 shows the sub-factor coding results for Sweden. For Nuclear (Fig. 5a), six factors contained at least one important or determinative sub-factor: Characteristics of the Sector, Characteristics of the Technology, Domestic Policies, Firm Structure & Organization, International Policy & Foreign Affairs, and Regulation. Only four sub-factors were determinative, all within Domestic Policies-Energy Security (92%), Political Philosophy (83%), Military and Weapons Program (75%), and Government Investment (75%). For Sweden Bioenergy (Fig. 5b), seven sub-factors were determinative across four factor clusters-Complementary Industries (86%) and Developed Energy Sector (79%) within Characteristics of the Sector; Environmental Concerns (86%) and Nature of the Fuel Stock (79%) within Characteristics of the Technology; Energy Security (86%) and Tax & Incentive Programs (79%) within Domestic Policies; and International Policy (86%) within International Policy & Foreign Affairs. The sub-factor coding results for the United States are shown in Fig. 6. For US Nuclear (Fig. 6a), five factors had at least one important or determinative sub-factor-Characteristics of the Sector, Corporate Culture, Decision-making Characteristics, Fig. 4. Identification of sub-factors revealed from coding analysis of interviews for Brazil: (a) nuclear and (b) bioenergy. The nine overall factors presented to participants are represented by the dark gray boxes on the left of each figure. These factors were chosen to span the possibility of factors that could undergird major energy technology transitions (see text). Additional information on structure within each factor was elicited from the interviews via a coding analysis of 48 sub-factors that were generated from the full set of interviews. Each light gray bar on the right of each figure shows the percentage of interviewees in each case who mentioned specific sub-factors, and numbers in parentheses indicate the fraction of participants mentioning that sub-factor. For example, in (a), 75% of interviewees (N\u00bc 12) discussed the sub-factor Technology Licensing within the factor Characteristics of Technology (TEC). The longest of the light-gray sub-factor bars indicate those sub-factors which were mentioned by greater than 75% of participants. We defined a revealed importance of each sub-factor according to whether it was mentioned by more than 50% (important) or 75% of participants (determinative). Domestic Policies, and Regulation. Government Investment (80%) was only determinative sub-factor. For US Bioenergy (Fig. 6b  . Additional information on structure within each factor was elicited from the interviews via a coding analysis of 48 sub-factors that were generated from the full set interviews. Each light gray bar on the right of each figure shows the percentage of interviewees in each case who mentioned specific subfactors, and numbers in parentheses indicate the fraction of participants mentioning that sub-factor. For example, in (a), 92% of interviewees (N \u00bc12) discussed the sub-factor Energy Security within the context of the factor Domestic Politics, Preferences, and Policy (DOM). The longest of the light-gray sub-factor bars indicate those sub-factors which were mentioned by greater than 75% of participants. We defined a revealed importance of each sub-factor according to whether it was mentioned by more than 50% (important) or 75% of participants (determinative). focused on a different policy tool to accomplish the transition-Technological Development programs in Brazil (f\u00bc0.50), National Strategy Policies in Sweden (f\u00bc0.82), and Tax & Incentive Programs in the US (f\u00bc 0.54).",
            "Discussion": " We have sought to select cases and apply methods such that our results are robust across technology and country contexts. However, this approach is not exhaustive, and there remain several limitations and uncertainties. Some limitations are inherent, but many exist for future research that either complement or build on these results. . Additional information on structure within each factor was elicited from the interviews via a coding analysis of 48 sub-factors that were generated from the full set of interviews. Each light gray bar on the right of each figure shows the percentage of interviewees in each case who mentioned specific subfactors, and numbers in parentheses indicate the fraction of participants mentioning that sub-factor. For example, in (a), 80% of interviewees (N \u00bc15) discussed the subfactor Government Investment within the context of the factor Domestic Politics, Preferences, and Policy (DOM). The longest of the light-gray sub-factor bars indicate those sub-factors which were mentioned by greater than 75% of participants. We defined a revealed importance of each sub-factor according to whether it was mentioned by more than 50% (important) or 75% of participants (determinative). One limitation is that we have only looked at two classes of technology, each of which carries its own idiosyncrasies. Similar empirical studies of factor weightings for different sectors or technologies would therefore be helpful. The trend toward increased empirical work in this field should provide some basis for contextualizing these results across other countries as well. Second, there remain reasonable questions about the selection of individual factors. A question embedded in our approach is the degree to which our identified factors-either as reported by participants or as coded from interviews-are independent of each other. Even in our selection of the nine overall factors, we were aware that some factors were clearly not orthogonal: for example, firm organization, corporate culture, and industry structure seem likely to be coupled in at least a loose way. Conversely, questions arise as to whether the same information can be captured by targeting fewer factors. While we do not believe that these issues undermine the validity of our results, there remains scope for increasing the elegance of explanation through reducing the number of factors. There are several statistical techniques that can be applied to this problem but, given our relatively small sample sizes for each case (roughly 12) and sector (roughly 36) and the absence of random sampling, we are reluctant to present any analysis as statistically definitive. This is nevertheless a potentially interesting locus for future research, which would be aided by gathering larger-N datasets, investigating factor covariances, and identifying a reduced set of combinations of factors that explain participant responses. A third question that arises is to what extent the participants are reliably and consistently reporting their sense of relative weight. We have one approach to check this question, as we can compare self-reported factors with the factors that arose from the coding analysis. Brazil Nuclear seems inconsistent, as none of the important or determinative factors identified with the coding, except domestic policies, were identified as determinative within the self-reported ranking. For Sweden Nuclear, however, all of the important or determinative factors from the coding were identified as determinative from the self-reported ranking, with the exception of regulation, which was not mentioned by the participants. Each of the remaining four cases had one determinative self-reported factor that did not show up in the sub-factor coding: Characteristics of the Technology for Brazil Bioenergy, Corporate Culture for Sweden Bioenergy, Characteristics of the Technology for US Nuclear, and International Policy and Foreign Affairs for US Bioenergy. There are two possible reasons for any disparity: either the participants themselves are not consistent, or the methods we are using are inaccurate. While these instances indicate that the approach is not perfect, the fairly close agreement we observed between the self-reported factors and the coded results gives us confidence that the results are reliable. Our results point to additional future research directions. While this study establishes relative importance of factors, a potentially important finding of the case studies was that interviewees described, for all cases of diffusion, at least three distinct phases to the technology diffusion process: (1) a take-off phase, (2) a pull-back phase, and (3) a new surge phase. Moreover, the importance of the factors changed over time as diffusion proceeded. By focusing on a set of nine non-economic factors in our initial research project, we identified several influential variables in the technology diffusion process that have not been captured by the classic S-curve depiction. The time dimension of these factors, however, remains open for research that could help create a richer understanding of that process, and to create new theoretical models with greater explanatory power. New empirical inquiries to expand the number and diversity of case studies could illuminate this process in more detail and inform the derivation of principles about the energy technology diffusion process through a study that tests the relative influence of a wide array of non-economic factors. In addition, a more focused and detailed examination of the most important factors would help indicate what best practices might be for countries wishing to encourage, through policy and market transformation, low-carbon technological transitions.",
            "Conclusion": " This paper presents results from six cases in which low-carbon energy technologies experienced a substantial growth over the past 50 years. Through interviews with key participants and experts, we traced not only the history of each technology in each country but also asked participants to select the factors they deemed most important in that technological trajectory. Our results show that several factors were viewed as particularly important in shaping these energy system changes: domestic policy that targeted goals such as domestic economic competitiveness, energy security, rural development, and support for existing industries. Other factors included the initial saturation or expertise in the technology and energy sector; as well as the structure of the private sector management, political networks, and financial capacity. These results illustrate the large degree to which major energy technology transformations are dependent on non-economic factors. While it is undoubtedly true that pricing externalities properly will help drive countries toward a lower-carbon economy, it is not at all clear that pricing policies are either forthcoming or feasible as an initial step across a wide swath of the global economy. Indeed, for the cases we present here, externality pricing was a following, and not a leading factor, to technological changes. In the cases we studied, a strong national commitment to the technologies, including steady and sustained market transformation policies, as well as a pre-existing sociotechnical infrastructure, were common features of successful transformations. Understanding these factors better, how they change over time, and how best to influence via policy, may be a productive path to achieving global emissions reductions through national policies."
        }
    },
    "10.1016/j.enpol.2006.01.027": {
        "file_name": "4 Explaining the failure of the Dutch innovation system for biomass digestion",
        "title": "Explaining the failure of the Dutch innovation system for biomass digestion-A functional analysis",
        "abstract": "Since the 1970s research on energy conversion technologies, such as biomass digestion, has been carried out in the Netherlands. However, after 30 years biomass digestion has not been implemented on large scale. The aim of this paper is to create insight into the underlying factors of this troublesome trajectory by applying the \u2018Functions of Innovation Systems\u2019 framework. This results in clear understanding of the (lack of) activities that took place in the innovation system of biomass digestion and the role of government policy in both inducing and blocking this development. The analysis provides several lessons to take into account when developing policies for the acceleration of the development and diffusion of biomass energy.",
        "label": "Mixed",
        "text": {
            "Introduction": " Since the energy crises in the 1970s and the increased climate change awareness in the nineties, research has been carried out to find alternative energy sources to replace fossil fuels. One of the most promising alternatives is biomass. The potential of biomass is estimated in long term scenarios to contribute about 1135 EJ/year (Hoogwijk, 2004). Biomass is a very diverse energy carrier with a multitude of potential sources and applications and it may be the main renewable energy alternative that could compete on large scale with fossil fuels. Even though the potential of biomass is clear, this does not imply that the implementation of biomass energy is easy. In the Netherlands for example realisation of the national goals regarding the use of biomass energy is far behind schedule. Therefore, in this paper we analyse the troublesome history of the development and application of a specific biomass conversion technology, i.e. biomass digestion, to learn lessons from the difficulties and problems that characterise this development during the last 30 years. Our main research question is therefore: How can we explain the slow diffusion of biomass digestion technology in The Netherlands? From earlier studies on the transformation of the energy system we have learned that the success of a new technology is not (only) determined by technological characteristics but (also) by the social system that develops, diffuses, implements or rejects new biomass technologies (Jacobsson and Bergek, 2004). We label this sociotechnical system as 'Technology Specific Innovation System' (TSIS). The conceptual starting point of this paper is that a well functioning TSIS is a requirement for the technology in question to be developed and widely diffused. In fact diffusion cannot take place on a large scale without a well functioning TSIS. However, what determines whether an TSIS functions well or not and how do we know that is does so (apart from studying the diffusion of the technology)? In a recent stream of articles, of which a significant number in Energy Policy, it is brought forward that a number of activities are of great influence to this system functioning (Jacobsson andJohnson, 2000, 2001b;Johnson and Jacobsson, 2001;Sagar and Holdren, 2002;Foxon et al., 2005). These key activities are labelled as 'Functions of Innovation Systems'. In earlier empirical papers these functions are successfully used to describe the dynamics of innovation system development and deliver explanations for the success and failure of TSIS in different countries. However, most of these analyses lack a research design into which all relevant activities are mapped over time to create insight in the precise evolution of functional patterns. In this case study we apply a method called process analysis (or history event analysis) to create deeper insight in the dynamics of innovation systems by a detailed mapping of innovation system activities (Abbot, 1995). The empirical case of biomass digestion in The Netherlands is reported before (Raven, 2004). It provided valuable insights in terms of how structural factors like the development of the socio-technical landscape and the impact of mismatched rule-sets influenced the diffusion of digestion technology. In this article we aim to add to these insights by focusing on the resulting patterns of activities that took place. We expect that structural factors and activities influence each other mutually. Therefore the aim of this paper is not only to learn lessons from the unsuccessful story of biomass digestion but also to test the 'Functions of Innovation Systems' approach by applying it in an innovative manner to structure empirical work so that complementary insights to previous work can be generated in order to provide complementary insights to previous work (Jacobsson and Johnson, 2000;Raven, 2004). The paper is structured as follows. In Section 2 an overview of the background of the Innovation System approach and the 'Functions of Innovation Systems' concept will be given with a focus on the functions that will be used in this paper. In Section 3 the methodology and the technical aspects will be described. In Section 4 the event description of biomass digestion and in Section 5 the function fulfilment will be analysed. Section 6 contains lessons from (a) a methodological perspective and (b) from a policy perspective building on a richer understanding of the activities and the lack of activities that took place.",
            "Analytical framework": "",
            "Technological change and innovation systems": " The underlying theory of this paper focuses on the 'lockin' of established systems and the difficulty that firms encounter when they want to develop a new technology and bring it to the market (Unruh, 2000(Unruh, , 2002)). It is argued in Unruh (2000) that ''industrial economies have been locked into fossil fuel-based energy systems through a process of technological and institutional co-evolution driven by path-dependant increasing returns to scale.'' He calls this condition 'carbon lock-in' since it creates persistent market and policy failures that inhibit the diffusion of carbon-saving technologies despite their apparent environmental and economic advantages. Unruh (2000) argues further that the ''lock-in occurs through combined interactions among technological systems and governing institutions, which perpetuate fossil fuel-based infrastructure in spite of their known environmental externalities and the apparent existence of cost-neutral, or even cost-efficient, remedies''. These technological systems have to be seen as large complex systems of technologies embedded in a powerful conditioning social context of public and private institutions. To avoid confusion with other definitions of technological systems (Hughes, 1983) we label these systems as 'TSIS', which are defined as: ya dynamic network of agents interacting in a specific economic/industrial area under a particular institutional infrastructure and involved in the generation, diffusion and utilisation of technology (Carlsson and Stanckiewicz, 1991). Once such a system is locked-in it is very difficult to displace it and alternative technologies can be locked-out for a long time even if they demonstrate improvements upon the established systems (Unruh, 2000). It is impossible to isolate a single factor, which could un-lock the system, but one possibility could be that the existing system loses viability because the selection environment is changing and provides new types of challenges which cannot be met with the dominant technology or require advances which are only possible at too high costs (Schot et al., 1994). When alternative technologies do meet the new challenges the process of building a new TSIS that is created around the new technology starts. In Jacobsson and Johnson (2000), the rise of renewable energy technologies are explained by analysing the development of a new TSIS that co-evolves with the development of a new technology. The growth of an emerging TSIS can be stylised by identifying different development phases, such as a formative phase and a diffusion phase (Jacobsson and Bergek, 2004). The formative phase is characterised by a range of competing designs, small markets, many entrants and high uncertainty in terms of technologies, markets and regulations (Jacobsson and Johnson, 2002). This phase involves the exploration of niche markets where the technology can develop and be tested by users and demonstrate its superiority in some dimension(s), such as environmentally or economically (Kemp et al., 1998). The development phase is characterised by a fast growing market, a selection of a dominant design and a fast reduction in production costs. To unlock the existing energy system, it is important that several TSIS develop successfully and take over part of the existing energy system. An important research question is: what are the determining factors that explain this successful growth? Edquist (Edquist, 2001) states that these determining factors can be traced by identifying all those activities that take place in innovation systems that influence the development, diffusion and use of an innovation. These activities are also called 'Functions of Innovation Systems'; from now on we will call them 'system functions'. The concept of system functions was developed by Jacobsson and Johnson (2000) who defined it as ''a contribution of a component or a set of components to a system's performance''. They argue that a TSIS, ''may be described and analysed in terms of its 'functional pattern', i.e. in how these functions have been served'' (Jacobsson and Johnson, 2000). The system functions are related to the character of, and the interaction between, the components of an innovation system, i.e. actors (e.g. firms and other organisations), networks and institutions, which may be specific to one innovation system or 'shared' between a number of different systems (Jacobsson and Johnson, 2000;Edquist, 2001). To understand how a technology is developed, diffused and implemented, the functional pattern of the related TSIS will be described and analysed through time. We expect that the more functions are served and the better they are served, the better the performance of the TSIS, thus the better the development, diffusion and implementation of innovations (Edquist, 2001). 1 In the following paragraph, the system functions and how they have been measured will be described.",
            "System functions": " In recent literature different sets of system functions are used to structure empirical material. In Hekkert et al. (forthcoming), these sets of system functions have been discussed and one system functions list is proposed. We will use this set of system functions to structure the empirical work on biomass digestion.",
            "Function 1: entrepreneurial activities": " The existence of entrepreneurs in the innovation system is of prime importance. Without these entrepreneurs innovation would not take place and the innovation system would not even exist. Thus the entrepreneur is essential for a well-performing system. The role of the entrepreneur is to turn the potential of new knowledge development, networks and markets into concrete actions to generate and take advantage of business opportunities. Entrepreneurs can be new entrants that see such opportunities in new markets or incumbent companies who diversify their business to take advantage of new developments. Our framework starts from the proposition that all seven system functions are important to reach a good system performance. However, when one would rank the different system functions, one might state that the functions two to seven are supportive in relation to function one; they should create the right entrepreneurial climate in which entrepreneurial activities can blossom. Note however, that it is the combination of the system functions that leads to system performance, not just entrepreneurial activities. This function can be analysed by mapping the number of new entrants, the number of diversification activities of incumbent actors and the number of experiments with the new technology (see Chapter Methodology for quantitative indicators).",
            "Function 2: knowledge development (learning)": " Mechanisms of learning are at the heart of any innovation process. For instance, according to Lundvall (1992) 'the most fundamental resource in the modern economy is knowledge and, accordingly, the most important process is learning'. This function includes 'Learning by Searching' and 'Learning by Doing'. We have mapped this function by counting the number of R&D projects per year.",
            "Function 3: knowledge diffusion through networks": " The network makes out the structure of the innovation system; it can be considered as an intermediate form of organisation between organisations and markets. According to Carlsson and Stanckiewicz (1991), its essential characteristic is the exchange of information. This is important in a strict R&D setting, but especially in a heterogeneous context where R&D researchers meet government, competitors and market. Networks allow policy decisions (standards, long-term targets) to be based on the latest technological insights and information through networks can lead to changing R&D agendas affected by changing norms and values. We mapped the number of workshops and conferences devoted to digestion. We used this indicator as a proxy for knowledge exchange in the digestion network.",
            "Function 4: guidance of the search": " Since resources are limited in nature, it is important that when various different technological options exist, specific foci are chosen for further investments. Without this selection there will be insufficient resources left over for the individual options. The function can be fulfilled by a variety of system components such as the industry, the government and/or the market. As a function, guidance of the search refers to those activities within the innovation system that can positively affect the visibility and clarity of specific wants among technology users. An example is the announcement of the government goal to aim for a certain percentage of renewable energy in a future year. This event grants a certain degree of legitimacy to the development of sustainable energy technologies and stimulates the allocation of resources for this development. An important, though elusive, class of phenomena here concerns expectations (see the work of van Lente, 1998van Lente, , 2000)). Often actors are 'initially' driven by little more than a hunch. Vague ideas are often tried out and their success (and failure) can be communicated to other actors, thereby reducing the (perceived) degree of uncertainty. Occasionally, under the influence of 'success stories', expectations on a specific topic converge and generate a momentum for change in a specific direction. This function can be evaluated by mapping specific targets set by governments or industries regarding the use of a specific technology and by mapping the number of articles in professional journals that raise expectations about new technological developments. By counting the number of articles that are positive or negative regarding the new technology development, the state of debate can be assessed. A strong discussion about the potential shortcomings of a new technology is likely to hamper further developments while a strong emphasis on the positive aspects is likely to stimulate technology development.",
            "Function 5: market formation": " A new technology often has difficulties to compete with embedded technologies, therefore it is important to create protected spaces for new technologies. One possibility is the formation of temporary niche markets (Schot et al., 1994) for specific applications of the technology. Another possibility is to create a temporary competitive advantage by favourable tax regimes or minimal consumption quotas. By mapping the number of niche market initiatives, specific tax regimes for new technologies and environmental standards that improve the chances for new sustainable technology, the fulfilment of this function can be assessed.",
            "Function 6: resources mobilisation": " Resources, both financial and human capital, are necessary as a basic input to all the activities within the innovation system. For biomass digestion, the allocation of sufficient physical resources, in the shape of the biomass material or land to grow, store or process it, is also necessary to make further developments possible. This function is difficult to analyse by specific indicators, since the information about whether resources are sufficiently available or not, can only be found from opinions of actors in the literature. We analysed this function by counting statements of actors in literature regarding their perception of resource availability.",
            "Function 7: support from advocacy coalitions": " In order to develop well, a new technology has to become part of an incumbent regime, or has to even overthrow it. Parties with vested interests will often oppose this force of 'creative destruction'. In that case, advocacy coalitions can function as a catalyst; they put a new technology on the agenda (function 3), lobby for resources (function 6), favourable tax regimes (function 5) and by doing so create legitimacy for a new 'technological trajectory' (Sabatier, 1988(Sabatier, , 1998;;Sabatier and Jenkinssmith, 1988). If successful, advocacy coalitions grow in size and influence and may become powerful enough to brisk up the spirit of creative destruction. The scale and success of these coalitions are directly dependent on the available resources (function 5) and the future expectations (function 3). We analysed this function by mapping the number of statements in literature by interest groups. Finally, the system functions are not independent from each other but interact and influence each other. It is possible that the fulfilment of a certain function has effects on other functions. For instance, a certain amount of knowledge creation is necessary to create expectations for the new technology, which may lead to legitimacy. Therefore, we expect a non-linear causal model with multiple interactions between the system functions that will positively affect the performance of the system. The fact that system functions interact and influence each other can even be considered a necessity. The function fulfilment can lead to positive (virtuous) cycles of processes that strengthen each other and lead to the building up of momentum to create a process of creative destruction within the incumbent system (Jacobsson and Bergek, 2004). Therefore, empirical research should focus on providing insight on how the process of momentum building takes place. However, the same reversed process can also occur, if some system functions are not fulfilled, a negative (vicious) cycle is set off. On the basis of empirical data, the interaction between the functions and whether a positive or negative cycle takes place can be found in Section 5 'System Functioning'.",
            "Methodology": "",
            "Historical event analysis": " In recent empirical work concerning system functions, generally qualitative analysis is used. This method strongly rests on the results from interviews. The set of system functions serves mainly as a way to structure empirical material, see (Andersson and Jacobsson, 2000;Jacobsson and Bergek, 2004). The downside of this method is that it is not possible to construct detailed patterns of function activities since interviews generally lead to information on a limited number of key-events. We propose to use as much quantitative indicators as possible in order to be able to map functional patterns over time (see description of System Functions). For this purpose we developed a method inspired by process analysis as deployed by Van de Ven and colleagues (Van de Ven et al., 1999;Poole et al., 2000). Stemming from organisational theory, their usual focus is on the firm and firm networks; in our case the analysis is deployed at system level. Basically, the approach consists of retrieving as many historical events related to a technological development as possible based on professional journals, newspapers and websites. The events are stored in a database, classified and systematically allocated to specific system functions. Functional patterns can then be extracted from the database. The methodology results in a coherent sequence of events and trends that describe how things change over time. In our case, the event sequence analysis is used to analyse the development, diffusion and implementation of biomass digestion in the Netherlands from 1974 to 2004. The system functions are measured by counting instances of event types over time. All events are weighted the same, but through the historical description some relevant events are highlighted by naming them explicitly in the storyline. However, a distinction should be made regarding the nature of the contribution of an event to the fulfilment of a function. Some events have a negative contribution to the development of the technology, for instance an expression of disappointment, or the opposition of an important political group. These events are counted separately and are represented as negative scores. In a similar way the relation between events and positive cycles is established. The negative and positive scores are not added, since the difference between the negative and positive component depicts the debate that is going on (see Table 1 for the indicators of the system functions). At this time we are not able to make an absolute statement on whether a function is fulfilled well enough or not since we lack empirical and theoretical insights on the size of such a threshold. We therefore focus on the rise and fall of the number of activities over time and whether interactions between system functions take place. The fulfilment of the system functions is represented in graphs. The positive line represents the total amount of positive activities per year and the negative line the sum of negative activities that occur per year for that particular function. The graphs are used to illustrate the development of the system functions throughout the examined time period and should not be interpreted as the absolute result/ answer of how the system functions have been fulfilled.",
            "Boundaries of this study": " This paper presents a chronological description of the events that have taken place in biomass digestion development in the Netherlands from 1974 to 2004. The analysis of biomass digestion is restricted to the digestion of manure, organic-and agricultural waste. Digestion of wastewater is not included since it involves a totally different innovation system with different actors and different institutions. Furthermore, the technological factors affecting the diffusion are not the same due to the difference in feedstock.",
            "Technical aspects of biomass digestion technology": " This paragraph will give an overview of the technical aspects of biomass digestion. Anaerobic digestion is a low-temperature biochemical process, through which a combustible gas-biogas-can be produced from biomass feedstock. Biogas is a mixture of The feedstock is placed into a digester, a warmed, sealed airless container. The digestion tank is continuously stirred and heated to create the ideal condition for biogas conversion. There are three types of temperature ranges where digestion can occur: psychophilic (10-25 1C), mesophilic (25-35 1C) and thermophilic (49-60 1C). However, most of the plants operate on the higher temperature (Raven, 2005). Although there is a constant inflow and outflow of material, the average retention time can vary from ten to 36 days, depending on the type of feedstock (Raven, 2005). This allows a significant percentage of the organic solids to be converted to biogas. The outflow of the digesters can be in two forms: biogas and a liquor/fibre mixture, known as 'digestate'. The gas from the digesters is stored to control the flow into the engine and this engine is used to generate heat and electricity for on-site or off-site use (see Fig. 1-diagram of digestion process).",
            "ARTICLE IN PRESS": " Policy lessons for an improved development and diffusion of biomass digestion follow directly from the above. Government policy should have focused on strengthening three system functions: guidance of the search, market formation and resources mobilisation. Specifically, this involves long-term, clear and supportive arrangements concerning the economics of biomass digestion plants, e.g. fixed feed-in tariffs for the electricity produced. This creates a market for digestion and due to the long-term character it guides entrepreneurs in their choice for this technology. Furthermore, supportive regulations regarding co-digestion (especially allowing carbon rich feedstock) would have greatly affected the developments. This would greatly influence the economics of digestion plants and resolve many uncertainties. We expect that by removing these two bottlenecks the biomass digestion community will grow and start fulfilling the other system functions that are necessary for biomass digestion development and diffusion. How useful is the functional analysis of emerging innovation systems? Does it lead to additional insights compared to the empirical analysis? First, the system function concept was very helpful in structuring the vast amount of empirical material and in analysing the empirical findings in a structured and coherent way. It helped to categorise different types of events that took place and to look for what the consequeces of certain events are on other events. Second, the description of activities provided additional insights compared to earlier empirical studies. In Raven (2004), the importance of structural factors like changes in the socio-technical landscape (e.g. change in oil prices) and a mismatch in rule sets (e.g. lack of co-digestion regulation) are highlighted. Also in our empirical work we highlight the same structural factors. However, on top of this the functional analysis shows the effect of these structural factors on the activities in the system and we show that these structural factors are in turn influenced by a lack of coordinated activities in the digestion innovation system. Hereby we get more understanding of the interplay between structural change of the institutional structure and the activities in the innovation system. Finally, the fact that we analysed this troublesome story in terms of system functions, allows us to compare this case with more successful developments. In this way we can learn how functional patterns differ in troublesome and successful processes of technological change and study the difference in interplay between institutional framework and innovation system activities. This is useful information when the aim of policy making is to contribute to well functioning sustainable energy innovation systems.",
            "Event description and system function fulfilment": " In this section, a chronological description of the events that took place in the biomass digestion trajectory is presented. The description will be subdivided into different year periods. The end of each period is chosen on the basis of change in activities or key events, therefore not all periods are equal in length.",
            "The pioneers era, 1974-1987": " The beginning of this period is characterised by pioneers setting up the first experiments on manure digestion, due to high and increasing energy prices as a result of the oil crises in the previous decades. Digestion of manure seems a promising option to convert a waste product (manure) into useful energy. Several farmers are enthusiastic about this option and digestion installations are set up on several farms (Verbong et al., 2001). Developers of digestion equipment, such as Paques, see a great market opportunity to install digestion equipment on farms. As a result the number of digestion plants on farms increases between 1979 and 1983, and consequently the application of digestion moves from laboratory scale to practical scale (Nes, 1988). However, a survey on the functioning of the digestion plants built on farms shows that there are many technical and economical problems. Nonetheless, it is believed that the problems are solvable and so the 'Netherlands Ministry of the Environment' (VROM) constructs a trial plant in Assendelft within the framework of the ''National Research Programme for Recycling of Waste'' (NOH programme) (Nes, 1988). However, shortly after its construction the plant is shut down, due to the decrease of conventional energy prices resulting in a lack of profits, technical problems and complicated permit regulations (Nes, 1988;Verbong et al., 2001). Here, the lack of supporting policies forms a barrier, in addition to the technical and economic problems. The government shows a lack of vision and strategy regarding the development and introduction of renewable energies in general, be it on short-or long-term, small-or large-scale, centralised or decentralised energy projects. For digestion the situation is even worse, since digestion is not seen as a key renewable energy technology that will contribute to the national energy supply like biomass combustion (Blok, 1985). Around 1985 the manure surplus in The Netherlands becomes an urgent problem. Several strategies to solve the problem are explored. One solution is to convert very wet manure streams into dry fertiliser that can easily be exported or transported to other parts in The Netherlands where there is a manure shortage. Digestion is seen as a means to reduce the energy demand of these manure conversion plants. The government support for manure digestion is from that moment only framed in the context of the manure problem and not in terms of its potential contribution to renewable energy. This is perceived as a great disappointment by the renewable energy lobby (Blok, 1985;Verbong et al., 2001). In addition to technical problems and the lack of supportive policy there is a drastic drop of oil prices in 1986 resulting in decreasing profits for biomass digestion (Lysen et al., 1992). Additionally Minister Braks of Agriculture announces in 1986 that no more money and support will be given to the further development of manure digestion nor to already existing projects, due to the technical problems and the reduced fossil fuel energy prices, resulting that digestion becomes expensive and unprofitable (Nes, 1988). The result is that by the end of this period hardly any activities occur around the development or diffusion of biomass digestion technology. Clearly, the guidance of search is not in favour of digestion.",
            "Impulses and inconsistency around digestion, 1988-1995": " Nonetheless the discontinuity of activities in the previous years, some activities are picked up again. In 1986, the community Deersum, Friesland has some plans to build a central manure digestion plant in combination with a wind turbine, which provides the village with electricity and makes it self-sustained. The wind turbine is in operation in August 1987 and the digestion plant at the beginning of 1988. The first year is used for experimentation and collecting performance data. For the digestion plant several start-up problems occur: congestion of the manure pumps, high content of hydrogen sulphide (H 2 S) and low electricity production of the combined heat and power (CHP) plant. Most of the problems are solved, however the costs for this installation remain high (Nes, 1989). The plant closes in 1994 due to technical problems and a poor economic performance.",
            "System functioning": " In this section, we will answer the research question 'how can we explain the low diffusion of digestion in the Netherlands?' by means of analysing the functional pattern of the digestion innovation system. At the beginning of the period 1974-1987, pioneers develop entrepreneurial activities (Fig. 2) and some knowledge is created (Fig. 3). The actions are not strongly coordinated and a lobby for better institutional arrangements  1974 1976 1978 1980 1982 1984 1986 1988 1990 1992 1994 1996 1998 2000 2002 2004  is lacking since only a very limited number of activities can be classified as advocacy coalitions (Fig. 7). This first period is also characterised by a lack of activities in terms of system functions such as guidance (see very low number of positive guidance activities in Fig. 5), market formation and resource allocation (see the complete lack of resource mobilisation in this period in Fig. 6). Thus, the initial experiments fail to lead to the build up of other system functions that are needed to propel this emerging technology. The consequence that after technological disappointments no continuation of activities takes place (see the negative lines in Fig. 2 that represent the projects stopped between 1978 and 1985; see Fig. 5 negative lines in 1983, 1985 and 1986). This results in a temporary stop of activities, and hardly anymore functions are fulfilled.",
            "Year": " Between 1989 and 1994 an impulse for biomass digestion occurs, due to the compulsory collection of organic waste, which is an interesting resource for biomass digestion, so that it is rediscovered as promising technology. Now we see a boost of research activities due to government programs (see peak in Fig. 3). This is accompanied by knowledge diffusion activities (see peak in 1992 in Fig. 4). We also observe the construction of several plants (see increase in positive cumulative line in Fig. 2 since 1988). However, even though the government gets involved in stimulating knowledge development, this does not lead to acceleration in the construction of digestion projects (this can be seen in the cumulative negative line in Fig. 2 that depicts the closing of digestion plants). An explanation that acceleration does not take place can be found in the functions guidance of the search (Fig. 5) and resources mobilisation (Fig. 6). Fig. 5 does not show a strong increase in positive guidance activities; In fact, every positive statement seems to be alternated by negative statements. This underpins our empirical story in which we show that digestion was never seen as a key technology  in terms of renewable energy and that the government has been quite negative about this technology. Fig. 6 shows that during this period actors complain regularly about the lack of financial support for this technology.",
            "Conclusions": " How can we explain the slow diffusion of biomass digestion in the Netherlands? The dynamic analysis of the functioning of the biomass digestion innovation system shows problematic functional patterns. Not one of the system functions that were analysed showed a continuous build up over the years. We regularly see short periods of entrepreneurial activities by enthusiastic pioneers but this does not lead to positive feedbacks with other system functions. Thus, the system never gains enough critical mass to overcome the technological problems. Furthermore, the institutional environment in which this innovation system needs to function is unstable and very often not stimulating for digestion initiatives. In turn the biomass digestion community is often unable to successfully lobby for improved institutional arrangements. We do not observe many network and lobby activities, neither many joint initiatives between academia, research institutes and   local projects. It seems that the promise and expectations around digestion are not able to mobilise a persistent group of actors that push forward this technology, also in difficult times. On the other hand, it is understandable that it is difficult to form a strong digestion network when the institutional framework is strongly fluctuating over the years, creating much uncertainty and is only sporadically in favour of digestion. Thus, what we see is a misalignment between government actions and the needs of entrepreneurs."
        }
    },
    "10.1016/j.enpol.2012.09.007": {
        "file_name": "60 Ambitious mitigation scenarios for Germany",
        "title": "Ambitious mitigation scenarios for Germany: A participatory approach",
        "abstract": "This paper addresses the challenge of engaging civil society stakeholders in the development process of ambitious mitigation scenarios that are based on formal energy system modeling, allowing for the explicit attachment of normative considerations to technology-focused mitigation options. It presents the definition and model results for a set of mitigation scenarios for Germany that achieve 85% CO2\u00a0emission reduction in 2050 relative to 1990. During consecutive dialogues, civil society stakeholders from the transport and electricity sector framed the definition of boundary conditions for the energy-economy model REMIND-D and evaluated the scenarios with regard to plausibility and social acceptance implications. Even though the limited scope of this research impedes inferential conclusions on the German energy transition as a whole, it demonstrates that the technological solutions to the mitigation problem proposed by the model give rise to significant societal and political implications that deem at least as challenging as the mere engineering aspects of innovative technologies. These insights underline the importance of comprehending mitigation of energy-related CO2\u00a0emissions as a socio-technical transition embedded in a political context.",
        "label": "Mixed",
        "text": {
            "Introduction": " Ambitious domestic mitigation efforts by Annex I countries are necessary for maintaining a likely chance to keep global warming below 2 1C (UNEP, 2010). The European Union has committed itself to reduce CO 2 emissions by 20% in 2020 relative to those in 1990 (European Parliament and the European Council, 2009). Member states share the mitigation effort according to individual capabilities. This decision led Germany to target a 21% cut in domestic CO 2 emissions by 2020. In the long-term, the German Government endorses an ambitious target of 80% to 95% energy system related CO 2 emission reduction by 2050 relative to 1990 (Federal Government, 2010). Model-based mitigation scenarios that indicate how this transformation can be accomplished are a frequently demanded form of scientific policy advice. As energy system modeling has traditionally been the domain of experts, particularly engineers, existing mitigation scenarios frame mitigation largely as a technology problem that can be solved by switching to innovative low-carbon technologies. For Germany, several model-based scenario studies have demonstrated that achieving the Government's long-term mitigation target will be technically feasible if best available technologies penetrate the market in large scale (e.g. Schlesinger et al., 2010;Nitsch and Wenzl, 2009;Nitsch et al., 2010;Kirchner et al., 2009). To achieve this, the studies suggest rigorous energy policy measures with far-reaching implications for the German society. However, it was not subject of the analysis in these scenario studies whether their projected developments align with societal preferences. In case they do not align, social refusal to adopt or allow for the adoption of low carbon technologies may challenge ambitious mitigation targets. Indications that this is a real challenge in Germany are already observed. Local protest against the exploration of carbon sequestration sites contribute to the paralysis in the policy process for passing European legislation on carbon sequestration. Widespread refusal to use petrol with 10% biofuel additive (E10) endangers Germany's fulfillment of the European biofuel quota (MWV, 2011). Local opposition against the construction of new power plants is considered as the most important market entry barrier for utilities (Deloitte, 2011). Further, local opposition against onshore wind farms, due to e.g. negative landscape externalities (Meyerhoff et al., 2010), have resulted in 40 negative out of 61 community referendums between 2009 and 2012 (L \u00f6hle, 2012). Since public or local oppositions and other acts of societal refusal can severely delay the rapid and large-scale deployment of best available technologies, the notion of 'social acceptance' has become a keyword in the energy policy arena. Often, social acceptance is understood as something that can be established ex-post to investment or policy decisions by providing sufficient information to the public (e.g., Federal Government, 2010). However, attempts to explain acceptance and opposition in literature increasingly resort to procedural and institutional factors like beliefs, concern, place attachment, perceived fairness and levels of trust (Devine-Wright, 2008) that cannot be mediated by mere information campaigns. Rayner (2010) argues that the process of how a society chooses an energy future itself is as important for a socially, politically, economically and environmentally sustainable outcome as the availability of low-carbon technology options. The Ethics Commission for a Safe Energy Supply, appointed by the Federal Government, corroborates that in order to ensure a high level of societal acceptance for the energy supply, transparency in the decisions made by both parliament and government as well as participation by societal groups in the decision-making process is a prerequisite (Ethics Commission for a Safe Energy Supply, 2011). Due to the decisive role that model-based mitigation scenarios can play as a form of scientific policy advice, the call for transparency and participation in their design and development process is valid accordingly. A further convincing argument for engaging societal groups that have a stake in energy system developments is that the choice of low-carbon technologies requires a wide range of normative considerations and value judgments for which science alone does not have a mandate. For taking into account societal preferences, the German Academies of Sciences advocate the application of 'analyticaldeliberative' approaches (Renn et al., 2011) which originate in the field of risk management (e.g., Stern and Fineberg, 1996;Renn, 1999). Their notable trait is to provide a recursive linkage between the two discrete processes of analysis, the use of replicable methods developed by experts, and deliberation, the thoughtful weighting of options. A careful deliberation of mitigation options requires that direct and indirect implications of mitigation options are considered, discussed and reflected by the spectrum of affected stakeholders, collectively. In order to develop model-based mitigation scenarios that explicitly take into account stakeholders' judgments and preferences, they need to be elicited and translated to configurations of model input parameters. Model results then carry contextual, normative meaning and enable substantive discussions on the sociopolitical implications of technology-focused mitigation options. This can only be achieved in a participatory approach in which deliberation frames analysis and analysis informs deliberation. Examples of participatory approaches to model-based mitigation scenarios are scarce in literature. The scenarios of the 'Roadmap 2050 for a low carbon economy' by European Commission (2011) have been assessed on their impact through an online questionnaire, which is a unilateral method only. The European Climate Foundation (ECF) periodically consulted a wide range of stakeholders throughout the preparation of mitigation scenarios for their 'Roadmap 2050' (ECF, 2010) but the concrete procedure is not described. To the authors' knowledge, there are no contemporary applications of participatory approaches to developing ambitious mitigation scenarios for Germany. This paper aims to contribute in filling the gap by exploring a methodology for developing a set of model-based, long-term mitigation scenarios for Germany that are defined and evaluated in a participatory process with civil society organization (CSO) stakeholders from the transport and electricity sector. It addresses the domestic mitigation challenges not only from a techno-economic point of view but also from a socio-political perspective by combining both analytical and deliberative elements in a participatory methodology. The exploratory research was conducted as a part of the EU project ENCI LowCarb (Engaging Civil Society in Low Carbon Scenarios). Due to the pilot project character, the scenario results are to be interpreted as indicative of trends rather than being representative for the German civil society as a whole. In dedicated stakeholder dialogues, CSO representatives discussed available mitigation options for the transport and electricity sector. Their judgments and preferences framed the scenario definition and corresponding parameter configurations for the hybrid energy-economy model REMIND-D (Schmid et al., 2012a). REMIND-D is based on the structural equations of the state-of-the-art global Integrated Assessment Model (IAM) REMIND-R (Leimbach et al., 2010). Since REMIND-D is a hybrid model, integrating a detailed bottom-up energy system module into a top-down representation of the macro economy, the scenarios can be analyzed both with respect to their technological and economic feasibility. In a second round of dialogues, stakeholders evaluated the plausibility of the scenarios and identified potential socio-political implications of the model-based mitigation scenarios. The outline is as follows: Section 2 presents the methodology. Section 3 discusses the outcomes of the participatory scenario definition process. Section 4 guides through the scenario results obtained with REMIND-D, focusing on structural trends in the development of CO 2 emissions by sector, modal splits in the freight and passenger transport sector and the electricity generation mix. Mitigation costs, along with a sensitivity analysis on how they depend on the stringency of the mitigation ambition, are presented in Section 4.4. Section 5 reports the CSO stakeholders' evaluations of the mitigation scenarios. Section 6 summarizes and concludes.",
            "Methodology": " The objective of this research is to develop ambitious mitigation scenarios for Germany that integrate both techno-economic and socio-political dimensions of the domestic mitigation challenge. In order to build a bridge between the two, the specific requirements on the research team go beyond pure expertise on energy-economy modeling and call for project partners that are well embedded in the civil society sphere. Thus, the core research team consisted of both non-governmental organization (NGO) partners and researchers that collaborated closely throughout the project. The participatory scenario definition and evaluation process illustrated in this paper was preceded by an intense preparatory phase in which the interdisciplinary research team developed a joint understanding of how stylized model parameters and results may be translated into real-world implications and vice versa. Details on this preparatory phase and its organizational setup are presented in Schmid et al. (2012b). The focus of the research was on the one hand on the electricity sector-a sector for which technology options are readily available and where the discussion about mitigation has a longer lasting tradition in Germany. On the other hand, the transport sector was chosen as it is acknowledged that there are major difficulties in decarbonizing the transport sector (e.g. Luderer et al., 2012). Due to the limited scope of the project, a deliberation of technological mitigation options in the industrial and residential heat sector was not included in the participative process. However, the methodology outlined in Fig. 1 and explained in the following can be transferred to more comprehensive scenario exercises in future research.",
            "Participatory scenario definition": " Scenarios are a linking tool that integrates qualitative narratives and quantitative formulations based on formal modeling (Nakicenovic et al., 2000). In order to define scenarios, i.e. formalize the link between the two elements, 'parsimonious narratives' have been established in the IAM community. They consist of contextual information on anticipated key future developments and corresponding quantitative projections for boundary conditions (Kriegler et al., 2010) and intend to convey substantive meaning to a particular set of boundary conditions for IAMs. Several parsimonious narratives for key future developments in the transport and electricity sector were developed in collaboration with CSO stakeholders during two dedicated stakeholder dialogues. One dialogue was conducted for each sector to allow for an in-depth discussion. The interdisciplinary research team pre-selected focal topics for each sector by striking a balance between technological mitigation options that are crucial from the point of view of the energy-economy model and developments that are likely to be subject to controversies regarding their social acceptance. The NGO partners conducted the selection of participants so as to cover the range of interest groups as good as possible given the limited scope of the project. The 11 and 13 participants in the transport and electricity sector stakeholder dialogues included representatives from environmental NGOs, industry and consumer associations, topic-related interest groups, urban planning, trade unions and industry. A detailed list of the represented organizations can be found in Appendix. During the stakeholder dialogues, pre-selected mitigation options and associated key future developments were discussed with respect to direct and indirect implications and their perceived desirability. After each discussion, stimulated by an introductory question, a questionnaire elicited CSO stakeholders' positions for formal analysis. The seven-point Likert-scale questionnaire (Likert, 1932) elicited judgments and preferences on possible future developments of key variables in the transport and electricity sector. For a number of possible developments, it asked to indicate whether its realization is perceived as likely or not as well as desirable or not. Due to the small sample size, the data is not suited for econometric analysis. Instead, descriptive statistic measures of central tendency are employed. Mean, standard deviation and mode give an indication of whether the perceptions of likely and desirable developments diverge and whether there is a degree of agreement across stakeholders. Along with the qualitative information obtained during the discussions as well as expert judgments from literature, the elicited data serves as a basis for generating sets of parsimonious narratives. Parsimonious narratives were developed for those mitigation options where stakeholders had an opinion and judgments on likely versus desirable developments diverged significantly or the desirability was particularly subject to dissent amongst stakeholders. This resulted in three scenarios. In order to keep the scenario definition tractable, a selection had to be made by the interdisciplinary research team and not all issues discussed during the stakeholder dialogues are actually differentiated in the scenarios. For those mitigation options which are not explicitly addressed by the scenario definition, the deployment decisions are endogenous to the model REMIND-D and boundary conditions are set equally for the scenarios according to expert judgments from literature. They can be consulted in the model documentation (Schmid et al., 2012a). It needs to be acknowledged that a mitigation scenario definition according to the criteria of likeliness, desirability with consent and desirability with dissent is not unique and influenced by the modeler's choice. Finally, the modeling team translates the parsimonious narratives into corresponding input parameter configurations for the model REMIND-D.",
            "The hybrid energy-economy model REMIND-D": " REMIND-D is a Ramsey-type growth model that integrates a detailed bottom-up energy system module coupled by a hard link (Bauer et al., 2008). It facilitates an integrated analysis of the long-term interplay between technological mitigation options in the different sectors of the German energy system as well as general macroeconomic dynamics. A detailed description of REMIND-D is provided in Schmid et al. (2012a). REMIND-D builds on the structural equations of the state-of-the-art IAM REMIND-R (Leimbach et al., 2010) which are reported in Bauer et al. (2011). The objective of REMIND-D is to maximize a social welfare function, i.e. the intertemporal sum of discounted logarithmic per capita consumption. Mitigation is enforced by means of a strict emission budget of 16 Gt CO 2 over the time horizon of the analysis, 2005-2050, resulting in roughly 85% emission reduction in 2050 relative to 1990. The budget approach is inspired by Meinshausen et al. (2009). When budgeting emissions, the model can choose annual emissions endogenously, thereby allowing for flexibility in the selection of mitigation options. In REMIND-D, future scarcities of energy carriers and CO 2 emissions are anticipated through shadow prices, implying perfect foresight. Hence, REMIND-D features optimal annual mitigation effort and technology deployment as a model output. Available mitigation options fall into four categories: (i) Deploying alternative low-emission technologies, (ii) substituting final energy and energy service demands, (iii) improving energy efficiency and (iv) reducing demand. The latter is generally avoided by the model as demand reductions have a negative impact on GDP. Limitations of REMIND-D are mainly that it abstracts from secondary and final energy imports and possesses coarse technology resolution in the residential and commercial heat sector. Further, infrastructure investments are only represented for energy distribution technologies but not for transport system infrastructure like railroad tracks, due to a lack of data. The energy system module of REMIND-D is endowed with a variety of alternative technologies that it may deploy endogenously. Endogenous capacity deployment is subject to potential and resource constraints for renewable primary energies and fuel costs for fossil primary energies. The fossil primary energy carriers hard coal, natural gas and crude oil are imported at exogenous prices (Nitsch and Wenzl, 2009, price path B). Domestic lignite resources are represented by an extraction cost curve approach. Approximately 70 energy conversion technologies are considered explicitly, as are 20 distribution and 40 transport technologies. Conversion technologies produce the secondary energy carriers electricity, district heat, local heat, hydrogen, gas, petrol, diesel, kerosene and heating oil. Distribution technologies convert secondary energies into final energies as the industry and residential & commercial sector demands. Transport technologies provide energy services for passenger and freight relocation. Upon choice, the Carbon Capture and Sequestration (CCS) technology is available for the electrification and liquefaction of coal, lignite, gas and biomass from 2020 onwards. According to the decisions of the German Government, nuclear capacities are phased out until 2022. Domestic renewable energy potentials include lignocellulose, oily and sugar & starch biomass, manure, deep and nearsurface geothermal, hydro, wind onshore, wind offshore and solar irradiation. Despite the time resolution in five-year steps, the model accounts for fluctuation of renewable electricity generation on short time scales explicitly via a residual load duration curve approach (Ueckerdt et al., 2011).",
            "Participatory scenario evaluation": " In the second round of stakeholder dialogues, the same CSO stakeholders as in the first round of dialogues evaluated the mitigation scenarios obtained with REMIND-D by discussing their plausibility and identifying where projected developments could raise concerns about social acceptance. The objective was to characterize critical socio-political implications of technological mitigation options. A better understanding of how goals of climate protection and energy security may conflict with those of an affordable energy supply for everybody and how these trade-offs can be tackled is essential for transforming Germany towards a low-carbon energy future.",
            "Scenario definition": " As outlined in Section 2.1, the development of parsimonious narratives, consisting of contextual information on anticipated key future developments and corresponding quantitative projections for boundary conditions, is central to this scenario definition process. Three scenarios were defined according to the criteria of likeliness, desirability with consent and desirability with dissent. The 'continuation' scenario enforces a set of parsimonious narratives in the transport and electricity sector that are deemed likely by CSO stakeholders. The 'paradigm shift' scenario reproduces a set of parsimonious narratives perceived as desirable by the majority of CSO stakeholders. A variant of the latter, the 'paradigm shift\u00fe' scenario, additionally allows for the deployment of several technological mitigation options which the stakeholders judged as undesirable or discussed controversially. Yet these technologies, e.g. CCS, are favored e.g. by the coal industry. Along the lines of the discussion questions raised during the stakeholder dialogues, the different parsimonious narratives are elaborated in the following. Is an increase of total annual freight mileage unavoidable? Historically, freight transportation and GDP growth rates correlated strongly, however, their causal relationship is not straightforward (Feige, 2007). It is intertwined through the indirect influence of transport technologies on production and distribution structures as well as other aspects of industrial organization and fundamental economic variables, e.g. the degree of specialization, economies of scale, comparative advantage and diffusion of technological progress. As indicated in Table 1, decoupling freight and GDP growth rates by reducing annual truck mileage and shifting freight from road to rail is perceived as a desirable mitigation option by CSO stakeholders. Yet they anticipate annual ton-km (t-km) mileage with fossil-fuel-based trucks to increase continuously until 2050. This scenario is corroborated by expert judgments. Lenz et al. (2010), e.g., predict a dramatic increase in diesel truck mileage from 466 Bn t-km in 2005 to 787 Bn t-km in 2030, constituting a severe carbon lock-in. In the 'continuation' scenario, this trend is enforced by an exogenous linear increase of annual freight transport with trucks up to 787 Bn t-km in 2050 as a conservative estimate. However, the CSO stakeholders strongly advocated policy efforts directed at reducing total transport mileage and achieve a shift from road to rail. They claim that viable solutions exist but lack of political will impedes their implementation. Holzhey (2010) finds that a doubling of freight transport with rail in Germany until 2030 is technically possible even though concerted investments are required. Consequently, in the two 'paradigm shift' scenarios, it is assumed that freight transport and GDP growth can be decoupled in the future. Is multi-modality a viable option for decarbonizing the passenger transport sector? The modal split in the passenger transport sector is heavily biased towards motorized individual transport (MIT) with cars accounting for roughly 80% of travelled person-km (p-km) annually (BMVBS, 2008). CSO stakeholders expect MIT to remain the dominant mode of transportation in the future. Hence, the 'continuation' scenario is bound to a share of 80% MIT in modal split annually. However, CSO stakeholders perceive a structural change in the modal split as a desirable future development, seeing some potential for public transport (PT) and also non-motorized short distance transport to increase, e.g. by means of a fast bicycle lane network. CSO stakeholders particularly stress the importance of increasing infrastructure investments for PT to enable multimodality transport patterns, supporting the proposals of the European Commission's white paper on transport (EC, 2011). By prescribing an increase in the share of PT in the modal split for both short and long distance passenger transport, these developments are reproduced in the two 'paradigm shift' scenarios. Which alternative low-carbon fuels ought to be dominant in the future? Instead of a shift in the mode of transportation, less carbon-intensive fuels for conventional vehicles are another technological mitigation option. Biodiesel can be produced from bio-oils and bioethanol from sugar and starch biomass; in the future, second generation biofuels from lignocellulose will possibly become available (e.g. Schulz et al., 2007). Other low carbon technologies for fuel production include the liquefaction of hard coal or lignite in combination with CCS and a shift towards hydrogen. CSO stakeholders are controversial about the desirability of first-generation biofuels and doubt that secondgeneration biofuel technologies will be available in large scale. Likewise, they doubted the technological feasibility of a hydrogen future (e.g. Fischedick et al., 2005), exploiting overproduction of REG capacities via electrolysis. Since the desirability of these technological options was contested, they are available to the model only in the 'paradigm shift\u00fe' scenario. Are landscape externalities of renewable electricity generation (REG) capacities and transmission lines problematic and what are potential remedies? A concomitant effect of large-scale deployment of REG and transmission line (TL) capacities is that they technologize the landscape. This landscape externality was in fact considered problematic with regard to social acceptance. Especially biogas electrification, accompanied by large corn monocultures, were judged as unacceptable, see Table 2. CSO stakeholders expect that TL extensions, necessary to distribute and balance fluctuating REG, are potentially impeded due to local resistance. However, they find it desirable that such local oppositions are resolved and encourage that REG technologies, with the exception of biogas electrification, constitute a very large share of the electricity mix in the future. Possible remedies for fostering social acceptance towards REG and TL capacities include procedural justice and increased participation and ownership by the local population (Musall and Kuik, 2011;Zoellner et al., 2008). To represent the effect of a certain degree of social refusal towards large-scale REG and transmission line deployment in REMIND-D, the REG potentials in the 'continuation' scenario are lower than in both 'paradigm shift' scenarios. Which energy efficiency growth rate is feasible and what is the role of the rebound effect? It is widely agreed that energy efficiency improvements are an important mitigation option in Germany especially for the electricity sector. Yet CSO stakeholders expect electricity demand to remain stable or increase in the future, despite judging high efficiency growth rates as a desirable development. Institutional barriers to exploiting technical energy efficiency potentials are substantial, e.g. lack and asymmetry of information, principal-agent problems, split incentives, hidden costs or bounded rationality (Gillingham et al., 2004). Also, the rebound effect is likely to prove itself as a real obstacle. It postulates that energy efficiency increases make individual energy services cheaper, leading to an increase in their consumption or the consumption of other carbon-intensive energy services (e.g. Sorrell et al., 2009). In order to translate these judgments, efficiency growth rates of the final energy demand perpetuate historical trends in the 'continuation scenario' averaging 0.5% annually. The two 'paradigm shift' scenarios assume significant improvements and the exogenous efficiency growth rates of final energy demand amount to an average of 2.3% annually. Which thermal electricity generation capacities are acceptable in the next decades? Due to the phase-out of nuclear until 2022, these generation capacities need to be replaced within the next decade. CSO stakeholders oppose the built-up of new CO 2 emission-intensive coal power plants. Instead, they consider it both likely and desirable to deploy gas power plants which are not only less CO 2 -intensive but are also better capable of balancing fluctuating REG (dena, 2010). 33% of all energy-related German CO 2 emissions in 2009 were incurred by lignite and hard coal power plants. The option of decommissioning them before the end of their techno-economic lifetime and replacing them with REG capacities, albeit hardly discussed, constitutes an effective mitigation option. Even though CSO stakeholders judged this option as desirable, they consider it as moderately realistic. To simulate a carbon lock-in from persistent coal electrification, existing hard coal and lignite power plants are subject to a mustrun constraint in the 'continuation' scenario. This must-run constraint implies that the coal power plants may not be put out of service before the end of their technical lifetime. A largescale deployment of the CCS technology was judged as neither particularly likely nor desirable and is hence available to the model only in the 'paradigm shift\u00fe ' scenario from 2025 onwards. Table 3 summarizes the model constraints defining the three scenarios. As already mentioned, the deployment of all mitigation options not mentioned in Table 3 is left endogenous to the model ",
            "Scenario results": " The model REMIND-D finds an optimal solution for each of the scenario configurations, despite the strict emission budget of 16 Gt CO 2 . Before going through the results, it needs to be highlighted once more that they are derived under the assumption of perfect foresight and constitute deterministic first-best solutions rather than forecasts. This is especially relevant to the counterfactual 'continuation' scenario which is forced to achieve ambitious mitigation despite restrictive boundary conditions. Notwithstanding these abstractions, the scenario results yield valuable insights into stylized trends and interrelations across sectors under different scenario configurations. The following presents for each scenario the CO 2 emissions, trends in the transport and electricity sector as well as mitigation costs.",
            "CO 2 emissions by sector": " Over the course of the next decades, mitigation shares of the three sectors transport, electricity and heat structurally differ across scenarios as illustrated in Fig. 2. Until 2015 CO 2 emission reductions are similar in all scenarios-a fast decrease of emissions of 29% to 33% in the electricity sector, 28% to 31% in the industrial, residential and commercial heat sectors and 4% to 9% reduction in the transport sector. However, from 2015 onwards, there are structural differences between the developments in the 'continuation' and both 'paradigm shift' scenarios. The speed of emission reduction in the electricity sector stagnates in the 'continuation' scenario due to the must-run constraint for the existing lignite and hard coal power plants. Additional committed emissions in the 'continuation' scenario originate in the prescribed increase in freight transport with trucks. The total carbon lock-in over the time horizon of analysis, 2005-2050, amounts to 6.15 Gt CO 2 from coal electrification and 2.67 Gt CO 2 from freight transport. In sum, these 8.8 Gt CO 2 deplete 55% of the total emission budget. Consequently, the heat sector needs to deliver a substantially higher mitigation effort in the 'continuation' scenario than in the two 'paradigm shift' scenarios in order to meet the total CO 2 emission budget. In the two 'paradigm shift' scenarios, the electricity sector decreases CO 2 emissions much faster, delivering a reduction of 80% between 2005 and 2020. Therefore, more CO 2 emissions can be incurred in the heat sector providing process heat for industry and residential heating. This structural effect is even more pronounced in the 'paradigm shift\u00fe ' scenario; here, the availability of new low-carbon technologies leads to an almost complete decarbonization of the freight and electricity sectors by 2035. These findings illustrate the advantage of an integrated approach to mitigation modeling allowing for an analysis of the interplay between different sectors.",
            "Transport sector": " Until 2050, total CO 2 emissions within the transport sector decrease by 47% in the 'continuation', 73% in the 'paradigm shift' and 93% in the 'paradigm shift\u00fe' scenario versus 2005. The majority of annual reductions are achieved during the next two decades, yet the drivers differ across the three scenarios. Clear structural breaks emerge in both modal splits in the two 'paradigm shift' scenarios. Aggregate trends in the freight sector for each scenario are illustrated in Fig. 3. The y-axis measures annual freight transport mileage in Bn t-km per year, whereas the x-axis displays the three sectors for each scenario. Time is indicated by color coding. First, Fig. 3 visualizes the structure of the sectoral relationships in one scenario, highlighted by the connecting lines in the years 2005, 2020 and 2050. Second, the sectoral trends over time can be compared across scenarios. And third, it emphasizes the speed of transformation: The larger the white areas are within a bar, the faster is the CO 2 emission reduction between two time steps. In all scenarios, freight transport by inland water navigation remains constant due to its limited potential. In the 'continuation' scenario, freight train capacities also remain at today's levels, however, freight transport with trucks increases continuously due to the scenario assumption of coupled GDP and freight transport growth rates. In consequence, the freight sector's annual emissions remain constant at 60-70 Mt CO 2 as the availability of alternative low-emission fuels is limited in this scenario. These committed emissions are avoided in both 'paradigm shift' scenarios. Here, the decoupling indicator (t-km/GDP) does not increase by 20% from 2005 to 2050 (as in the 'continuation' scenario) but decreases by 20% and 10%, respectively. Apart from keeping freight transport mileage constant at today's level, through restructuring the economic system towards less transport-intensive value chains, mitigation is enabled by massive rail infrastructure expansions allowing for train mileage to tripe until 2030. In the 'paradigm shift\u00fe' scenario, the truck mileage remains at higher levels than in the 'paradigm shift' scenario due to the availability of alternative low emission fuel technologies, e.g. second generation biofuels and liquefaction of lignite in combination with the CCS technology. As regards the passenger sector, annual per capita mileage decreases from 13,000 km in 2005 to 11,000 km in the year 2050 in both 'paradigm shift' scenarios; the parsimonious narrative foresees that one part of the difference will be substituted by non-motorized traffic, i.e. cycling and walking. In the 'continuation' scenario, however, the per capita p-km are forced to decrease down to 9000 p-km in 2050 due to mitigation pressure induced by the carbon lock-in in the freight and electricity sector. The total annual p-km by transport mode for each scenario are illustrated in Fig. 4. Here, the structural change in both 'paradigm shift' scenarios becomes evident: MIT decreases at a decreasing rate until 2050 and PT steadily increases until 2020, remaining constant thereafter. Hybrid buses, electrified light rail and regional trains deliver additional short distance PT. Together, they account for roughly 50% of the modal split of short distance transport in 2050. Incremental long distance PT will be delivered with electric trains. In all scenarios, anticipated carbon budget restrictions and implicit carbon pricing make conventionally fuelled cars too expensive to operate so they are phased out entirely until 2030. Diesel cars, predominantly suitable for long distance driving, are first substituted by diesel hybrids and then by hybrid gas cars in all scenarios. Petrol cars are replaced with hybrid-plug in gasoline cars which are electric cars with a petrol-fuelled rage extender. In the 'paradigm shift\u00fe ' scenario, they are partly replaced with hydrogen hybrid cars as hydrogen is produced from lignocelluloses with CCS here, with the ability to extract CO 2 from the atmosphere and producing de-facto 'negative' CO 2 emissions. In all scenarios, there is a trend to gradually electrify the transport sector with the total demand of electricity for transport increasing by several orders of magnitude until 2050, yet never exceeding 15% of the total electricity production.",
            "Electricity sector": " The aggregated technology mix of the electricity sector for the three scenarios is illustrated in Fig. 5. In the two 'paradigm shift' scenarios, where the model is given the option to decommission existing hard coal and lignite power plants from 2015 onwards, these capacities are shut down by 2020. They are temporarily replaced by gas turbines, about 25 GW capacity are built between 2015 and 2020. Once enough REG capacity is installed, the gas turbines go out of service again in both 'paradigm shift' scenarios by 2030. In the 'continuation' scenario, there is no such temporary increase in gas capacities as existing coal and lignite power plants continue to produce electricity. In all scenarios, REG is rapidly expanded and doubling over the next five years. From 2020 onwards, the installed REG capacities stagnate in the 'continuation' scenario. This is due to the moderate potential in the scenario definition, motivated by a restrictive public attitude that constrains the incremental deployment of RE capacities and transmission lines. Total electricity production is forced to decrease from 620 TWh in 2005 to 375 TWh in 2050. Because of the carbon lock-in from freight transport and coal electrification, the model cannot afford to allocate more CO 2 from the emission budget to the electricity sector for covering gas turbines. These could provide more balancing capacities so solar potentials could be fully exploited which is not the case in the 'continuation' scenario. Instead, REMIND-D opts for the least attractive mitigation option of imposing electricity demand reductions in all sectors, including industry. A consequence of this is a reduction in GDP growth. In both 'paradigm shift' scenarios, REG capacities continuously expand, especially offshore wind, and total electricity production stabilizes between 530 and 560 MWh. The slightly reduced demand is due to high efficiency growth rates. In 2050, onshore wind capacities reach a maximum of 100 GW in both 'paradigm shift' scenarios. Offshore capacities reach 150 GW in the 'paradigm shift' scenario and 180 GW in the 'paradigm shift\u00fe ' scenario. Geothermal electricity production also plays a vital role in all scenarios with 20-35 GW installed capacity. REMIND-D installs 110 GW of solar photovoltaic in the 'continuation' scenario by 2050. In the 'paradigm shift' scenarios, other less expensive technologies, e.g. wind onshore and offshore, provide sufficient electricity generation potential and solar photovoltaic plays only a minor role. Biomass electrification plays a subordinate role in all scenarios as REMIND-D prefers to use all available biomass for fuel production. In the 'paradigm shift\u00fe' scenario, 14 GW of lignite power plants with the oxyfuel CCS technology are installed as well as 25 GW of natural gas combined cycle plants with CCS. When compared to the 'paradigm shift' scenarios, these capacities somewhat reduce the need for REG.",
            "Mitigation costs": " Comparing the results of two scenarios that differ with respect to the emission constraint only allows for determining the differential effects of mitigation enforcement. One measure of economic mitigation costs is the cumulative difference in discounted GDP losses (referred to as cumulative GDP losses hereafter) between two scenario runs that have the same restrictions, except for the size of the CO 2 emission budget. Fig. 6 illustrates how cumulative GDP losses between scenarios diverge with increasingly strict carbon budgets. For ease of interpretation, the x-axis displays the respective % of CO 2 emission reduction achieved in 2050 relative to 1990. Macroeconomic mitigation costs in terms of cumulative GDP losses for the 'continuation', 'paradigm shift' and 'paradigm shift\u00fe' scenario amount to 3.5%, 1.4% and 0.8% between 2005 and 2050. The respective reference case with a larger carbon budget leads to moderate 40% to 45% CO 2 emission reduction in 2050 relative to 1990. For moderate mitigation targets up to 65% CO 2 emission reduction in 2050, GDP losses remain below 0.5% in all scenarios. Mitigation costs in this order of magnitude are also found by global IAM analyses (e.g., Edenhofer et al., 2010;Luderer et al., 2012). However, for more ambitious targets, the mitigation costs in the 'continuation' scenario increase relatively faster than in the two 'paradigm shift' scenarios. This divergence is induced through the differences in scenario assumptions. The main drivers for increasing GDP losses in the 'continuation' scenario are moderate efficiency growth rates and endogenously enforced demand reductions because of the aforementioned carbon lock-in in the freight and electricity sector. GDP losses remain significantly lower for all mitigation targets in the 'paradigm shift' scenario. Higher efficiency growth rates in all sectors of the economy, larger REG potential and the option to avoid the carbon lock-in are responsible for this. In terms of the underlying parsimonious narratives, the results indicate that ambitious mitigation in Germany can be achieved at relatively lower costs if structural changes in modal splits of the freight and passenger transportation sector and a fast decarbonization of the electricity sector are pursued. Mitigation costs in the 'paradigm shift\u00fe' scenario remain even lower for all levels of mitigation ambition. This is due to additionally available technological mitigation options in the form of CCS and larger biofuel potentials and in line with findings in other scenario exercises (e.g., Edenhofer et al., 2010;Luderer et al., 2012). Yet, the incremental effect is not as decisive as moving from the 'continuation' to the 'paradigm shift' scenario.",
            "Scenario evaluation": " CSO stakeholders perceive three projected developments in the 'continuation' scenario as implausible mainly due to socio-political implications that conflict with objectives in other policy arenas. First, the model results indicate a strong decrease of motorized individual transport that is not compensated for by more public transport mileage. Massive state intervention would be necessary to induce behavioral changes of such magnitude, e.g. through carbon pricing policies entailing prohibitively high transport costs. In such a world, individual mobility would become a luxury good. The CSO stakeholders assess that such policies will lack social acceptance and strongly emphasize the value of individual mobility in modern societies. Second, the required electricity and heat demand reductions are considered as politically not enforceable in reality. To induce such a development, again, rigorous carbon pricing policies would be required which would increase the price of electricity and heating substantially. Several stakeholders pointed out the dangers of energy poverty if any such mitigation policy is not accompanied by effective redistribution schemes. Third, the CSO stakeholders doubt that the projected CO 2 emission reductions and efficiency improvements in the heat sector can be realized, seeing institutional barriers as for example the well-known landlord-tenant conflict of responsibility. In sum, these critical socio-political implications motivated the CSO stakeholders to assess the 'continuation' scenario as highly undesirable, despite the fact that it reaches the required mitigation target. However, they reconfirmed the likeliness of its projected developments in the freight transport and electricity sector, leading to a lock-in into current behavior and carbonintensive infrastructure. In consequence, they conclude that, if the carbon lock-in becomes reality, ambitious mitigation targets will likely be out of reach. The 'paradigm shift' scenarios see the carbon lock-in resolved. CSO stakeholders largely corroborate the desirability of its proposed developments, especially the fast increase in renewable electricity generation. However, they point out that several model projections appear unrealistic such as the near-term decommissioning of coal power plants, the rapid shift from road to rail in freight transport or the widespread electrification of private transport until 2030 and the simultaneous shift to public transport. They doubt that it is possible to establish the necessary collective political will for enforcing policies that lead to such technology deployment. Several concerns were articulated for policies that aim at inducing the structural breaks from historical trends inherent to the 'paradigm shift' scenario: The quality of public transport services needs to increase significantly, both in urban environments and in rural areas. Inter alia, this would require a redirection of infrastructure investments from road to rail, an issue considered long overdue by the CSO stakeholders. Furthermore, the projected rapid decommissioning of existing coal power plants may entail increasing regional unemployment rates in Germany's structurally weak lignite mining areas. Finally, a fast deployment of renewable electricity generation and transmission line capacities requires high procedural justice throughout the planning and installation process, including institutionalized possibilities for local communities to participate, also financially. CSO stakeholders preferred the 'paradigm shift' scenario over the 'paradigm shift\u00fe' scenario as they predict substantial public protest against the large-scale deployment of CCS infrastructure and biofuel production. They argue that the incremental effect on decreasing mitigation costs may not outweigh the direct and indirect costs of public protest. ",
            "Summary and conclusion": " This paper presents three model-based mitigation scenarios for Germany that achieve 85% CO 2 emission reduction in 2050 relative to 1990. These scenarios were defined and evaluated in a participatory process with CSO stakeholders. During separate dialogues, their preferences on future developments related to mitigation in the transport and electricity sector were discussed and elicited. Along with findings from literature, the input from the CSO stakeholders built the basis to generate parsimonious narratives on future developments of key variables in the transport and electricity sector according to the criteria of likeliness, desirability with consent and desirability with dissent. The 'continuation' scenario is characterized by enforcing a set of developments that are deemed highly likely by all participants. These include the dominance of motorized individual transport, unabated coal electrification, moderate energy efficiency growth rates, local resistance against windmills and transmission lines as well as the continuation of coupled freight transport and GDP growth rates. Coal electrification and fossil-fuel-based freight transport mileage induce 8.8 Gt CO 2 of committed emissions. This carbon lock-in accounts for 55% of the total CO 2 emission budget over the time horizon of analysis from 2005 to 2050. As a consequence, non-technical mitigation options slowing down economic growth are exploited by REMIND-D for meeting the CO 2 budget constraint. These include significant energy service demand reductions in passenger transportation as well as final energy demand reductions for electricity and the provision of heat. Additionally bound to moderate energy efficiency improvements, the 'continuation' scenario exhibits mitigation costs of 3.5% cumulative GDP losses over the period 2005-2050 as compared to a reference case that achieves 40% CO 2 emission reduction in 2050 relative to 1990. Stakeholders judged the results of this counterfactual scenario as highly problematic from a socio-political point of view and conclude that under carbon lock-in, ambitious mitigation will likely be out of reach. The two 'paradigm shift' scenarios reproduce future developments judged as desirable by participating stakeholders. These include a decrease in total freight transport mileage, a shift in the modal split of freight transport sector from road to rail, a substantial increase of public and non-motorized transport in the modal split of passenger transportation, a widespread electrification of private transport by 2030, a phase-out of conventional coal electrification until 2020, a rapid and large-scale deployment of renewable electricity generation and transmission line capacities as well as a fourfold increase in energy efficiency growth rates. REMIND-D immediately exploits these mitigation options whereby mitigation costs decrease by more than half when compared to the 'continuation' scenario, with 1.4% of cumulative GDP losses. Yet the necessary fundamental policy changes for such a scenario are put into question by stakeholders as they doubt that sufficient collective political will can be established. The 'paradigm shift\u00fe' scenario which additionally allows for the controversial use of CCS and large-scale biofuel production achieves even lower mitigation costs of 0.8%. However, CSO stakeholders remain skeptical whether these technologies are feasible in large scale, particularly due to social refusal. Overall, the deliberative elements in this participatory mitigation scenario exercise have demonstrated that the transformation towards a low-carbon energy system constitute as much a societal effort as an engineer's project. Socio-political implications of technological mitigation options are abundant and would indeed have an impact on the society as a whole. It is questionable, however, if the institutional aspects to the use of energy services can be adapted as rapidly as suggested by the optimal scenarios derived under the assumption of perfect foresight. This corroborates the thoughts of Unruh (2000) who suggests that energy model results are biased due to abstracting from technological evolution and institutions. He argues that sectors of the energy systems cannot be comprehended as discrete technological artifacts but rather as complex systems of technologies embedded in a powerful conditioning social context of public and private institutions. However, the direct implementation of social context and institutions into numerical energy system models appears impossible due to a lack of theoretical concepts and unobservability of data. In order to attach contextual meaning to parameters in available energy system models, the use of narratives, as explored in this paper, proves to be a promising avenue. Pursuing a participatory approach to developing mitigation scenarios results in a much stronger focus on the process of scenario definition and evaluation and allows for the explicit attachment of normative consideration to modeling results. As a form of scientific policy advice, such scenarios deal with value judgments openly and do not attempt to hide them behind seemingly factual or technical statements. Even though the limited scope of this research impedes inferential conclusions on the German energy transition as a whole, it has demonstrated that the technological solutions to the mitigation problem proposed by the model results give rise to significant societal and political implications that deem at least as challenging as the mere engineering aspects of innovative technologies. These insights underline the importance of comprehending mitigation of energy-related CO 2 emissions as a sociotechnical transition embedded in a political context. Thus, in future mitigation scenario exercises the questions of how to govern the transition and which kinds of policy instruments are suitable for enabling the transition should be treated more explicitly. If this participatory research could be repeated under these considerations and at larger scope and scale, emerging mitigation scenarios potentially enjoyed a higher level of ownership and acceptance amongst societal and political actors and ideally contributed to shared vision-building. 50 Hz Transmission GmbH, LichtBlick AG, RWE AG, Industriegewerkschaft Bergbau, Chemie, Energie (IG BCE)."
        }
    },
    "10.1016/j.enpol.2013.06.057": {
        "file_name": "64 Stakeholder perspectives on carbon capture and storage in Indonesia",
        "title": "Stakeholder perspectives on carbon capture and storage in Indonesia",
        "abstract": "Carbon capture and storage (CCS) is being considered as an option to reduce CO2\u00a0emissions worldwide. Yet recent cases show that CCS faces divergent public acceptance issues. This paper investigates stakeholder perspectives on CCS in Indonesia. Q methodology was adopted to analyse the diversity of stakeholder perspectives. Four perspectives were identified: (1) \u201cCO2\u00a0emissions reduction through clean energy sources rather than CCS\u201d; (2) \u201cCCS as one of the options in the transition to a sustainable energy system\u201d; (3) \u201cCCS as the only optimal solution to reduce CO2\u00a0emissions\u201d; (4) \u201cCCS is only a tactic to keep burning coal forever\u201d. Based on these results, we argue that stakeholder acceptance of CCS should be understood as a complex notion. This means that understanding whether or under what conditions stakeholders would be willing to support CCS, requires consideration of stakeholders' viewpoints about broader questions of CO2\u00a0emission reduction and energy supply in Indonesia, rather than studying attitudes towards CCS in isolation. We discuss how the approach taken in this study can be used and followed up in policymaking on CCS in Indonesia.",
        "label": "Mixed",
        "text": {
            "Introduction": " Carbon Capture and Storage (CCS) is being considered as an option in the (future) energy portfolio for countries all over the world (Gibbins and Chalmers, 2008;Johnsson et al., 2010). CCS refers to a range of technologies that are used to capture CO 2 from fossil fuels at large point sources (e.g. power plant) and to transport and store that in geological reservoirs (Gibbins and Chalmers, 2008). In this way, CCS prevents the emission of CO 2 to the atmosphere and contributes to the mitigation of climate change. Yet it has become clear that CCS is not uncontroversial. Several cases have been reported for example where CCS projects have met severe local resistances (e.g. Barendrecht in the Netherlands and Brandenburg in Germany) (Brunsting et al., 2011;D\u00fctschke, 2011). So although CCS is considered technically feasible on a commercial scale (Gibbins and Chalmers, 2008), a lot of questions remain with regard to non-technical aspects, such as public acceptance (Huijts et al., 2007;van Alphen et al., 2007). As a policy issue, CCS involves different stakeholders, defined as actors involved in, affected by, knowledgeable of, or having relevant expertise or experience on the issue at stake (based on van Asselt Marjolein and Rijkens-Klomp, 2002). These stakeholderssuch as local communities, industry, governments, science, NGOs and society in a wider sensemay have different ideas about the conditions under which it should be implemented or whether it should be implemented at all. Whereas some people see CCS as a necessary step towards a more sustainable energy system, others may see it as a lock-in of coal-fired power plants (Praetorius and Schumacher, 2009). Nevertheless, several countries, developed and developing, consider CCS as part of their low-carbon energy portfolio. Indonesia is one of those countries. The Indonesian Government has committed to a reduction of the country's carbon emissions up to 26% by 2020 from a business as usual scenario (Reuters, 2009). Following the Presidential Regulation on the National Energy Mix Target 2025, policies are geared towards reducing carbon emissions, mainly from the energy sector, through energy diversification and conservation. In fact, in this target plan fossil fuels (oil, natural gas, and coal) remain dominant with 83% and renewables have a share of 17%. Coal in particular takes in 33% of total energy mix target as to deal with energy demand growth (ESDM, 2006;ICSWG, 2009). Within this context, Indonesia considers CCS as a way to reduce CO2 emissions from the energy sector (ICSWG, 2009;Simamora, 2008). A preliminary study was carried out in 2009 by the Indonesia CCS Study Working Group to analyse the CCS potential in Indonesia. This study focused on technical issuessuch as capture technology, transportation method, and subsurface geological storageand non-technical issuessuch as the regulatory framework, financing, long-term liability and public acceptance (ICSWG, 2009). According to the study, the barriers for CCS concern mainly the non-technical issues. The study however did not address stakeholder perspectives or public attitudes on CCS. With this study we aim to fill this gap, considering the importance of societal acceptance for successful implementation of any new technology (Johnsson et al., 2010;van Alphen et al., 2007). Strategies towards the implementation and diffusion of new energy technologies such as CCS involve multiple stakeholders who have different interests, values and beliefs with regard to those technologies and the energy transition in general. CCS as a policy issue can be considered wicked (Rittel and Webber, 1973) or unstructured (Hisschemoller and Hoppe, 2001), which means that stakeholders differ in terms of how they define the problem and the preferred means for dealing with the problem. The policy sciences, especially in the field of energy and environment, suggest that dealing with wicked issues requires a deliberative approach (Burgess et al., 2007;Cuppen, 2012a;Wynne, 1996). Such an approach can be characterized as a learning process: through the interaction between stakeholders with different perspectives a better understanding of the issue (knowledge and values) at stake can be achieved (Cuppen, 2012a(Cuppen, , 2012b)). This is necessary in order to come to robust policies that integrate divergent perspectives in order to contribute to the energy transition. This notion of policy as learning (Hisschemoller and Hoppe, 2001) is the starting point for this paper. It suggests that a policy process starts with the articulation of divergent perspectives (Cuppen, 2012a(Cuppen, , 2012b)). A perspective is defined here as the integrated whole of beliefs, values and presumptions that stakeholders use to get to grips with a particular problem (Cuppen et al., 2010). In this paper we aim to set the stage for such a policy process by identifying the diversity of stakeholder perspectives on CCS in Indonesia. Most studies that have been published in relation to policy making on CCS focus on European countries (Pietzner et al., 2011;Radgen et al., 2009;Shackley et al., 2007Shackley et al., , 2009;;van Alphen et al., 2007) and the United States (Chaudhry et al., 2013;Feldpausch-Parker et al., 2011;Stephens and Jiusto, 2010) As such, this paper may enrich the policy relevant knowledge base on CCS from a developing country perspective. This paper is structured as follows. Section 2 presents the method used to identify stakeholder perspectives and how it was applied. Section 3 presents the results of the study. Section 4 discusses the similarities and differences between the resulted perspectives. Section 5 discusses implications of the study for research and policy making. And finally Section 6 wraps up with conclusions and discussions.",
            "Methodology": "",
            "Selecting a congruent method: Q methodology": " Above we have stated that CCS can be considered a wicked policy issue. The wicked nature implies that problem boundaries are not well defined but need to be probed. Dunn (1997) refers to this as 'estimating the boundaries of ignorance'. This needs to be taken into account when selecting a method for the analysis of stakeholder perspectives. Such a method should be congruent (Dunn, 1997) with the wicked nature of the CCS issue. Congruency means that it facilitates 'estimating the boundaries of ignorance', rather than adopting assumptions with regard to the problem boundaries or classes within the problem (e.g. who knows or values what, or which categories of perspectives there are or need to be taken into account). The social sciences have a number of methods at disposal to investigate perspectives in such a way, both qualitative and quantitative. Examples of qualitative techniques that are used quite often are interviewing and discourse analysis (e.g. Hajer and Versteeg, 2005). Also qualitative are cognitive mapping (Axelrod, 1976;Kitchin, 1994), value-focused thinking (Keeney, 1997) and policy Delphi (De Loe, 1995;Turoff, 1970). Both Q methodology and repertory grid technique (Fransella and Bannister, 1977;Kelly, 1995) are examples of combined qualitative-quantitative methods that have been used in the policy science field: repertory grid (e.g. Dunn, 1988;van de Kerkhof et al., 2009), and Q methodology (e.g. Breukers, 2006;Ellis et al., 2007;van Eeten, 2001). Each of these methods obviously has its own values and constraints. Q-methodology stands out, as shown by the large and growing number of publications in the policy science field (see below), as it allows for investigating perspectives in an open yet structured way, that is able to unravel more marginal perspectives next to more dominant perspectives. Developed in 1935 by William Stephenson, Q methodology is aimed to study people's subjectivity (Brown, 1980;Stephenson, 1935). Q methodology has been used in numerous accounts in environmental and energy policy research, where analysis of conflicting knowledge claims might lead to more effective policy solutions (Clarke, 2002;Cuppen et al., 2010;Ellis et al., 2007;Fisher and Brown, 2009;Ockwell, 2008;Reed et al., 2009;van Eeten, 2001;Webler et al., 2001;Wolsink and Breukers, 2010). It has been used as a tool for facilitating stakeholder involvement, for example in forest policy and management (Kangas et al., 2010;Steelman and Maguire, 1999) and sustainable bioenergy (Cuppen et al., 2010). Q methodology typically employs small numbers of respondents and the in-depth study of single case is not uncommon (McKeown and Thomas, 1988). It integrates the strength of both quantitative and qualitative research methods, where anyone with a basic knowledge of research statistics can conduct Q research (McKeown and Thomas, 1988;Webler et al., 2009). It is considered quantitative since factor analysis is used as a calculation method and qualitative because discourse analysis or a descriptive approach is applied to interpret the Q results. The key elements in Q methodology are the (1) 'concourse', i.e. the full range of ideas and opinions on the issue under study; (2) the 'Q sample', i.e. the set of statements that reflect the diversity of the concourse; and (3) the 'P set', i.e. the group of respondents (Cuppen et al., 2010;Davies and Hodge, 2007). The central task in Q methodology is a Q interview, in which each respondent sorts the statements (the Q set). The sorting task is usually added upon by follow-up questions that can be used to gain more insight into individual perspectives. The Q sort is based on a (normally) distributed scale. This scale represents a subjective evaluation, usually something like 'most agree' to 'most disagree'. Regular factor analysis is used to analyse the Q sorts. The resulting factors are qualitatively interpreted as different perspectives on the issue under study. In the remainder of this section we will subsequently discuss each of the steps of Q methodology taken in this study to analyse stakeholder perspectives on CCS in Indonesia.",
            "Generating and selecting Q statements": " This step should lead to a set of statements that reflects the diversity of possible viewpoints on CCS in Indonesia. These statements form the basis for the perspectives that will be identified in later stages of the procedure. As such, this is a critical step in the procedure. This set will be sorted by each respondent in the Q interview. Around two hundred and fifty statements were collected in attempts to reflect the variety of ideas and opinions on CCS in Indonesia. Statements were taken from scientific articles, cyber-news articles, reports (especially the report from the Indonesia CCS study working group), websites, etc. Ideally, statements should come as much as possible from the investigated context, in this case the Indonesian discourse on CCS. Since CCS was a relatively new issue in Indonesia, finding statements that were specific for Indonesia was not so easy. The report from the Indonesia CCS Study Working Group provided a good starting point. It included for example capture and transport technology, potential CO 2 sources and storage, and methodology for site selection. Other issues, such as regulatory frameworks and enabling policies, were however hardly covered. Because the report provided mainly technical, pro CCS viewpoints, we used more general statements on CCS to make sure that the sample represented a wide range of possible viewpoints. Diversity was checked by categorizing the statements according to different category systems, e.g. categories based on elements of the valuechain and categories based on enabling policy and regulation. The Q sample of about two hundred and fifty statements needed to be reduced to a manageable size for the Q sorts. Using the category systems, overlapping and redundant statements were deleted or merged. A final set of forty-five statements remained, which reflected the diversity of ideas and opinions on CCS in Indonesia. These statements are listed in Appendix A.",
            "Selection of respondents": " The aim of respondent selection is to make sure that people with divergent perspectives are included. Due to the specific nature of Q methodology, these different viewpoints do not have to be balanced (as in a survey or questionnaire). Q methodology relies on purposive sampling, which means that when a person who is assumed to have a different point of view this is considered enough reason to include him/her in the sample (Cuppen et al., 2010;McKeown and Thomas, 1988). This means that, compared to common random sampling (e.g. surveys or questionnaires), sample sizes are relatively small (McKeown and Thomas, 1988). An initial list of stakeholders was added upon by the snowballsampling technique: each respondent was asked to mention another stakeholder with a similar or different view on CCS in Indonesia. This resulted in a final P set of thirty respondents, comprising stakeholders with different organizational backgrounds and affiliations: national government, energy/power companies, academia and research institutes, NGOs, international counterparts, and media. Due to privacy reasons, none of their names can be mentioned here. Table 1 gives an overview of the stakeholders that participated in the study.",
            "Collecting the data": " The Q interviews were held in Jakarta mid-2010 (partly in local language -Bahasa). Twenty-two interviews took place face-to-face with printed-out paper cards and distribution chart/score sheet. Due to practical reasons, eight interviews were conducted by telephone. These respondents did the Q sorting task on their computer or laptop, using a software Q sort application; the FlashQ (Braehler and Hackert, 2010). The interviews consisted of the Q sorting task and a number of open questions, and took about fortyfive to ninety minutes to complete. Two opening questions were asked to the respondents: \"Could you tell briefly about your organization/company and what you do in the organization/ company?\" and \"Could you tell me your ideas on CCS related to the CO 2 emissions reduction target for Indonesia?\" The second question was asked to support qualitative interpretation of the factors resulting from the quantitative factor analysis. Then respondents were asked to do the Q sort. Participants were asked to sort these statements reflecting as close as possible their point of view. Respondents were first asked to read the statements and then to sort them into three piles of indeterminate scores -\"Agree\" pile, \"Neutral\" pile, and \"Disagree\" pile. Next, respondents were asked to sort the statements, starting with either the \"Agree\" pile or the \"Disagree\" pile, and put the cards into a normal distribution score sheet (see Fig. 1). The rank of scores was from one to eleven, with position one as \"most disagree\" and position eleven as \"most agree\". After sorting the statements into the score sheet, respondents were given a chance to change the position of the statements. It was emphasized that there is no \"right\" or \"wrong\" answer, but that it should purely be based on their beliefs and understandings. After finishing the Q sorting task, respondents were asked to elaborate on the statements at the two extremes of the distribution (\"Why do you agree/disagree most strongly?\"). They were furthermore asked if they missed specific statements and why. This was done to check the composition of the Q sample. Finally, the respondent was asked to give any remaining remarks on the issue of CCS in Indonesia.",
            "Analysis of the data": " Analysis of Q sorts was performed with the help of PQMethod 2.11 (Schmolck, 2002). The Q sorts obtained from the interviews were correlated in 30 \u00c2 30 matrix and then factor-analysed using Centroid in order to find associations among the different Q sorts. By default, Centroid analysis produces unrotated factor matrix with seven factors extracted. The unrotated factors were then rotated by using Varimax rotation (common in Q analysis). Rotation helps to identify significant factors and to maximize the number of individuals associated with just one factor (Webler et al., 2009). The number of factors to extract was based on three \"rules of thumb\". The first rule is the Kaiser's criterion or Eigenvalue criterion. Factors with Eigenvalue 41 were selected for extraction (Brown, 1980). The second is to accept factors that have at least two significant loadings (Brown, 1980). As noted by Brown (1980), \"Factor loadings are the correlation coefficients representing the degree to which a Q sort correlates with a factor\". Loading is calculated as 2.58 n standard error (SE) where SE \u00bc1/\u221aN with N equals the number of statements (Brown, 1980;McKeown and Thomas, 1988). In this case, with 45 statements, SE\u00bc 1/\u221a45 \u00bc0.149. Loading is accepted as statistically significant at 0.01 level when it is exceeding 2.58(SE), and at 0.05 level when it is exceeding 1.96 (SE) (Brown, 1980;McKeown and Thomas, 1988). The third \"rule of thumb\" is to follow Humphrey's rule. A factor is significant if the cross-product of two highest loadings exceeds 2(SE) (Brown, 1980). Based on these rules of thumb, two to four factors could be extracted. Besides statistical criteria, also theoretical significance of factors can be used to determine the number of factors to extract since the factor size is affected by the variables (respondents) which are included in the study (Brown, 1980). Theoretical significance follows from insights gained from qualitative interview data. Applying both statistical and theoretical criteria, three factors were finally extracted and subjected to Varimax rotation. Appendix B shows the distribution of Q sorts in the factor matrix after Varimax rotation. The sorts which load significantly on a factor are marked by an X. The factor loadings indicate the degree to which each Q sort corresponds to each factor. With significant loadings to be equal to or greater than 70.3846, out of the thirty respondents, sixteen respondents load significantly on only one factor, twelve respondents load significantly on more than one factor, and two respondents do not load on any of the factors. Respondents who loaded in more than one factor were identified as confounders and considered to be eliminated from subsequent analysis (Webler et al., 2009). But the elimination of confounders from the final analysis can yield in the loss of valuable perspectives. In order to counter this occurrence, the strategy was to raise the significance level to 70.500 (which will only make the statistical criteria more stringent) (Watts and Stenner, 2005). As a result, and taking the qualitative interview data into account as well, thirteen respondents load significantly only on one factor. Of these thirteen respondents, two respondents loaded significantly on Factor 1, five on Factor 2, six on Factor 3. Factor 3 had positive and negative significant loadings, where four respondents had positive loadings (respondent nos. 2, 7, 13, and 20), and two respondents had negative loadings (respondent nos. 22 and 30). Therefore Factor 3 is identified as a \"bipolar factor\" and interpreted in Section 3 as two contrasting perspectives. Five respondents did not load significantly on any of the factors, and the remaining twelve respondents loaded significantly on more than one factor. The total variance explained of the three factors was 48%. This is considered relatively low in regular factor analysis, yet for Q methodology it is not considered problematic. 1 In order to interpret factors as perspectives (Cuppen et al., 2010;McKeown and Thomas, 1988), three things are used: (1) the statements that define each of the factors (statements with the highest and lowest z-score), (2) the statements that distinguish one factor from another (statements for which the z-scores on each of the factors are most different), and ( 3) the open questions asked in the interviews. In the next section we will present the interpretation of the three factors as four perspectives (bipolar factor 3 interpreted as two contrasting perspectives).",
            "Results: four perspectives on CCS in Indonesia": " Factor 1 represents Perspective 1, and Factor 2 represents Perspective 2. Meanwhile Factor 3, since it is bipolar, represents two opposing perspectives; Perspectives 3 and 4. Perspective 3 is the representation of the positive significant loadings, and Perspective 4 is the representation of the negative significant loadings. These four perspectives are presented below. For each perspective a table is shown with the eight defining statements (the highest positive and negative scores), the most distinguishing statements and some relevant quotes from the interviews. Each perspective is labeled by us with a meaningful title covering the narrative belonging to the perspective.",
            "Perspective 1: \"CO 2 emissions reduction through clean energy sources rather than CCS\"": " This perspective emphasizes the use of clean energy sources in order to reduce CO 2 emissions and rejects CCS as a major element of a low carbon economy for Indonesia. According to this perspective, the use of fossil fuels is the root of climate change itself, as expressed by one respondents as follows: \"\u2026the truth is that using dirty fossil fuels is the root of the climate change problem, therefore using clean energy sources is an inevitable choice if we want to significantly reduce CO 2 emissions and fight against climate change\". Coal utilization is not believed to be essential to boost economic growth, neither is CCS believed to be the way forward to have sustainable growth in developing countries. This perspective sees that even if CCS could significantly reduce CO 2 emissions, it is not able to deal with other harmful emissions of fossil fuels. With respect to this argument, one respondent argues: \"Not only CO 2 is released from burning dirty fuels like coal, but it also releases sulfur oxide and nitrogen oxide. Both can retain incoming solar radiation and cause acid rain which damages infrastructure and environment\". This perspective emphasizes the artificial character of storing CO 2 in sedimentary basins which creates risks related to storage and transport. Although this perspective holds that CCS is not the appropriate solution for climate change, CO 2 reduction or other problems related to the combustion of fossil fuels, neither for economic and/or sustainable growth, it still considers CCS a cost-effective answer to a high carbon tax \"\u2026since Indonesia is still dominated by the use of fossil fuels\". Still CCS is regarded a very high cost technology. A good financial performance and the incentives from government are needed, as well as the commitment of and cooperation between stakeholders. Two respondents load significantly on this perspective: one from an NGO (WWF) and one from an energy/power company (Medco Energi). This means that this perspective is shared by people from different, but not all, stakeholder groups. Table 2 presents the statements that characterize this perspective: statements with the highest positive and negative scores, the most distinguishing statements, and some relevant quotes from interviews. 3.2. Perspective 2: \"CCS as one of the options in the transition to a sustainable energy system\" The core belief of this perspective is that climate and energy policies must not rely on one single option in order to cut CO 2 emissions. As one respondent states: \"there are many other options, so don't stick only to CCS. If we rely only on CCS, we will not be able to move forward on the sustainable energy way\". Another respondent: \"\u2026.Many things can be done to reduce CO 2 emissions on the technology side and also the policy side. CCS cannot be regarded as the only means. Many options can be utilized to fight climate change\". This perspective considers CCS as an option in the CO 2 emissions reduction portfolio but, in the long run, favours other, more sustainable options. \"CCS should be considered as a contingency measure to forcefully downgrade the level of CO 2 emissions using the current energy source of fossil fuels. Meanwhile the proactive approach in the long term should be to find alternative energy\". This perspective takes into account socio-economic aspects related to CO 2 reduction options. As CCS does not benefit local communities in the long term, whereas renewable energy and energy efficiency do promote local employment and new economic opportunities, the latter are favoured to CCS. This perspective furthermore stresses that concerns about CCS from local communities are legitimate and that they should be addressed: \"CCS is very specific in terms of site selection. The public understanding of CCS is low, therefore we should inform the public on CCS. The decision on site selection of CCS must consider the viewpoints of the public\". A point of critique is the high costs of CCS: \"it will not be easy to finance CCS, and sole reliance on CCS will hamper economic growth\". This perspective disfavors the carbon market or emissions trading scheme as financing mechanism for CCS: \"the carbon market is based on mechanisms set by CDM principles, while CCS is not yet an approved methodology in CDM. Therefore it will be very difficult and complicated to make CCS works under this scheme\". CCS's close fit with current fossil fuel practices is seen as a potential advantage of the technology. \"CCS for EOR has been used by oil and gas companies\" which makes that this perspective disagrees with the statement (25) that \"CCS is complex enough in itself, it should not be linked to other possible advantages such as Enhanced Oil Recovery\" (EOR: see Hondroyiannis et al., 2002). However, new applications, such as CCS for biomass or gas processing plants, are not favoured that much as \"CCS will face many opposition to settle this as a requirement in such related industry\". Out of the five respondents who agree with this perspective two are from National Government (KLH and BKPM), two from an energy/power company (PGN, PLN), and one from academia (ITB). So, just like Perspective 1, Perspective 2 is shared by people from different, but not all, stakeholder groups. Table 3 shows the statements that characterize this perspective: statements with the highest positive and negative scores, the most distinguishing statements, and some relevant quotes from interviews. 3.3. Perspective 3: \"CCS as the only optimal solution to reduce CO 2 emissions\" This perspective is strongly in favor of CCS. Based on the idea that it is hardly possible for the world to be independent from fossil fuels within a reasonable time, CCS is seen as the only effective way to remediate the uncaring behavior in using fossil fuels. CCS is the solution to climate change and therefore it is not a temporary but a long-lasting solution. This perspective strongly believes that technology is not the problem: \"CCS component technologies have been used many years in many industries, so no worries about its deliverability, it will be on time\u2026\". Also the costs will not be a problem in the long run: \"The cost of CCS is still high since it is not yet deployed on a large scale. It is common for such technology in a demonstration phase, but it will reach affordable cost\". CCS can be the powerful complement for the development of renewable technologies, and therefore it will speed up the penetration of renewables. The reason behind this is that CCS will be supported by the price of carbon when the costs of CCS are lowered and carbon prices rise as caps on CO 2 emissions become tighter. The money from carbon trading can then be used to invest in renewables. This perspective stresses that government should develop a CCS roadmap and embody it in the national energy plan. Furthermore, developed countries should lead the CCS efforts and make sure that CCS is spread rapidly to developing countries: \"Technology transfer is important for CCS development. It is impossible for developing countries to implement CCS by themselves. There should be voluntary efforts from developed countries to support developing countries\". Two respondents from National Government (ESDM and BPPT), one from an energy company (Shell), and one from academia (University of Indonesia) load significantly on this perspective. This perspective is thus also shared by people from different, but not all, stakeholder groups. Table 4 shows the statements that characterize this perspective: statements with the highest positive and negative scores, the most distinguishing statements, and some relevant quotes from interviews.",
            "Perspective 4: \"CCS is only a tactic to keep burning coal forever\"": " The last perspective portrays the antithesis of Perspective 3. It firmly rejects CCS as a CO 2 reduction option for Indonesia. In the words of a respondent: \"CCS is only a tactic from coal-fired power plants and mine industries to have justification in keep burning coal forever. With CCS they will have more justification that GHG emissions from burning coal will not be a problem any longer\". CCS provides no benefits to Indonesia. It will only increase the dependency on fossil fuels. The adoption of CCS will be contraproductive to the development of renewables: \"The adoption of CCS will only make renewable energy technology development slow since people will then remain using fossil fuels\". CCS is even not a partial solution to the climate change neither will it be ready in time to overcome it. Therefore there are no reasons to rely on this unproven technology either temporarily or in the long run. The only effective way to fight climate change is by reducing dependency on fossil fuels. Furthermore, this perspective believes that a shift to renewable energy and energy efficiency can promote employment and new economic opportunities. Two respondents load significantly on this perspective: one from an NGO (Greenpeace) and one from Academia (ITB). Table 5 shows the statements that characterize this perspective: statements with the highest positive and negative scores, the most distinguishing statements, and some relevant quotes from interviews.",
            "Similarities and differences between perspectives": " In order to enhance the comprehension of the perspectives, the similarities and differences between perspectives are examined. Table 6 shows the correlations between the three factors resulting from the factor analysis in PQMethod. Please note that due to the bipolarity of the third factor it has been split up into two factors to improve interpretation: Factor 3a (Perspective 3) and Factor 3b (Perspective 4). The higher the correlation between two factors, the more similarity there is between those two perspectives. Table 6 shows that Factors 1 and 2 (Perspectives 1 \"CO 2 emissions reduction through clean energy sources rather than CCS\" and 2 \"CCS as one of the options in the transition to a sustainable energy system\") are most strongly related (0.4346). Both perspectives are critical towards CCS yet see it as an option in the CO 2 emissions reduction portfolio. They agree that CCS is a high cost technology for developing countries to adopt. However, whereas Perspective 1 is critical with regard to CCS because of its risks and its lack of solving other fossil-fuel related problems (other emissions than CO 2 ), Perspective 2 is critical with regard to CCS because of its lack of local benefits (e.g. employment, as compared to renewable energy). Furthermore, Perspective 2 is a more policy-oriented perspective focused on the long term There should be voluntary efforts from developed countries to support developing countries\". \"It is too extreme to say CCS is just a tactic. In fact, we still need coal as source of energy and CCS is an option to deal with the emissions\". \"In fact CCS component technologies have been used many years in many industries, so no worries about its deliverability, it will be on time\u2026\". \"With CCS we can be more careful to the environment while using fossil fuels. No matter how difficult and expensive the technology, but soon or later, CCS will come to affordable cost\". \"The cost of CCS is still high since it is not yet deployed in the large scale. It is common for such technology in a demonstration phase, but it will reach affordable cost\". \"The responsibility of government is vital in order to support CCS development, and at the same time to increase public awareness of it\". transition to sustainable energy. Perspective 1 is rooted more in current practice and focuses mainly on the use of clean energy sources (e.g. renewables) in the energy sector, because this sector is the biggest CO 2 emitter. Perspective 2 considers not only renewable energy but also energy efficiency as the option, which is not explicitly mentioned by Perspective 1. Both perspectives 3 and 4 are not strongly correlated to either Perspective 1 or 2 (|0.21| and |0.20| respectively). Whereas Perspectives 1 and 2 are nuanced with regard to the role that CCS can or should play, Perspectives 3 and 4 are very explicit. Perspective 3 sees CCS as the solution, whereas Perspective 4being the counterpart of Perspective 3rejects CCS categorically. Perspectives 3 and 4 can be considered believers and disbelievers of CCS respectively. Perspective 3 is very much technology-oriented while Perspective 4 is more environment-oriented.",
            "Policy implications": " The results of this study show that CCS is implicitly linked by all perspectives to centralized, coal-fired power plants. Other options such as CCS in conjunction with EOR or natural gas plants are not salient in people's understanding of CCS. Perspective 2 (\"CCS as one of the options in the transition to a sustainable energy system\") is the only perspective that explicitly addresses EOR; it states that CCS should not be linked to EOR. In fact, Indonesia's oil and gas industry may offer significant potential for EOR or EGR (Enhanced Gas Recovery) (ICSWG, 2009;Pasarai and Utomo, 2012). At the moment, the government sees the use of CO 2 for EOR as the most suitable near-term deployment of CCS (Pasarai and Utomo, 2012). Our results suggest a discrepancy between the current perspective of the government and stakeholder perspectives. The CCS and EOR issue might therefore deserve more attention in the Indonesian policy debate. Apart from CCS for EOR, CCS in bioenergy plants may be an interesting avenue to explore further. Bio-energy plants with negative emissions may offer great potential for achieving the CO 2 emission reduction target, especially considering Indonesia's bioenergy potential of about 50 Giga-watts (ESDM, 2011;Singh and Setiawan, 2013). Yet this option is not an element in any of the perspectives we found in this study. This could be due to several issues, such as biomass utilization being still low and the immaturity of biomass industries. At the moment, the scale of biomass industries in Indonesia is considered too small for supplying CO 2 and retrofitting with the capture technology (Pasarai and Utomo, 2012). Our findings suggest that most stakeholders tend to be (at least) conditional supporters of CCS. This implies that the conditions which CCS is deemed acceptable need to be mapped out clearly in the process of policy formulation. Policymakers should well address the issues considered important by stakeholders. In addressing such issues, policymakers should heed the importance of deliberative dialogue between stakeholders. In the introduction of this paper we argued that 'policy as learning' (Hisschemoller and Hoppe, 2001) is an appropriate approach for dealing with the wicked policy issue of CCS. We argued that 'policy as learning' starts with the articulation of divergent perspectives; the approach as taken in this study can be seen as a first step in such a process. By thinking about stakeholder perspectives in a more contextualized and nuanced way than stakeholder \"acceptance\" or \"rejection\", such an approach can contribute to openingup (Stirling, 2008) the policy process. The role of Q methodology for opening up policy appraisal has been illustrated before by Ockwell (2008). A next step can be to set up a deliberative process with stakeholders to inform policymaking, in which different scenarios or visions can be constructed based on the four stakeholder perspectives. Such a pluralist process can support the development of new knowledge with regard to emission reduction and energy supply in Indonesia, and the identification of robust policy strategies. Similar approaches have been followed with regard to the role of hydrogen in the Dutch energy system (Hisschem\u00f6ller and Bode, 2011;van de Kerkhof et al., 2009) and sustainable biomass in the Dutch energy system (Cuppen et al., 2010). Also, experiences with approaches such as 'backcasting' (Quist, 2007;Quist and Vergragt, 2006) and transition management (Loorbach, 2007;Rotmans et al., 2001) may provide good Relevant quotes from interviews \"CCS is not the right way to cut global emissions, it contradicts with renewables and energy efficiency\". \"The adoption of CCS will only make renewable energy technology development slow since people then will remain using fossil fuels\". \"CCS is only a tactic from coal power plants and mine industries to have justification in keep burning coal forever. With CCS they will have more justification that GHG emissions from burning coal will not be a problem any longer\". \"Increased adoption of CCS will be contra-productive to the development of renewables not only for Indonesia but also the whole world\". starting points for a policy process geared towards the development of robust, long-term and acceptable policy strategies, grating stakeholder perspectives. Yet, acknowledging the importance of context, more research is needed into the specific policy, social and cultural context in Indonesia.",
            "Conclusion and discussion": " This study has revealed four shared perspectives on CCS in Indonesia. Two of these are opposing perspectives; one embraces CCS as the solution (Perspective 3: \"CCS is the only optimal solution to reduce CO 2 emissions\") while the other one rejects CCS (Perspective 4: \"CCS is only a tactic to keep burning coal forever\"). The other two perspectives (Perspectives 1 and 2) are more nuanced with regard to CCS. Both are critical and emphasize the importance of renewable energy rather than CCS, yet see it as an option in the CO 2 emissions reduction portfolio. These two perspectives differ in terms of their critiques on CCS and their focus on either current practice in energy production (Perspective 1) or the long-term energy transition (Perspective 2). The findings of this study shed light on the issues on which stakeholders might converge and issues for which there is conflict. Stakeholders disagree with regard to the necessity and possibility to reduce the role of fossil fuels in the Indonesian energy system. Furthermore, for some stakeholders CCS is not an option at all, for some it is a temporary option, whereas for others it is a long-lasting option. Related to this, some see CCS as a way to stimulate the transition to renewables, whereas others think that CCS hampers the transition to renewables. The four perspectives we identified are valid for the Indonesian situation. Yet, some of the perspectives have articulated issues that may be salient in other emerging countries as well. For example, both Perspectives 1 and 2 stress the high costs of CCS, in particular for developing countries. Perspective 2 is furthermore critical about the lack of local benefits of CCS, which is why this perspective favors renewable energy options. Local benefits may be especially salient for less developed regions. Finally, Perspective 3 stresses that developed countries should lead the development of CCS and work on transfer of the technology to developing countries. On a more general level, at least three issues received similarly great attention from most stakeholders in the interviews: cost of CCS and its financing mechanism, the need of technology transfer, and low public awareness. These findings appear quite similarly in other research related to CCS in other developing or emerging countries, although the methods used are different. For example Duan (2010) conducted survey research on public perspectives on CCS in China. The result showed that public awareness of CCS was low, and the acceptance of CCS was mainly determined by several factors such as technology maturity, risks and uncertainties, and government support. Rom\u00e1n (2011) interviewed stakeholders in Brazil, South Africa, and India, and found that costs of CCS and economic considerations form the main factor that decides the position of those three countries towards CCS. In addition, the findings of this research also displayed the importance of technology transfer for the deployment of CCS in emerging countries. This complements the research by Gallagher (2010), Garg andShukla (2009), andOckwell et al. (2008) which argued that developed countries should take a lead in demonstrating CCS in developing countries. Interestingly, to some extent our findings are also quite similar to those found in some developed countries. For example, Ashworth and Quezada (2011) reported that economic considerations, social responsibility, and government support are the issues that need to be addressed in the deployment of CCS in Australia. Also Ashworth et al. (2010) found public awareness and understanding of CCS in Australia was low. Pietzner et al. (2011) concluded that public awareness and perception of CCS in six European countries (Germany, Greece, The Netherlands, Norway, Romania, and the United Kingdom) were relatively low. Meanwhile Chaudhry et al. (2013) carried out semistructured interviews in four US states and found that economic, technical, and political risks are perceived as the key issues in the deployment of CCS. Nevertheless, perhaps the main difference between developing and developed countries regarding CCS lies in the how CCS is framed as a policy option. For developed countries, CCS may be seen as an option to tackle the challenges of climate change and energy security, but for developing countries CCS may only be seen as just an option for CO 2 emissions reduction (Liu and Liang, 2011). We would like to finish with a reflection on the notion of stakeholder acceptance and the research methodology. Rather than thinking about stakeholder acceptance of CCS in terms of pro and con positions, Q methodology allowed for uncovering the variety of shared perspectives amongst stakeholders. As a combined quantitative and qualitative approach, it resulted in a meaningful interpretation of stakeholders' considerations with regard to CCS in Indonesia. What our results furthermore show is that stakeholder acceptance of CCS is a complex notion. That is, in order to understand why (not) or under which conditions stakeholders would be willing to support CCS, it is important to consider their broader ideas and viewpoints about CO 2 emission reduction or energy supply in Indonesia, rather than considering their attitudes towards CCS in isolation. The Q perspectives showed for example that a nuanced opinion vis-\u00e0-vis CCS can have different motivations. Perspective 1 is critical with regard to CCS because of its risks and its lack of solving other fossil-fuel related problems, whereas perspective 2 is critical because of the lack of local socio-economic benefits of CCS. Stakeholder perspectives towards CCS are thus not one-dimensional, but are integrated wholes of divergent values and issues considered as relevant by specific stakeholders. The four perspectives we have identified with Q methodology offer a starting point for analysing the issues and values associated with stakeholder perspectives on CCS. Our results furthermore show that stakeholders from similar affiliations (e.g. government, research, NGOs, etc.) are scattered over the four perspectives, and that none of the perspectives is represented by only one group of stakeholders. This means that based on the affiliation, it cannot be assumed what kind of perspective a particular stakeholder has. This underlines the relevance of our approach.",
        }
    },
    "10.1016/j.enpol.2006.02.014": {
        "file_name": "65 Photovoltaic deployment strategy in Japan and the USA\u2014an institutional appraisal",
        "title": "Photovoltaic deployment strategy in Japan and the USA -an institutional appraisal $",
        "abstract": "Photovoltaic (PV) is a renewable energy technology, along side with other modular energy generation technologies such as micro-turbines, fuel cells, etc., which will enable the alternative distributed generation paradigm compared to the incumbent fossil fuel based centralized generation paradigm. Distributed generation utilizing renewable energy resources offers opportunities for significant carbon dioxide and emissions reductions thus contributing solutions to broader climate change issues. Yet, renewable energy technologies like PV face various barriers for their widespread adoption. Aside from technical and cost issues, renewable technologies have to overcome the so-called carbon lock-in effects. This refers to the techno-institutional complex associated with the fossil-fuel based centralized generation regime that currently dominates energy production and use. Governmental interventions to address these issues usually can be seen as composed of research, development, demonstration and deployment or RD3 [PCAST, 1999. Panel on International Cooperation in Energy Research, Development, Demonstration, and Deployment]. This paper focused on comparing the deployment aspect of PV technology in Japan and the USA. While both governments promoted PV as part of their larger strategies to address various environmental and energy security issues, Japan has built a PV installation capacity three times that of the USA as of December 2003 with over 90% of PV installation in the grid-connected small residential system category. This is in marked contrast to the case in the USA in which the cumulative installation is spilt among different types of applications involving the grid and off the grid.\n\nWe put forward two models to explain these differences in deployment strategies and their possible consequences. The first deployment model leverages upon PV as a manufactured technology with minimal customization to achieve massive deployment. The second deployment model leverages upon PV as an information technology-like technology focusing upon user oriented customization to achieve deployment. Different models have different implications to the system engineering aspect of solar PV. A focus upon the standard grid-connected distributed category in the residential setting avoids the heavy customized engineering associated with many off-grid and one-off type projects.\nJapanese PV deployment strategy of concentrating upon a dominant category or niche with mass market potential also well matches the institutional structure of production [Coase, 1991. The Institutional Structure of Production, in Essays on Economics and Economists. The University of Chicago Press, Chicago] within the local PV technology suppliers industry. Major vertical integrated firms can facilitate system-related learning easier than a fragmented industry within the PV value chain with minimal transaction cost. This highly suggests that deployment strategy of PV or other renewable energy technologies must address the issues of adopting a globally developed technology to local (national) conditions and has strong institutional underpinnings in addition to financial subsidies, learning investment thinking.",
        "label": "Mixed",
        "text": {
            "Introduction": " Large scale deployment of renewable energy sources to supplement or even to replace fossil fuels for electricity generation offer a means to reduce greenhouse gas emissions and to minimize the risks of climate change caused by burning of the fossil fuels. Renewable energy refers to distributed energy resources that occur naturally and repeatedly in the environment and which can be harnessed for human benefit. Examples of renewable energy systems include solar, wind, and geothermal energy (getting energy from the heat in the Earth). Among all these distributed renewable energy alternatives, modular photovoltaic (PV) technology is fundamentally well suited for decentralized electricity generation and is already market ready. Yet, despite these potentials, PV, along with other renewable technologies, faces various barriers for widespread adoption. Industrial economies have been locked into fossil-based energy systems through a process of technological and institutional co-evolution driven by path-dependent increasing returns to scale. In conceptual terms, Unruh (2000) suggested that this carbon lock-in or structuration arises from systemic interactions among technologies and institutions resulting in a technoinstitutional complex (TIC). TIC is difficult to displace and can lock-out alternatives such as potential renewable energy technologies for extended periods, even when the alternatives demonstrate improvements upon the established TIC. Others have conceptualized a more active and autonomous picture for the adoption of renewable energies in terms of their sustainable diffusion. Tsoutsos and Stamboulis (2002) suggested renewable energy technologies constitute a techno-economic system that is radically different from conventional systems or regimes. Incorporation of renewable into the existing regime of energy will have system-wide consequences. As long as renewable technologies seek to answer the old questions or problems, they will run up against established heuristics, infrastructure and complementary assets associated with the incumbent technological regimes. One penetration strategy is therefore to seek novel ways to describe and address the energy problem, in terms of function, benefit, objectives and performance. The aim is to shift the focus of performance to new territory where conventional technologies would not be in an advantageous position. Formally, this can be cast in terms of a penetration-promotion strategy in market segments for the transition to a new technological regime (Kemp et al., 1998;Weber and Dorda, 1999) which is based on creation of protected niches for the development and use of renewable technologies. A general outlook of the strategic niche management literature is that any discussion of technology must include the relations between the technological artifact and the social organization that brings the overall ''socio-techno-logical configuration'' into use. In this niche theory, as Smith (2003) has suggested, growth is ensured through: (a) degree of niche compatibility with the dimensions of incumbent regime, (b) robustness or sustainability of performance of the niche chosen. For a general physical technology with potentially many applications, it is therefore important to choose the right niche to start with that has the least disruption to the existing system and yet has the most development potential and possibly in terms of spillover to other applications in order for widespread adoption of the physical technology in the future. This paper utilizes the strategic niche management (SNM) framework to compare the PV deployment strategies of Japan and the USA. We paid particular attention to the fact that a working PV system will involve customized system engineering and yet a dominant system design has not been established. In fact, the polymorphy and site-specificity (Tsoutsos and Stamboulis, 2002) of PV raise the necessity of dealing with system design, integration and installation case-by-case in the context of each application. This system engineering aspect of renewable technology received scant attention in the renewable energy literature. Our contention is that the choice of an initial niche application, which constitutes the second phase1 of bringing on new renewable technology to commercial maturity, needs to address this system engineering or system technology aspect strategically with a long-term perspective. System engineering concerns not only design but also have implications to installation, safety, quality and durability2 and even re-cycling issues for a PV system. System engineering also has to be designed knowing that the downstream integration will necessarily involve a community of practice, spanning across boundary of firms and involving many independent market players. As a result, the more standardized the system engineering aspect of a chosen niche, the more the niche will lend itself to a mass production-deployment model, given an institutional structure of production (Coase, 1991) or community of practice. The corollary is therefore that whether existing institutional structure of production matches the system engineering and production-learning implications of the choice of a niche application may determine the initial and sustaining success of a particular niche strategy. In this sense, the system engineering aspect of PV underscores the institutional underpinnings of its deployment in the context of strategic niche management. The choice of a niche or, broadly, a niche strategy will necessitate a particular system design and production-learning economy which must match the learning characteristic of the underlying institutional structure of production in order for the niche to take off. In the context of this paper and PV deployment, an institutional structure of production may be a vertical integrated structure of a major firm for the case of Japan conducive to mass production learning or a somewhat fragmented structure with an independent professional community of system integrators mediated by industry standards engaging in cross-learning or spillover learning for the case of the USA. The rest of the paper is organized as follows: Section 2 reviews the PV installation situation in Japan and the USA and proposes two deployment models based upon the general purpose nature of PV. Section 3 reviews the cost dynamics of constituents within a PV system. Section 4 attempts an explanation of difference of these models from an institutional perspective. We will conclude in Section 5 with some recommendations for future study.",
            "PV deployment in Japan and the USA": " A review of the cumulative PV installed base (as of December 2003) in Japan and the USA shows a marked contrast. Not only has Japan built an installed base three times that of the USA; in terms of PV applications, approximately 90% of the Japanese cumulative installed base is in grid-connected distributed category while in the USA, the distribution of applications is more uniform with the grid-connected category constituting approximately only 30% of the installed base. See Figs. 1 and 2 for comparison. By the end of FY 2003, the cumulative PV power installed in Japan has reached 860 MWp with approximately 623 MWp installed as residential PV system; no single factor will explain the driving forces for residents to install PV systems, it may be a combination of growing public and environmental awareness, the subsidies offered as well as possibilities of selling generated electricity back to utilities. As we will show later, the fact that several major housing manufacturers combine PV installation in their newly built houses create a new and homogenous grid-connected market for PV installation. This, in turn, subscribes a close model of PV deployment. For the case of the USA, there is no single dominant market for PV as yet. It is a conglomeration of regional markets and special applications for which PV offers the most cost-effective solution relative to centralized generated electricity. Until recently, the PV market has been dominated by off-grid applications, such as remote residential power, industrial applications, telecommunications and infrastructure, such as highway and pipeline lighting or buoys (Jager-Waldau, 2004). This deployment pattern leverages the general nature of PV principle and adapts it to applications not necessarily with market potential of massive magnitude. This, in turn, falls into an open or applications driven model of deployment.",
            "ARTICLE IN PRESS": "",
            "The essence of the two deployment models": " To fix idea, we proposed two different market deployment models based upon the differences between the nature of information technology and manufactured technology (Watanabe et al., 2003) to formalize our inquiry. The information technology development model refers to an open model in which diffusion is based upon developing a variety of new application categories for PV leveraging its self-propagation, general-purpose nature driven by customization and user requirements. The manufactured technology development model refers to a close model in which a dominant category of PV application is developed revolving around the existing utility grid infrastructure or grid-connected distributed applications. The resultant PV system features are therefore dictated by technology suppliers and the economy of production driven by that of mass production rather than customization or valuebased. These two deployment models draw upon the same global cost dynamics of PV cell and other components of PV system but have differing implications on local installation and balance-of-system (BOS) system engineering requirements. The next section reviews the cost structure of a PV system to illustrate the possible effects of deployment on different cost drivers of a PV system.",
            "Existing studies on cost dynamics of PV systems": " A PV system consists of the PV modules and the socalled BOS as shown in Fig. 3. BOS is an equipment which is needed to integrate the modules into the user's system, and it contains different components for different categories of applications. The cost of BOS and installation and that of the modules are the major cost drivers of a PV system and these two are of the same order of magnitude (Fig. 4). The PV modules remain a significant proportion of system prices (generally about 50-60% for grid-connected systems; IEA, 2003) and, compared to the widely varying non-technical and BOS costs, continue to present a useful 'international' indicator for tracking the changes in PV technology costs over time. However, the learning patterns for these two drivers are quite different.  199231 Dec. 199331 Dec. 199431 Dec. 199531 Dec. 199631 Dec. 199731 Dec. 199831 Dec. 199931 Dec. 200031 Dec. 200131 Dec. 2002 31 endogenous (Aghion and Howitt, 1998) mechanisms for reducing uncertainty and improving performance and costs of an infant technology. These two activities cannot be treated separately as sources of technological dynamics. Watanabe (1995a, b) has empirically demonstrated that there is a 36% reduction in PV cost per each doubling of cumulative production. However, when the same PV cost time series data is empirically regressed against the logarithm of cumulative expenditure consisting of R&D expenditure (a proxy for the technology knowledge stock) and production investment (a proxy for accumulated experience), there is a 54% drop in PV costs per doubling of cumulative expenditures. It strongly suggests that the PV cost dynamics is more sensitive to cumulative expenditure than cumulative production. This is due to that cumulative expenditure embodied both the effects of accumulated production experience and technological knowledge. This suggests that cost learning of PV modules is driven by the joint effects of production learning and knowledge stock due to research and development. In fact, their effects on cost of PV modules may be directly modeled by a single learning curve3 (Grubler, 1997). However, both production learning and research and development of module technology exhibit international spillovers due to two mechanisms. According to IEA PV working group's system price survey in 2004, very few countries have a balance between local production and capacity installed (six or seven countries can be said to have significant production available for export, eight countries produce between zero and 40% of their local demand). This suggests that PV module production learning will be spillover among countries. In fact, there are now a number of examples of imported modules selling for considerably less than the local production. In addition, most of the module manufacturing is done by internationally operating countries and there is extensive exchange of scientific and technological information on module technology between nations. As a result, cost of PV module can be assumed to be globally the same (Wene, 2000;Schaeffer, 2003;Alsema, 2003).",
            "Existing studies on cost of BOS": " As we have defined above, BOS of a PV system consists of all the systems or engineering components apart from the PV modules or cells. The BOS is a significant part of the cost of an installed PV system, and is responsible for controlling and managing the power output of the PV modules-array. BOS primarily consists of an inverter to transform the direct current (DC) output from the PV array into a form of alternating current (AC) electricity that can be synchronized with and connected to the electric utility grid. Other equipment includes wiring, switches, an electric meter, and circuit breakers and fuses. Some systems are equipped with a charge controller and battery to provide backup power, but due to large expense of batteries, they are currently included in only 1-2% of new installations (Sterzinger and Svrcek, 2005). The cost learning of BOS has not been studied as widely as the cost learning of PV cells or modules. Noted exceptions are from Schaeffer (2003) and Hegedus and Okubo (2004). For grid-connected residential systems, the BOS experience curve is sustaining a progress ratio of 0.78 during 1992-2000. However, unlike PV module learning which is inherently both R&D driven and production or manufacturing driven, BOS learning has not been attributed to cost reductions of individual hardware components. In fact, most of these hardware components comprised of mass-produced electrical components with mature markets outside the solar industry except for discrete technological innovation due to development of important components such as inverter. Therefore, BOS learning can mostly be attributed to cumulative experience of system designers and installers, attained through greater system integration and a reduction in the number of BOS parts. A significant opportunity for further reducing BOS costs is standardizing BOS to the greatest degree possible or to minimize the on-site customization proportion (Harmon, 2000). This effectively changes customization oriented BOS engineering to a manufactured activity subjected to economies of scale and factory production learning. One of the key questions in the study of BOS learning is if BOS learning is local or global in character? Inverter part 1 9 9 1 1 9 9 2 1 9 9 4 1 9 9 6 1 9 9 8 2 0 0 0 2 0 0 2",
            "Comparing system costs in Japan and the USA": " To provide some empirical evidences for our hypothesis that BOS learning is local driven, we draw upon the international statistics from the respective country reports from IEA (2003). This tracks the system price for smallscale grid connected residential systems in our study period and is shown in Fig. 5. System price is defined as the per wattage price of the system net of that of module and the unit is in 2006 US$. We assume system price is a proxy of BOS and construction cost controlled for market effects. The depicted trends seem to confirm that Japan sustains a lower system price than that of the USA during the studied period when Japan is theorized to deploy PV using a closed manufacturing model with a deployment focus vs. the States' using an open and diversity or information technology approach. More detailed analysis can derive the learning rates of the respective system cost curves with respect to cumulative installation in the grid-connected residential category. We utilized the following cost dynamics formulation for our analysis: c t\u00fe1 \u00bc c 0 \u00bdv cuml;t\u00fe1 b , c t\u00fe1 \u00bc instantaneous system cost; v cuml;t\u00fe1 \u00bc cumulative installation up to time t \u00fe 1, b \u00bc learning rate; c 0 \u00bc constant: Our findings (more advanced analysis are available from authors upon request) are such that Japan sustains a learning rate, b, of 33.7% (adj. R 2 \u00bc 0:85) over the period 1993-2003 while that of the USA sustains a learning rate of 27.6% (adj. R 2 \u00bc 0:935) from 1994 to 2003. It must be noted that learning rate may depend upon a whole host of factors such as process and product innovations, product redesign and standardization. Our hypothesis in this paper is that this may be dependent upon the particular local model of PV deployment. This particular set of data seems to support that a closed manufacturing model of deployment sustains both a lower level of system [BOS] cost and a higher learning rate.",
            "The two PV development models-from an institutional standpoint": " It is the contention in this review that different models of deployment as elucidated in Section 2 would have most effects upon the PV BOS learning. A deployment strategy that focuses upon building installation base in a specific application category will expedite this local learning process of BOS and system engineering of this application, assuming a global cost learning dynamics for PV cell. This confers local (national) advantages and creates a virtuous cycle for the subsequent further development of the niche market. On the other hand, a strategy which deploys among several applications categories will sustain several BOS trajectories. This will spilt the learning investment among different categories and dramatically slows down the BOS learning process. The differences of these models can also be studied from a formal institutional perspective in the context of strategic niche management (SNM) approach for technical change. Since the manufacturing technology model focuses upon mass deployment of a niche, the choice of this initial niche, as we have elaborated in Section 2, is especially critical. What is a right niche? The next section proposes that the choice should take into account the degree of niche compatibility with the dimensions of incumbent regime. This compatibility can be measured in terms of magnitude of PV BOS cost.",
            "Niche compatibility in terms of magnitude of BOS cost": " The initial system engineering efforts for different niches or applications are different and can be measured in terms of the magnitude of respective BOS cost. For two different applications or niches, the higher the BOS cost, the more the customization is necessary and this may be due to the application's incompatibility with the existing electricity infrastructure. As Hegedus and Okubo (2004) have empirically demonstrated, BOS cost for off the grid system is much higher than that of on-grid since grid-tied systems do not need batteries or charge controller. In a gridconnected PV system, the grid acts like a battery with an unlimited storage capacity. Therefore, the total efficiency of a grid-connected PV system will be better than the efficiency of an off-grid system. There is virtually no limit to storage capacity whereas in off grid application, the batteries of the PV system will be sometimes fully loaded and excessive generated electricity cannot be utilized. Since Japan is almost entirely covered by the electric utilities, it was quite natural course to focus upon grid tied standardized residential system if large deployment of PV is the objective. In fact, the project-''utility-connected, residential applications mounted on roofs'' has been chosen as Japan's major target from an early stage of PV research and development (Kurokawa, 1994). Grid-connected residential PV system has a lower BOS cost and higher total efficiency to start with than other PV application categories and is the most compatible to the existing electricity infrastructure or the built environment. This therefore justifies that Japan's choice of this category for mass deployment, at least from a myopic point of view. However, the system-oriented BOS is also partially driven by the institutional environment rather than mere technical considerations. Institutions are the rules of the game in a society or, more formally, are the humanly devised constraints that shape human interaction. In consequence, they structure incentives in human exchange. General as this definition from North (1990) may be, he continues to propose that transaction costs are the most observable dimension of the institutional framework that underlines constraints in exchange. Transaction costs consist of those measurable costs that go through the market and those hard-to measure costs that include time acquiring information, queuing, bribery and so forth as well as the losses due to imperfect monitoring and enforcement. These hard-to-measure costs make it difficult to assess precisely the real transaction costs of conducting exchange from a particular institution. Nevertheless, to the degree we are able to measure, we progress in measuring and performing comparative analysis of the effectiveness of institutions. Connecting small scale PV system to the grid is subjected to safety [islanding], legal and other institutional requirements and this will have an impact upon the BOS cost or component counts. Different countries, through new legislative packages, facilitate deployment of grid-tied PV systems by standardizing interconnection protocols, net metering, no-hassle power purchase contracts from PV system owners. These actions strive to minimize the institutional impact upon BOS cost. It goes without saying that policies of some countries may be more ''institutions friendly'' than others to the grid tied small system category of application. This highlights that niche compatibility, in terms of BOS cost magnitude, is co-determined by inherent technical factors related to the built environment and actions in the institutional environment.",
            "Niche sustainability in terms of learning potential": " Having established the niche compatibility in terms of the BOS cost implications of different initial niches, it is further postulated here that the continual development of the initial niche depends upon BOS cost learning dynamics and is subjected to whether the chosen deployment model matches the institutional structure of production of each country. The learning drivers for PV BOS correspond to the specific barriers, related to system engineering, to widespread use of PV. These include (Ginn et al., 2003): specific technical problems related to balance-of-systems BOS components (such as inverters) and systems engineering, lack of standard approaches to interconnection to the utility grid, lack of awareness and experience with the technology by potential users, lack of sound data regarding field performance and true life-cycle costs, lack of certification (italics added) and unmet need for system quality assurance in installation and system management. In the Japanese deployment model of focusing upon the grid-tied PV residential application, since the application is homogenous, a standard approach to interconnection to the grid and a dominant design can be set up which avoids the highly customized engineering aspect associated with a lot of the off-grid applications due to unique on-site conditions. Deploying PV in the relatively standardized small grid-tied residential setting reduces it into a PV appliance subjected to mass production learning. A special feature of the institutional structure of production of the Japanese PV industry is that a few large and integrated companies bundle the whole or at least large portions of the PV value chain inside their own company. These may include solar cell, module (many solar cells combined together), BOS components such as inverters, power electronics and sometimes even the installation and maintenance of the PV systems are offered from the same company. Since the average life-time of a residential home is 25-35 years and corresponds well with that of solar modules, a lot of houses are prefabricated using standardized building components highly favorable for the integration of solar modules at the time of pre-fabrication. This advantage was immediately recognized by the solar cell manufacturers and the latter have either bought housing or construction companies or forged strategic with such companies (Jager-Waldau, 2004). There are several economic advantages to this development: (a) the locus of learning is within a company and can be internalized rather than involving many different independent players in the markets; (b) the pre-installation and mass fabrication of the unit home enable the manufacturer to limit actual installation work of the PV system on the building site to fine tuning or optimizing of system performance and lead to considerable savings for the installation aspect; (c) with respect to the BOS learning barriers mentioned, a large potential volume will sustain innovation efforts on continual improvement of components and system engineering. These innovation efforts will in turn be applied to future installation. This strong multiplier or rate (Arrow, 1999) effect is the basis of increasing return. Niche sustainability may ultimately depend upon this virtuous cycle of large volume drives innovation in BOS and innovation in BOS will drive ever larger potential volume. On the other hand, the current institutional structure of production in the USA PV industry consists mostly of small intermediary systems integrators and a very fragmented PV value chain. USA has consistently pursued a PV deployment policy of explorations of the high-value diverse markets (Serchuk and Singh, 1998). This alternative approach is contingent upon the advantage of characteristics of PV such as reliability and customizability. While allowing the self-propagation or information technology like characteristics of PV to play out, it requires the emergence of a new knowledge infrastructure to enhance cross-learning (Shum, 2003;Nagamatsu et al., 2004) or knowledge spillover among diverse PV customization applications. This cross learning will need to take place among systems integrators in critical areas such as systems engineering, maintenance, capitol formation or management. Cross learning leads to a dynamic economy of scope (Shum and Watanabe, 2004) to compensate for the foregone mass production economy of focusing upon a standard category of application. Due to the fragmented nature of the PV value chain, inter-projects learning among different market players will be more challenging than mass production learning within a vertical integrated structure. Even though training and certification of the system integrators or installers community in the USA is emerging (IEA PV status report, 2003) and will somewhat accelerate standardization of professional practices and learning, this will not happen immediately and the new institutional structure of production mediated by professional system integration or engineering practice will need time to co-evolve. From a niche sustainability point of view, one of a kind system may not have the volume to sustain disciplined learning and innovation among different market players. Instead of a volume driven virtuous cycle we have seen for a mass deployment strategy, a viscous cycle may emerge.",
            "Implications to learning investment in the experience curve framework": " These two separate institutional appraisals of the strategic niche management aspect can also be understood ",
            "Cost of technology": " The speed down the experience curve and the slope of the curve is dependent upon the compatibility and sustainability of the chosen niche A B C Fig. 6. An experience curve for the PV BOS cost for the grid tied small-scale residential PV system and conceptual illustration of effects of niche compatibility and sustainability. from the unified framework of experience curve for new technologies (Wene, 2000). Many such new technologies such as renewable are too expensive, at the outset, for commercial deployment. While publicly supported research and development are important, policy focus is also addressing measures to bring such technologies to the market. Experience curves suggest that to drive down cost for new technologies, financial investment is necessary. Learning investments are financial investments needed to ''buy the volume'' necessary for the ride down the experience curve in order to make the new technology cost competitive to the incumbent. Learning investments are primarily provided through market mechanism and they always involve different actors in the market and the socioeconomic system at-large and are therefore subjected to institutional factors. Fig. 6 illustrates the concept of learning investment, in the context of experience curve (IEA, 2003). Two quantities characterize the learning curve, the initial unlearned cost level4 and the slope of the experience curve related to the progress ratio. Learning investment is graphically shown as the triangle area (ABC) which will bring an emerging technology to the breakeven level. In the context of our discussion of the niche compatibility and sustainability in PV deployment in Japan and the USA, niche compatibility can be understood in terms of the level of the initial un-learned BOS cost to start with associated with the niche or application. As we have explained, this level is both contingent upon the application itself and the institutional actions or policies. On the other hand, the slope of the learning curve is dependent upon many factors including research and development, system innovation and design, etc. The niche sustainability, based upon a volume potential and match of learning requirements to existing institutional structure of production, will influence the slope of learning. The joint effects and synergy of having a lower level of cost to start with and a steep learning curve are decisive in terms of reducing the learning investment necessary (a smaller triangle in Fig. 5) and achieving the break-even cost level faster. Our empirical results in Section 3.3 seem to verify that a manufactured technology deployment model focusing upon a niche with large potential volume using a vertical integrated structure may show better BOS cost learning performance in the small grid tied system category compared to the information technology approach.",
            "Conclusion": " The incorporation of clean and benign renewable energy into our existing energy system will help to address both environmental and energy security concerns and is there-fore the focus on policy making in these respective areas. Yet, despite the potential of renewable energy, it faces many technical, market and non-technical barriers. No single effort will dominate in the introduction of renewable into the mainstream. But there is certainly a place government may play in facilitating research development, demonstration and deployment (PCAST, 1999) of renewable. Research development demonstration are relatively upstream efforts to address the scientific and technical aspects of renewable while deployment activities need to address downstream market, social and institutional aspects of the technology. This paper focused on the deployment aspect of introduction of PV. We have adopted a manufactured technology vs. information technology framework to aid our research. Our finding is that PV as a renewable energy technology is in essence a general-purpose energy technology that has potential applications in many areas and contexts. In this sense, PV is similar to a general-purpose information technology with numerous applications supporting different business models. However, deploying PV along many applications at the outset will hinder downstream and local oriented BOS learning especially when a learning infrastructure facilitating cross-learning among these applications (Shum, 2003) is not in place. In fact, due to the one off nature of many PV projects contingent upon unique site conditions, a lot of project specific system level knowledge is not easily transferable. In addition, different applications do not necessarily have a large volume of deployment to sustain a mass production type of efficiency thus rendering cost learning slower. A more prudent approach to deploy PV is therefore to leverage its characteristic as a manufactured technology which is less dependent on on-site customization engineering and which can be subjected to factory mass production learning economy. This depends upon focusing on a right niche that has massive potential volume to sustain learning and most compatible to the learning characteristic of existing institutional structure of production. The Japanese focus on grid-connected distributed small-wattage (3-5 KW) residential application in newly fabricated houses meets several criteria of niche compatibility and sustainability. In addition, the Japanese PV industry features PV companies that are highly vertically integrated which can facilitate learning in manufactured products in the areas of quality and durability. In a nutshell, the institutional characteristics in the Japanese PV industries match the production learning requirements for a manufactured model of deployment. An important topic that needs to be addressed is as more and more applications for PV are envisioned, how will the manufacturing model of PV deployment need to be adapted? There is a fundamental contradiction as less standardized applications are increasingly difficult to be addressed by a mass production logic or institution since they involve extensive on-site customization system engineering efforts. On the other hand, for an information technology model of deployment, the problem is how to standardize as much as possible and builds up volume for system engineering learning given the constraints of customization. Ongoing PV system engineering technology research to develop a general PV technology platform customizable to various applications, in additional to R&D at the individual component level, may hold the key to address these dilemmas."
        }
    },
    "10.1016/j.enpol.2009.04.007": {
        "file_name": "66 An innovation management approach for renewable energy deployment\u2014the case of solar photovoltaic (PV) technology",
        "title": "An innovation management approach for renewable energy deployment-the case of solar photovoltaic (PV) technology",
        "abstract": "\"Photovoltaic (PV) is a renewable energy technology, along side with other modular energy generation technologies such as micro-turbines, fuel cells, etc., which will enable the alternative distributed generation paradigm compared to the incumbent fossil fuel based centralized generation paradigm. Distributed generation utilizing renewable energy resources offers opportunities for significant carbon dioxide and emissions reductions thus contributing solutions to broader climate change issues. Yet, renewable energy technologies like PV face various barriers for their widespread adoption. Aside from technical and cost issues, renewable technologies have to overcome the so-called carbon lock-in effects. This refers to the techno-institutional complex associated with the fossil-fuel based centralized generation regime that currently dominates energy production and use. Governmental interventions to address these issues usually can be seen as composed of research, development, demonstration and deployment or RD3 [PCAST, 1999. Panel on International Cooperation in Energy Research, Development, Demonstration, and Deployment]. This paper focused on comparing the deployment aspect of PV technology in Japan and the USA. While both governments promoted PV as part of their larger strategies to address various environmental and energy security issues, Japan has built a PV installation capacity three times that of the USA as of December 2003 with over 90% of PV installation in the grid-connected small residential system category. This is in marked contrast to the case in the USA in which the cumulative installation is spilt among different types of applications involving the grid and off the grid.We put forward two models to explain these differences in deployment strategies and their possible consequences. The first deployment model leverages upon PV as a manufactured technology with minimal customization to achieve massive deployment. The second deployment model leverages upon PV as an information technology-like technology focusing upon user oriented customization to achieve deployment. Different models have different implications to the system engineering aspect of solar PV. A focus upon the standard grid-connected distributed category in the residential setting avoids the heavy customized engineering associated with many off-grid and one-off type projects. Japanese PV deployment strategy of concentrating upon a dominant category or niche with mass market potential also well matches the institutional structure of production [Coase, 1991. The Institutional Structure of Production, in Essays on Economics and Economists. The University of Chicago Press, Chicago] within the local PV technology suppliers industry. Major vertical integrated firms can facilitate system-related learning easier than a fragmented industry within the PV value chain with minimal transaction cost. This highly suggests that deployment strategy of PV or other renewable energy technologies must address the issues of adopting a globally \n developed technology to local (national) conditions and has strong institutional underpinnings in addition to financial subsidies, learning investment thinking.\" ",
        "label": "Mixed",
        "text": {
            "Introduction": " The strategic approach to the deployment of renewable energy aims to overcome several barriers commonly encountered by renewable energy projects. The underpinning objective of the strategic approach is predominantly economic, using up-front subsidies to finance learning investments that will drive down the costs of new technologies at the system level. Lower costs encourage more adoption, which sustains more learning. This dialectal reinforcing action loop between learning and installation is an important endogenous mechanism for the 'learning investment' argument (Neuhoff, 2004;Shum and Watanabe, 2007a, b). Strategic deployment programs must cover the differences between wholesale electricity prices and the costs of new technologies at the outset. The costs of renewable energy technologies are initially high, as they have not undergone improvements through market experience (both from the suppliers' learning curve and from user-driven experience). With increasing cumulative installation and market experience, the costs of new technologies are expected to fall. Strategic deployment accelerates the installation process and continues until the cost of a new renewable technology becomes competitive with conventional technology. This is the familiar 'learning-by-doing' effect. When the break-even point is reached, new technologies produce electricity below the costs of established technologies, resulting in savings through which the up-front subsidies can be recouped. The time to payback of these financial subsidies is influenced by the learning rate of the renewable technology and by the cost of conventional electricity, which is determined by the degree to which environmental effects are internalized. More refined arguments concerning the effective use of financial subsidies for learning investment center around the notion of 'learning-before-doing' (Shum and Watanabe, 2007a, b). The lower the system costs are at the outset, the more installation a given amount of financial subsidies can finance. This suggests targeted applications of financial subsidies to selected photovoltaic (PV) niche applications that are relatively least disruptive. Indeed, a global market for renewable energy technologies supports a mix of local financial policies, each tailored to local regulatory and technology circumstances, for the mainstreaming of renewable energy. There are in general two broad categories of such strategic financial policies: (1) those that aid installation of renewable energy equipment, and (2) those that support the market price of electricity derived from renewable sources and thus encourage the use of the installed equipment. For the purposes of this paper, we will briefly1 illustrate these policies with regard to gridconnected residential distributed PV systems in Japan and the United States.",
            "Policies that aid installation of equipment": " In Japan, up-front capital subsidies and tax deductions provide financial support for the initial investment in residential PV rooftop systems. The first program designed to stimulate the implementation of PV in Japan, the 'Monitoring Program for Residential PV systems,' lasted from 1994 to 1996 and was managed by the New Energy Foundation (NEF) on behalf of the Japanese Ministry for International Trade and Industry (MITI) (now known as the Ministry of Economy, Trade and Industry). This program subsidized 50% of the installation costs of residential PV systems. This led to a reduction in energy costs from 2 million f/kWp2 in 1994 to 1.2 million f/kWp in 1996. The annual budget of the program was relatively modest, increasing from 2 billion f in 1994 to 4.06 billion f in 1996. The number of installations per year increased from 539 to 1986 during this time. In 1997, the 'Program for the Development of the Infrastructure for the Introduction of Residential PV Systems' was launched, with a massive increase in subsidies. From 1997 to 2001, funding increased from 11.11 billion f to 23.5 billion f. Funding levels decreased slightly in 2002 and 2003. The national subsidies decreased from 340,000 f/kWp in 1997 to 90,000 f/kWp in 2003 and to 45,000 f/kWp in 2004. The average price of a PV residential system decreased from about 1 million f/kWp to 500,000-700,000 f/kWp. Price targets for the future range between 300,000 and 500,000 f/kWp and should be realized with the help of increased PV production and integration into buildings. In addition to national subsidies, handled by NEF, some local governments (more than 260 additional entities) add supplementary funds to a maximum of 40% of the total installation costs of PV systems. As a result, in FY 2003, the number of prefectures with more than 1000 PV installations per year increased from 16 to 22. The top ten prefectures in 2003 accounted for more than 43% of all cumulative residential photovoltaic installations. Importantly, the number of applications to install PV systems has increased steadily, in spite of decreasing subsidies (Fig. 1). A national support framework for residential PV systems was completed in 2005, and the market for residential PV systems has become self-supported. PV systems have been made standard equipment by major pre-fabricated housing manufacturers. Recently, PV systems have begun to be introduced to collective housing units. In the United States, policies that support renewable energy equipment installation come from public budgets for market stimulation, demonstrations and field tests and research and development. According to Poole et al. (2008), the federal budget for PV funds the Solar America Initiative (SAI), the goal of which is to accelerate widespread commercialization of clean solar energy technologies across the United States by 2015. The federal budget for PV research and development was approximately US$138.3 million for 2007, which is a US$78.3 million increase over that of 2006. Federal tax credits for the purchase of PV equipment went into effect in 2006 and included a 30% tax credit for residential grid-connected systems, with an annual system cap of US$2000. On the state level, more than 20 states have established clean energy funds that will collect more than US$6 billion in aggregate over the next decade through a small surcharge on retail electricity rates known as a 'system benefits charge'. Almost all No. of applicants in thousands Fig. 1. Despite decreasing subsidies for residential PV installation, the number of applications has increased in Japan (NEDO, 2004). state funds currently provide some form of support for customersited PV systems. Many funds have implemented 'buy-down' programs, under which funds are distributed as grants to subsidize the initial cost of a system.",
            "Policies that encourage the use of renewable energy equipment": " While government subsidies can serve as an incentive to install equipment, another set of policies are designed to encourage the actual use of the equipment for the production of renewable electricity. Some examples of such policies are described below.",
            "Renewable portfolio standards (RPS)": " RPS laws oblige electric power companies to expand the use of electricity generated from new and renewable energy sources. In Japan, the target minimum ratio of renewable energy usage in 2010 is 12,200 GWh, which accounts for 1.35% of new energy demand. The Ministry of Economy, Trade and Industry (METI) has taken special measures to double-count the electricity generated from PV as RPS electricity, which will strongly accelerate the expansion of PV use. In the United States, most of the states that revised their RPS portfolio (Fig. 2) in 2007 promoted solar technologies (Poole et al., 2008).",
            "Net metering": " Net metering contributes to electric power companies' meeting the renewable portfolio standards above. Electric power companies in Japan have consistently continued net billing since 1992, buying back surplus electricity generated by PV from their customers at the selling price of electricity across the country on a voluntary basis. This increases the incentive for customers to actually use the PV equipment to generate electricity. During FY 2006(April 2006to March 2007), the electric power companies purchased 654.7 TWh of surplus PV electricity. The volume of surplus electricity purchased has increased each year. In the United States, as of September 2007, 39 states had adopted statewide programs that established rules and net metering for compensating consumers who own grid-connected renewable energy systems. Net billing exists in states where net metering is allowed. However, the credit varies in each state, and is not necessarily equivalent to 100% kWh.",
            "Renewable energy certificates (RECs)": " RECs, also known as Green tags, renewable energy credits, or tradable renewable certificates, are tradable environmental commodities in the United States. One REC constitutes proof that one megawatt-hour (MWh) of electricity was generated from an eligible renewable energy source. These certificates can be sold and traded, and the owner of the REC can claim to have purchased renewable energy. RECs can encourage the use of renewable energy by providing a production subsidy or production tax credits for electricity generated from renewable sources. The energy associated with a REC is sold separately and is used by another party. The consumer who purchases a REC receives only a certificate. In states that have a REC program, a green energy provider (such as a wind farm) is credited with one REC for every 1000 kWh or 1 MWh of electricity it produces (for reference, an average residential customer consumes about 800 kWh in a month). A certifying agency gives each REC a unique identification number to make sure that it will not be double-counted. The renewable energy is fed into the electrical grid (by mandate), and the accompanying REC can then be sold on the open market. Most such subsidies finance installation at the system level and are targeted at users' purchasing decisions. The policy objective of this paper is to augment such blanket financial subsidies and/or market-based support policies with an innovation perspective for the deployment of solar photovoltaic technology. Solar photovoltaic technology, like most renewable energy technologies, is a decentralized technology to be installed in customer sites. It is not exactly a manufactured technology, 3 as an extensive amount of work must be done in the field. The deployment of solar PV depends upon a host of intermediary actors and input suppliers, the competencies and incentives of which influence the deployment process. The innovation perspective takes the entire set of players as a unit of analysis, in contrast to the financial perspective, which is focused upon the suppliers and users only. In turn, other players or stakeholders can potentially be targets of financial subsidies in order to expedite their learning. We therefore suggest an extended renewable  energy policy framework to study other potential targets for learning investment (Fig. 3).",
            "A primer on Innovation value-added chains": " According to Afuah and Bahram (1995, p. 56), the focus of most innovation literature has been on the impact of an innovation on the capabilities and assets of the innovator. For the innovator, the primary concern has been the impact of the innovation upon its organizational competence; i.e., whether the innovation enhances or decreases competence (Abernathy and Utterback, 1978;Tushman and Anderson, 1986) and whether the innovation is radical, incremental, architectural or modular (Henderson and Clark, 1990). Established firms are usually better at managing component innovation than architectural innovation, because effective firms often organize different groups of engineers that focus on different components. Communication channels between workgroups associated with different components are usually fixed, admitting only component-level changes. When architectural changes in the products are required, these innovator firms often fail to respond, because the organizational or information communication structure makes it difficult for them to handle new patterns of communication or partitioning of tasks. Christensen (1997) has studied a number of industries in depth, particularly focusing on hard disk drive manufacturers because they represent an industry in which several generations of dominant designs can be found within a relatively short history. With each generation, almost all of the previously successful players failed to make the transition effectively and were squeezed out of the market or into bankruptcy (Tidd et al., 2005). The reason was not these incumbent firms' failure to cope with technological breakthrough; indeed, all of the technologies involved in the new dominant design for each generation were well established, and many of them originated in the laboratories of the incumbent firms. Rather, the changes were due to the emergence of new markets with very different needs and expectations. In essence, the incumbent firms were too good at working with their mainstream users and failed to see the longerterm potential in the newly emerging markets. While these emerging markets appeared irrelevant to the mainstream players, their requirements determined what would become the new dominant design, with consensus gradually building up among users and suppliers (Geroski, 2003). As a new market grows and the technology involved in delivering the dominant design matures and becomes more reliable, it becomes able to meet not only the needs of the new markets but also those of the mainstream (original) markets. This is when market disruption emerges. A record of past success in following an existing dominant design shapes the signals that firms perceive about future opportunities and the ways in which they allocate resources. Riding along on one particular technological trajectory makes a firm vulnerable in or constrain its ability to jump on to the next one when it starts to emerge. The common practice of classifying innovations according to their impacts on the innovating entities' capabilities with reference to their existing technology and markets is not adequate  for technological innovations that require critical input components and equipment from suppliers, that depend on complementary innovations for success, and that require high levels of learning by customers and intermediary players. The hypercube of innovation model (Afuah and Bahram, 1995) generalizes a model of innovation by (1) formulating an innovation value chain consisting of the supplier, innovator, customer and complementary innovator of the (new) innovation under consideration, and (2) postulating how the same innovation can present itself differently, in terms of degree of novelty to different players in the innovation value chain. In an electric car, for example, the power train of a gasolinepowered automobile (the engine, transmission, fuel injection and exhaust system) is replaced by an electric motor, battery and electric motor controller. To suppliers of power train components, the shift to electric cars destroys much of their competence. To customers, however, the electric car is an incremental innovation, since drivers of gasoline-powered cars can retain their driving skills and other knowledge about operating a vehicle. On the other hand, the adoption of a more efficient computer keyboard (such as the DSK keyboard) will require customers to learn how to type all over again, abandoning the accumulated skills for using the QWERTY keyboard (David, 1985). (In historic and longitudinal terms, this accumulation is due to path dependency driven by the initial arbitrary adoption of the QWERTY keyboard and increasing returns to adoption.) Another disincentive to adopt the DSK keyboard is that QWERTY skills may be more valuable to customers, since most employers use QWERTY keyboards. The impact of an innovation on the capabilities and assets of the innovator's customers has very important implications for the market success of the innovator. An innovation that negates the acquired knowledge and built-up assets of customers may encounter greater resistance to adoption. A direct corollary is that for a given innovation, different formulation or deployment by the innovating entity may result in a different magnitude of disruption for players in the respective innovation value-added chains (see Fig. 4), and thus a different likelihood of the innovation being adopted. Alternatively, to the extent that an innovation may pose new learning challenges to players in the innovation value-added chain, the innovating entity can choose to deploy it in a manner that will make it easier for those players to acquire new competences and learning. In the case of renewable energy technologies such as solar photovoltaic systems for grid-tied small residential application, a simplified innovation value-added chain can be formulated. This IVC consists of suppliers of PV modules, inverters and other BOS components; complementary innovators such as utility owners; systems installers and integrators; and end users. Here, we compare the ways in which this innovation is deployed across Japan and the United States and its effects on the learning of a key player in the IVC, the system integrators.",
            "PV deployment patterns in Japan and the United States": " The cumulative installed PV base between December 1992 and December 2003 in Japan is shown in Fig. 5, while that of the United States is shown in Fig. 6 (all dimensions in kWh). Japan has accumulated an installed base three times that of the United States. In terms of the diversity of PV applications, approximately 90% of the Japanese cumulative installed base is in the gridconnected category, while the distribution of applications in the United States is more fragmented, with the same category constituting only about 30% of the installed base. By the end of December 2007, the cumulative PV power installed in Japan had reached 1918.9 MWp, with approximately 1823.24 MWp installed as grid-connected distributed energy (Ikki and Mastubara, 2008). This represents about 95% of the cumulative PV generation capacity in the nation. Of this, about 85% is installed as grid-connected residential PV systems or PV appliances. PV appliances are relatively standardized with minimal user-customization features for massive deployment, as shown in Fig. 7. They can therefore be regarded as manufactured technology, with suppliers controlling the product features and minimal on-site customization. The production economy is primarily driven by factory learning by doing. This is reinforced by the fact that several major housing manufacturers vertically integrate many of the intermediary steps to combine PV installation and system integration in their newly built houses, creating a new and homogenous PV appliance market. The combination of focused deployment by highly vertically integrated firms can be summarized as a closed model of PV deployment (Shum and Watanabe, 2007a, b). In terms of the suggested innovation value-added chain, the innovating entity in this context is the housing manufacturer that internalizes many of the roles in the IVC. Thus, the IVC can simplified to consist of only two players: the housing manufacturer and the end user. In the United States, the cumulative PV power installed by the end of 2007 reached 830.5 MWp, with approximately 465 MWp installed as grid-connected distributed energy Poole et al. (2008). The PV market is a conglomeration of regional markets and special applications for which PV offers the most costeffective solution. Until recently, the PV market has been dominated by off-grid applications, such as remote residential power, industrial applications, telecommunications infrastructure, highway and pipeline lighting or buoys (Jager-Waldau, 2004 4 ) and other applications in which grid extension is prohibitively expensive. Currently, PV deployment increasingly focuses on the gridconnected distributed category (both residential and commercial). Growth of the on-grid sector may be due to the growing popularity of state tax credits and rebates as well as federal 5 tax credits. However, for residential PV systems, this growth still lacks the uniformity of the Japanese PV appliance system and consists of mostly one-off customization projects. In addition, the United States PV industry consists mostly of small intermediary systems integrators and other component suppliers. The increased demand for grid-connected systems has prompted some component distributors to become full-service system installers, causing intensive competition and rendering the industry very fragmented compared to that of Japan. The combination of diverse applications and fragmented industry structure consisting of many independent systems integrators can be summarized as an open model of deployment (Shum and Watanabe, 2007a, b). In terms of the suggested innovation value-added chain, the innovating entity in this context is not clear, with a lack of overall coordination. The IVC for on-grid-connected residential PV systems consists of component suppliers, systems integrators and customization-driven end users.  4 PV status report 2004, European Commission. 5 For example, federal tax credits for the purchase of PV systems went into effect in 2006 and include a 30% investment tax credit for commercial on-grid systems and a 30% tax credit for residential on-grid systems with an annual cap of US$2000 per residential system.",
            "Characterization of the closed and open models of PV deployment": " Previous research (Shum and Watanabe, 2007b) has shown that the diffusion patterns of PV appliances are different under open and closed deployment contexts. PV appliances in Japan diffuse as a manufactured technology, closely fitting a simple logistic growth equation. PV appliances in the United States, on the other hand, diffuse in a complex pattern6 (Davies, 1979) due to their customization-driven nature and require continual institutional co-evolution. Thus, as expected, the rate of diffusion in the category of small PV appliances is faster in than in the United States (Watanabe and Zhu, 2002). Increasing industry standardization in systems technology and training of system installers will help the open deployment model to support an economy of systems integration and customization (Shum and Watanabe, 2008), due to local inter-project spillover or crosslearning. Another way to characterize the differences between the open and closed models is through examination of dynamic learning behavior in the PV appliance systems integration costs. As described above, systems integration in the closed model of deployment is performed within vertically integrated housing manufacturing firms that are the innovating entities in the IVC, with minimal participation of third-party systems integrators. On the other hand, systems integration in the open model is performed in the context of a much more distributed learning system made up of independent installers and integrators. The IVC is less integrated with no apparent innovating entity coordinates and internalizes the learning. We here attempt to determine how learning effectiveness differs in the context of such learning system differences. Drawing upon the system price data for small residential grid-connected PV systems from the International Energy Agency (IEA, 2004), we assume that these prices can serve as a proxy of system costs. If we further subtract the module costs from the system costs, we obtain the system integration costs. Our objective is to determine the learning behaviors of system integration costs. Based on a conventional model of learning by doing with a time-varying learning coefficient, we estimate the following cost dynamic formulation: c t \u00bc c 0 \u00bdv cuml;t l\u00f0t\u00de where c t is the instantaneous system integration cost per watt, v cuml,t is the cumulative installed base up to time t and \u00c0l(t) is the time-varying learning coefficient. Letting 7 l(t) \u00bc a 1 +a 2 t+a 3 t 2 and taking the natural logarithm, we therefore have ln c t \u00bc ln c 0 \u00fe l\u00f0t\u00de ln\u00f0v cuml;t \u00de ln c t \u00bc ln c 0 \u00fe \u00f0a 1 \u00fe a 2 t \u00fe a 3 t 2 \u00de ln v cuml;t ln c t \u00bc ln c 0 \u00fe a 1 ln v cuml;t \u00fe a 2 t ln v cuml;t \u00fe a 3 t 2 ln v cuml;t Rewriting this, let ln c 0 \u00bc a 0 ln v cuml;t \u00bc z 1;t t ln v cuml;t \u00bc z 2;t t 2 ln v cuml;t \u00bc z 3;t ln c t \u00bc a 0 \u00fe a 1 z 1;t \u00fe a 2 z 2;t \u00fe a 3 z 3;t",
            "Japan": " Data for Japan are shown in Table 1. The regression equation determined using backward elimination is as follows: ln c t \u00bc 8:96 \u00f046:63\u00de \u00c0 3:60 \u00c2 10 \u00c02 z 2;t \u00f0\u00c09:44\u00de \u00fe 1:80 \u00c2 10 \u00c03 z 3;t \u00f06:62\u00de adj:R 2 \u00bc 0:956 DW \u00bc 1:10 The dynamic learning coefficient for the case of Japan therefore has the form of l \u00bc 0:036t \u00c0 0:0018t 2",
            "Discussion and conclusion": " Policies for the deployment of renewable energy still consist mostly of the use of financial subsidies, such as grants, investment and tax credits, to subsidize the installation of equipment. Subsidies can be seen as 'learning investments' to expedite the volume-driven cost learning process. To the extent that such learning effects are internalized and reflected in future lower costs of the technology, such learning investments can be recouped through future cost savings. Another key policy initiative is to encourage the actual use of the renewable energy technology via renewable portfolio standards, net metering, RECs, etc. These policies, however, remain top-down and aggregate in nature and are targeted mainly to end users, without considering or taking advantage of the innovation dynamics of the renewable energy technology under consideration. We have introduced herein an alternative way to explore and manage the deployment process, which is to formulate an innovation value-added chain for the renewable energy technology. An IVC broadens the perspective regarding the critical success factors for an innovation beyond those associated with the innovator or the innovating entity. The IVC framework suggests that suppliers, complementary innovators and customers all play critical roles in the deployment of a new technology. A technology that causes minimal disruption, does not destroy accumulated assets, and is competency enhancing for as many players as possible may have a higher chance of success than a technology that disrupts more players. There is also a prescriptive benefit to the IVC: if a technology can be deployed so as to cause minimal disruption and leverage existing players' strengths, then it may have a higher chance of being adopted. We have compared the deployment of solar photovoltaic renewable energy in the particular area of small grid-connected residential systems between Japan and the United States. We have proposed that the deployment patterns in these two nations can be understood as closed and open models, respectively. The closed model of Japan deploys this category of PV applications using a highly integrated innovation value-added chain with a clear entity playing the role of the innovator to internalize the system integration costs learning. Small grid-connected residential PV systems are deployed as a standardized manufactured product with minimal participation from The PV deployment  1993199419951996199719981999200020012002 Fig. 8 Fig. 8. Comparison of dynamic trends in system integration costs of PV appliances in Japan and the United States (1992)(1993)(1994)(1995)(1996)(1997)(1998)(1999)(2000)(2001)(2002) 1993 1994 1995 1996 1997 1998 1999 2000 2001 2002 = 0.004 t pattern in the United States is diversified into a number of applications using intermediary and independent third-party system installers and integrators. PV systems are typically deployed as customization projects (Shum and Watanabe, 2008). The innovation value-added chain is fragmented and lacks an innovator entity capable of coordinating all the discrete innovation steps. Our empirical analysis of the learning dynamics of the system integration costs for this category of PV applications across the two nations verifies that Japanese costs and learning effectiveness are higher but declining, and that those in the United States are initially much lower but are increasing due to the development of standards that facilitate inter-project learning (Davies and Hobday, 2005;Shum and Watanabe, 2008) among independent systems integrators.",
            "Future research directions": " Several possible future research directions suggested by our findings are discussed below.",
            "The role of the innovator": " From our comparative study, it is evident that the organization of the innovation value-added chain for small grid-connected PV systems in Japan and the United States differs in terms of the extent of integration and the role, or lack thereof, for the innovating entity. These differences are seen in the levels of system integration costs and of learning effectiveness. Future research can seek to determine what economic criteria influence which of the players within an IVC for renewable energy deployment should emerge as the innovator. This line of inquiry is consistent with the concept of a platform leader (Gawer and Cusumano, 2002) in many high-technology industries. The disproportionate influence of this class of innovators is reinforced by ( 1) what the innovators produce on their own and encourage others to produce; (2) technology (how much detail about product architecture or interface and design they disclose to outsiders); (3) alliances (how collaborative or competitive their relationships with those outsiders are); and ( 4) organization (what structures best balance subsequent external and internal conflicts). In Japan, housing developers serve as the platform leaders, since they integrate photovoltaic solar cells into building materials and internalize many of the system integration procedures during the construction of a house. There are no proprietary standards concerning the porting (Kodama, 2008) of solar cells into the building shingles and the integration of other components such as the controllers, inverter and battery. Since housing developers can massively produce standard housing integrated with PV, the suppliers of these other components follow suit and produce complementary inputs. The emergence of such platform leader in the IVC would facilitate an economy of scale in both the product (economy of scale) aspect and project (economy of scope via inter-projects learning) aspect of PV systems deployment.",
            "Smart PV and associated enabling technologies": " The above IVC is formulated for the installation and deployment processes of solar photovoltaic technology. It is necessary to think beyond the present to a future state in which PV systems will have become a widespread and integral part of the electricity supply (Frantzis et al., 2008). There are many technological developments underway meant to facilitate the integration of distributed energy resources (DER), including PV, into the utility grid. These include general-purpose technologies to resolve constraints on power generation and instability of the grid caused by massively clustered (Ikki and Mastubara, 2008) PV systems connected to the grid. These control technologies include analysis and evaluation of higher harmonics, analysis and evaluation of devices for mis-actuation of function to prevent islanding operation, etc. Other relevant technologies include distribution system automation, information communication technologies to address the intermittency of renewable energy sources, smart grids, etc. Specific ongoing projects related to 'smart PV' (PV systems retrofitted with Information Communications Technologies) include: (1) Developing information models for PV systems, including an object model, a service model, and a protocol to facilitate data exchange between PV systems, other distributed energy resources, and the utility distribution network. (2) Integrating these models and protocols into an open Utility Communication Architecture (UCA-DER, 10 Electricity Innovation Institute 11 2004). (3) Leveraging the above to allow different kinds of distributed energy resources to interact with all levels of the utility grid and with complementary input suppliers, such as database and content providers for energy transactions or services, leading to communications network-based commerce and business models for DERs. In addition to such systems technologies, other hardware-based technologies to improve the stand-alone capabilities of PV systems, such as electricity storage functions 12 and active gridcontrol technology using multi-functional inverters, are also under investigation. We conclude that in order for PV to be successfully integrated into the grid, many complementary advanced technologies must be put in place. Some players, such as utility owners, will exert disproportionate influence in this transition. The role of the utility owner as the innovator in the IVC cannot be underestimated, since most of the critical systems technologies needed to integrate DERs into the grid must be implemented using the distribution grid infrastructure. Under the scenario of full integration of PV into the grid, we expect business models to emerge with variations in system ownership, operation, control (Frantzis et al., 2008) and utility owners playing a key role. As a result, the IVC for making economic profits by operating PV will differ from the IVC for installation and deployment. The optimal innovator in these respective cases will also differ. Energy policy must anticipate such differences. One viable framework is to formulate this process as a 'two-staged PV deployment game' (Shum and Watanabe, 2006), with the first stage being PV deployment and installation and the second stage being ongoing operations with full integration into the grid. The optimal IVC organization across these two stages is one that is induced in reverse from the second stage to the first stage. This gives rise to a sub-game perfect solution to this two-staged game. Such evolutionary policies truly constitute a forward-looking and strategic policy for the deployment of PV and other renewable energy technologies."
        }
    },
    "10.1016/j.enpol.2014.02.018": {
        "file_name": "72 Lobbying the \u2018Energiewende\u2019. Assessing the effectiveness of strategies to promote the renewable energy business in Germany",
        "title": "Lobbying the 'Energiewende'. Assessing the effectiveness of strategies to promote the renewable energy business in Germany",
        "abstract": "The article examines the influence of renewable energy companies on the decision-making process related to the German energy transition. It identifies clusters of different lobbying activities and styles through in depth interviews with 20 stakeholders from policy-making and business. The research used Repertory Grid Technique in combination with HOMALS multivariate analysis. Its main findings are: First, although the big four electric utilities operating on the German energy market still possess wide influence, companies of renewable energy have developed from a niche into important players of the energy regime. Second, lobbies by the renewable energy sector are mainly aimed at the legislative framework, particularly on the Renewable Energy Sources Act and the feed-in-system. Third, interviewees identified 36 different lobby activities; the most effective ones are: \u2018Regular and personal maintenance of contact to politicians\u2019, \u2018Lobbying within an association\u2019, \u2018Knowledge development with correct information\u2019 and \u2018Top-down contacting of most powerful politicians\u2019. Fourth, the statistical analysis reveals clear distinctions between companies with regards to their lobby strategies which are evaluated differently by stakeholders. Finally, the article concludes that companies have a strong influence on political-decision making and \u2013 together with governmental actors \u2013 form a \u2018policy network\u2019 that strongly shapes the German energy transition.",
        "label": "Mixed",
        "text": {
            "Introduction": " For decades, Germany has been a forerunner in the development and application of renewable energy sources (RES). The country's support policies for RES have received positive attention worldwidethe feed-in tariff model, determined by the Renewable Energy Sources Act (\"EEG\") of 2000, has been adopted by more than two thirds of EU member states. The Act determines that every kilowatt-hour generated from renewable energy receives a fixed feed-in tariff and that network operators must feed in this electricity into the grid preferentially to the electricity generated by conventional sources. Moreover, renewable energy plant operators receive a 20 year guaranteed payment for their produced electricity (Erneuerbare-Energien-Gesetz (EEG), 2011). Amendments of the EEG are being made almost every year, supported by several other policy decisions favoring renewable energy. As a result of this governmental support, renewable energy technologies continuously increased their share in the German energy mix. By 2012, renewables contributed 12% to the total energy supply1 and 23% to electricity supply. 2 As for the latter, wind power by far contributes the largest share, followed by biomass, solar photovoltaic and hydro power. The adoption of the German Energy Concept aiming at generating 35% of the energy supply from renewables by 2020 and 80% by 2050 and the decision in 2011 to phase out nuclear power by 2022 has definitely accelerated the energy transition (Bundesministerium f\u00fcr Wirtschaft und Technologie (BMWi), 2010; 2011). Achieving the so called 'Energiewende' is a major issue in political decision-making and public discourse. Corporate business plays a critical role in the energy transition. Apart from its economic activities, the sector lobbies political decision-making, especially as regards the rate of feed-in tariffs. Not only companies focusing on renewable energy products have a stake in energy policy, but also the main electric utilities ('Big Four'), which control close to 90% of the electricity market: E.ON SE, RWE AG, EnBW Energie Baden-W\u00fcrttemberg AG and Vattenfall Europe AG. All economic stakeholders operating on the German energy market interact with the political system through lobbying. In general, lobbying relates to the activities of private interest groups to influence political decision-making, particularly governmental and legislative actors (Encyclopedia Britannica Inc, 2012). Much research has been done on lobbying in general and on a supranational level, particularly in the European Union (e.g. Kl\u00fcver, 2011;EU Insight, 2008;Gullberg, 2008;Beyers et al., 2008). Studies concerning lobby activities of the renewable energy sector are still a new research area. The German situation is particularly interesting in this respect, as the booming sector has gained prestige to such an extent that it may have become part of the energy regime rather than being a niche player as in many other countries (Kemp et al., 1998;Kemp, 1994). The role of German interest organizations' lobbying on German renewable energy legislation has been studied by Lauber andMez (2004, 2006), Jacobsson and Lauber (2006), Dagger (2009) and lastly by Ydersbond (2012). However, an extensive qualitative and quantitative study of explicit lobby strategies of different companies has not yet been published. This article reports on a study, which identifies and compares the various lobby strategies used by the German renewable energy sector and assesses their effectiveness. The study thereby employed Repertory Grid Technique, a research method that can be characterized as a bottom-up approach and allows for a combination of qualitative and quantitative analysis. Section 2 of the paper discusses the methodology and the research approach. Section 3 presents the qualitative interview findings. Section 4 presents the statistical analysis. Reflections on methodology can be found in Section 5. Section 6 discusses some implications for the German energy transition. Section 7 provides a summary and conclusion.",
            "Material and methods": "",
            "Repertory Grid Technique": " Repertory Grid Technique (RTG: Kelly 1955, Fransella et al., 2004;Diamond, 1982) assumes that every person (re)creates a personal construct system that helps to make sense of the world. People never affirm anything without simultaneously denying something. Constructs are therefore dichotomous, having one affirmative and one negative pole. Originally, Repertory Grid has been used in clinical settings. More recently, the method became applied in the field of policy analysis (Dunn et al. 1986;Dunn, 2001;Van de Kerkhof et al., 2009;Vasileiadou et al., 2013). Repertory Grid includes two main components, 'elements' and 'constructs': Elements are usually subjects or objects that people face in the world around them and recognize as more or less relevant for them. Constructs, on the other hand, reflect the distinctions that people make as to relate the elements to their personal, individual world (Fransella et al., 2004;Van de Kerkhof et al., 2009). The first step in RTG is the structured interview. Interviewees randomly select a triad of elements (usually presented on cards) and are then asked to specify the way in which two of the elements are similar and different from the third. Next, interviewees select the constructs that they consider most relevant for the topic at hand and rank all elements on this construct (e.g. from sustainable to unsustainable) on a x.point scale. This enables a statistical analysis of the findings using a method for multivariate analysis. This analysis delivers a so-called point cloud, which visualizes the distance between the elements as perceived by the interviewees. Clusters of elements refer to a network, in our case actors using similar lobby strategies. The meaning of the plot must be found by linking it to the qualitative interview findings. There are several arguments in support of this methodology. First, RTG is a bottom-up technique in that the interviewee is not steered by questioning (Dunn, 2001). 3 Second, the method requires only a limited number of interviews as to identify the full range of constructs among the interview sample. Normally, saturation of constructs is reached between 15 and 25 interviews, which means that new respondents are very unlikely to add new information (Dunn, 2001). Third, as the interviewees are recruited among the networks of actors immediately involved in the issue under consideration, in our case policy and business people who know lobbying from their own experience, the findings can be considered as to represent a valid measurement of the actual lobby strategies in use among actors in the renewable energy field. This claim is supported by expectation status theory (Berger et al., 1972(Berger et al., , 1977(Berger et al., , 1980;;Berger and Zelditch, 1985) and the reputational methodology in the measurement of power (e.g. Stokman et al. (2009)).",
            "Methodological approach in the research": " The methodological approach in this research consisted of five different steps: 1. Identification of elements (companies) 2. Selection of interviewees 3. Actual interviews 4. Qualitative analysis 5. Statistical analysis First, with the help of national experts4 fourteen companies were identified which serve as 'elements'. These fourteen include the 'Big Four'. A long list of companies merely focusing on renewables was identified by an internet search. Out of the many German and foreign companies operating in the areas of wind, solar, hydro, biomass and geothermal energy the 25 most successful in terms of total revenue per year and number of employees were selected (Hoppenstedt Firmendatenbank, 2012). Next, experts identified the 10 they considered most innovative and influential with respect to German energy policy. Unavoidably, companies with a core business in wind power and solar photovoltaic are overrepresented in the sample, whereas companies with a focus on hydropower, biomass and geothermal are somewhat underrepresented. This is due to the fact that wind and particularly solar companies have benefited most from the EEG and have managed to expand their businesses over the last years. Furthermore, they are usually more known among stakeholders than companies of hydro or bioenergy. Table 1 lists the fourteen companies that were included in the analysis. The company 'Andritz Hydro' (Table 1: 14) was unknown to almost all interviewees and was therefore excluded from the final analysis. As a second step, 20 interviewees were identified (see Table 2). The interviewees from business included company representatives involved in Public Affairs and Corporate Communication and representatives of business associations which serve as a 'common voice' of industry vis-a-vis politics. Interviewees from politics include energy spokespersons or their assistants from all five parties that were in 2012 present in the 'Bundestag'. Also, representatives of the Federal Ministry of Economics and Technology, the Federal Ministry for the Environment, Nature Conservation and Nuclear Safety and the Federal Network Agency were invited for an interview. Two interviewees relate to other organizations, an anti-lobby NGO and the German Energy Agency. 5The actual interviews were conducted in the period May-June 2012. Each interview took approximately 60 min. At the start some open questions were asked with respect to the interests that companies pursue in relation to their view on the potential of renewable energy. Then, the RTG was applied. The elements (names of the companies identified) were presented on cards. In different rounds (between five and seven), three cards were picked and the question asked: In what respect are two companies similar and different from the third company as regards their lobby strategy ? Next, when no new constructs came up anymore, the interviewees were asked to select the three constructs pointing to what they consider the most effective lobby strategies. They then ranked all 13 elements with respect to these constructs on a 10-point scale. As a last step, a qualitative and quantitative analysis were carried out. Part of the analysis was a check as to whether the interviews show a saturation of constructs (Section 5). As for the statistical analysis, we used HOMALS, a Multiple Correspondence Analysis suited for dealing with data on a nominal scale (De Leeuw and Mair, 2009;Meulmann and Heiser, 2010). The statistical analysis was carried out for the rankings of all elements on the constructs the interviewees identified as most relevant.",
            "Qualitative results": " Section 3.1 reports on the interests that the renewable sector in Germany has in common (open questions). Next, the section reports on the outcomes of the RTG interviews. The interviewees identified 36 constructs, listed in Table 3. These were structured into four categories 6 : In what way to lobby? (Section 3.2), Whom to lobby? (Section 3.3.), Styles of lobbying (Section 3.4) and Resources of different kinds (Section 3.5).",
            "Joint interests of the sector": " The joint interests of the sector all relate to profit maximization. First, companies focus their lobby on the feed-in tariffs. As the rate of tariffs is frequently amended, each company aims at the highest tariff for their customers who receive the feed-in tariffs. Second, companies disapprove of frequent changes within the EEG. A long term time horizon of 20 years would provide stable market conditions. As one interviewee put it: \"The EEG is our business model\". Third, a few business interviewees claim that the subsidy system cannot last and companies must become independent from government support. Although many interviewees tend to agree on this, only a few companies actually behave according to this vision. Policy makers stated that no company included in the analysis has lobbied so far for market independence and the end of subsidies (I1, I11).",
            "In what way to lobby (C1, 2, 5, 6, 7, 9, 10, 11, 12, 15, 22, 23, 26, 32, 34)":" This category relates to all activities that are aimed at an (immediate) impact on German energy policy. Most frequently mentioned is continuous keeping in touch with political decision-makers (C1) for political stakeholders it is important to have a \"relationship of confidence\" (I2) with the lobbyist, being a person of integrity. One expert called this \"quiet diplomacy\" indicating that lobbyists should present themselves as  6 These categories are mainly introduced to allow for an encompassing report of the broad range of constructs elicited. It must be noticed though that any qualitative categorization of constructs carries an element of subjectivity and overlap cannot be avoided. Moreover, methods such as repertory grid technique confront the analyst with the fact that similar wording may express different meaning, whereas different wording may express similar meaning. Therefore, qualitative analysis must take into account the context in which specific constructs were elicited, i.e. the specific triads from the renewable business sample offered to the interviewee. diplomats of their companies with an appropriate behavior. In their contacts, lobbyists should look trustworthy and enable a constructive exchange of ideas and opinions. Personal contacts are important, because politicians \"do not want to feel lobbied\" (I1). Therefore, a personal network is considered critical for achieving the company's goals of lobbying. Traditionally, the Big Four possess a very extensive network and easily get appointments with members of parliament. Also companies of the renewable energy sector (juwi, Enercon and Vestas) have been successful in establishing personal networks. Interviewees emphasized that networking requires their presence in the proximity of political stakeholders (C7, 9). Most companies keep a representative office in Berlin where most of national political decision-making takes place. As an exception SolarWorld, a big player on the solar PV market, operates in Bonn, which as the former capital hosts the ministry of environment (BMU), responsible for the EEG. Companies that do not have financial resources to keep a representative office often hire external public affairs agencies that represent their interests. Political landscape management (C5) includes all activities of a company to establish and maintain close relations to political parties and their leaders. A common form of political landscape management is inviting politicians to visit production sites in order to connect them to their board of management. Companies or business associations organize political events where they meet with high level decision-makers. Within a week of parliamentary session, up to 10 different events can take place. These activities have a reciprocal benefit: Political stakeholders get up to date information and companies usually receive positive media coverage when a high level politician visits their production plants. A common form of landscape management is donations, either to support parties' election campaigns or individual politicians. In Germany, party donations beyond \u20ac 50,000 must be reported to the President of Parliament and are published subsequently; donations from \u20ac 10,000-\u20ac 50,000 need to be publicly accounted for by political parties. Interviewees confirm that party donations from companies operating in the field of renewable energy occur regularly but are not as publicly discussed as donations from other industry or banking companies. While in the past most donations were given to SPD and Gr\u00fcne, nowadays all parties may receive donations from the sector. After all, coalitions change regularly. Interviews and internet research indicate that the solar sector in particular has financially supported parties over the last years. Since they are quite common in Germany, donations are not accredited very influential, unless accompanied by other lobbying activities, continuous personal contacts with politicians in particular. Some interviewees indicated that donations can backfire to a company if they are too high and negatively perceived by the public. For one case an interviewee even used the term \"bribery\" (I20). Apart from personal networks, the most common way of representing business interests is through an industry association (C2). Usually, associations follow internal democratic procedures before publishing official statements for policy makers. This process was described as 'finding the least common denominator' Trying to impose decisions Not trying to impose decisions 1 34. Focus on various topics Focus on topic \"100% renewable\" 1 35. High credibility of company within energy transition Low credibility of company within energy transition 1 36. Knowing the right time to contact Not knowing the right time to contact 1 N a \u00bcnumber of people who mentioned the construct. N C \u00bc number of construct. as all companies need to agree on a common interest. Interviewees perceive associations differently. On the one hand, policy makers value their importance as they represent the entire sector rather than a single company, thereby increasing companies\u00b4influence and the credibility of policy decisions. An MP referred to the role of associations as \"a mediator between companies and politics\" (I17). On the other hand, associations cannot provide more specific information than a company. Instead, by representing the least common denominator of interests, concerns of individual companies become less visible. Consequently, many political stakeholders prefer talking to associations and different companies simultaneously in order to get 'the whole picture'. Critical in effective lobbying is offering usable information (C 6, 10, 11, 12, 15, 23, 26, 32, 34). Policy makers emphasized that they are not interested in a \"mere promotion of the company\" (I1). It is crucial that the information provided by the company is correct. By providing false information a company would significantly harm itself, raising skepticism and mistrust. Respondents also consider companies more credible if they look beyond their own borders and take (future) challenges for the energy system into account. Policy makers prefer companies that communicate a holistic vision on the energy system rather than only RES related interests, who manage to present the sector's interest as a German national interest and take, where possible, the international (EU) context into account. An example mentioned relates to system integration of renewables through necessary grid extensions. Deep lobbing relates to the process that shapes the intellectual atmosphere around a decision-making agenda (Wallace-Wells, 2003). Think tanks play a role in influencing politics through publications or subliminal messages. Especially the Big Four regularly commission studies. These often emphasize the high costs of solar PV whereas studies commissioned by the wind, solar or biomass sectors highlight the benefits of each RES source. Some interviewees put forward that scientific publications do have an influence on political stakeholders and are cited in political statements. Though the scientific correctness can hardly be denied, these studies reflect interests of (part of) the business sector. Part of deep lobbying is to establish close relations to journalists and the media. Media involvement with certain companies is considered common practice, but some express concern that journalists may lose their critical control function in a democracy. Knowledge development implies that solutions are framed in a technical manner. In official statements, companies may chose such wording that these could serve as a draft policy decision. Some companies even suggest exact formulations or draft an entire law that decision-makers can readily adopt. Some policy makers mentioned that if they appreciate the contents, they may forward the company's proposal to the next higher decision-level. It was also mentioned that ministers sometimes even prefer information provided by the companies over information provided by their own ministries. (C3, 14, 17, 20 and 21) Lobbying political decision-makers can be done either topdown, bottom-up or a combination of both. Top-down lobbying refers to tackling the most powerful decision-makers, i.e. the chancellor, the responsible ministers and the chairs of parliamentary committees. Only a few companies are able to use these channels of communication due to their longtime position in the German energy market. In particular the Big Four play a critical role and are therefore always incorporated in key decisions concerning the energy market. Their CEOs have a personal relation to the chancellor and are capable of using it 'at the right moment'. At government energy summits, the Big Four are important participants. Next to the chancellor and ministers, companies, the Big Four in particular, establish personal contacts with Ministries' Division Heads. SolarWorld is the only player of the renewable energy sector that has established close links to the ministries as well. This is mainly an effect of their geographical proximity to the BMU in Bonn and the performance of its CEO.",
            "Whom to lobby": " Companies who are unable to establish personal relations with the upper-level follow a bottom-up approach in that they focus on MPs or the working level of ministries. Tackling as many politicians as possible is considered most effective. Companies especially concentrate on the (scientific) assistants of politicians, who take a position as gatekeepers in processing requests and information. Respondents stressed the relevance of knowing the 'right people' to contact and of companies' ability to interact with opponents in a constructive manner. Although all political parties support RES now days, there are still differences. Traditionally, SPD and Gr\u00fcne show a preference for solar PV, which is explained by the fact that these politicians predominantly come from urban areas, whereas many politicians from the CDU/CSU are from rural areas and, hence, are more supportive of biomass-based solutions. (C4, 18, 19, 25, 27, 30, 31, 33, 35) Lobbying style refers to three dimensions, (1) mobilizing of media and public, (2) the level of antagonism employed and (3) companies' ability with respect to professional lobbying.",
            "Style of lobbying": " Advertisements in newspapers and magazines, television spots or banner ads in football stadiums serve a twofold aim. First, they may increase public acceptance of renewable energy and prevent a 'NIMBY' ('Not in my backyard') response in case of e.g. large grid extension projects. Second, political decision-makers are \"very susceptible\" for and \"highly influenced\" by the voters' will (I3, I19, I20), because they are dependent on public support for their re-election. Interviewees evaluate public relations campaigns differently. Whereas some acknowledge their positive impact on public acceptance and political decisions, others refer to possible negative impacts: heavy attacks on political decision-makers may backfire on the companies involved in the campaign. A specific case of public mobilization is 'astroturphing' (Beder, 1998), the creation of a citizens or expert group by a company to publicly promote the interests of this company. In the one example mentioned, a big utility hired a public relations firm to \"create\" a citizens group as to publicly convey the company\u00b4s message. The interviews reveal two distinct styles of lobbying, an aggressive and partly arrogant style and one described as friendly, constructive and down-to-earth. An example mentioned frequently relates to SolarWorld, which is known because of its aggressive lobbying style and controversial public campaign through which politicians who did not support the company's interests were labeled as 'climate killers', unable of sustainable thinking. Hence, SolarWorld manages to get a lot of (positive) public attention, but it does not have a good reputation as a lobbyist among politicians. The Big Four, especially RWE and E.ON, were mentioned as having an arrogant attitude and being a 'knowit-all'. Arrogant and aggressive lobbying is also related to providing false information, e.g. through presenting disaster scenarios. Threatening with disaster is generally not well perceived by the lobbied people as it often turns out to be false. The solar sector and the Big Four are named in this respect. Until recently, the renewable energy sector contrasted itself strongly from the Big Four thereby exploiting the 'good guys-bad guys' dichotomy. Although this distinction is still used in public campaigns, today the positions of the renewable sector and the Big Four are closer than in the past. Hence, most companies included in the analysis are described as pursuing a constructive way of lobbying, appearing friendly and serious. They have a relaxed, but also intensive personal relation to MPs. These companies claim to present the interests of the whole sector rather than the company's. Furthermore, they are capable of accepting hints from politicians regarding energy related issues. Enercon, juwi, Q.Cells and Schott Solar have been mentioned as firms pursuing this kind of attitude. Some companies are represented by specialists with competent knowledge on energy related issues. Whereas some described technical expertise as positive because knowledge transfer can be ensured, others noted that this type of lobbyists might not fully comprehend the political process. The other type lobbyists are characterized as all-rounders, 'professional lobbyists' knowing how to influence and persuade people. When needed, they add an internal technical expert to a conversation with an MP or a ministry employee. Such a highly professional form of lobbying is especially conducted by the Big Four. 3.5. Resources (C8,13,24,28,36) Obviously, the abilities of a company to work with professional lobbyists largely depends on their resources. As far as finances are concerned, there are huge differences between on the one hand the Big Four and, on the other, relatively small renewable companies in biomass-related activities. The Big Four are mentioned capable of recruiting professional lobbyists, often former politicians and high level civil servants. These are able to communicate the message to the right person at the right point in time, which is highly appreciated by policy makers with a busy time schedule. Politicians also prefer talking to a company with a concrete topic who is able to clarify its interest. As one interviewee put it: MPs need to know \"what they can do for the company\" (I1).",
            "Quantitative results": "",
            "Most effective lobby strategies": " After having identified the full range of constructs, interviewees selected the three constructs related to what they considered the most effective (aspect of) a lobbying strategy. Out of 36 unique constructs, 21 were selected and ranked for all elements, which provided the input for the quantitative analysis. Fig. 1 shows the complete range of 21 most effective lobby strategies. Mentioned by 13 out of 20 interview partners, 'Having a regular and personal contact to politicians' is considered most effective. Seven experts named 'Knowledge development with correct information'. Apart from these two, respondents had rather different thoughts of the most effective ways of influencing politics: ten most effective strategies were only mentioned by one interviewee.",
            "Statistical analysis and its interpretation": " Fig. 2 presents the HOMALS analysis for the 13 companies in a two dimensional plot. The plot reflects a complex relationship between different constructs, all referring to specific features that make companies more or less different and similar as regards their lobby strategy. Interpretation requires to look into both the statistical analysis and the qualitative data. Two procedures are followed below. First, we look into the meanings of the axes, as the meaning of the X and Y axes is not given by the statistical analysis itself. 7 Then, we look into the company clusters.",
            "The axes": " For defining the axes we look into the discrimination measures for the 50 rankings produced by 17 interviewees. Constructs that score (relatively) high on dimension 1 and low on dimension 2, have explanatory value for the X axis. Three items appear salient (representing 11 out of the 21 construct rankings). The Big Four on the left have a convincing score where it comes to 'top-down contacting', including a direct line to ministers and the Bundes Chanceller, whereas actors in the right quadrants tend to focus on bottom-up contacting (1 ranking). Four rankings that appear decisive for the distribution of actors over the X axes relate to the item 'Regular and personal contacts with politicians'. The more an actor is situated on the right, its contacts with politicians may be of a less regular and personal nature, in particular as regards the highest level of decision-makers (3 rankings). A construct also put under this category is a company's ability to arrange appointments with many different MPs (left column) as opposed to 'contacting specific people only' (right column). The more on the left, companies organize and attend many political events and seek other forms of publicity (2 rankings). In conclusion, the X-axis visualizes companies' (dis)advantage in lobbying in so far it depends on abundant (financial) resources to invest time and high quality personnel in lobbying. The renewable companies haveto a varying degreeless resources than the Big Four. They compensate by inviting politicians to visit their companies. A last item relates to companies' credibility and willingness to assist decision-makers with reliable technical information (3 rankings). For the respondents who ranked the companies on these constructs, the renewable parties on the right are generally more credible than the Big Four on the left. The renewable companies are considered more successful in offering technical expertise and 'competent and factual knowledge transfer'. However, the interview findings indicate that respondents are in disagreement with respect to the competence and credibility of companies and that their statements may depend on their own position in the transition debate. The same is true where it comes to a company's ability of self-criticism (1 ranking) The Y-axis can be understood through identifying rankings that show a low score on dimension 1 and a (relatively) high score on dimension 2. However, the Y-axis appears to have less explanatory value for the differences between companies' lobbying strategies, since 9 out of the 13 companies get about a similar ranking. This axis is interesting because of the deviant position of the two solar companies on top and the two bio-energy related companies on the bottom. There are four items that may help to interpret the Yaxis (representing 6 out of 21 constructs). In part, they overlap with the items that constitute the X-axis. Companies on top tend to be better in managing regular and personal contacts with (high level) politicians (2 rankings). Yet, the majority of the renewable energy companies most active in lobbying (Fig. 3, on top) do not 7 The X and Y axes are not a necessary part of the plot. They can be included but rotation is also possible. have an immediate line to ministers and the German Chancellor, but focus on specific MPs and high level civil servants, whereas the companies at the bottom tend to lobby through 'contacting anyone unspecifically' (1 ranking). A second distinctive feature of this axis relates to the organization of lobbying using a well elaborated strategy. Companies in the upper quadrants are supposed 'to know the right target group', whereas companies in the lower segment have less knowledge with respect to their target group (1 ranking). The companies in the upper quadrants (the Big Four as well as most RES companies) are also recognized as active participants within an association, whereas the companies in the lower quadrant, in spite of association membership, are considered to operate more on an individual basis (1 ranking). Furthermore, the companies on top are considered more effective in mobilizing the public through PR (1 ranking). Finally, it may be concluded with caution that the higher a company is positioned in the plot, the more effective they are in 'trying to impose decisions' (1 ranking). In conclusion, as the X axis, the Y-axis also appears to relate effective lobbying to companies' resources, but now it is companies' exposure that counts.",
            "The clusters": " In order to look into the different clusters, we look into what respondents have specifically said about what makes the companies in the clusters similar and different from companies in other clusters.",
            "Cluster the Big Four": " The Big Four are concerned with an overall development of the fossil based energy system, pursuing interests different from the companies merely focusing on RES. The Big Four score high on the ranking 'Having regular and personal contacts to politicians' due to their longtime lobbying history. They possess the right \"channels\" and know exactly whom, when and in what way to contact. These companies have the privilege to personally contact the most powerful decision-makers such as the chancellor or ministers. They spend such high sums on lobbying that allow them to operate representative offices in Berlin, employ many lobbyists and organize well attended political events. E.ON (1) is located farthest to the left which confirms that this company scores best on 'Top-down contacting'. Interviewees referred to the \"highly professionalized way of lobbying\" (I1) which is, however, occasionally not as \"relaxed and personal\" as several renewable energy companies. RWE (2) follows the same approach as E.ON and possesses longtime contacts to MPs and ministries which were particularly used by its former long-time CEO. EnBW (3) is located slightly more above which may indicate that, due to its regional bonds with the state of Baden-W\u00fcrttemberg, the company is regarded more \"down-to earth\" (I7) and is positively perceived by the public. Vattenfall ( 4) is positioned lowest from all of the four companies. Following the same lobby approach as E.ON, EnBW and RWE, and operating on the German energy market for ten years, Vattenfall is still considered as \"the Swedish enterprise\" with a little less influence than the three traditionally German electric utilities.",
            "Cluster SolarWorld and First Solar": " The upper right quadrant shows two clusters. On top there are two solar PV producing companies closely together, Solar World and the American First Solar. These companies strongly demand a continuation of feed-in tariffs for solar PV and oppose any reduction. Taking into account the German market with falling tariffs and Asian markets with lower production costs, First Solar decided to cease manufacturing in Germany in 2012. SolarWorld is peculiar in various ways. It pursues 'high pressure lobbying' through media and public relations campaigns that some interview partners criticized as \"aggressive\", in one case referring to personal attacks on politicians (I9). Politicians who support the interests of SolarWorld are being supported by the company through financial donations in election campaigns (I20). It is also peculiar in that the company rarely seeks agreements with other companies from the solar sector (I4). It focuses on close connections with the environment ministry in Bonn and regional decision-makers and has less high level relationships with the Economics ministry in Berlin. Moreover, the company prefers to conduct its lobby activities mainly through the work of its dominant CEO and a few lobbyists.",
            "Cluster renewables mixed": " Lower in the same quadrant is a cluster of four RES companies with wind turbine producer Enercon closest to the centre and solar PV producer Q-cells somewhat closer to the top. Q.Cells, which recently went over in Korean hands, is one of the biggest and well-known solar companies in Germany. Enercon (11) and Vestas (10) are among the biggest manufacturers of wind turbines, whereas juwi (8), as a project engineer and developer, combines all sectors of renewable energy in its portfolio. The positions close to the centre (and to the Big Four on the left) of juwi and Enercon may be explained as a result of their high market share and company size which provides them with more financial resources to influence politics. The companies in this cluster are being described as having a positive and friendly attitude, even an ability of self-criticism, and following a 'quiet diplomacy' approach. They engage in regular networking, in particular through organizing and visiting political events and offer their expertise and exclusive information to political stakeholders. They are also aware of the importance of scientific assistants of MPs. The solar companies, Q. Cells (7) and Schott Solar (9), mainly lobby with their associations and try to benefit from frequent and personal contacts to political decision-making, especially local politicians. They do not spend as many financial resources on lobbying as the Big Four or Solar-World. In general, the way of lobbying of companies in this cluster is considered the 'mainstream' way of lobbying.",
            "Marginal players": " The bottom right quadrant depicts a form of lobbying which is less visible than lobby activities from companies positioned above. They follow a more passive lobby strategy and do not have the same opportunities to influence politics as the others. While agri. capital (13) develops and operates biogas plants, Viessmann ( 5) is traditionally a manufacturer of heating systems. Their business areas may explain their 'outside position' in the plot. Viessmann follows a distinct lobby approach by focusing on specific branch or topic lobbying: it concentrates its activities on a few though concrete issues. Moreover, it does not operate aggressively but rather \"reserved and conservative\" and establishes a strategic network of political partners (I9). Respondents familiar with the company have a positive impression with respect to its way of lobbying. However, Viessmann is quite unknown among the public. Agri.capital ( 13) is also publicly unknown. It cannot exert high influence as the sector of biomass does not have one strong association, but several pursuing different interests. Also, agri. capital received low to medium scores when it comes to 'Having regular and personal contact to politicians'. However, it must be noted that the ranking of agri.capital has many missing values due to the fact that many experts were not able to evaluate the lobby activities of the company. Out of 50 possible values, agri.capital only received 22 which certainly influences the analysis and its position in the plot. To conclude, the findings with respect to the clusters and axes largely reinforce each other. The left column on the X-axis shows a cluster with the Big Four fossil-based companies, having abundant resources available for regular and personal contacts with the highest level decision-makers. The right column includes companies with a core business in renewables, who do not have immediate access to the upper level decision-makers but generally manage to effectively compensate for this. The mixed cluster closest to the centre is appreciated because of their relaxed style of lobbying, even referred to as 'mainstream'. More on top of the Y-axis, companies follow a more aggressive approach, mobilizing the public and media in their attempts to counter the reduction of feed-in tariffs. The bio energy and heating companies in the lower right quadrant are less well organized and do not manage to get sufficient public attention.",
            "Reflections on methodology": " Repertory grid analysis inter alia claims that with a limited number of in depth interviews the full range of constructs relevant for understanding the variety of perspectives can be identified. In this research, the line of new constructs flattens out up to the point that new interviewees do not elicit new constructs. Fig. 3 depicts that in this case saturation was reached after about 15 interviews. In consequence, we are confident that no major issues are left out in this study. The fact that all interviewees are experts as well as personally involved in decision-making on the German energy transition, adds to the observation that the results of the study are likely to reflect the social and political reality with respect to the German renewable energy lobby. Yet, the methodology also brings to light that not all interviewees turned out familiar with all companies presented to them, which led to missing values in the ranking for the heat and bioenergy related actors (Fig. 2, down right quadrant). In fact, uncertainty among the interviewees as regards the features of these companies' lobbying strategies (less visible and less heard) may in part explain their marginal position in the plot.",
            "Discussion": " The methodological reflections above form the point of departure for highlighting four issues that, in our view, come out as most challenging with respect to the research findings and analyses presented. First, the findings and analysis that shape the plot in Fig. 2 can be understood as to reflect the current state of the German energy transition in the context of its main recent history. On the one hand, the big four fossil based companies still have a strong position in the energy regime. They have become active in renewables and therefore also benefit from the feed-in tariff system. In spite of their powerful lobby, they have lost terrain over the first decade of the 21st century. Since the 1950s they have received high subsidies for coal, which will be phased out by 2018 (Meyer et al., 2010). On the other hand, the renewable energy sector has received tremendous support through the EEG. More recently, their position has further been strengthened by the decision to phase out nuclear power in 2022. Whereas for many countries the renewable sector is considered a 'niche' struggling for power against a fossil based regime, for Germany this label looks inadequate for large parts of the renewable sector. The presence of a renewable cluster close to the centre in Fig. 2, may very well articulate their incorporation into the energy regime in which international utilities and the (inter)national renewable business balance each other. Within the renewable sector and notwithstanding the fact that geographically Germany might not be the ideal location, the solar PV business has taken most advantage of the financial support schemes, which were boosted by the government coalition of SPD and Gr\u00fcne (1998)(1999)(2000)(2001)(2002)(2003)(2004)(2005). The position of SolarWorld is exemplary in this respect. Although often labeled as \"aggressive\" and \"arrogant\", interviewees consider their lobby strategy quite effective. Whereas solar PV companies (high on the Y axis) have benefited most from the German financial schemes, the companies on bottom have, so far, benefited least. Also in this regard, the plot reflects the current state of the transition. At the same time, however, the plot also reflects specific uncertainties with respect to the (near) future of the energy transition. For SolarWorld it remains to be seen if it will be able to maintain its high political influence. Decisions to further decrease tariffs for solar PV and raising the importance of other renewable sources indicate a shift in political priorities. For this reason, First Solar (forming the solar cluster with Solar World in Fig. 2), has already closed down its German production units. The position of the companies on bottom, Viessmann and agri.capital, appears surrounded with even more uncertainties. Although apparently less effective in lobbying than most other renewable businesses, the interview findings do not indicate that their lobby strategy has been very different from companies in the centre. Some interviewees praise the way they communicate their knowledge and their ability of self-criticism. The main difference with other companies is that they are apparently less well organized in that their associations do not manage to move into the spotlight. As regards the future opportunities for Viessmann and agri.capital as to lobby themselves closer to the regime parties in the centre, the findings do not offer much of a clue either. We are left with the observation that they are in a position of disadvantage. At this point, a third issue must be raised. Interviewees agree that corporate business of renewable energy strongly influences political decision-making related to the German energy transition. Political decision-makers express the need for lobbying in order to acquire information and incorporate interests of affected stakeholders in their decisions. The great majority of interviewees (with as exceptions those representing the views of the left-wing party \"Die Linke\" and an anti-lobby NGO) perceive political lobbying as positive for democracy, as long as companies are honest. To carry this point a little further, interviewees active in politics argued for a \"relationship of confidence\" on a regular basis with companies as 'quiet diplomats'. In contrast they mentioned to dislike the 'feeling to be lobbied'. As politicians prefer regular rather than sporadic contacts to company lobbyists, companies that do not engage in lobby activities cannot \"enter\" the policy network, thus being often disregarded. The dominant vision on lobbying therefore may have as a consequence that lobbying fosters the status quo. Those who have benefitted most from the system have more resources available for this way of lobbying than parties who are at the fringe of the system. In this respect, lobbying may have implications similar to what has been referred to as the 'participation paradox' (Seley, 1983): participation may be aimed at considering views normally not taken into account, but benefits those who are already more able to promote their views and interests. Finally, notwithstanding the impressive results of the EEG and the feed-in tariff system for the German energy transition, there is an increasing awareness that the system has become expensive and in need of revision. Some interviewees ask companies to abstain from an approach of \"produce it and forget it\" (I12). Rather than to rely on politics they need to become more competitive by themselves. However, as politics has set the ambitious targets of a 30% by 2020 and an 80% by 2050 share of renewables in the energy supply, economic stakeholders expect politics to make it work. This may contribute to a situation, which fosters conservatism rather than innovation. This is especially a risk in case policy networks involve companies of renewable energy who already made it and deny access to innovative companies representing a niche (Hisschem\u00f6ller et al., 2006). Hence, the current practices of environmental lobbying in Germany may, in spite of their wide acceptance, pose a serious challenge.",
            "Conclusion and policy implications": " The decision of 2011 to fundamentally transform the German energy system was a political will. Although it is politics that took main responsibility for the success of the energy transition, electric utilities and the sector of renewable energy play a critical role in the process of implementation, providing technological and economic benefits on the one hand while pursuing their company interests on the other. This study reported on the activities of companies to influence the German energy transition. It identified and compared various lobby strategies in order to detect the most effective ones. Repertory Grid Technique in combination with HOMALS for multivariate analysis was chosen as a methodology that proved to be suitable for investigating the topic. As for the qualitative results, 36 different constructs of lobby strategies have been mentioned by the interviewees indicating a wide range of lobby activities in German politics. With regards to companies operating on the market of renewables, an effective lobby strategy ensures the inclusion of their interests in political decision-making. In order to influence political decision making, 'Having a regular and personal contact to politicians' is considered to be most effective for a company. Moreover, 'Knowledge development with correct information' and 'Lobbying within an association' contribute to an effective lobby approach of companies. It may be questioned why 'Establishing regular and personal contacts' is most effective and important to politicians. Usually, only companies with high financial resources can ensure these contacts. Interests of innovative companies, however, that might contribute to the energy transition with technological developments and business ideas, but refrain from investing in lobbying, will most likely not be considered by politicians. Political decisions are taken within policy networks that tend to institutionalize and hence, lead to conservatism and impair innovation. The findings of this study reflect the current state of the German energy transition. Through political support and continuous lobby activities, the sector of renewable energy does no longer represent a niche, but is incorporated in the German energy regime. At the same time, it remains to be seen what role the renewables sector will take in the progress of the energy transition. Challenges such as grid extension and higher electricity costs may lead to a shift in political priorities with less support for renewable energy sources."
        }
    },
    "10.1016/j.enpol.2015.06.003": {
        "file_name": "74 Synergies and trade-offs between governance and costs in electricity system transition",
        "title": "Synergies and trade-offs between governance and costs in electricity system transition",
        "abstract": "Affordability and costs of an energy transition are often viewed as the most influential drivers. Conversely, multi-level transitions theory argues that governance and the choices of key actors, such as energy companies, government and civil society, drive the transition, not only on the basis of costs. This paper combines the two approaches and presents a cost appraisal of the UK transition to a low-carbon electricity system under alternate governance logics. A novel approach is used that links qualitative governance narratives with quantitative transition pathways (electricity system scenarios) and their appraisal. The results contrast the dominant market-led transition pathway (Market Rules) with alternate pathways that have either stronger governmental control elements (Central Co-ordination), or bottom-up proactive engagement of civil society (Thousand Flowers).\u00a0Market Rules\u00a0has the lowest investment costs by 2050.\u00a0Central Co-ordination\u00a0is more likely to deliver the energy policy goals and possibly even a synergistic reduction in the total system costs, if policies can be enacted and maintained.\u00a0Thousand Flowers, which envisions wider participation of the society, comes at the expense of higher investment and total system costs. The paper closes with a discussion of the policy implications from cost drivers and the roles of market, government and society.",
        "label": "Mixed",
        "text": {
            "Introduction": " In 2008, the United Kingdom (UK) was the first G20 economy to adopt an ambitious, legally-binding target to reduce its greenhouse gas emissions from the energy sector by 80% in 2050, as compared to the levels of 1990. Multiple studies showed that this target could be achieved at least cost through an early transition to low-carbon electricity generation, which would then facilitate the electrification of heating and transport (Anandarajah et al., 2009;Ekins et al., 2011;Williams et al., 2012). The UK Department of Energy and Climate Change (2012) estimates that d110 billion of investment (US$170 billion) by 2020 is needed in the UK electricity generation, transmission and distribution system. Existing concerns about the costs and affordability of such a transition have been amplified by the global financial crisis in [2007][2008]. Such concerns play a significant role in UK's recent Electricity Market Reform (DECC, 2012). In particular, the levels of investment needed (and who will pay for them) are highly debated (DECC, 2014a;Ernst & Young, 2009;LSE, 2012;National Grid, 2013b;Ofgem, 2009Ofgem, , 2010)). In this context, this paper appraises the investment and total system costs of the UK transition to a low-carbon electricity system from 2010 to 2050. In a parallel track to this cost-focused debate, a multi-level perspective to socio-technical transitions has been developed. It focuses on governance and the choices of key system actors, such as electricity companies, government and civil society (Geels, 2002;Geels and Schot, 2007). The links between cost drivers and governance have been conceptually discussed. As compared to the state-governed electricity system, market rationale can improve the economic efficiency of the system and thus reduce the total system costs (Goldthau, 2012;Helm, 2003). Lately, market rationale has been challenged because it may not deliver high investment levels required for climate change mitigation and supply security (Bolton and Foxon, 2015;Goldthau, 2012). Even if the government could incentivize higher investment levels, this could increase the total system costs and feed back to affordability concerns. Such dynamic changes in governance have been retrospectively shown to substantially influence the energy system transition (Arapostathis et al., 2013;Pearson and Watson, 2011), but they have been barely analysed on quantitative basis. Existing studies on electricity system costs account for parametric uncertainties, such as economic growth and emission mitigation efforts (Ernst & Young, 2009;LSE, 2012;National Grid, 2013b;Ofgem, 2009Ofgem, , 2010)), deployment levels of specific technologies (Ernst & Young, 2009;Hara, 2014), and supply security requirements (Ernst & Young, 2009). However, limited efforts were dedicated to quantitative, modelling-based analysis of the role of governance. This paper primarily focuses on the implications of alternative governance pathways on the UK's electricity system transition and its costs. Quantitative modelling and cost appraisal of the electricity system transition under different governance pathways is a challenging task because our knowledge of governance is often of a conceptual and experiential nature (Hughes and Strachan, 2010;Pfenninger et al., 2014;Trutnevyte et al., 2014). For this reason, a story-and-simulation approach is appropriate (Alcamo, 2008;Schweizer and Kriegler, 2012;Swart et al., 2004;Trutnevyte et al., 2014;Trutnevyte et al., 2012). Qualitative governance narratives are linked with quantitative electricity system transition pathways (scenarios), and a cost appraisal is subsequently performed. Qualitative narratives allow for capturing the governance arrangements, decisions of the key actors and broader contextual developments that are often ignored in purely quantitative studies (Trutnevyte et al., 2014). Quantitative modelling and assessment allows for rigorous and internally consistent quantification of these narratives and their implications. The cost appraisal, presented in this paper, is part of the Realising Transition Pathways project, funded by the UK Engineering and Physical Sciences Research Council. In this project, an interdisciplinary research team from nine UK universities investigates what needs to be done to achieve the UK electricity system transition that successfully addresses the energy policy 'trilemma', i.e. simultaneous delivery of low-carbon, secure and affordable energy services. In the preceding Transition Pathways project three narratives of this UK transition under alternate governance logics were developed: Market Rules, Central Co-ordination and Thousand Flowers (Foxon, 2013;Foxon et al., 2010;Hammond and Pearson, 2013). The Market Rules narrative represents the market-dominated governance, where the choices of electricity companies that interact with the national policy framework shape the electricity system transition. The Central Co-ordination narrative assumes the dominant role of the national government in delivering the lowcarbon system. The Thousand Flowers narrative envisions civil society becoming the leading change agent through the deployment of bottom-up solutions. These three governance narratives have already been addressed from the perspectives of technical feasibility (Barnacle et al., 2013;Pudjianto et al., 2013), environmental impacts (Hammond et al., 2013;Hammond and O'Grady, 2013), supply security (Boston, 2013), and uncertainty and future branching points (Foxon et al., 2013;Hughes et al., 2013). In the project to date, the economic perspective has not been systematically considered using quantitative modelling approach and has only been discussed conceptually (Foxon, 2013;Hammond and Pearson, 2013). Thus, this paper adds this missing economic perspective to the Realising Transition Pathways project. In comparison to the other project's activities, this is the most comprehensive cost appraisal with the widest system boundaries (electricity generation, transmission and distribution, electric heating and transport, and cost savings due to replaced fossil fuel based heating and transport). Trutnevyte et al. (2014) present further efforts to combine eight technical feasibility, economic and environmental models to assess the Central Co-ordination narrative from a quantitative perspective beyond economics. Trutnevyte (2014) experiments with modelling of different electricity generation portfolios for the three governance narratives. But neither of the two latter studies appraises the costs of the narratives in such a detailed and broad manner. The paper is structured as follows: Section 2 describes the methodology and introduces the Realising Transition Pathways narratives; Section 3 summarises and discusses the cost appraisal results; Section 4 interprets the results in terms of the previous studies, discusses the limitations and identifies future research needs; and Section 5 concludes with policy insights from the contrast between cost appraisal versus governance approaches to analysing long-term electricity transitions.",
            "Methodology and the three governance narratives": " The analysis starts with the qualitative governance narratives that describe governance arrangements, choices of the key actors and the respective energy transitions (Section 2.1). Each qualitative narrative is then 'translated' into a quantitative electricity system transition pathway (Section 2.2). This pathway shows the detailed, technically-elaborated evolution of the electricity demand and supply, including the technology choices of electricity companies and consumers. The costs of the quantitative pathways -that are the representations of the qualitative governance narratives-are finally appraised and compared (Section 2.3).",
            "Governance narratives": " The three governance narratives, described in detail by the Transition Pathways (2012) and by Foxon (2013), define alternate UK transitions to a low-carbon electricity system, its governance arrangements and the choices of key system actors from 2010 to 2050. The narratives distinguish between three ideal-types of governance logics (Fig. 1): market logic in the Market Rules narrative, government logic in the Central Co-ordination narrative, and the civil society logic in the Thousand Flowers narrative. While these narratives picture the ideal-type governance logics, the UK electricity system governance in reality will likely be a hybrid of all these three logics with different strengths. Today's governance is argued to be a hybrid of the Market Rules and Central Co-ordination narratives (Bolton and Foxon, 2013;Goldthau, 2012).",
            "Market Rules narrative": " The Market Rules narrative envisions that market logic will dominate the UK electricity system transition. Large electricity companies and other market actors will deliver the transition, when freely interacting with the policy framework. This policy framework will set broad goals and implementation mechanisms, but otherwise will minimise its interference. In this narrative, a strong worldwide consensus on mitigating climate change and UK-wide concerns on supply security will lead to the focus on large-scale power plants with low or zero-carbon emissions, such as coal and gas with carbon capture and storage (CCS), nuclear, offshore and onshore wind. Small-scale technologies will not emerge in such a market. The large electricity companies will see the highly electrified energy system as a business opportunity and thus there will be a substantial increase in the use of electric heating and plug-in hybrid electric vehicles (PHEV). Consumers will play a passive role, with regards to voluntary energy demand reductions and deployment of small-scale generators. Carbon price floor, renewable obligations, capacity mechanisms and other policy instruments introduced by the government will determine the evolution of the system, but the investment context will be comparatively risky due to the high degree of freedom in the market.",
            "Central Co-ordination narrative": " The Central Co-ordination narrative envisions a greater direct role for the government, working closely with large electricity companies in delivering the aspired electricity system transition. After some progress and a moderate worldwide commitment in international climate negotiation, UK will step forward by establishing a Strategic Energy Agency. This agency will steer the electricity system transition towards the desirable generation portfolio by issuing contracts for 5-year tranches to specific types of power plants in order to reduce investment risk. These contracts will be used for large-scale generation, such as nuclear, offshore wind and coal with CCS, while small-scale electricity generators will receive agreements to purchase their excess electricity after 2038 only. The consumers will play a passive role, but the government will initiate major energy efficiency programmes to reduce demand by means that require little direct consumer engagement and increase the uptake of electric vehicles (EVs), PHEVs and electric heating. The evolution of the electricity system will thus be primarily determined by these central contracts for specific technologies.",
            "Thousand Flowers narrative": " The Thousand Flowers narrative envisions households, communities, local governments and non-governmental organisations to play an active role through local, bottom-up initiatives. Such transition is enabled through the matching UK policy framework that is less coupled to the international scene. The initial government feed-in tariffs for small-scale technologies will gradually put more pressure on energy companies to increase efficiency of their consumers. This will lead to the successful market entrance of energy service companies (ESCOs) and, to some extent, large electricity companies adopting the ESCO business model; the ESCO model is described in more detail by Pantaleo et al. (2014). As a result, there will be a substantial deployment of micro-and community-scale combined heat and power (CHP) plants, solar photovoltaic (PV) elements and onshore wind. Due to growing awareness of the climate change impacts, electricity consumers will voluntarily adopt various technological and behavioural enduse demand reduction measures, including EVs. Due to the success of these bottom-up initiatives, the ESCO model and the government support, the investment context will favour small-scale generation.",
            "Quantitative transition pathways": " Each narrative is 'translated' into a quantitative electricity system transition pathway (scenario). As these quantitative pathways are tightly linked to the qualitative narratives, they already include implications of governance and decisions of the key actors in terms of technology choices and electricity demand evolution. As described by Foxon (2013), the Transition Pathways Technical Elaboration Working Group iteratively developed these quantitative pathways by merging insights from two electricity supply models and one demand model (Barnacle et al., 2013;Barton et al., 2013;Robertson et al., 2012aRobertson et al., , 2012b)). In the typology of energy models (Bhattacharyya and Timilsina, 2010), these three models fall in the accounting framework category. One of the supply models had 1-h temporal resolution, while the other supply model and the demand model had 1-year resolution (Trutnevyte et al., 2014). They investigated only technical feasibility of the pathways and used predefined technology merit order, rather than assumptions on future costs, to model future transition. Every quantitative pathway describes complete portfolios of electricity supply and demand technologies, including annual electricity demand and its structure, installed power plant capacity, and generated and imported electricity flows until 2050, in 5-year intervals (Foxon, 2013). Fig. 2 depicts the structure of electricity demand and supply for the three narratives, including a detailed account of electric heating and transport as well as heat produced in CHP plants. All three pathways differ in their total electricity demand and its structure as well as in the electricity generation portfolio. In terms of the annual electricity demand, Market Rules has the highest electricity demand growth until 2050, which is primarily driven by growing industrial electricity demand. Market Rules also envisions a substantial uptake of electric resistive heating and heat pumps in domestic and commercial sectors as well as PHEV and EV, which leads to higher electricity demand. Central Co-ordination also assumes similar levels of electric heating and transport, but the industrial electricity demand stays roughly constant until 2050. Thousand Flowers has the lowest electricity demand of the three pathways because it assumes that energy consumers will adopt pro-environmental behaviours and invest in efficient energy use. Electric heating will not be adopted as widely in Thousand Flowers, but EVs would have the highest growth rate among the three pathways. As annual electricity demand and governance arrangements differ for the three pathways, the electricity generation portfolios differ too as described in Sections 2.1.1-2.1.3. All three pathways are assumed to meet the UK greenhouse gas emissions target by 2050, all coal and gas power plants that are unabated (without CCS) are assumed to phase out in all three pathways. Necessary additional detail for the cost appraisal is added to the quantitative transition pathways from Fig. 2. The retirement of existing capacity and the installation of new capacity are modelled on the basis of planned capacity retirement (DECC, 2010) and, otherwise, on the basis of capacity retirement rates and technical lifetimes of power plants. Lifetime extensions and retrofitting are not considered. The predefined quantitative pathways already assumed retirement of the existing nuclear power plants (Fig. 2). The UK coal power plant fleet is close to the end of its lifetime (DECC, 2010) and the substantial share of gas plants will be close to it too by the time, when CCS is assumed to get significantly deployed in the three pathways. The pathways are disaggregated into one-year steps from 2010 to 2050 so that existing capacity retirement year and lifetimes, which are not multipliers of 5, could be modelled more precisely. This enables capturing the investment dynamic better. In order to evaluate the costs of transmission and distribution, these infrastructure requirements are modelled with the Holistic Approach to Power System Optimisation model (HAPSO), described by Strbac et al. (2012). HAPSO is a bottom-up, cost-minimisation model that determines the optimal transmission and distribution network, storage and interconnection requirements and their costs. The model optimises simultaneously the longterm investment and short-term operating decisions from 2010 to 2050, including generation dispatch with one-hour resolution, demand side response, storage cycles and electricity import and export. As spatial distribution of electricity demand and generation drives the network expansion, the UK territory is divided into five regions: Scotland, north England and Wales (EW), Midlands, south EW, and London area. The UK electricity system is integrated in the European system that comprises the UK, Ireland and continental Europe. Thus, interconnectors between Scotland and Ireland, Scotland and Norway, Midlands and Ireland, south EW and continental Europe, and Ireland and continental Europe are considered. In order to model the infrastructure requirements of the three pathways, the quantitative electricity demand and generation assumptions from Fig. 2 are enforced in HAPSO and the results of investment costs for transmission and distribution are used in the cost appraisal. As HAPSO models the electricity exchange with the rest of Europe, HAPSO's assumptions of the EU wholesale electricity prices for the UK imports are used (Supplementary Material A).",
            "Cost appraisal methodology and its key assumptions": " This section describes the cost appraisal methodology, including the appraisal boundaries, method, key quantitative assumptions and sensitivity analysis.",
            "Boundaries and methodology": " Three governance narratives and their respective quantitative transition pathways depict the UK transition to a low-carbon electricity system from 2010 to 2050. As they describe changes in the electricity generation portfolio and in electricity demands, the cost appraisal primarily focuses on (i) large-scale electricity generation and storage, (ii) small-scale electricity generation, (iii) electricity transmission, distribution and interconnectors with Europe, (iv) electric heating and electric transport. As electric heating and transport provide different levels of energy services for space heating, hot water and transportation, it is necessary to account for these differences between the three pathways. It is thus calculated that energy services, provided by electric heaters, heat pumps, CHPs, lead to cost savings in the current conventional technology of gas boilers. The energy services, provided by electric transport (electric rail, electric buses, PHEVs and EVs), lead to cost savings in transportation with internal combustion engine (ICE). These cost savings are then deducted from the total costs. The cost appraisal includes investment costs, fixed and variable O&M costs, fuels costs, financing costs, and carbon price. Investment and O&M costs and the related assumptions are reported in Supplementary Material A. Fuel and financing costs are discussed in Section 2.3.2. Large-scale power plants are assumed to take part in an emission trading scheme. As all three pathways assume transition to a low-carbon system, carbon price (Table 1) is assumed equal to the carbon price floor, set by the Electricity Market Reform until 2030 (DECC, 2012), and afterwards equal to the central estimates by the UK Department of Energy and Climate Change (2011). The appraisal methodology is based on an accounting framework (Bhattacharyya and Timilsina, 2010) with one-year time resolution from 2010 to 2050. The present value approach is used for appraising the investment and total system costs, because it accounts for the investment costs, when they occur rather than annualises them throughout the lifetime. In order to evaluate the present value of costs, a social discount rate of 3.5% until 2040 and 3% afterwards is used (European Commission, 2008;HM Treasury, 2011). This paper also conducts a stylised comparison of the technology-specific costs and the whole generation mix costs per unit of electricity generated. This comparison is based on levelised costs of electricity (Short et al., 1995). The predefined quantitative pathways (Foxon, 2013) did not include detailed dispatch data within one year. Annual electricity generation levels are only enough to calculate levelised costs of electricity. Levelised costs do not capture the dynamics of electricity costs and prices due to dispatch effects and they blend investment and annual costs into one number that does not give any indication of investment attractiveness. Yet, levelised costs are still useful to compare technologies with different characteristics, such as investment and annual costs, lifetimes, generated electricity amounts etc. These costs are evaluated as total costs per discounted MWh of generated electricity, including investment costs, financing costs, annual O&M costs, and annual fuel costs both with and without a carbon tax. With the exception of the carbon tax, the total costs exclude the effects of any policies, such as subsidies or feed-in tariffs, as the likely future implementation of such policies is unknown. For CHP, it is assumed that the heat output is sold at a price equivalent to the cost of producing heat in gas boilers, and these revenues are deducted from the total costs. The whole mix costs per unit of electricity generated are evaluated as an average of technologyspecific costs, weighted according to how much electricity the different technologies generate. The year 2010 is the reference year for this appraisal and all the costs that occur afterwards are accounted for. There is no Business as Usual or Baseline pathway. Thus, the three pathways-Market Rules, Central Co-ordination and Thousand Flowers-need to be compared with respect to each other in terms of their costs after 2010.",
            "Sensitivity analysis": " Fossil fuel prices and financing costs are examined in the sensitivity analysis because these assumptions result in differences between the three pathways (Fig. 2) and are most likely to affect the relative costs of the pathways. Fossil fuel prices are important because the three pathways incorporate different deployment levels of fossil fuel-based electricity generation and replace different numbers of gas boilers and ICE vehicles. Low, central and high price projections for coal, gas and crude oil are taken from DECC (2013) for 2012-2030. For 2030-2050, the price assumptions are kept at the level of 2030, assuming that the range sufficiently reflects the uncertainty. This range between low prices, which assume decreasing oil and gas and stable coal prices, and high prices, which assume growth of all fossil fuel prices, captures implications of various potential outcomes of the worldwide commitment to climate change mitigation. These assumptions are used to vary the prices of coal, gas (for large-scale generation and gas boilers), gasoline and diesel. These projections are summarised in Table 2. Financing costs are affected by governance and policy stability, and can therefore reveal further differences between the pathways. In this appraisal financing costs are considered as the weighted average cost of capital, which accounts for both cost of debt and equity. The cost of debt for power generation technologies in countries like the UK is on average 5-6% (Blyth et al., 2014;Schmidt, 2014) and the cost of equity is on average 10% (Schmidt, 2014). In the central case, all electricity generation technologies are assumed to have financing costs of 7% in line with DECC (2014b). In reality, the cost of capital may vary substantially between different technologies. For example, riskier investments have higher interest rates and thus the costs of debt are higher (Brealey and Myers, 2000;Oxera, 2011;Schmidt, 2014). At the same time, stable policies reduce investment risks and financing costs (Oxera, 2011). In addition to the central case, three other cases are analysed (Table 3). The \"Differentiated for technologies\" case assumes higher financing costs for technologies with higher risks, in line with Oxera (2011). The \"Differentiated for governance narratives\" cases aim to capture the potential implications of governance as described in the governance narratives (Section 2.1). For example, if the Central Co-ordination narrative envisions that the newly established Strategic Energy Authority issues longterm contracts for specific types of generation to reduce investment risks, it is assumed that these types of generation would receive better interest rates and thus the financing costs would be lower. Two \"Differentiated for governance narratives\" cases are analysed: one with intermediate and one with strong implications of policies on the financing costs. All three narratives envision equally strong emphasis and related policies on end-use investments, such resistive heaters, heat pumps, transport and micro-CHPs. Thus, 7% financing costs are assumed to reflect that such investment would have a low to moderate risk level in all three pathways. All three governance narratives also consider transmission, distribution and storage as planned investment. As this investment faces low risk, a rate of 5% is assumed in line with National Grid (2013a). Multiple other uncertainties may influence the electricity system transition and its costs (Hughes et al., 2013;Usher and Strachan, 2013). First, other existing analyses explore sensitivity of their results to economic growth and emission mitigation efforts  (Ernst & Young, 2009;LSE, 2012;National Grid, 2013b;Ofgem, 2009Ofgem, , 2010)), deployment levels of specific technologies and security of supply requirements (Ernst & Young, 2009). This cost appraisal cannot address these sensitivities, because electricity demand structure and generation portfolio are fixed through 'translation' of narratives into quantitative assumptions (Fig. 2). Sensitivity analysis of different electricity generation portfolios for the three pathways is already explored in Trutnevyte (2014). Second, sensitivity to different carbon prices is not analysed because it would not reveal further differences among the pathways as all of these pathways reduce their emissions to similar levels (Hammond et al., 2013;Hammond and O'Grady, 2013). Third, costs of electricity generation and end-use technologies could cause greater variations in investment costs and total system costs, but such variations are already to some extent covered by the sensitivity analysis of different financing cost assumptions. For example, if technologies are supported by policies in the narrative, they will receive lower interest rates, which will reduce their costs. Fourth, sensitivity to cost assumptions for non-electric heating and transport is explored by varying fossil fuel costs. As a result, only fossil fuel costs and financing costs are examined in this paper.",
            "Results of the transition pathway cost appraisal": "",
            "Investment costs and total system costs": " Cumulative investment costs and total system costs, evaluated using the present value approach for the three pathways from 2010 to 2020, 2030 and 2050, are summarised in Table 4. In terms of the investment costs, Market Rules requires the lowest investment costs for the system as a whole, whether the cost savings for heating and transport are included or not. Although Market Rules has the highest investment levels in electricity generation, transmission and distribution, it requires lower investment costs in electric heating equipment and electric transport. Thousand Flowers requires the highest investment costs in electricity generation, electric heating and especially in electric transport due to costly EVs. At the same time, it needs less investment in transmission and distribution. Large-scale generation drives the transmission investment costs, while distribution costs are driven by the levels of electric heating and transport deployed. Thousand Flowers has a substantially lower level of electric heating, while electricity from community-and micro-scale CHPs is primarily consumed at a local level. Investment costs for Central Co-ordination fall between those of the Market Rules and Thousand Flowers pathways. Without cost savings in heating and transport, Market Rules again leads to the lowest total system costs, even if it generates more electricity than the other two pathways. If cost savings are accounted for, Market Rules does not have the lowest total costs, because its cost savings due to replaced fossil fuel alternatives in heating and transport are not as high as in other pathways. Market Rules assumes high deployment of cheaper PHEVs rather than EVs (Supplementary Material A). As PHEVs do not lead to such high fossil fuel savings as EVs, cost savings due to replaced fossil fuels in transport are not as high as in other pathways. When cost savings are considered, Central Co-ordination has the lowest cumulative total system costs, even if it does not have the lowest investment costs. Thousand Flowers has the highest total costs. When cost savings in heating and transportation are accounted for, Thousand Flowers and Market Rules perform almost exactly the same, but Market Rules has the highest electricity demand and Thousand Flowers include deployment of expensive small-scale electricity generators and, in particular, costly EVs. In terms of the ratio between investment and total system costs Overall, depending on how the system boundaries are drawnonly generation or covering other parts of the system too-the ranking of the three pathways in terms of costs varies. Market Rules and Central Co-ordination perform fairly similarly across multiple cost indicators, but this is not surprising because they both focus on large-scale generation that is less costly. The pathways are relatively similar in terms of both the investment costs and total system costs, as the differences do not exceed 10%. But such minor differences are common in cost appraisals of highly diversified energy systems. Costs of individual technologies can vary substantially, as shown in the Supplementary Material A. But when total costs of the whole system are evaluated, where multiple technologies-cheaper and more expensive ones-are simultaneously deployed, differences in the total costs of the whole system even out and are not as pronounced as differences in costs of individual technologies.",
            "Generation costs per unit of electricity": " As the three pathways differ in their electricity demand levels, generation costs per unit of electricity, calculated on the basis of levelised costs of electricity, is the most suitable indicator to compare the electricity generation mix costs. Whether the carbon price is considered as a part of the price or not, Central Co-ordination has the lowest costs per MWh of generated electricity in 2050 (Table 5). Yet, the difference to Market Rules is very small. Thousand Flowers has a substantially higher costs per MWh. This is not surprising because it envisions significant deployment of such costly technologies as micro-CHP and community CHP. Yet, in terms of total system costs, such an expensive electricity generation mix is compensated by cost savings due CHPs replacing gas boilers for heating. The overall trend for the generation cost per MWh is to peak at 2030 and then decrease. This is caused by the assumptions of: (i) learning effects that reduce investment costs in low-carbon technologies (investment cost assumptions are reported in Supplementary Material A) and (ii) reduced use of increasingly expensive fossil fuels and reduced greenhouse gas emissions in a low-carbon system. The difference between the costs with or without carbon costs diminishes towards 2050, assuming the transition to a low-carbon system. For additional detail into the cost differences between the pathways, Table B1 in the Supplementary Material B compares the technology-specific costs per MWh of generated electricity with the whole mix generation costs per MWh (including carbon price). Based on the typology of power plants as base load, shoulder load or peak load plants, insights on the economic feasibility are gathered. Electricity generated by unabated fossil fuel power stations (coal ASC, coal IGCC and gas CCGT) that are primarily base load plants becomes very costly after 2030. This is caused by rising fossil fuel and carbon prices and lower capacity factors of these technologies in a low-carbon system with a high of intermittent renewables. Without additional support, such plants would not be competitive for supplying base load and shoulder load electricity demand, as the costs become too high. Coal and gas plants with CCS become less competitive towards 2050 as well due to rising fossil fuel prices and the cost of emitting the assumed 10% of produced CO 2 that is not captured. These results indicate a changing role for such large-scale technologies with fossil fuels in a low-carbon system with intermittent renewables. If policy support, other than carbon price, is not considered, the stylised comparison in Table B1 still shows that some low-carbon technologies would require support to become integrated into the system. In all the three pathways tidal, wave and hydro power as well as biomass plants have comparatively high electricity generation costs for base load and shoulder load plants. Solar power is not competitive until 2030, but later becomes competitive due to technology learning effects. Electricity generated by micro-CHP Stirling engines has very high costs due to high investment costs throughout the whole appraisal timeframe. Even with policy support, substantial deployment of such power plants in the case of Thousand Flowers may be over-ambitious. Table B1 generally raises economic feasibility concerns over the envisioned governance narratives, especially because investment in large-scale power plants that would run with low capacity factors would hardly be realistic. As discussed in Section 2.2, three technical feasibility models that originally informed the development of the quantitative pathways used a predefined, constant merit order instead of modelling electricity generation on the basis of technology costs and detailed dispatch (Trutnevyte et al., 2014). For example, these models prioritised the full integration of intermittent renewable electricity and at the same time assumed substantial deployment of coal and gas CCS, which would need to operate with low load factors. However, economic feasibility of costly CCS plants, used with low load factors, would in reality limit the attractiveness of these plants to investors, unless specific policies are enacted. Such considerations point to the need for simultaneous, rather than sequential, linking of energy-economyenvironment models and governance narratives, as demonstrated by Trutnevyte (2014). 3.3. Sensitivity analysis 3.3.1. Sensitivity to fossil fuel prices Fig. 3 presents the fossil fuel price sensitivity results in terms of cumulative total costs for the electricity sector, including generation, transmission, distribution and interconnectors, and excluding or including electric heating and transport. Overall, the total system costs are not affected substantially, because in the low-carbon energy future that is depicted in the three pathways, the role of fossil fuels diminishes by 2050. Although fossil fuel prices affect the individual costs of electricity generation or cost savings, they do not affect the ranking of the pathways as compared to the central case. If cost savings are not accounted for, Thousand Flowers under all sensitivity cases remains as the most costly pathway. However, higher the fossil fuel prices, the smaller the cost gap between Thousand Flowers and the other two pathways.",
            "Sensitivity to financing costs": " Fig. 3 presents results of the sensitivity analysis to different financing cost assumptions. If different financing costs are assumed for each generation technology, the cumulative total costs increase in 2050 for all three pathways. This is primarily caused by the fact that financing costs were increased for several technology types (see Table 3) as compared to the central case, especially for the comparatively risky low-carbon technologies. Yet, the cumulative total costs increase the most for Market Rules and Central Coordination, which both include numerous large-scale, low-carbon technologies with assumed high financing costs, especially CCS, marine and tidal. If the role of policies, described in the governance narratives (Section 2.2), are 'translated' into lower financing cost assumptions in these pathways, then the total system costs decrease. That is, if policies can reduce investment risks, then the total system costs are reduced too due to lower interest rates that energy companies receive. Of course, this transfers some risk from private firms to the public sector. Even with different financing cost assumptions, the ranking of the three pathways does not change in terms of total costs of electricity sector or total costs of generation, transmission and distribution. If cost savings are accounted for (not reported in Fig. 3), there are still no major differences between the pathways. In the case of cumulative total costs for generation, transmission and distribution in Fig. 3, the largest decline in total costs is seen in the case of Central Co-ordination. Central Co-ordination assumes that the central UK government will implement firm policies to support low-carbon generation, especially by issuing contracts to specific types of generation. Such policies could substantially reduce the investment risks (Oxera, 2011) and hence could reduce the total system costs by 1-2%. If stable policies are implemented in other pathways as well (Fig. 3), then their costs also decrease.",
            "Discussion": "",
            "Comparison of the results with existing cost estimates": " In recent years, increasing concerns over the affordability of the ambitious UK emission mitigation targets (similar to the debate in other G20 economies) has led to numerous cost appraisals (DECC, 2014a;Ernst & Young, 2009;LSE, 2012;National Grid, 2013b;Ofgem, 2009Ofgem, , 2010;;Trutnevyte, 2014). Although with its focus on the role of governance, the cost appraisal performed in this paper is unique, its findings are compared in Table 6 with other aforementioned studies for validation. As every study used different appraisal boundaries and methodologies as well as reported  Cumulative investment costs for electricity generation (Table 6) in the case of Market Rules, Central Co-ordination and Thousand Flowers are comparable, but a little lower than the estimates from existing studies. The values are lower for two reasons. First, when the data on actual retirement time of existing power plants were not available, the retirement rates were used. As a substantial number of UK power plants will have to retire by 2020 (DECC, 2012), there will be a peak in investment levels by then, but the presented appraisal could not capture it due to the non-availability of some of the planned retirement dates. Second, most of the other studies do not state explicitly whether their cost estimates have been discounted, what discount rate and which year's currency have been used. The undiscounted cumulative investment costs of the three pathways are d81-89bn (US$125-138bn) by 2020, d168-188bn (US$260-290bn) by 2030 and d286-352bn (US$442-545bn) by 2050. Assuming that some of the existing estimates have not been discounted, the results of this cost appraisal would fall in the comparable range with other existing estimates. The values of annual investment costs also fall within the ranges, set by the other studies. The upper values of d5-6bn/year (US$8-9bn/year) in all three pathways look ambitious. Historically, the investment after privatisation, between 1997 and 2004, was rather low due to high spare capacity in the system and varied from roughly d3-4bn/year (US$5-6bn/year). In the recent years, due to Renewables Obligations the investment increased to up to d8bn/year (US$12bn/year) in 2011 (DECC, 2012). Ernst & Young (2013) reported that between 2010 and 2013, d29bn (US$45bn/ year) of investment was announced in renewable energy generation. Therefore, such annual investment levels in the three pathways as compared to the historical values may be realistic, if the UK commits to low-carbon transition. The annual and cumulative investment costs in transmission, distribution and interconnectors for the three pathways are in the same range as in other studies. None of the other studies report total system costs with comparable appraisal boundaries, but a technology-by-technology comparison for heating and transport of the total system costs from Table 4 with DECC (2014a) yields similar results for the same end-use technology uptake levels.",
            "Limitations and future research needs": " This analysis provides a novel attempt to gather insights into the role of governance in shaping the UK electricity system transition and its costs. The analysis will be extended in the future to provide a more comprehensive understanding of links between governance and the whole energy system costs. The first aim will be to extend the system boundaries (Section 2.3.1). The current transition pathways would benefit from additional detail on electricity use efficiency improvements through behavioural and technical measures. If such data were available, then investment and total costs of efficiency and demand reduction, and the value of lost load, could be evaluated. The current version of the appraisal also includes only the costs of heat producing equipment, such as CHPs, heat pumps, resistive heating or gas boilers, but does not account for any auxiliary equipment, such as heat storage, installation of heating systems, etc. The total costs are evaluated accounting for cost savings in non-electric types of heating and transport. This is a relatively simplistic accounting that does not require a more detail modelling of the whole heat supply portfolio and the whole vehicle mix. In order to undertake a more systematic analysis, an extension of the system boundaries to include heating and transport could be conducted by energy system models, such as UK MARKAL (Dodds et al., 2014;Ekins et al., 2011) and UKTM (UCL Energy Institute, 2014). These models are purely market-based models that do not consider governance narratives, but they can provide additional insights by disaggregating the vehicle fleet (Dodds and Ekins, 2014;Dodds and McDowall, 2014) and the housing stock (Dodds, 2014). In addition, interactions between the low-carbon transition in the electricity sector and the rest of the energy system as well as the associated costs could then be captured. In terms of the cost appraisal boundaries, the presented appraisal focuses only on annual system costs and levelised costs of electricity, but does not evaluate electricity companies' revenues, investment attractiveness, short-run or long-run marginal prices, consumer prices, and cost savings. When the pathways are further fleshed out with more detail on hour-by-hour dispatch or by adding a baseline pathway, such an extension of the appraisal would become feasible. The presented appraisal also focuses only on monetary costs and does not analyse either externalities (costs to the environment, society at large etc.) or benefits. These pathways would have different impacts on the environment, key stakeholders and wider society. While some of these impacts can be monetised (e.g. wider macroeconomic impacts), the cost appraisal is only one assessment pillar and a broader interdisciplinary appraisal needs to be conducted (Stagl, 2006(Stagl, , 2007)). Moreover, as the three pathways differ in their governance arrangements (organisation structure, number and role of the key actors etc.), it is very likely that these pathways would have different transaction costs and would affect the key system actors differently. A detailed assessment of the costs and cost savings borne by different actors may reveal that some market participants are significantly disadvantage or require guarantees and even cross-subsidies. Thus, the cost appraisal should be disaggregated in the future to reflect on the implications and attractiveness of the pathways to the various actors. The current version of the appraisal is based deterministic values of technology costs, fuel prices and other assumptions, but does not model other types of parametric uncertainty than fossil fuel prices or financing costs. As future technological improvements, technology costs and wider international developments, such emission mitigation commitments, may have a substantial impact on the appraisal results, a systematic uncertainty analysis should be conducted. Such systematic uncertainty analysis could adopt the story-and-simulation approach in order to capture interactions among multiple parametric assumptions (Alcamo, 2008;Schweizer and Kriegler, 2012). Stories, that are internally consistent combinations of parametric assumptions, would then be developed and used for sensitivity analysis. Such stories would help capturing how increased carbon price is coupled to faster technology improvements of low-carbon technologies or how changes in fossil fuel prices affect global inflation rates, raw material costs and eventually the investment costs of the electricity technologies. Yet, the sensitivity analysis in Section 3.3 shows that the appraisal results do not vary substantially because of the fixed quantitative pathways and the generally diverse technology portfolios. In fact, these fixed pathways do not allow for addressing uncertainties in technology deployment levels due to co-evolution of governance and the electricity system. A more systematic modelling attempt that links governance narratives directly to an energy-economy-environment model, by-passing the translation of each governance narrative into a single quantitative pathway, should be undertaken. However, the majority of existing models still acknowledge costs as the key (and often-the only) transition driver and thus do not leave enough space for accounting for the role of governance and decisions of the key actors, beyond costs. For example, optimisation-based energy-economy-environment models, such as UK MARKAL or UKTM (UCL Energy Institute, 2014), are limited to the analysis of cost-optimal pathways only. Thus, these models can hardly capture non-cost drivers and softer governance implications that underpin energy transition. Although various policies or actor preferences can be enforced in these models as constraints or tailored parametric assumptions, the energy system is still assumed to respond in the cost-optimal way. This glosses over the uncertainty that system response may not only depend on costs, but also on other drivers and softer governance as multi-level transitions theory argues. The EXPANSE model (Trutnevyte, 2013;Trutnevyte, 2014;Trutnevyte and Strachan, 2013), which captures near-optimal energy pathways in addition to the cost-optimal one, is especially suitable for an integrated analysis of governance and costs. Trutnevyte (2014) proved the concept of translating the three narratives Market Rules, Central Co-ordination and Thousand Flowers into a thousand of diverse quantitative pathways each in order to account for uncertainties in technology deployment. This approach now needs to be refined and completed.",
            "Conclusions and policy implications": " The conventional economic view identifies costs as the key determinant of energy transition. The multi-level perspective to socio-technical transitions advocates an alternative viewpoint that places governance and the choices of key actors as the crucial influences. Such distinct analytical perspectives give inflexible insights to policy makers, with findings dependent on either a cost optimising world-view or an actor-decision world-view. This paper has combined the two approaches in a novel analysis of UK electricity system transition and its costs under alternate governance logics. The analysis shows that market-led transition, as described in the Market Rules narrative, follows the most investable pathway and has the lowest investment costs. Given policies, such as carbon price floor, market could deliver the UK electricity system transition that meets the 'trilemma' of low-carbon, affordable and secure system, but the benefit of low investment comes at the expense of certainty of successfully addressing the 'trilemma'. If government would take a more active role in steering the transition by, for example, issuing contracts for specific low-carbon electricity technologies, as described in the Central Co-ordination narrative, this would increase the likelihood of achieving lowcarbon and secure system. In addition, if such governmental control elements can be enacted and maintained, they could lead to a synergy between achieving these policy goals and simultaneously reducing total system costs. However, this would require higher investment levels and some of the investment risk would need to be faced by the government. The society-led transition, envisioned in the Thousand Flowers narrative about bottom-up, proactive engagement of the civil society, would come at the expense of higher investment and total system costs, but would ensure wider participation of the society at large. Although the investment challenge would be higher than in the market-led and government-led pathways, this society-led pathway would spread this challenge across a wider range of investors, including households. Policy makers, tasked with understanding and governing electricity system transition, shall acknowledge such synergies and trade-offs between governance and costs, because some of these trade-offs need to be made. First, if delivery of the investment is left to the market mechanisms, the investment levels may be comparatively low to prevent the failure of achieving the 'trilemma' of low-carbon, affordable and secure system. If stricter governmental policies would be enacted to mobilise higher investment levels, then achievement of energy policy goals would be more likely and the total system costs in the long term could be simultaneously reduced. Yet, the investment needs would be higher than in the case of free market and this challenge would need to be addressed by the government. The ease of this challenge by spreading the investment across a wider range of actors, including ESCO companies and end-use consumers (e.g. households), would come at the expense of higher investment and total costs, but would bring the benefits of higher societal engagement and awareness of energy challenges. Such synergies and trade-offs between governance and costs reach beyond the electricity generation, transmission and distribution to the sectors of heating and transport too. In fact, the identified trade-offs and synergies are dealt with across multiple governmental departments for energy, environment, business, transport, communities and others, who have different mandates. Thus, cross-departmental discussion and decision making is necessary."
        }
    },
    "10.1016/j.enpol.2014.06.017": {
        "file_name": "78 Can a low-carbon-energy transition be sustained in post-Fukushima Japan",
        "title": "Can a low-carbon-energy transition be sustained in post-Fukushima Japan? Assessing the varying impacts of exogenous shocks $",
        "abstract": "In the aftermath of the Fukushima nuclear crisis, Japan began contemplating energy policy reforms that drew inspiration from low-carbon research. This article focuses on a question central to advancing low-carbon research in Japan and elsewhere: namely, how does an exogenous shock affect the onset, magnitude, and permanence of changes in electricity consumption? The article employs intervention analysis with an autoregressive moving average (ARMA) model to answer this question. The data analysis reveals that post-Fukushima electricity use underwent a sudden, significant, and sustained reduction across Japan. The shock not only affected the Tokyo Electric Power Company (TEPCO) coverage area but the more distant Kansai Electric Power Company (KEPCO) coverage area. Large electricity users responded with an immediate and significant reduction in electricity consumption that rebounded to below pre-crisis levels; households responded more gradually with no rebound. Two of the more interesting results from the data analysis \u2013 the persistence in reductions in the more distant KEPCO coverage area and the rebound among large users \u2013 are then explained with a review of survey data and policy trends. Overall the quantitative and qualitative evidence suggests that an exogenous shock may give rise to a reduction in electricity consumption but cannot sustain a low-carbon transition.",
        "label": "Mixed",
        "text": {
            "Introduction": " In the aftermath of the Fukushima nuclear crisis, experts from Japan's Ministry of Economy Trade and Industry (METI) and the Ministry of the Environment (MoE) came together in a pioneering effort to draft an innovative energy and environment strategy. The strategy would combine planned cutbacks in nuclear power with a slate of energy savings initiatives, renewable energy targets, and liberalising reforms to regional electricity monopolies (CAO, 2012a(CAO, , 2012b)). Many of the more forward-looking provisions in the new strategy drew upon the same low-carbon models that informed Japan's mid-term greenhouse gas (GHG) emissions target in the lead up to the 15th Conference of the Parties (COP 15) to the United Nations Framework Convention on Climate Change (UNFCCC) in 2009. 3 Yet the degree to which the strategy's key provisions would induce and sustain changes would depend upon their performance not during the relative calm preceding COP 15 but after a potentially transformative crisis. The impacts of Japan's low-carbon research would hence hinge upon an exogenous shock. This article seeks to answer a question advancing lowcarbon research in Japan and elsewhere: namely, how does an exogenous shock affect the onset, magnitude, and permanence of changes in key energy-related metrics such as electricity consumption? The article employs intervention analysis with an autoregressive moving average (ARMA) model to answer this question. ARMA models can filter temporal and seasonal patterns from time-series data, thereby isolating the effects of shocks. The data analysis reveals that post-Fukushima electricity use underwent a sudden, significant, and sustained reduction across Japan. The shock not only affected the Tokyo Electric Power Company (TEPCO) coverage area but the more distant Kansai Electric Power Company (KEPCO) coverage area. Large energy users responded with an immediate and significant reduction in electricity consumption that rebounded to below pre-crisis levels; households responded more gradually with no rebound. A review of survey data and policy trends helps illuminate the channels through which the two more interesting results from the data analysis emerged. In the KEPCO area, an outpouring of nationwide antinuclear sentiment prompted decisions to extend temporary plant closures and prolong voluntary reduction quotas to fill regional supply shortfalls. Among large electricity users, many industries retained low-cost electricity savings measures but post-crisis activity levels and electricity consumption returned as supply chain disruptions eased. Overall the quantitative and qualitative evidence suggests that an exogenous shock like the Fukushima disaster may give rise to a reduction in electricity consumption but cannot sustain a low-carbon transition. Sustaining that transition may require governance reforms that can keep open and expand post-shock windows of opportunity. The article is divided into five sections. First, the article reviews literature on the drivers of low-carbon transitions to arrive at hypotheses on the effects of post-shock electricity use. Second, the article provides a review of the varying energy policy reforms after Fukushima to put those hypotheses in context. Third, the article draws upon ARMA models with intervention analysis to estimate the onset, magnitude, and permanence of the effect of the Fukushima shock on Japan's electricity consumption across regions, user groups, and time. Fourth, the article draws upon survey data and a review of recent policy reforms to shed light on the reasons behind the more interesting results from the data analysis. Fifth, the paper discusses those results and presents conclusions.",
            "Low-carbon transitions and exogenous shocks": " In the early 2000s, the realisation that \"warming of the climate system is unequivocal\" and \"very likely due to\u2026increase[s] in anthropogenic greenhouse gas concentrations\" brought public attention to a growing body of low-carbon research (IPCC, 2007). This research addressed two fundamental questions (Skea and Nishioka, 2008;Strachan et al., 2008aStrachan et al., , 2008b;;NIES, 2008aNIES, , 2008b;;Hughes et al., 2013): first, what visions (scenarios) could lead to a low-carbon future? Second, what policy and technical options were consistent with those visions? These dual concerns were central to work that the National Institute for Environmental Studies (NIES, 2008a(NIES, , 2008b) ) conducted to demonstrate the technical and economic feasibility of a 70% CO 2 emission reduction below 1990 levels by 2050 in Japan. The NIES studies were based on two scenariosa technology-driven and nature-oriented scenariothat involved options that changed activity levels, reduced service demand, improved energy intensity, or improved carbon intensity. The NIES research further illustrated that while about 17-33% of the 2050 reductions could be achieved with shifts to low-carbon energy sources or installations of carbon capture technologies on the supply-side, about 83-67% of the reductions would come from changes to the industrial, residential/commercial and transportation sectors on the demand-side (NIES, 2008a(NIES, , 2008b)). But while this research yielded revealing insights into the longterm feasibility of a low-carbon future, the short-term difficulties of a low-carbon transition were not explored with comparable analytical rigour. These difficulties warranted attention because moving onto low-carbon development paths often involved overcoming inertia in technological systems that favoured less efficient technologies and production processes (Unruh, 2000). Yet another set of difficulties stemmed from well-established political-economic interests that stood to lose from introducing new technologies and production processes. A related set of challenges emanated from existing political-economic institutions that could privilege well-established over emerging interests (Hourcade and Crassous, 2008). The combination of these technological and institutional forces could create \"techno-institutional lock-in, a persistent state that creates systemic market and policy barriers to technological alternatives\" (Konnola et al., 2006, 239). In contrast to the predictions of much of the low-carbon modelling research, the combined resistance of existing technologies and institutions could undermine a low-carbon transition. Rather than selecting low-carbon development paths, the techno-institutional lock-in often meant policymakers favoured staying the course (Konnola et al., 2006;Carrillo, 2004). Although there is a tendency to maintain the status quo, there is also a possibility of breaking lock-ins. Two sets of forces could help in this regard: social movements could agitate for policy change, or exogenous shocks could fundamentally alter technological and policy choices. The former possibilitya social movementunderlines that emerging interests can increase public awareness as well as persuade policymakers and businesses of the merits of a low-carbon policy (Kemp et al., 2007). Such a movement could gather momentum as a critical mass of people adapt to a new technological system (Witt, 1992;Safarzynska and van den Bergh, 2010;Geels and Schot, 2007). The latter possibilityan exogenous shockhighlights the potential of unanticipated triggering events or environmental jolts from outside of the techno-institutional complex to break down interests and institutions preventing reforms within the system (Cowan and Hult\u00e9n, 1996;March and Olsen, 1989;Hughes, 1987;Biggs et al., 2011;Biggs et al., 2009;Sine and Robert, 2003;Kinzig et al., 2006). To be sure, both the social movement and exogenous shock explanations were not mutually exclusive. The two could complement each other; mounting public concerns could extend the reach or deepen a shock's impacts. This possibility suggests that whether an exogenous shock enables and then sustains a low-carbon transition can hinge on several conditioning factors. Three possible channels through which those impacts are transmitted can help to illuminate those factors. First, the macroeconomy channel involves the immediate effect of a shock on infrastructure that can reverberate throughout the economy by, for example, disrupting supply chains, changing production levels, and altering energy use patterns (see the grey curved arrow in Fig. 1). Second, the public awareness channel involves the immediate effect on public perceptions that can also ripple through the economy by, for instance, inducing lifestyle changes, modifying consumption decisions, and altering energy use patterns (see the striped curved arrow in Fig. 1). Third, the policy channel involves policy reforms that target direct responses (footnote continued) experts from institutions with energy modelling expertise and a Vice Ministerial level review team. from energy suppliers and electricity users to specific reforms (see the black arrows in Fig. 1). The macroeconomy, public awareness and policy channels again may be complementary because policy reforms could target increases in public awareness that could affect consumption decisions. Moreover, the ultimate effects would depend on whether and to what extent suppliers and users select from the options in the categorisation scheme in the NIES modelling (see boxes at the bottom of Fig. 1). While the shift to low-carbon fuels or carbon capture technologies on the supply side are important to that modelling (and indeed reductions in CO 2 ), the following hypotheses and data analysis focuses chiefly on the demand-side, referring to the supply-side as appropriate.",
            "Hypothesis 1: regional variation": " The effects of a shock on the demand-side could vary across regions. A relatively straightforward reason is the proximity to the shock. Controlling for other conditioning factors, one would anticipate that the closer to the shock, the sooner, greater, and more sustainable its effects on electricity consumption. To illustrate with an example, once heavily polluted Japanese cities such as Kawasaki now manufacture the country's most advanced pollution abatement equipment in part because of the city's greater exposure and response to pollution. Moreover, proximity may be measured not only in physical distance but also through the conditioning factors and transmission channels in Fig. 1. Japan's energy-saving reforms in the post-oil shock of the 1970s were introduced sooner (Sugiyama et al., 2010;Sugiyama and Kajiki, 2010) and had a more significant and longer lasting effect than other countries for reasons related to relatively greater energy security risks. Though this hypothesis is rather straightforward, it raises a related question regarding to what extent a shock's impacts will be felt beyond directly impacted areas. Expanding the reach of a shock is likely to depend on the underlying characteristics of those areas; conditioning factors such as public awareness may be important in expanding this reach.",
            "Hypothesis 2: user group variation": " Another set of reasons for a shock's varying impacts involves differences across user groups. The logic behind this variation is less straightforward. A reasonable inference is that a few large consolidated industrial users may reduce energy consumption more quickly, significantly, and sustainably than numerous and dispersed households. This is partially because it is easier to reduce energy demand at a higher level of aggregation; less effort is required to introduce technologies and enforce electricity savings measures for an entire factory than a neighbourhood. It is also because when large users invest in energy-saving technologies, they can register steeper and longer lasting changes than households. By the same token, household users might have less to gain and thereby weaker incentives to undertake reforms. However, as with the first hypothesis, there is also a set of additional conditioning factors that warrant consideration. Large energy users may be able to exert greater pressure on policymakers to scale back post-shock policies than households; they may also have greater incentives to resist the costs of the investing in energy savings technologies and may have more clout to register resistance than comparatively diffuse households. This could be potentially important if large users temporarily adjust activity levels but do not invest in more permanent energy savings technologies after a shock.",
            "Post-Fukushima: the first wave of reforms": " Prior to testing these hypotheses, it is important to summarise some of the policy reforms that followed the Fukushima nuclear accident. Indeed, the March 11, 2011 triple disaster was a potentially transformative event. Prior to March 11, 2011, the Fukushima nuclear power complex was one of the cornerstones of the Tokyo Electric Power Company (TEPCO) service area, covering the densely populated Kanto area (see Fig. 2 for a map of service areas). However, the March 2011 emergency shutdown or damage of not only nuclear but also thermal and other electricity-generating facilities resulted in a decrease of the overall supply capacity to approximately 31,000 MW (from 52,000 MW) at TEPCO (Hayashi and Hughes, 2013). More than two-thirds of the loss of total electricity capacity in Japan (21,000 MW) of capacity was lost in the TEPCO coverage area. Shortly after the crisis and by the end of April 2011, about 9000 MW were recovered with thermal power and emergency standby power resources that were brought in to help fill a capacity shortfall. However, around the same juncture policymakers realised either a sizeable boost in capacity or reduction in demand would be needed to meet peak demand in the July-September summer months. During the summer of 2010, the maximum peak demand for electricity reached 60,000 MW (20,500 MW in large electricity users, 21,500 MW in small electricity users, 18,000 MW in household). As the summer of 2011 approached, the available power supply was expected to be only 53,800 MW. Hence, if the maximum peak demand hit 2010 levels, electricity users in TEPCO risked a sizeable shortfall (METI, 2010). Recognising this risk and experiencing the impacts of the rolling blackouts immediately after the Fukushima accident, the Japanese government focused on reducing demand. Toward that end, the Japanese government encouraged public and private organisations to set up an energy-saving business plan that incorporated a suite of electricity-saving measures. The most significant of these measures were mandatory energy reductions for large electricity users that were enforced under Article 27 of the Electricity Business Act from July 1 to September 27, 2011. Within the Tokyo and Tohoku electric power company coverage areas, 15% reduction targets (off of 2010 use levels) were adopted during peak electricity demand hours (from 9:00 until 20:00 on weekdays). In the Kansai electric power company coverage area, a voluntary 10% reduction was promulgated. At the same time, small electricity users (less than 500 kW) and households were encouraged to work toward a voluntary energy reduction target of 15%, paralleling the reductions set for large users in the Kanto area where electricity is mainly supplied by TEPCO. To help reach this target, the government recommended several electricity-saving measures (such as limiting lighting, maintaining an air-conditioning temperature equal to or below 28 1C, and switching off automated office equipment). The government also embarked on an awareness-raising campaign that consisted of publishing electricity use data and presenting user-friendly visualisations of these data on the internet. These efforts were complemented by an alarm system that warned when electricity demand may outpace supply. As a result of these efforts, TEPCO achieved an 18% (10,770 MW) reduction compared to the amount of energy consumed in the summer peak demand of 2010 (METI, 2011a). The data in Table 1 also list the other changes in electricity consumption patterns in three different regional electricity companies (Tokyo, Tohoku, and Kansai) between 2010 and 2011. Although these largely demand-side emergency measures were temporary responses to the shortage of electricity supply, these actions were part of a broader effort to rein in demand. Initially, the overall impacts of the electricity crisis took centre stage at a review of the Basic Energy Plan (BEP) in May 2011; more detailed assessments of specific emergency measures figured even more prominently in an Energy and Environment Conference (Cabinet decision held on October 21, 2011) that concentrated on short-and medium-term innovative energy and climate change strategies up to 2030. At the same time, a discussion on feed-in tariffs (FIT) eventually led to their enactment in July 2012. It is also worth emphasising that the emergency actions on the demand side were not made permanent across Japan. For instance, the reduction targets in the TEPCO service area in 2011 did not remain in place in 2012, whereas the voluntary reduction target for the 2012 summer peak demand in KEPCO did remain in place. 4 The achievement of this voluntary target was again expected to be implemented on the demand-side. As illustrated in Table 2, the nature of the reforms differed across user groups within regions and over time. Table 2 provides a useful qualitative backdrop for the quantitative analysis. The quantitative analysis focuses on testing the hypotheses in Box 1.",
            "Methodology": " To test the hypotheses in Box 1, monthly electricity-use data were gathered from the Agency for Natural Resources and Energy (ANRE) 5 for the months from January 2008 to December 2012. The electricity-use data were further subdivided by (1) the Kanto and Kansai areas 6 and (2) large users and households. 7 Monthly Fig. 2. The ten electric power companies by service area in Japan. Source: Electricity Review Japan, \u00a9 The Federation of Electric Power Companies, Japan. 4 Originally, a 15% voluntary reduction target compared to the amount of energy consumed in 2010 was set for the peak demand in the summer of 2012. However, after the Oi Daisan nuclear plant was reactivated, caveat provisions were introduced that allowed for a switch from a 10% target to a 5% reduction target if the reductions disrupted industrial production. 5 Data are available at the following link: http://www.enecho.meti.go.jp/info/ statistics/denryoku/result-2.htm (accessed in April 2014). 6 This paper identifies all energy users in Kanto area as users within the TEPCO coverage area and all energy consumes in Kansai area as users within the KEPCO coverage area because they are one of ten general electric utilities (including Okinawa) that dominate the electricity market, providing approximately 90% of Japan's electricity. The actual electricity use statistical data extracted from ANRE include electricity generated from wholesale trade electric enterprise, special electric utilities, and power producers, as well as general electric utilities. 7 Large users constitute companies with a contract for more than 500 kW of electricity, whereas household users cover electricity users who contract less than 50 kW of electricity (for the analysis in the paper including the contract of metre rate lighting of the A, B, and C categories). Therefore, household data may include information not only about households but also small shops that contract less than 50 kW of electricity. temperature data were also collected from the Japan Meteorological Agency8 for Tokyo (to represent the Kanto region) and Osaka (to represent the Kansai region). Two possible methods exist for analysing short-term electricity demand: microeconomic and econometric models. A microeconomic model subdivides energy use by different applications, builds a demand model for each application, and compiles the prediction results. Although the microeconomic model has the advantage of capturing the structure of electricity demand, it does not analyse the relationships between regular patterns in the data and external factors affecting overall demand in the short-term; these consideration are effectively left as a black box. A microeconomic model is therefore not suitable for analysing the drivers of short-term changes of electricity use. The paper instead draws upon econometric analysis.",
            "Model identification": " Standard econometric models, such as linear regression estimated with ordinary least squares (OLS), are rarely appropriate for time-series analysis because time-series observations violate the independent errors assumption. This assumption is broken because the electricity used from one month shapes electricity used the following month; it is also violated due to parallels between energy used during seasons in one year and the next. A more appropriate method involves using Autoregressive Moving Average (ARMA) models to conduct intervention analyses. An ARMA model can filter both seasonal and local temporal effects. When combined with intervention analysis, the model can assess the onset, magnitude, and permanence of an isolated effectsuch as a natural disaster, the emergence of innovative new products, or significant policy reformsbeyond recurring temporal patterns in the data. ",
            "Box 1-Hypotheses": " H1: Areas closer to a shock will respond more quickly, significantly and sustainably than more distant areas. H2: Large energy users will respond more quickly, significantly and sustainably than residential users. To specify the ARMA model, the first step is determining the order of the autoregressive (AR) and moving average (MA) components. The order of the model indicates the number of previous values and errors that should be used to predict present values. This is done by using the autocorrelation function (ACF) and partial autocorrelation function (PACF) to determine which correlations are statistically significant and thus the right ordering for the AR component (which calls for lags of the dependent variable) and the MA terms (which call for lags of the error term) in the model. A similar approach is also used to determine the seasonal components of the ARMA model. The article follows the patterns described by Chramcov and Bal\u00e1t\u011b (2008) to uncover the ARMA process that best characterises the data. When multiple models seem plausible, the models can be compared by considering the Akaike Information Criterion (AIC). Once a possible order of the ARMA model is selected, the ARMA parameters can be verified with diagnostics, including examining the significance of the coefficient estimates for the AR and MA terms, the ACF of the residuals (for a good model, all autocorrelation terms for the residual series should be insignificant), and Ljung-Box tests for the joint significance of residual autocorrelation across several lags. After fitting an appropriate ARMA model, the next step is intervention analysis (Box and Tiao, 1975). Because the ARMA specification can filter out local and seasonal temporal dependencies, it is then possible to assess whether and to what extent the intervention (in this case the Fukushima crisis and accompanying policy reforms) affects the dependent variable: levels of energy consumption. In this article, the specific functions estimated are of the form: y t \u00bc x 0 t \u03b2 \u00fe \u03c9 0 1 \u00c0\u03b4 1 B I t \u00fe 1 \u00fe \u03b8 1 B 1 \u00c0 \u03d5 1 B 1 1 \u00c0\u03d5 12 B 12 a t\u00f01\u00de Here, the vector x t is a vector of monthly covariates, including a constant, the average temperature, and the squared temperature. \u03b2 is a vector of regression coefficients. B is the backshift operator such that By t \u00bc y t \u00c0 1 . a t is a filtered, latent white noise error term. Based upon the aforementioned approach, in Eq. ( 1) the article specifies an error model of ARMA(1,1)(1,0) 12 . This error model fits all of the electricity consumption series in the study. This notation means that the model relies on a local ARMA(1,1) process, such that there is a first-order autoregressive or AR term and a first-order moving average or MA term. In the equation, \u03b8 1 is the coefficient for the moving average process, and this term captures the effect of the previous error (a t\u00c0 1 ). Meanwhile, \u03d5 1 is the coefficient for the autoregressive term, which captures the effect of the previous level of energy use (y t \u00c0 1 ). Additionally, this notation means that the model has a seasonal autoregressive process, so \u03d5 12 is the seasonal autoregressive coefficient capturing the fact that a current month's energy consumption is similar to consumption twelve months prior in the same month the previous year (y t \u00c0 12 ). In Eq. ( 1), the intervention I is the month of March 2011, when the Fukushima nuclear crisis occurred. This intervention has one initial main effect (\u03c9 0 ) beginning the month of the disaster and a decay term (\u03b4 1 ), which reflects either how long an effect persists for transient interventions or how much an effect accumulates for permanent interventions. As will be described later, in some cases the decay term is assumed to be 0 and the input is a step, or permanent, effect. In other cases, the effect is transient and the decay term captures the lingering effect. Finally, one model has both step and pulse effects, or compound permanent and transient effects. In the analysis, five types of interventions are considered: step, pulse, build-up, decay, and compound effects. The interventions are described as \u03c9 0 I t for a step (I t \u00bc 1 when tZT and I t \u00bc0 when toT); \u03c9 0 P t for a pulse (with P t \u00bc 1 when t\u00bcT and P t \u00bc0 otherwise); (\u03c9 0 /(1 \u00c0\u03b4 0 B))I t for a build-up; and (\u03c9 0 /(1 \u00c0 \u03b4 0 B))P t for a decaying effect with an immediate change that eventually returns back to the previous level. A compound effect includes both the step effect, \u03c9 0 I t , and a decaying effect, (\u03c9 0 /(1\u00c0 \u03b4 0 B))P t . Once the ARMA model is specified, the models consistent with each of these descriptions are fitted and the substance and significance of the coefficients, as well as the overall fit, are examined. This process involves a sequence of three checks. First, a pulse is examined by estimating a transfer function with a dummy intervention that is coded 1 only for March 2011. The significance of the coefficient on the pulse dummy is examined, as well as whether the coefficient on the decay term is nearly equal to one. A decay term coefficient near one suggests that there is persistence in the impact of the shock and it is best to try a step dummy. If the coefficient of the step is significant, the build-up function is also tested to examine whether there is a gradual or immediate change in energy consumption. If the coefficient on the build-up is significantly different from zero, the step with a build-up is selected. If not, a simple step function with a sustained effect is fit to the data. Finally, in cases in which the effect appears to be transient but does not decay all the way back to the original level, it is possible to estimate a compound model with both a pulse intervention that decays and a step intervention.",
            "Comparing impacts": " Three datasets are analysed to compare post-Fukushima impacts. The first looks at the total electricity consumption data across pre-and post-Fukushima Japan. The second looks at the differences between TEPCO and KEPCO coverage areas pre-and post-Fukushima. The third looks at differences between large and household electricity users pre-and post-Fukushima. To facilitate the analysis, the electricity-use variable is converted to a natural logarithm scale. To control for the influence of weather changes (above and beyond seasonal impacts from the ARMA process), controls for temperature are included in all of the models. Based on the process described above, the paper finds for this and the other analysed time series that an ARMA(1,1)(1,0) 12 model best fits the time series for total final electricity energy consumption across Japan. Table 3 also shows that the model of the Fukushima intervention that best fits these data is a step intervention with no build-up. The results of this step intervention model are presented in Table 4. The estimate for the intervention effect is a \u00c0 0.0896 coefficient on logged energy use that is significantly less than zero. This result indicates that energy consumption post-Fukushima was on average 8.6% lower than before the incident, and this lower level of consumption persists beyond the accident, all else equal (Fig. 3).",
            "Patterns by region (TEPCO and KEPCO)": " The same process is also used to model the data covering the TEPCO area (Table 5). Similar to the data for all of Japan, there is a step function with a effect estimate of \u00c0 0.1283 that is significantly less than zero (Table 6). This result indicates that in the Kanto region, energy consumption per month dropped by a sustained 12% on average ceteris paribus (Fig. 4). The coefficient estimates suggest that the impact of the shock in the KEPCO region, though statistically significant, is smaller in absolute terms than in the TEPCO region (Table 7). Specifically, in Kansai, monthly energy consumption in megawatt hours dropped by 4.8% (based on the coefficient of \u00c0 0.0493) on average and all else equal (Table 8). This figure is less substantial than Kanto's 12% drop, as can be seen when contrasting the predicted effects in Fig. 4 (Kanto) and Fig. 5 (Kansai). In other words, the reductions were indeed greater in the Kanto (TEPCO) area that was     geographically closer to the Fukushima disaster than the Kansai areas (KEPCO).",
            "Patterns by user group": " The remaining datasets differentiate between large and household users rather than regions. An ARMA(1,1)(1,0) 12 model again is employed for large users. For large energy users, it is observed that a compound intervention model fits best (Table 9). This model includes both a pulse intervention to capture transient effects and a step intervention to capture permanent effects. Because these two terms are collinear, the individual terms are not statistically significant in the compound model (although they are statistically significant in separate models). Nevertheless, a likelihood ratio test shows that, as a group, the pulse and step terms are significant (\u03c7 2 df \u00bc 3 \u00bc 13.1299, p \u00bc0.0044) (Table 10). Fig. 6 illustrates the functional form of this model: a very large effect takes place immediately and then dissipates, but electricity consumption never fully returns to its original levels. Initially, the expected drop in consumption, holding all else equal, was 8.4% (based on the sum of the coefficients \u00c00.0302 and \u00c0 0.0576 on the logged scale). The long-term drop relative to pre-Fukushima levels, though, is only 3% on average and all else equal (based strictly on the \u00c0 0.0302 coefficient). The final data set consists of energy use at the household level. The same set of previously described procedures again led to the selection of an ARMA(1,1)(1,0) 12 model. Intervention analysis is then used to identify a step function with a gradual build-up (Table 11). In households, the coefficient on the initial effect of logged energy consumption is a drop of \u00c0 0.0279, which means monthly energy consumption in megawatt hours dropped by an expected 2.8% at first, holding all else equal (Table 12). Over time, though, the effect accumulated, leading to a long-term average decrease of 9.5% relative to pre-Fukushima consumption, ceteris paribus. As suggested by the results in Fig. 7, the post-Fukushima shock's impacts are gradual, significant, and sustained. To summarise, the statistically significant 8.6% effect for all of Japan suggests that energy use underwent a significant, sudden, and sustained reduction throughout the country following the    Fukushima accident. Across regions, the magnitude of the shock was both statistically and substantively greater in the TEPCO area (12%) than the KEPCO area (4.8%), though the KEPCO reductions were non-negligible and persisted. Across user groups, for large users an initially estimated 8.4% post-shock reduction gradually dissipated to a 3% reduction. Meanwhile, reduction levels gradually fell for small energy users, initially dropping by 2.8% and ultimately by 9.5%.",
            "Explaining the results": " The quantitative analysis reveals changes in electricity consumption across regions and user groups. Two of the more interesting results from the data analysis are as follows: (1) areas farther from a shock responded by reducing energy consumption significantly, though the impact was still smaller than areas closer to a shock. (2) Large energy users responded more quickly than households, but that change was not sustained. This section draws upon insights from the literature review to sheds light on the reasons behind these two results before commenting on the hypotheses in Section 2.",
            "Cross-regional differences": " The Fukushima accident raised concerns about the safety and cost-effectiveness of nuclear power across Japan. Amidst those concerns, the Japanese national government decided not to restart nuclear plants until the completion of two-phased stress tests in 2011 (required under Japan's revised nuclear safety assessment process). Although the national government intended to resume plant operations following the stress tests, a chain reaction of factors came together to amplify bottom-up resistance from local governments, residents and citizen groups. The first such factor was a public safety agreement that most local government and operators sign to protect the safety of local residents and the surrounding environment. 9 The second was that the governor of Fukui prefecture requested to tentatively put in place safety standards that would lead to a plant restart after the Oi nuclear reactors passed the stress tests. The third was a groundswell of nationwide opposition to plant re-openings in the KEPCO area in response to the governor of Fukui's restart decision for the Oi plant. 10 The ultimate outcome, the decision to delay the restart, conformed to a well-documented pattern of public opinion on nuclear power shaping Japanese energy policy and practice (WEC, 2007;Hayashi and Hughes, 2013). As a result, in the KEPCO area the 5.70 billion kWh of nuclear energy (in August 2010) was halved to 2.55 billion kWh (in August 2011), reaching 0 kWh in March 2012 in the KEPCO area. 11  The carry-over effects of this opposition were also reflected in policy and consumption patterns in the KEPCO area. Most notably, the voluntary reduction target for summer peak demand remained in place in the KEPCO area through 2012 due to concern about electricity shortages; the TEPCO area did not retain even a voluntary target. Perhaps most interestingly, although KEPCO restarted 1 billion kWh of nuclear power generation in July 2012 before the summer, the reduction of the amount of electricity sales was a sizable 10.6% in July 2012 compared to 2011 and 11.1% from July to August with 16.9% reductions in households, 7% in offices and 6.3% in factories. 12 The combination of the shock's effect through public awareness and then policy carried over to reductions in consumption. This, in turn, arguably led to the sustained reductions in consumption in a Kansai area that was not immediately affected by the earthquake, tsunami, and nuclear crisis.",
            "User-group differences": " The second intriguing result was the significant and sudden drop followed by the modest rebound among large-users (see Fig. 6). This pattern was particularly compelling when contrasted to the gradual and more sustained household reductions (see Fig. 7). These differences require several explanations. The first relates to the effect that the electricity shortage immediately following the Fukushima accident had on activity levels in key industries. A review of the evidence suggests that the initially sharp drop was chiefly due to supply shortfalls and disruptions in supply chains that brought down activity levels (Tokui et al., 2012;METI, 2011b). Supporting this assessment are seasonal adjustment of indices of industrial production (IIP) figures showing a 16.9% (from 102.7 in February to 85.8 in March) drop among manufacturers that remained at these lower levels for two months following the accident. 13 Hence, reductions in activity levels were arguably the chief factor behind the sizable reduction in electricity demand among large users; increases in production were also part of the reason that the consumption levels rebounded after supply chains were repaired (the IIP recovered to 98.7 in July). Yet some of the reductions remained even after activity levels rebounded, underlining a second supporting explanation. According to the questionnaire survey on activities of Japanese firms to reduce electricity use in response to the electricity shortage, more than half (53.7%) of the energy savings measure involved private power generation and shifts in work schedules to off-peak demand periods in large factories (Fig. 8) (Kimura et al., 2012). But these measures changed the timing not volume of generation and thus reduced peak demand not total electricity consumption. As such, other measures were likely behind an estimated 21.3% reduction in total power demand from 2010 to 2011 (METI, 2011). Energy-saving implementation reports (known as Eco-First reports)14 that major environmental friendly enterprises submitted to the MOEJ indicate that these other measures were probably reductions in the use of air conditioning, conservation in lighting, and small cutbacks in production volumes. These same Eco-First reports point to electricity consumption reductions by more than 15% and 30-40% reductions in peak demand from July to September 2011 (Fig. 9). A third piece of evidence involves the sustainability of the effects of the measures recorded in the Eco-First reports. Interestingly, the implementation of these measures initially seemed likely to remain in place. Approximately 70% of companies indicated that they planned to continue implementing at least one of the following measures: private power generation, time shifts, and limiting production. However, follow-up surveys conducted one year after the Fukushima disaster by Kimura and Nishio (2013) reveal that enthusiasm waned in the TEPCO area for reasons partially related to the removal of reduction target in the summer 2012; the percentage of companies implementing time shifts and private energy generation dropped from 66% to 23% and 24% to 11% respectively in the TEPCO coverage area, while other areas with power companies that set up a voluntary target, including KEPCO's coverage area, maintained similar levels of implementation. Moreover and perhaps most importantly, the measures carried out during the summer of 2011 focused more on changing consumption patterns and company policies than purchasing energy-efficient equipment and technologies (Fig. 10). The above consideration may be particularly important for the next part of the explanation: the more gradual but potentially more sustainable reductions for households. The gradual pattern suggests that it took more time for awareness raising and information dissemination among households but those messages registered when they reached recipients. For instance, according to a survey conducted by METI (2011) after the summer of 2011, only 5.8% of households in the TEPCO area indicated that the 15% reduction target from 2010 electricity consumption levels during the summer peak was difficult to reach, whereas 81.1% responded they were easy to meet (1200 individuals responded to the survey). In addition, 92.6% indicated that they intend to continue energy-saving activities, and 64.7% noted that a 10% reduction was not hard. At the same time, results from that survey suggest that 86.1% of sampled residential users understood the effectiveness of turning off the lights during the day and reducing lighting during night, and 81.2% implemented the practice (Fig. 11). A related set of incentives were financial in nature. In contrast to the hypotheses, it proved easier to change daily behaviour and reap the savings from electricity consumption for households. Households could readily see savings on monthly electricity bills. Furthermore, in stark contrast to profit-maximizing industries, households did not need to consider the balance between production levels and electricity use. In fact, as shown in Fig. 9, large users did not replace equipment or facilities with more energy efficiency equipment or facilities in response to the Fukushima accident. Although the energy use and survey data suggest a change in behaviour, they also imply more limited shifts to energy-savings technologies.",
            "Reviewing the hypotheses": " The above results also have implications for the hypotheses. For the hypothesis regarding regional differences, there is fairly strong evidence that the area closer to the shock experienced a more significant impact, though the sustainability of that impact may depend on the conditioning factors in the public awareness and policy channels. For the hypothesis regarding user group differences, there is some evidence that savings were more sudden and significant among large users, though perhaps not as sustainable. Moreover, it is difficult to ascertain whether the logic underpinning that hypothesis regarding the economies-of-scale (advantages of aggregation) for large-users held; instead many of the sustained reductions in electricity consumption involved behavioural changes and company policies rather than investments in energy-saving technologies. Though additional research will be needed, large-users seemed more inclined to wade out the postcrisis storm and less likely to invest in technologies that would save electricity than households. Further, the macroeconomic transmission channel appears to have had the most significant effect on electricity use from a disruption and then recovery in supply chains.",
            "Discussion and conclusions": " This article analysed the varying impacts of an exogenous shock on electricity consumption in Japan after the March 2011 nuclear crisis. It found that the impacts of the shock varied across time, space, and user groups. Areas closer to the Fukushima nuclear power plant experienced a more significant impact than those further away. Large users experienced an initially greater effect than households but rebounded to levels only moderately below pre-crisis consumption levels. To a certain extent, the results are consistent with hypotheses, though additional research is needed on whether large consumers can find substantial savings due to economies-of-scale. However, two of the results are more interesting. The first is that the KEPCO area saw its energy consumption levels fall and remain at below crisis levels even after the shock, partially due to the carry-over effects of anti-nuclear sentiment on supply shortfalls. The other intriguing result is the rebound among large electricity users after Fukushima and the sustained reductions among household energy users. A few additional points regarding low-carbon transitions merit additional comment. This article focused chiefly on the challenges of sustaining electricity savings post-Fukushima; it has not discussed increases in CO 2 emissions that could occur if fossil fuel replaced nuclear power. In fact, thermal plants targeted for a longterm phase out were given a new lease on life after 2011 (ten plants were reactivated through April 2013) (METI, 2013a). The thermal power share of total energy generation in Japan increased to 78.9% in 2011 from 59.3% in 2010 (METI, 2013(METI, , 2012)). This jump caused an increase in CO 2 emissions by approximately 15% from 1990 levels and 2% from 2010 levels in the TEPCO coverage area. 15On the other hand, specific measures were not introduced on the supply-side after the Fukushima disaster with the exception of the feed-in-tariff (FIT). Rather, fossil fuels such as oil and gas compensated for the lack of electricity supply in several areas. This resulted in an increase of average emission factors of nine regional electricity companies from 0.000423 t-CO 2 /kWh in 2010 to 0.000538 t-CO 2 /kWh in 2011. 16 The energy conversion sector in 2011 increased to 61,145 kt-CO 2 in direct emissions from 2010, which the total CO 2 emissions in Japan. Therefore, increasing the share of renewable energy will be critical to reducing CO 2 emissions moving forward. Another set of noteworthy considerations involve the recent developments in Japanese energy policy and implications for lowcarbon research. In October 2011, the Japanese Cabinet decided to hold an Energy and Environment Conference. The conference aimed to develop national short-, medium-, and long-term innovative energy and environmental strategies and national-level global warming countermeasures. Much of the discussion focused on nuclear power as well as a first-of-its-kind public opinion poll on post-Fukushima energy policy. Following the Energy and Environment Conference, the government released a draft of an innovative energy and environmental strategy in September 2012. The draft included energy conservation and energy-saving goals for different time periods, new targets for renewable energy, and plans to phase out the construction and expansion of nuclear power plants by the 2030s. To implement these reforms, the government planned to develop a \"green policy outline\" by the end of 2012. The \"green policy outline\" would serve as a roadmap for green energy expansion replete with plans for technology development and dissemination as well as enabling budgetary and regulatory reforms (CAO, 2012c). But before these reforms could be introduced, the incumbent Democratic Party suffered a sizeable defeat at the polls to the Liberal Democratic Party (LDP) in December 2012. The new government initiated another review of the medium-and long-term energy policy as part of the \"Basic Energy Plan.\" The policy consultations led the LDP to reduce the primary dependence on nuclear power \"as much as possible,\" while retaining policies to boost the installation of renewable energy with the FIT. The recent turn of events highlights that, despite the efforts to systematically analyse the technical and economic feasibility of low-carbon options, many of these reforms are contemplated in a  governance context that depends on non-systemic factors. In fact, the search and selection of mitigation options is better characterised as \"satisficing\" than rationally weighing the merits of competing options (Simon, 1956). This may particularly be the case in the aftermath of a significant crisis when policymakers have less time to fully explore the merits of their decisions and may lack the necessary insights to foresee their impacts over time and space. A particularly interesting comparative case study might involve studying the differences between the governance context in post-Fukushima Japan and a non-crisis Germany to determine how an arguably less ad hoc approach influenced the selection and sequencing of energy savings reforms. 17As suggested by the final two comments, an important next step for low-carbon research in post-Fukushima Japan will be developing a sense of how to keep windows of post-crisis opportunity open longer and for broader segments of the energy systems. This would include strengthening the linkages between the Fukushima reforms and the promotion of renewables as well as further energy-conservation to reduce CO 2 emissions across different sectors and regions in Japan. The recent introduction of the FIT and the exploration of basic electricity system reform, approved in the cabinet in November 2013, represent steps in the right direction. In taking these steps, Japan may begin to narrow the gap between low-carbon research and practice."
        }
    }
}